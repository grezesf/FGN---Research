{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing comparison for gaussian activity computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcrescent\u001b[0m  Tue Oct  1 16:37:49 2019\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[1;31m 68'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 6812\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mrichardso21\u001b[0m(\u001b[0;33m151M\u001b[0m) \u001b[1;30msalami\u001b[0m(\u001b[0;33m6651M\u001b[0m)\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[1;31m 67'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 6218\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mrichardso21\u001b[0m(\u001b[0;33m483M\u001b[0m) \u001b[1;30msoumi\u001b[0m(\u001b[0;33m1839M\u001b[0m) \u001b[1;30mnear\u001b[0m(\u001b[0;33m2311M\u001b[0m) \u001b[1;30msoumi\u001b[0m(\u001b[0;33m1573M\u001b[0m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# manualy set cuda device\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "out_features = 64\n",
    "in_features = 28*28\n",
    "ordinal = 0.5\n",
    "covar_type = 'diag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "inputs = nn.Parameter(torch.Tensor(batch_size, in_features), requires_grad=True).to(device)\n",
    "print(inputs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular NN weights (transposed at the start, see order of Tensor(dims))\n",
    "weights = nn.Parameter(torch.Tensor(out_features, in_features), requires_grad=True).to(device)\n",
    "# centers of FGNs\n",
    "centers = nn.Parameter(torch.Tensor(out_features, in_features), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  inverse covariance will actually be used\n",
    "if covar_type == 'sphere':\n",
    "    inv_covar = nn.Parameter(torch.Tensor(out_features,), requires_grad=True).to(device)\n",
    "elif covar_type == 'diag':\n",
    "    inv_covar = nn.Parameter(torch.Tensor(out_features, in_features,), requires_grad=True).to(device)\n",
    "elif covar_type == 'full':\n",
    "    inv_covar = nn.Parameter(torch.Tensor(out_features, in_features, in_features,), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # method 1: Unsqueeze (large RAM memory reqs)\n",
    "# # distance to centers\n",
    "# g = inputs.unsqueeze(1)\n",
    "# print(g.shape)\n",
    "# g = g-centers\n",
    "# print(g.shape)\n",
    "# g = torch.sum(g, dim=2)\n",
    "# print(g.shape)\n",
    "# # g = torch.einsum('zij, ij -> zi', g, inv_covar**2)\n",
    "# # # g = torch.einsum('zij, ij, zij->zi', g, inv_covar**2, g)\n",
    "# # print(g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1cd04d55602c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             (torch.abs(inputs-center)+1e-32)*(inv_covar), ordinal),\n\u001b[1;32m     14\u001b[0m         dim=1) \n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minv_covar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_covars_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # method 2\n",
    "\n",
    "# # create list params [(in_feats,) for each neuron]\n",
    "# centers_list = [nn.Parameter(torch.Tensor(in_features,), requires_grad=True) for _ in range(out_features)]\n",
    "centers_list = [c for c in centers]\n",
    "inv_covars_list = [i for i in inv_covar]\n",
    "\n",
    "# # compute distances\n",
    "# g_list = [torch.sum(inputs-center, dim=1) for center in centers_list]\n",
    "g_list = [\n",
    "    torch.sum( \n",
    "        torch.pow( \n",
    "            (torch.abs(inputs-center)+1e-32)*(inv_covar), ordinal),\n",
    "        dim=1) \n",
    "    for (center,inv_covar) in zip(centers_list, inv_covars_list)\n",
    "]\n",
    "\n",
    "print(g_list[0].shape)\n",
    "g = torch.stack(g_list)\n",
    "print(g.shape)\n",
    "\n",
    "g = torch.t(g)\n",
    "print(g.shape)\n",
    "\n",
    "# # print(g.shape)\n",
    "# # for i,x in enumerate(inputs):\n",
    "# #     g[i] = torch.sum(((x-centers)**2)*inv_covar, dim=1)\n",
    "    \n",
    "# # # g = torch.from_numpy(np.array([torch.sum(((x-centers)**2)*inv_covar, dim=1) for x in inputs]))\n",
    "# # print(g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 50\n",
    "inputs = nn.Parameter(torch.Tensor(batch_size, in_features), requires_grad=True).to(device)\n",
    "# distance to centers\n",
    "g = inputs.unsqueeze(1)\n",
    "g = g-centers\n",
    "g = torch.sum(g, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 50\n",
    "inputs = nn.Parameter(torch.Tensor(batch_size, in_features), requires_grad=True).to(device)\n",
    "# compute distances\n",
    "g_list = [torch.sum(inputs-center, dim=1) for center in centers_list]\n",
    "g = torch.stack(g_list)\n",
    "g = torch.t(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
