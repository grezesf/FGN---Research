{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce12f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of various conv1d models on the SPEECHCOMMANDS dataset\n",
    "# classic / fgn trained from scratch / converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f16bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c81a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb27928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad07c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110be973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b60f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_loader, val_loader, test_loader) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "                                                                          batch_size = 32,\n",
    "                                                                          batchsize_for_val =32,\n",
    "                                                                          num_workers=5, \n",
    "                                                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4570dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to test models\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "    print(f\"Accuracy: {correct}/{len(loader.dataset)} ({100. * correct / len(loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b27576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model classes\n",
    "\n",
    "## classic model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "    \n",
    "# FGN model    \n",
    "class FGN_M5(nn.Module):\n",
    "    \n",
    "    # changes:\n",
    "    # nn.Conv1d -> fgnl.FGN_Conv1d\n",
    "    # added g to conv inputs and outputs\n",
    "    # make sure you pass g through the same pooling steps as x\n",
    "    \n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.fgn_conv1 = fgnl.FGN_Conv1d(in_channels=n_input, out_channels=n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv2 = fgnl.FGN_Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv3 = fgnl.FGN_Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv4 = fgnl.FGN_Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        \n",
    "        #TODO change to self.pool1d_fgn() for each pooling of Gs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, g = self.fgn_conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        g = self.pool1(g)\n",
    "        x, g = self.fgn_conv2(x, g)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        g = self.pool2(g)\n",
    "        x, g = self.fgn_conv3(x ,g)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        g = self.pool3(g)\n",
    "        x, _ = self.fgn_conv4(x, g)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570df71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "\n",
    "classic_model_name= 'sample_classic_model_SPEECHCOMMANDS'\n",
    "fgn_model_name = 'sample_FGN_model_SPEECHCOMMANDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b733ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M5(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_model = M5()\n",
    "classic_model.load_state_dict(torch.load(save_path+classic_model_name+'_state_dict.pth'))\n",
    "classic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d421b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgn_model = FGN_M5()\n",
    "fgn_model.load_state_dict(torch.load(save_path+fgn_model_name+'_state_dict.pth'))\n",
    "fgn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d6c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test models\n",
    "test(classic_model, train_loader)\n",
    "test(classic_model, val_loader)\n",
    "test(classic_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26887222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(fgn_model, train_loader)\n",
    "test(fgn_model, val_loader)\n",
    "test(fgn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579deba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb16bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_model = copy.deepcopy(fgn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b624a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n"
     ]
    }
   ],
   "source": [
    "for classic_model_layer,fgn_model_layer in zip(classic_model.children(), converted_model.children()):\n",
    "\n",
    "    if type(fgn_model_layer)==fgnl.FGN_Conv1d:\n",
    "        print('converting conv layer')\n",
    "        fgnl.convert_layer_conv1D_to_fgn(classic_model_layer,fgn_model_layer)\n",
    "    else:\n",
    "        print('transfering state_dicts')\n",
    "        fgn_model_layer.load_state_dict(classic_model_layer.state_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d5ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the converted model matches classic behavior\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5be4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the original model hasn't changed\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74b9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eefd8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d73f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb71cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target) + lmbda_sigma*fgnl.sigmas_loss(model, covar_type='sphere')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a99b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_retrained_converted_model = copy.deepcopy(converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3856c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda_sigma = 1e-5\n",
    "optimizer = optim.Adam(fast_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# note LR is 10x smaller because the models have already beenm trained for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ee78a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ed0c8763e4412daa5fccda0e862477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 0.610373\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.645607\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.579490\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.535614\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.980923\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.571227\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.767941\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.815552\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.571576\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.602827\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.632937\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 0.765995\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.867665\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.812223\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.519671\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.644513\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 1.016459\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.758924\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.616922\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.744688\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.809868\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.650633\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 0.655302\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 0.527350\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.525699\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.649202\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.582673\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 1.013721\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.682531\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 0.629510\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 0.710424\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.531028\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.668023\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.831677\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.584850\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 1.094284\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.745168\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 0.692196\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.781860\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.589560\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 0.599226\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.464430\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.837069\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 0.781372\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.548547\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 0.736402\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.791159\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.781134\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.699924\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.965269\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.969956\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.619786\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.771404\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 0.835739\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.701133\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.718376\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.787180\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.617099\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.795075\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.570045\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.669137\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.523159\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.685935\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 0.549121\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 1.159282\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.771567\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.585203\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.733228\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.468810\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.567377\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.872447\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.485471\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.717758\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.911785\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.829026\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.874336\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.945941\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.451617\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.674189\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.930345\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.519295\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 0.541832\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.853462\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.597113\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.865024\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.504044\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.634963\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.734965\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.710674\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.371827\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.936317\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.758345\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.716087\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.737042\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.480132\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.821815\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.728222\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 0.657025\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.955996\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.445176\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.392623\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.490813\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.804959\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.655330\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.616723\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.612380\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.701428\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.630391\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.737213\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 0.572857\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.791150\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.410626\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.575939\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.540734\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.719172\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.769911\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.818096\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.818784\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 1.286502\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.618095\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.536215\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 0.573920\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 1.121288\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.663179\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 1.016791\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 0.928374\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.515011\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.783111\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 0.916768\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 0.854636\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.776532\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.616613\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.511481\n",
      "Accuracy: 9394/11005 (85%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 1\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(fast_retrained_converted_model, epoch, log_interval)\n",
    "        test(fast_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4ff4596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76264/84843 (90%)\n",
      "\n",
      "Accuracy: 8654/9981 (87%)\n",
      "\n",
      "Accuracy: 9394/11005 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(fast_retrained_converted_model, train_loader)\n",
    "test(fast_retrained_converted_model, val_loader)\n",
    "test(fast_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d7c6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c75a837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_retrained_converted_model = copy.deepcopy(fast_retrained_converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "381ed0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(long_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf2ad61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d695760768324f1882f4512c24818a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 0.348346\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.479827\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.205879\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.192954\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.545493\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.829692\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.770129\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.469428\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.378918\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.334953\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.640286\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 0.213752\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.513733\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.192990\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.527903\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.269706\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 0.314105\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.370575\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.340445\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.445145\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.404358\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.388254\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 0.514030\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 0.544574\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.166443\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.340933\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.306889\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 0.815570\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.276978\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 0.597218\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 0.231149\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.337916\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.347626\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.719875\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.287949\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 0.245629\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.736402\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 0.337070\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.603886\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.204430\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 0.502498\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.469779\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.237738\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 0.282281\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.749931\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 0.678682\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.405625\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.309463\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.625328\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.546462\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.282819\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.540324\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.233954\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 0.150741\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.167984\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.564149\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.400449\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.274478\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.163836\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.267218\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.300148\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.452167\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.617840\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 0.616058\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 0.343632\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.683959\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.529567\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.128459\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.253474\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.464047\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.414784\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.252193\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.571507\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.317949\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.547632\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.399114\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.176393\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.249283\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.102386\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.434076\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.591404\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 0.385422\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.266737\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.519977\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.456774\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.588005\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.396915\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.423572\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.563984\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.325061\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.559887\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.499580\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.469183\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.520243\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.687332\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.630340\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.300614\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 0.508699\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.356635\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.412054\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.133700\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.383517\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.359311\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.309041\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.422793\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.360316\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.231565\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.457010\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.362996\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 0.134017\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.394775\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.482765\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.301344\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.191269\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.304962\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.336661\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.302521\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.251732\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 0.450761\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.283634\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.708700\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 0.630543\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 0.763057\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.240870\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 0.469542\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 0.248413\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.466175\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.210771\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 0.319454\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 0.328265\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.469476\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.220441\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.135884\n",
      "Accuracy: 9418/11005 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/84843 (0%)]\tLoss: 0.281248\n",
      "Train Epoch: 2 [640/84843 (1%)]\tLoss: 0.383452\n",
      "Train Epoch: 2 [1280/84843 (2%)]\tLoss: 0.439727\n",
      "Train Epoch: 2 [1920/84843 (2%)]\tLoss: 0.697160\n",
      "Train Epoch: 2 [2560/84843 (3%)]\tLoss: 0.474054\n",
      "Train Epoch: 2 [3200/84843 (4%)]\tLoss: 0.456765\n",
      "Train Epoch: 2 [3840/84843 (5%)]\tLoss: 0.179442\n",
      "Train Epoch: 2 [4480/84843 (5%)]\tLoss: 0.415109\n",
      "Train Epoch: 2 [5120/84843 (6%)]\tLoss: 0.210446\n",
      "Train Epoch: 2 [5760/84843 (7%)]\tLoss: 0.461259\n",
      "Train Epoch: 2 [6400/84843 (8%)]\tLoss: 0.751299\n",
      "Train Epoch: 2 [7040/84843 (8%)]\tLoss: 0.343194\n",
      "Train Epoch: 2 [7680/84843 (9%)]\tLoss: 0.705480\n",
      "Train Epoch: 2 [8320/84843 (10%)]\tLoss: 0.489875\n",
      "Train Epoch: 2 [8960/84843 (11%)]\tLoss: 0.229356\n",
      "Train Epoch: 2 [9600/84843 (11%)]\tLoss: 0.369679\n",
      "Train Epoch: 2 [10240/84843 (12%)]\tLoss: 0.664598\n",
      "Train Epoch: 2 [10880/84843 (13%)]\tLoss: 0.272278\n",
      "Train Epoch: 2 [11520/84843 (14%)]\tLoss: 0.761806\n",
      "Train Epoch: 2 [12160/84843 (14%)]\tLoss: 0.155319\n",
      "Train Epoch: 2 [12800/84843 (15%)]\tLoss: 0.358900\n",
      "Train Epoch: 2 [13440/84843 (16%)]\tLoss: 0.183710\n",
      "Train Epoch: 2 [14080/84843 (17%)]\tLoss: 0.496201\n",
      "Train Epoch: 2 [14720/84843 (17%)]\tLoss: 0.503545\n",
      "Train Epoch: 2 [15360/84843 (18%)]\tLoss: 0.370535\n",
      "Train Epoch: 2 [16000/84843 (19%)]\tLoss: 0.174959\n",
      "Train Epoch: 2 [16640/84843 (20%)]\tLoss: 0.461457\n",
      "Train Epoch: 2 [17280/84843 (20%)]\tLoss: 0.524114\n",
      "Train Epoch: 2 [17920/84843 (21%)]\tLoss: 0.398378\n",
      "Train Epoch: 2 [18560/84843 (22%)]\tLoss: 0.418028\n",
      "Train Epoch: 2 [19200/84843 (23%)]\tLoss: 0.436117\n",
      "Train Epoch: 2 [19840/84843 (23%)]\tLoss: 0.298533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [20480/84843 (24%)]\tLoss: 0.245680\n",
      "Train Epoch: 2 [21120/84843 (25%)]\tLoss: 0.268497\n",
      "Train Epoch: 2 [21760/84843 (26%)]\tLoss: 0.419716\n",
      "Train Epoch: 2 [22400/84843 (26%)]\tLoss: 0.427023\n",
      "Train Epoch: 2 [23040/84843 (27%)]\tLoss: 0.222852\n",
      "Train Epoch: 2 [23680/84843 (28%)]\tLoss: 0.261749\n",
      "Train Epoch: 2 [24320/84843 (29%)]\tLoss: 0.630232\n",
      "Train Epoch: 2 [24960/84843 (29%)]\tLoss: 0.479708\n",
      "Train Epoch: 2 [25600/84843 (30%)]\tLoss: 0.398689\n",
      "Train Epoch: 2 [26240/84843 (31%)]\tLoss: 0.305570\n",
      "Train Epoch: 2 [26880/84843 (32%)]\tLoss: 0.439521\n",
      "Train Epoch: 2 [27520/84843 (32%)]\tLoss: 0.604596\n",
      "Train Epoch: 2 [28160/84843 (33%)]\tLoss: 0.356882\n",
      "Train Epoch: 2 [28800/84843 (34%)]\tLoss: 0.687430\n",
      "Train Epoch: 2 [29440/84843 (35%)]\tLoss: 0.341426\n",
      "Train Epoch: 2 [30080/84843 (35%)]\tLoss: 0.622214\n",
      "Train Epoch: 2 [30720/84843 (36%)]\tLoss: 0.596685\n",
      "Train Epoch: 2 [31360/84843 (37%)]\tLoss: 0.595180\n",
      "Train Epoch: 2 [32000/84843 (38%)]\tLoss: 0.644832\n",
      "Train Epoch: 2 [32640/84843 (38%)]\tLoss: 0.360376\n",
      "Train Epoch: 2 [33280/84843 (39%)]\tLoss: 0.359185\n",
      "Train Epoch: 2 [33920/84843 (40%)]\tLoss: 0.455700\n",
      "Train Epoch: 2 [34560/84843 (41%)]\tLoss: 0.442953\n",
      "Train Epoch: 2 [35200/84843 (41%)]\tLoss: 0.110876\n",
      "Train Epoch: 2 [35840/84843 (42%)]\tLoss: 0.779353\n",
      "Train Epoch: 2 [36480/84843 (43%)]\tLoss: 0.741394\n",
      "Train Epoch: 2 [37120/84843 (44%)]\tLoss: 0.266859\n",
      "Train Epoch: 2 [37760/84843 (44%)]\tLoss: 0.152455\n",
      "Train Epoch: 2 [38400/84843 (45%)]\tLoss: 0.237493\n",
      "Train Epoch: 2 [39040/84843 (46%)]\tLoss: 0.461851\n",
      "Train Epoch: 2 [39680/84843 (47%)]\tLoss: 0.486353\n",
      "Train Epoch: 2 [40320/84843 (48%)]\tLoss: 0.650606\n",
      "Train Epoch: 2 [40960/84843 (48%)]\tLoss: 0.084705\n",
      "Train Epoch: 2 [41600/84843 (49%)]\tLoss: 0.540228\n",
      "Train Epoch: 2 [42240/84843 (50%)]\tLoss: 0.120439\n",
      "Train Epoch: 2 [42880/84843 (51%)]\tLoss: 0.200542\n",
      "Train Epoch: 2 [43520/84843 (51%)]\tLoss: 0.311285\n",
      "Train Epoch: 2 [44160/84843 (52%)]\tLoss: 0.250389\n",
      "Train Epoch: 2 [44800/84843 (53%)]\tLoss: 0.408097\n",
      "Train Epoch: 2 [45440/84843 (54%)]\tLoss: 0.110146\n",
      "Train Epoch: 2 [46080/84843 (54%)]\tLoss: 0.704581\n",
      "Train Epoch: 2 [46720/84843 (55%)]\tLoss: 0.338886\n",
      "Train Epoch: 2 [47360/84843 (56%)]\tLoss: 0.674003\n",
      "Train Epoch: 2 [48000/84843 (57%)]\tLoss: 0.199834\n",
      "Train Epoch: 2 [48640/84843 (57%)]\tLoss: 0.682945\n",
      "Train Epoch: 2 [49280/84843 (58%)]\tLoss: 0.396234\n",
      "Train Epoch: 2 [49920/84843 (59%)]\tLoss: 0.307244\n",
      "Train Epoch: 2 [50560/84843 (60%)]\tLoss: 0.366625\n",
      "Train Epoch: 2 [51200/84843 (60%)]\tLoss: 0.629001\n",
      "Train Epoch: 2 [51840/84843 (61%)]\tLoss: 0.243095\n",
      "Train Epoch: 2 [52480/84843 (62%)]\tLoss: 0.673684\n",
      "Train Epoch: 2 [53120/84843 (63%)]\tLoss: 0.144391\n",
      "Train Epoch: 2 [53760/84843 (63%)]\tLoss: 0.277145\n",
      "Train Epoch: 2 [54400/84843 (64%)]\tLoss: 0.466339\n",
      "Train Epoch: 2 [55040/84843 (65%)]\tLoss: 0.362177\n",
      "Train Epoch: 2 [55680/84843 (66%)]\tLoss: 0.344323\n",
      "Train Epoch: 2 [56320/84843 (66%)]\tLoss: 0.507964\n",
      "Train Epoch: 2 [56960/84843 (67%)]\tLoss: 0.220570\n",
      "Train Epoch: 2 [57600/84843 (68%)]\tLoss: 0.228006\n",
      "Train Epoch: 2 [58240/84843 (69%)]\tLoss: 0.274502\n",
      "Train Epoch: 2 [58880/84843 (69%)]\tLoss: 0.374491\n",
      "Train Epoch: 2 [59520/84843 (70%)]\tLoss: 0.493568\n",
      "Train Epoch: 2 [60160/84843 (71%)]\tLoss: 0.305875\n",
      "Train Epoch: 2 [60800/84843 (72%)]\tLoss: 0.442207\n",
      "Train Epoch: 2 [61440/84843 (72%)]\tLoss: 0.215478\n",
      "Train Epoch: 2 [62080/84843 (73%)]\tLoss: 0.650585\n",
      "Train Epoch: 2 [62720/84843 (74%)]\tLoss: 0.370242\n",
      "Train Epoch: 2 [63360/84843 (75%)]\tLoss: 0.518610\n",
      "Train Epoch: 2 [64000/84843 (75%)]\tLoss: 0.713424\n",
      "Train Epoch: 2 [64640/84843 (76%)]\tLoss: 0.198127\n",
      "Train Epoch: 2 [65280/84843 (77%)]\tLoss: 0.763464\n",
      "Train Epoch: 2 [65920/84843 (78%)]\tLoss: 0.362565\n",
      "Train Epoch: 2 [66560/84843 (78%)]\tLoss: 0.457211\n",
      "Train Epoch: 2 [67200/84843 (79%)]\tLoss: 0.424155\n",
      "Train Epoch: 2 [67840/84843 (80%)]\tLoss: 0.509338\n",
      "Train Epoch: 2 [68480/84843 (81%)]\tLoss: 0.352567\n",
      "Train Epoch: 2 [69120/84843 (81%)]\tLoss: 0.241892\n",
      "Train Epoch: 2 [69760/84843 (82%)]\tLoss: 0.150183\n",
      "Train Epoch: 2 [70400/84843 (83%)]\tLoss: 0.783824\n",
      "Train Epoch: 2 [71040/84843 (84%)]\tLoss: 0.350666\n",
      "Train Epoch: 2 [71680/84843 (84%)]\tLoss: 0.093739\n",
      "Train Epoch: 2 [72320/84843 (85%)]\tLoss: 0.284656\n",
      "Train Epoch: 2 [72960/84843 (86%)]\tLoss: 0.296805\n",
      "Train Epoch: 2 [73600/84843 (87%)]\tLoss: 0.194171\n",
      "Train Epoch: 2 [74240/84843 (87%)]\tLoss: 0.251207\n",
      "Train Epoch: 2 [74880/84843 (88%)]\tLoss: 0.710050\n",
      "Train Epoch: 2 [75520/84843 (89%)]\tLoss: 0.657876\n",
      "Train Epoch: 2 [76160/84843 (90%)]\tLoss: 0.556932\n",
      "Train Epoch: 2 [76800/84843 (90%)]\tLoss: 0.390121\n",
      "Train Epoch: 2 [77440/84843 (91%)]\tLoss: 0.796177\n",
      "Train Epoch: 2 [78080/84843 (92%)]\tLoss: 0.413849\n",
      "Train Epoch: 2 [78720/84843 (93%)]\tLoss: 0.373898\n",
      "Train Epoch: 2 [79360/84843 (94%)]\tLoss: 0.313764\n",
      "Train Epoch: 2 [80000/84843 (94%)]\tLoss: 0.324468\n",
      "Train Epoch: 2 [80640/84843 (95%)]\tLoss: 0.204782\n",
      "Train Epoch: 2 [81280/84843 (96%)]\tLoss: 0.488593\n",
      "Train Epoch: 2 [81920/84843 (97%)]\tLoss: 0.752299\n",
      "Train Epoch: 2 [82560/84843 (97%)]\tLoss: 0.197141\n",
      "Train Epoch: 2 [83200/84843 (98%)]\tLoss: 0.566401\n",
      "Train Epoch: 2 [83840/84843 (99%)]\tLoss: 0.459489\n",
      "Train Epoch: 2 [84480/84843 (100%)]\tLoss: 0.402413\n",
      "Accuracy: 9470/11005 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/84843 (0%)]\tLoss: 0.469222\n",
      "Train Epoch: 3 [640/84843 (1%)]\tLoss: 0.456892\n",
      "Train Epoch: 3 [1280/84843 (2%)]\tLoss: 0.257587\n",
      "Train Epoch: 3 [1920/84843 (2%)]\tLoss: 0.482713\n",
      "Train Epoch: 3 [2560/84843 (3%)]\tLoss: 0.228760\n",
      "Train Epoch: 3 [3200/84843 (4%)]\tLoss: 0.404565\n",
      "Train Epoch: 3 [3840/84843 (5%)]\tLoss: 0.366714\n",
      "Train Epoch: 3 [4480/84843 (5%)]\tLoss: 0.199450\n",
      "Train Epoch: 3 [5120/84843 (6%)]\tLoss: 0.224237\n",
      "Train Epoch: 3 [5760/84843 (7%)]\tLoss: 0.382400\n",
      "Train Epoch: 3 [6400/84843 (8%)]\tLoss: 0.904985\n",
      "Train Epoch: 3 [7040/84843 (8%)]\tLoss: 0.533015\n",
      "Train Epoch: 3 [7680/84843 (9%)]\tLoss: 0.379179\n",
      "Train Epoch: 3 [8320/84843 (10%)]\tLoss: 0.368123\n",
      "Train Epoch: 3 [8960/84843 (11%)]\tLoss: 0.538552\n",
      "Train Epoch: 3 [9600/84843 (11%)]\tLoss: 0.307241\n",
      "Train Epoch: 3 [10240/84843 (12%)]\tLoss: 0.328349\n",
      "Train Epoch: 3 [10880/84843 (13%)]\tLoss: 0.319139\n",
      "Train Epoch: 3 [11520/84843 (14%)]\tLoss: 0.169810\n",
      "Train Epoch: 3 [12160/84843 (14%)]\tLoss: 0.278843\n",
      "Train Epoch: 3 [12800/84843 (15%)]\tLoss: 0.303910\n",
      "Train Epoch: 3 [13440/84843 (16%)]\tLoss: 0.184726\n",
      "Train Epoch: 3 [14080/84843 (17%)]\tLoss: 0.550849\n",
      "Train Epoch: 3 [14720/84843 (17%)]\tLoss: 0.238484\n",
      "Train Epoch: 3 [15360/84843 (18%)]\tLoss: 0.376280\n",
      "Train Epoch: 3 [16000/84843 (19%)]\tLoss: 0.315160\n",
      "Train Epoch: 3 [16640/84843 (20%)]\tLoss: 0.417179\n",
      "Train Epoch: 3 [17280/84843 (20%)]\tLoss: 0.383899\n",
      "Train Epoch: 3 [17920/84843 (21%)]\tLoss: 0.539294\n",
      "Train Epoch: 3 [18560/84843 (22%)]\tLoss: 0.601873\n",
      "Train Epoch: 3 [19200/84843 (23%)]\tLoss: 0.402898\n",
      "Train Epoch: 3 [19840/84843 (23%)]\tLoss: 0.217991\n",
      "Train Epoch: 3 [20480/84843 (24%)]\tLoss: 0.234396\n",
      "Train Epoch: 3 [21120/84843 (25%)]\tLoss: 0.265727\n",
      "Train Epoch: 3 [21760/84843 (26%)]\tLoss: 0.322389\n",
      "Train Epoch: 3 [22400/84843 (26%)]\tLoss: 0.343884\n",
      "Train Epoch: 3 [23040/84843 (27%)]\tLoss: 0.500868\n",
      "Train Epoch: 3 [23680/84843 (28%)]\tLoss: 0.057723\n",
      "Train Epoch: 3 [24320/84843 (29%)]\tLoss: 0.362883\n",
      "Train Epoch: 3 [24960/84843 (29%)]\tLoss: 0.448654\n",
      "Train Epoch: 3 [25600/84843 (30%)]\tLoss: 0.414612\n",
      "Train Epoch: 3 [26240/84843 (31%)]\tLoss: 0.722199\n",
      "Train Epoch: 3 [26880/84843 (32%)]\tLoss: 0.220154\n",
      "Train Epoch: 3 [27520/84843 (32%)]\tLoss: 0.230541\n",
      "Train Epoch: 3 [28160/84843 (33%)]\tLoss: 0.214894\n",
      "Train Epoch: 3 [28800/84843 (34%)]\tLoss: 0.375450\n",
      "Train Epoch: 3 [29440/84843 (35%)]\tLoss: 0.539560\n",
      "Train Epoch: 3 [30080/84843 (35%)]\tLoss: 0.260677\n",
      "Train Epoch: 3 [30720/84843 (36%)]\tLoss: 0.450635\n",
      "Train Epoch: 3 [31360/84843 (37%)]\tLoss: 0.527893\n",
      "Train Epoch: 3 [32000/84843 (38%)]\tLoss: 0.471275\n",
      "Train Epoch: 3 [32640/84843 (38%)]\tLoss: 0.411683\n",
      "Train Epoch: 3 [33280/84843 (39%)]\tLoss: 0.181238\n",
      "Train Epoch: 3 [33920/84843 (40%)]\tLoss: 0.333453\n",
      "Train Epoch: 3 [34560/84843 (41%)]\tLoss: 0.416222\n",
      "Train Epoch: 3 [35200/84843 (41%)]\tLoss: 0.354980\n",
      "Train Epoch: 3 [35840/84843 (42%)]\tLoss: 0.317772\n",
      "Train Epoch: 3 [36480/84843 (43%)]\tLoss: 0.443307\n",
      "Train Epoch: 3 [37120/84843 (44%)]\tLoss: 0.513618\n",
      "Train Epoch: 3 [37760/84843 (44%)]\tLoss: 0.235973\n",
      "Train Epoch: 3 [38400/84843 (45%)]\tLoss: 0.083154\n",
      "Train Epoch: 3 [39040/84843 (46%)]\tLoss: 0.568557\n",
      "Train Epoch: 3 [39680/84843 (47%)]\tLoss: 0.517582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [40320/84843 (48%)]\tLoss: 0.938480\n",
      "Train Epoch: 3 [40960/84843 (48%)]\tLoss: 0.648893\n",
      "Train Epoch: 3 [41600/84843 (49%)]\tLoss: 0.445032\n",
      "Train Epoch: 3 [42240/84843 (50%)]\tLoss: 0.250747\n",
      "Train Epoch: 3 [42880/84843 (51%)]\tLoss: 0.228693\n",
      "Train Epoch: 3 [43520/84843 (51%)]\tLoss: 0.516209\n",
      "Train Epoch: 3 [44160/84843 (52%)]\tLoss: 0.428560\n",
      "Train Epoch: 3 [44800/84843 (53%)]\tLoss: 0.371515\n",
      "Train Epoch: 3 [45440/84843 (54%)]\tLoss: 0.120085\n",
      "Train Epoch: 3 [46080/84843 (54%)]\tLoss: 0.230140\n",
      "Train Epoch: 3 [46720/84843 (55%)]\tLoss: 0.435369\n",
      "Train Epoch: 3 [47360/84843 (56%)]\tLoss: 0.427850\n",
      "Train Epoch: 3 [48000/84843 (57%)]\tLoss: 0.454382\n",
      "Train Epoch: 3 [48640/84843 (57%)]\tLoss: 0.854145\n",
      "Train Epoch: 3 [49280/84843 (58%)]\tLoss: 0.165196\n",
      "Train Epoch: 3 [49920/84843 (59%)]\tLoss: 0.528404\n",
      "Train Epoch: 3 [50560/84843 (60%)]\tLoss: 0.436877\n",
      "Train Epoch: 3 [51200/84843 (60%)]\tLoss: 0.458452\n",
      "Train Epoch: 3 [51840/84843 (61%)]\tLoss: 0.331807\n",
      "Train Epoch: 3 [52480/84843 (62%)]\tLoss: 0.402165\n",
      "Train Epoch: 3 [53120/84843 (63%)]\tLoss: 0.448544\n",
      "Train Epoch: 3 [53760/84843 (63%)]\tLoss: 0.531932\n",
      "Train Epoch: 3 [54400/84843 (64%)]\tLoss: 0.584620\n",
      "Train Epoch: 3 [55040/84843 (65%)]\tLoss: 0.385702\n",
      "Train Epoch: 3 [55680/84843 (66%)]\tLoss: 0.456677\n",
      "Train Epoch: 3 [56320/84843 (66%)]\tLoss: 0.532498\n",
      "Train Epoch: 3 [56960/84843 (67%)]\tLoss: 0.227627\n",
      "Train Epoch: 3 [57600/84843 (68%)]\tLoss: 0.536065\n",
      "Train Epoch: 3 [58240/84843 (69%)]\tLoss: 0.666466\n",
      "Train Epoch: 3 [58880/84843 (69%)]\tLoss: 0.162360\n",
      "Train Epoch: 3 [59520/84843 (70%)]\tLoss: 0.373100\n",
      "Train Epoch: 3 [60160/84843 (71%)]\tLoss: 0.488910\n",
      "Train Epoch: 3 [60800/84843 (72%)]\tLoss: 0.229142\n",
      "Train Epoch: 3 [61440/84843 (72%)]\tLoss: 0.336536\n",
      "Train Epoch: 3 [62080/84843 (73%)]\tLoss: 0.150039\n",
      "Train Epoch: 3 [62720/84843 (74%)]\tLoss: 0.359275\n",
      "Train Epoch: 3 [63360/84843 (75%)]\tLoss: 0.449796\n",
      "Train Epoch: 3 [64000/84843 (75%)]\tLoss: 0.088270\n",
      "Train Epoch: 3 [64640/84843 (76%)]\tLoss: 0.631515\n",
      "Train Epoch: 3 [65280/84843 (77%)]\tLoss: 0.856598\n",
      "Train Epoch: 3 [65920/84843 (78%)]\tLoss: 0.497905\n",
      "Train Epoch: 3 [66560/84843 (78%)]\tLoss: 0.224894\n",
      "Train Epoch: 3 [67200/84843 (79%)]\tLoss: 0.348625\n",
      "Train Epoch: 3 [67840/84843 (80%)]\tLoss: 0.509656\n",
      "Train Epoch: 3 [68480/84843 (81%)]\tLoss: 0.244518\n",
      "Train Epoch: 3 [69120/84843 (81%)]\tLoss: 0.450249\n",
      "Train Epoch: 3 [69760/84843 (82%)]\tLoss: 0.310558\n",
      "Train Epoch: 3 [70400/84843 (83%)]\tLoss: 0.159385\n",
      "Train Epoch: 3 [71040/84843 (84%)]\tLoss: 0.210730\n",
      "Train Epoch: 3 [71680/84843 (84%)]\tLoss: 0.261438\n",
      "Train Epoch: 3 [72320/84843 (85%)]\tLoss: 0.230750\n",
      "Train Epoch: 3 [72960/84843 (86%)]\tLoss: 0.899797\n",
      "Train Epoch: 3 [73600/84843 (87%)]\tLoss: 0.427970\n",
      "Train Epoch: 3 [74240/84843 (87%)]\tLoss: 0.240710\n",
      "Train Epoch: 3 [74880/84843 (88%)]\tLoss: 0.220905\n",
      "Train Epoch: 3 [75520/84843 (89%)]\tLoss: 0.631367\n",
      "Train Epoch: 3 [76160/84843 (90%)]\tLoss: 0.609326\n",
      "Train Epoch: 3 [76800/84843 (90%)]\tLoss: 0.417489\n",
      "Train Epoch: 3 [77440/84843 (91%)]\tLoss: 0.360663\n",
      "Train Epoch: 3 [78080/84843 (92%)]\tLoss: 0.634063\n",
      "Train Epoch: 3 [78720/84843 (93%)]\tLoss: 0.456605\n",
      "Train Epoch: 3 [79360/84843 (94%)]\tLoss: 0.218212\n",
      "Train Epoch: 3 [80000/84843 (94%)]\tLoss: 0.413919\n",
      "Train Epoch: 3 [80640/84843 (95%)]\tLoss: 0.431144\n",
      "Train Epoch: 3 [81280/84843 (96%)]\tLoss: 0.439191\n",
      "Train Epoch: 3 [81920/84843 (97%)]\tLoss: 0.348351\n",
      "Train Epoch: 3 [82560/84843 (97%)]\tLoss: 0.132124\n",
      "Train Epoch: 3 [83200/84843 (98%)]\tLoss: 0.194515\n",
      "Train Epoch: 3 [83840/84843 (99%)]\tLoss: 0.601871\n",
      "Train Epoch: 3 [84480/84843 (100%)]\tLoss: 0.266056\n",
      "Accuracy: 9488/11005 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/84843 (0%)]\tLoss: 0.293311\n",
      "Train Epoch: 4 [640/84843 (1%)]\tLoss: 0.052186\n",
      "Train Epoch: 4 [1280/84843 (2%)]\tLoss: 0.468816\n",
      "Train Epoch: 4 [1920/84843 (2%)]\tLoss: 0.175710\n",
      "Train Epoch: 4 [2560/84843 (3%)]\tLoss: 0.390455\n",
      "Train Epoch: 4 [3200/84843 (4%)]\tLoss: 0.413804\n",
      "Train Epoch: 4 [3840/84843 (5%)]\tLoss: 0.500094\n",
      "Train Epoch: 4 [4480/84843 (5%)]\tLoss: 0.380041\n",
      "Train Epoch: 4 [5120/84843 (6%)]\tLoss: 0.223594\n",
      "Train Epoch: 4 [5760/84843 (7%)]\tLoss: 0.658895\n",
      "Train Epoch: 4 [6400/84843 (8%)]\tLoss: 0.085681\n",
      "Train Epoch: 4 [7040/84843 (8%)]\tLoss: 0.256608\n",
      "Train Epoch: 4 [7680/84843 (9%)]\tLoss: 0.374983\n",
      "Train Epoch: 4 [8320/84843 (10%)]\tLoss: 0.370824\n",
      "Train Epoch: 4 [8960/84843 (11%)]\tLoss: 0.428143\n",
      "Train Epoch: 4 [9600/84843 (11%)]\tLoss: 0.577622\n",
      "Train Epoch: 4 [10240/84843 (12%)]\tLoss: 0.380483\n",
      "Train Epoch: 4 [10880/84843 (13%)]\tLoss: 0.448404\n",
      "Train Epoch: 4 [11520/84843 (14%)]\tLoss: 0.567338\n",
      "Train Epoch: 4 [12160/84843 (14%)]\tLoss: 0.318939\n",
      "Train Epoch: 4 [12800/84843 (15%)]\tLoss: 0.346470\n",
      "Train Epoch: 4 [13440/84843 (16%)]\tLoss: 0.110893\n",
      "Train Epoch: 4 [14080/84843 (17%)]\tLoss: 0.131768\n",
      "Train Epoch: 4 [14720/84843 (17%)]\tLoss: 0.340478\n",
      "Train Epoch: 4 [15360/84843 (18%)]\tLoss: 0.270530\n",
      "Train Epoch: 4 [16000/84843 (19%)]\tLoss: 0.231834\n",
      "Train Epoch: 4 [16640/84843 (20%)]\tLoss: 0.491363\n",
      "Train Epoch: 4 [17280/84843 (20%)]\tLoss: 0.171259\n",
      "Train Epoch: 4 [17920/84843 (21%)]\tLoss: 0.745402\n",
      "Train Epoch: 4 [18560/84843 (22%)]\tLoss: 0.251605\n",
      "Train Epoch: 4 [19200/84843 (23%)]\tLoss: 0.473066\n",
      "Train Epoch: 4 [19840/84843 (23%)]\tLoss: 0.350310\n",
      "Train Epoch: 4 [20480/84843 (24%)]\tLoss: 0.265789\n",
      "Train Epoch: 4 [21120/84843 (25%)]\tLoss: 0.247099\n",
      "Train Epoch: 4 [21760/84843 (26%)]\tLoss: 0.370519\n",
      "Train Epoch: 4 [22400/84843 (26%)]\tLoss: 0.426307\n",
      "Train Epoch: 4 [23040/84843 (27%)]\tLoss: 0.289822\n",
      "Train Epoch: 4 [23680/84843 (28%)]\tLoss: 0.462764\n",
      "Train Epoch: 4 [24320/84843 (29%)]\tLoss: 0.239707\n",
      "Train Epoch: 4 [24960/84843 (29%)]\tLoss: 0.376131\n",
      "Train Epoch: 4 [25600/84843 (30%)]\tLoss: 0.638983\n",
      "Train Epoch: 4 [26240/84843 (31%)]\tLoss: 0.458109\n",
      "Train Epoch: 4 [26880/84843 (32%)]\tLoss: 0.499955\n",
      "Train Epoch: 4 [27520/84843 (32%)]\tLoss: 0.491150\n",
      "Train Epoch: 4 [28160/84843 (33%)]\tLoss: 0.532738\n",
      "Train Epoch: 4 [28800/84843 (34%)]\tLoss: 0.548493\n",
      "Train Epoch: 4 [29440/84843 (35%)]\tLoss: 0.309975\n",
      "Train Epoch: 4 [30080/84843 (35%)]\tLoss: 0.223876\n",
      "Train Epoch: 4 [30720/84843 (36%)]\tLoss: 0.362607\n",
      "Train Epoch: 4 [31360/84843 (37%)]\tLoss: 0.283364\n",
      "Train Epoch: 4 [32000/84843 (38%)]\tLoss: 0.261345\n",
      "Train Epoch: 4 [32640/84843 (38%)]\tLoss: 0.563012\n",
      "Train Epoch: 4 [33280/84843 (39%)]\tLoss: 0.538441\n",
      "Train Epoch: 4 [33920/84843 (40%)]\tLoss: 0.340981\n",
      "Train Epoch: 4 [34560/84843 (41%)]\tLoss: 0.499379\n",
      "Train Epoch: 4 [35200/84843 (41%)]\tLoss: 0.230037\n",
      "Train Epoch: 4 [35840/84843 (42%)]\tLoss: 0.228394\n",
      "Train Epoch: 4 [36480/84843 (43%)]\tLoss: 0.576916\n",
      "Train Epoch: 4 [37120/84843 (44%)]\tLoss: 0.292050\n",
      "Train Epoch: 4 [37760/84843 (44%)]\tLoss: 0.268508\n",
      "Train Epoch: 4 [38400/84843 (45%)]\tLoss: 0.307657\n",
      "Train Epoch: 4 [39040/84843 (46%)]\tLoss: 0.274715\n",
      "Train Epoch: 4 [39680/84843 (47%)]\tLoss: 0.336481\n",
      "Train Epoch: 4 [40320/84843 (48%)]\tLoss: 0.480924\n",
      "Train Epoch: 4 [40960/84843 (48%)]\tLoss: 0.337415\n",
      "Train Epoch: 4 [41600/84843 (49%)]\tLoss: 0.307776\n",
      "Train Epoch: 4 [42240/84843 (50%)]\tLoss: 0.382791\n",
      "Train Epoch: 4 [42880/84843 (51%)]\tLoss: 0.267631\n",
      "Train Epoch: 4 [43520/84843 (51%)]\tLoss: 0.657142\n",
      "Train Epoch: 4 [44160/84843 (52%)]\tLoss: 0.246760\n",
      "Train Epoch: 4 [44800/84843 (53%)]\tLoss: 0.542432\n",
      "Train Epoch: 4 [45440/84843 (54%)]\tLoss: 0.481829\n",
      "Train Epoch: 4 [46080/84843 (54%)]\tLoss: 0.219760\n",
      "Train Epoch: 4 [46720/84843 (55%)]\tLoss: 0.285042\n",
      "Train Epoch: 4 [47360/84843 (56%)]\tLoss: 0.324814\n",
      "Train Epoch: 4 [48000/84843 (57%)]\tLoss: 0.642606\n",
      "Train Epoch: 4 [48640/84843 (57%)]\tLoss: 0.218004\n",
      "Train Epoch: 4 [49280/84843 (58%)]\tLoss: 0.254017\n",
      "Train Epoch: 4 [49920/84843 (59%)]\tLoss: 0.274542\n",
      "Train Epoch: 4 [50560/84843 (60%)]\tLoss: 0.299860\n",
      "Train Epoch: 4 [51200/84843 (60%)]\tLoss: 0.433040\n",
      "Train Epoch: 4 [51840/84843 (61%)]\tLoss: 0.377639\n",
      "Train Epoch: 4 [52480/84843 (62%)]\tLoss: 0.378342\n",
      "Train Epoch: 4 [53120/84843 (63%)]\tLoss: 0.212713\n",
      "Train Epoch: 4 [53760/84843 (63%)]\tLoss: 0.646635\n",
      "Train Epoch: 4 [54400/84843 (64%)]\tLoss: 0.385241\n",
      "Train Epoch: 4 [55040/84843 (65%)]\tLoss: 0.748281\n",
      "Train Epoch: 4 [55680/84843 (66%)]\tLoss: 0.254446\n",
      "Train Epoch: 4 [56320/84843 (66%)]\tLoss: 0.178266\n",
      "Train Epoch: 4 [56960/84843 (67%)]\tLoss: 0.115977\n",
      "Train Epoch: 4 [57600/84843 (68%)]\tLoss: 0.389615\n",
      "Train Epoch: 4 [58240/84843 (69%)]\tLoss: 0.525237\n",
      "Train Epoch: 4 [58880/84843 (69%)]\tLoss: 0.544583\n",
      "Train Epoch: 4 [59520/84843 (70%)]\tLoss: 0.278640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [60160/84843 (71%)]\tLoss: 0.107670\n",
      "Train Epoch: 4 [60800/84843 (72%)]\tLoss: 0.180370\n",
      "Train Epoch: 4 [61440/84843 (72%)]\tLoss: 0.523560\n",
      "Train Epoch: 4 [62080/84843 (73%)]\tLoss: 0.468805\n",
      "Train Epoch: 4 [62720/84843 (74%)]\tLoss: 0.170641\n",
      "Train Epoch: 4 [63360/84843 (75%)]\tLoss: 0.365492\n",
      "Train Epoch: 4 [64000/84843 (75%)]\tLoss: 0.526902\n",
      "Train Epoch: 4 [64640/84843 (76%)]\tLoss: 0.227416\n",
      "Train Epoch: 4 [65280/84843 (77%)]\tLoss: 0.415259\n",
      "Train Epoch: 4 [65920/84843 (78%)]\tLoss: 0.161429\n",
      "Train Epoch: 4 [66560/84843 (78%)]\tLoss: 0.284726\n",
      "Train Epoch: 4 [67200/84843 (79%)]\tLoss: 0.400763\n",
      "Train Epoch: 4 [67840/84843 (80%)]\tLoss: 0.195684\n",
      "Train Epoch: 4 [68480/84843 (81%)]\tLoss: 0.693775\n",
      "Train Epoch: 4 [69120/84843 (81%)]\tLoss: 0.378970\n",
      "Train Epoch: 4 [69760/84843 (82%)]\tLoss: 0.232132\n",
      "Train Epoch: 4 [70400/84843 (83%)]\tLoss: 0.330962\n",
      "Train Epoch: 4 [71040/84843 (84%)]\tLoss: 0.670096\n",
      "Train Epoch: 4 [71680/84843 (84%)]\tLoss: 0.743091\n",
      "Train Epoch: 4 [72320/84843 (85%)]\tLoss: 0.173388\n",
      "Train Epoch: 4 [72960/84843 (86%)]\tLoss: 0.380660\n",
      "Train Epoch: 4 [73600/84843 (87%)]\tLoss: 0.752915\n",
      "Train Epoch: 4 [74240/84843 (87%)]\tLoss: 0.671399\n",
      "Train Epoch: 4 [74880/84843 (88%)]\tLoss: 0.458382\n",
      "Train Epoch: 4 [75520/84843 (89%)]\tLoss: 0.329899\n",
      "Train Epoch: 4 [76160/84843 (90%)]\tLoss: 0.458130\n",
      "Train Epoch: 4 [76800/84843 (90%)]\tLoss: 0.317097\n",
      "Train Epoch: 4 [77440/84843 (91%)]\tLoss: 0.322820\n",
      "Train Epoch: 4 [78080/84843 (92%)]\tLoss: 0.825826\n",
      "Train Epoch: 4 [78720/84843 (93%)]\tLoss: 0.260458\n",
      "Train Epoch: 4 [79360/84843 (94%)]\tLoss: 0.219327\n",
      "Train Epoch: 4 [80000/84843 (94%)]\tLoss: 0.374785\n",
      "Train Epoch: 4 [80640/84843 (95%)]\tLoss: 0.433199\n",
      "Train Epoch: 4 [81280/84843 (96%)]\tLoss: 0.282475\n",
      "Train Epoch: 4 [81920/84843 (97%)]\tLoss: 0.372016\n",
      "Train Epoch: 4 [82560/84843 (97%)]\tLoss: 0.513347\n",
      "Train Epoch: 4 [83200/84843 (98%)]\tLoss: 0.562506\n",
      "Train Epoch: 4 [83840/84843 (99%)]\tLoss: 0.231193\n",
      "Train Epoch: 4 [84480/84843 (100%)]\tLoss: 0.411587\n",
      "Accuracy: 9414/11005 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/84843 (0%)]\tLoss: 0.294404\n",
      "Train Epoch: 5 [640/84843 (1%)]\tLoss: 0.441132\n",
      "Train Epoch: 5 [1280/84843 (2%)]\tLoss: 0.304710\n",
      "Train Epoch: 5 [1920/84843 (2%)]\tLoss: 0.474413\n",
      "Train Epoch: 5 [2560/84843 (3%)]\tLoss: 0.333613\n",
      "Train Epoch: 5 [3200/84843 (4%)]\tLoss: 0.185187\n",
      "Train Epoch: 5 [3840/84843 (5%)]\tLoss: 0.400794\n",
      "Train Epoch: 5 [4480/84843 (5%)]\tLoss: 0.324986\n",
      "Train Epoch: 5 [5120/84843 (6%)]\tLoss: 0.439892\n",
      "Train Epoch: 5 [5760/84843 (7%)]\tLoss: 0.327727\n",
      "Train Epoch: 5 [6400/84843 (8%)]\tLoss: 0.273149\n",
      "Train Epoch: 5 [7040/84843 (8%)]\tLoss: 0.365031\n",
      "Train Epoch: 5 [7680/84843 (9%)]\tLoss: 0.085227\n",
      "Train Epoch: 5 [8320/84843 (10%)]\tLoss: 0.198778\n",
      "Train Epoch: 5 [8960/84843 (11%)]\tLoss: 0.258241\n",
      "Train Epoch: 5 [9600/84843 (11%)]\tLoss: 0.329878\n",
      "Train Epoch: 5 [10240/84843 (12%)]\tLoss: 0.795948\n",
      "Train Epoch: 5 [10880/84843 (13%)]\tLoss: 0.689737\n",
      "Train Epoch: 5 [11520/84843 (14%)]\tLoss: 0.258837\n",
      "Train Epoch: 5 [12160/84843 (14%)]\tLoss: 0.061036\n",
      "Train Epoch: 5 [12800/84843 (15%)]\tLoss: 0.397812\n",
      "Train Epoch: 5 [13440/84843 (16%)]\tLoss: 0.185787\n",
      "Train Epoch: 5 [14080/84843 (17%)]\tLoss: 0.501780\n",
      "Train Epoch: 5 [14720/84843 (17%)]\tLoss: 0.341585\n",
      "Train Epoch: 5 [15360/84843 (18%)]\tLoss: 0.430806\n",
      "Train Epoch: 5 [16000/84843 (19%)]\tLoss: 0.192584\n",
      "Train Epoch: 5 [16640/84843 (20%)]\tLoss: 0.085110\n",
      "Train Epoch: 5 [17280/84843 (20%)]\tLoss: 0.182751\n",
      "Train Epoch: 5 [17920/84843 (21%)]\tLoss: 0.326799\n",
      "Train Epoch: 5 [18560/84843 (22%)]\tLoss: 0.137458\n",
      "Train Epoch: 5 [19200/84843 (23%)]\tLoss: 0.374602\n",
      "Train Epoch: 5 [19840/84843 (23%)]\tLoss: 0.126124\n",
      "Train Epoch: 5 [20480/84843 (24%)]\tLoss: 0.416021\n",
      "Train Epoch: 5 [21120/84843 (25%)]\tLoss: 0.496265\n",
      "Train Epoch: 5 [21760/84843 (26%)]\tLoss: 0.389678\n",
      "Train Epoch: 5 [22400/84843 (26%)]\tLoss: 0.652002\n",
      "Train Epoch: 5 [23040/84843 (27%)]\tLoss: 0.223619\n",
      "Train Epoch: 5 [23680/84843 (28%)]\tLoss: 0.706545\n",
      "Train Epoch: 5 [24320/84843 (29%)]\tLoss: 0.464680\n",
      "Train Epoch: 5 [24960/84843 (29%)]\tLoss: 0.311356\n",
      "Train Epoch: 5 [25600/84843 (30%)]\tLoss: 0.110134\n",
      "Train Epoch: 5 [26240/84843 (31%)]\tLoss: 0.324890\n",
      "Train Epoch: 5 [26880/84843 (32%)]\tLoss: 0.472127\n",
      "Train Epoch: 5 [27520/84843 (32%)]\tLoss: 0.236889\n",
      "Train Epoch: 5 [28160/84843 (33%)]\tLoss: 0.433370\n",
      "Train Epoch: 5 [28800/84843 (34%)]\tLoss: 0.181768\n",
      "Train Epoch: 5 [29440/84843 (35%)]\tLoss: 0.320143\n",
      "Train Epoch: 5 [30080/84843 (35%)]\tLoss: 0.185312\n",
      "Train Epoch: 5 [30720/84843 (36%)]\tLoss: 0.248420\n",
      "Train Epoch: 5 [31360/84843 (37%)]\tLoss: 0.248398\n",
      "Train Epoch: 5 [32000/84843 (38%)]\tLoss: 0.457150\n",
      "Train Epoch: 5 [32640/84843 (38%)]\tLoss: 0.154426\n",
      "Train Epoch: 5 [33280/84843 (39%)]\tLoss: 0.404493\n",
      "Train Epoch: 5 [33920/84843 (40%)]\tLoss: 0.249681\n",
      "Train Epoch: 5 [34560/84843 (41%)]\tLoss: 0.236777\n",
      "Train Epoch: 5 [35200/84843 (41%)]\tLoss: 0.407994\n",
      "Train Epoch: 5 [35840/84843 (42%)]\tLoss: 0.182748\n",
      "Train Epoch: 5 [36480/84843 (43%)]\tLoss: 0.292404\n",
      "Train Epoch: 5 [37120/84843 (44%)]\tLoss: 0.242744\n",
      "Train Epoch: 5 [37760/84843 (44%)]\tLoss: 0.364258\n",
      "Train Epoch: 5 [38400/84843 (45%)]\tLoss: 0.475167\n",
      "Train Epoch: 5 [39040/84843 (46%)]\tLoss: 0.412707\n",
      "Train Epoch: 5 [39680/84843 (47%)]\tLoss: 0.323815\n",
      "Train Epoch: 5 [40320/84843 (48%)]\tLoss: 0.658327\n",
      "Train Epoch: 5 [40960/84843 (48%)]\tLoss: 0.433587\n",
      "Train Epoch: 5 [41600/84843 (49%)]\tLoss: 0.145970\n",
      "Train Epoch: 5 [42240/84843 (50%)]\tLoss: 0.372436\n",
      "Train Epoch: 5 [42880/84843 (51%)]\tLoss: 0.407771\n",
      "Train Epoch: 5 [43520/84843 (51%)]\tLoss: 0.400114\n",
      "Train Epoch: 5 [44160/84843 (52%)]\tLoss: 0.376457\n",
      "Train Epoch: 5 [44800/84843 (53%)]\tLoss: 0.372774\n",
      "Train Epoch: 5 [45440/84843 (54%)]\tLoss: 0.079727\n",
      "Train Epoch: 5 [46080/84843 (54%)]\tLoss: 0.606089\n",
      "Train Epoch: 5 [46720/84843 (55%)]\tLoss: 0.531618\n",
      "Train Epoch: 5 [47360/84843 (56%)]\tLoss: 0.757568\n",
      "Train Epoch: 5 [48000/84843 (57%)]\tLoss: 0.569247\n",
      "Train Epoch: 5 [48640/84843 (57%)]\tLoss: 0.513638\n",
      "Train Epoch: 5 [49280/84843 (58%)]\tLoss: 0.331132\n",
      "Train Epoch: 5 [49920/84843 (59%)]\tLoss: 0.342506\n",
      "Train Epoch: 5 [50560/84843 (60%)]\tLoss: 0.399976\n",
      "Train Epoch: 5 [51200/84843 (60%)]\tLoss: 0.372407\n",
      "Train Epoch: 5 [51840/84843 (61%)]\tLoss: 0.636614\n",
      "Train Epoch: 5 [52480/84843 (62%)]\tLoss: 0.351712\n",
      "Train Epoch: 5 [53120/84843 (63%)]\tLoss: 0.873663\n",
      "Train Epoch: 5 [53760/84843 (63%)]\tLoss: 0.288569\n",
      "Train Epoch: 5 [54400/84843 (64%)]\tLoss: 0.570090\n",
      "Train Epoch: 5 [55040/84843 (65%)]\tLoss: 0.382100\n",
      "Train Epoch: 5 [55680/84843 (66%)]\tLoss: 0.258074\n",
      "Train Epoch: 5 [56320/84843 (66%)]\tLoss: 0.211196\n",
      "Train Epoch: 5 [56960/84843 (67%)]\tLoss: 0.316633\n",
      "Train Epoch: 5 [57600/84843 (68%)]\tLoss: 0.357424\n",
      "Train Epoch: 5 [58240/84843 (69%)]\tLoss: 0.555652\n",
      "Train Epoch: 5 [58880/84843 (69%)]\tLoss: 0.275628\n",
      "Train Epoch: 5 [59520/84843 (70%)]\tLoss: 0.189890\n",
      "Train Epoch: 5 [60160/84843 (71%)]\tLoss: 0.312660\n",
      "Train Epoch: 5 [60800/84843 (72%)]\tLoss: 0.284636\n",
      "Train Epoch: 5 [61440/84843 (72%)]\tLoss: 0.077128\n",
      "Train Epoch: 5 [62080/84843 (73%)]\tLoss: 0.198274\n",
      "Train Epoch: 5 [62720/84843 (74%)]\tLoss: 0.205913\n",
      "Train Epoch: 5 [63360/84843 (75%)]\tLoss: 0.521257\n",
      "Train Epoch: 5 [64000/84843 (75%)]\tLoss: 0.386202\n",
      "Train Epoch: 5 [64640/84843 (76%)]\tLoss: 0.390410\n",
      "Train Epoch: 5 [65280/84843 (77%)]\tLoss: 0.225556\n",
      "Train Epoch: 5 [65920/84843 (78%)]\tLoss: 0.443499\n",
      "Train Epoch: 5 [66560/84843 (78%)]\tLoss: 0.508108\n",
      "Train Epoch: 5 [67200/84843 (79%)]\tLoss: 0.149247\n",
      "Train Epoch: 5 [67840/84843 (80%)]\tLoss: 0.381162\n",
      "Train Epoch: 5 [68480/84843 (81%)]\tLoss: 0.600455\n",
      "Train Epoch: 5 [69120/84843 (81%)]\tLoss: 0.641617\n",
      "Train Epoch: 5 [69760/84843 (82%)]\tLoss: 0.301473\n",
      "Train Epoch: 5 [70400/84843 (83%)]\tLoss: 0.558740\n",
      "Train Epoch: 5 [71040/84843 (84%)]\tLoss: 0.398784\n",
      "Train Epoch: 5 [71680/84843 (84%)]\tLoss: 0.287243\n",
      "Train Epoch: 5 [72320/84843 (85%)]\tLoss: 0.304378\n",
      "Train Epoch: 5 [72960/84843 (86%)]\tLoss: 0.443573\n",
      "Train Epoch: 5 [73600/84843 (87%)]\tLoss: 0.420242\n",
      "Train Epoch: 5 [74240/84843 (87%)]\tLoss: 0.597237\n",
      "Train Epoch: 5 [74880/84843 (88%)]\tLoss: 0.384786\n",
      "Train Epoch: 5 [75520/84843 (89%)]\tLoss: 0.164199\n",
      "Train Epoch: 5 [76160/84843 (90%)]\tLoss: 0.102119\n",
      "Train Epoch: 5 [76800/84843 (90%)]\tLoss: 0.548344\n",
      "Train Epoch: 5 [77440/84843 (91%)]\tLoss: 0.334074\n",
      "Train Epoch: 5 [78080/84843 (92%)]\tLoss: 0.503231\n",
      "Train Epoch: 5 [78720/84843 (93%)]\tLoss: 0.484912\n",
      "Train Epoch: 5 [79360/84843 (94%)]\tLoss: 0.243103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [80000/84843 (94%)]\tLoss: 0.585719\n",
      "Train Epoch: 5 [80640/84843 (95%)]\tLoss: 0.217395\n",
      "Train Epoch: 5 [81280/84843 (96%)]\tLoss: 0.459779\n",
      "Train Epoch: 5 [81920/84843 (97%)]\tLoss: 0.384416\n",
      "Train Epoch: 5 [82560/84843 (97%)]\tLoss: 0.643645\n",
      "Train Epoch: 5 [83200/84843 (98%)]\tLoss: 0.546282\n",
      "Train Epoch: 5 [83840/84843 (99%)]\tLoss: 0.307496\n",
      "Train Epoch: 5 [84480/84843 (100%)]\tLoss: 0.529441\n",
      "Accuracy: 9439/11005 (86%)\n",
      "\n",
      "Train Epoch: 6 [0/84843 (0%)]\tLoss: 0.466370\n",
      "Train Epoch: 6 [640/84843 (1%)]\tLoss: 0.292768\n",
      "Train Epoch: 6 [1280/84843 (2%)]\tLoss: 0.348256\n",
      "Train Epoch: 6 [1920/84843 (2%)]\tLoss: 0.359594\n",
      "Train Epoch: 6 [2560/84843 (3%)]\tLoss: 0.169439\n",
      "Train Epoch: 6 [3200/84843 (4%)]\tLoss: 0.521422\n",
      "Train Epoch: 6 [3840/84843 (5%)]\tLoss: 0.293633\n",
      "Train Epoch: 6 [4480/84843 (5%)]\tLoss: 0.361731\n",
      "Train Epoch: 6 [5120/84843 (6%)]\tLoss: 0.188456\n",
      "Train Epoch: 6 [5760/84843 (7%)]\tLoss: 0.340224\n",
      "Train Epoch: 6 [6400/84843 (8%)]\tLoss: 0.389033\n",
      "Train Epoch: 6 [7040/84843 (8%)]\tLoss: 0.173618\n",
      "Train Epoch: 6 [7680/84843 (9%)]\tLoss: 0.345997\n",
      "Train Epoch: 6 [8320/84843 (10%)]\tLoss: 0.435050\n",
      "Train Epoch: 6 [8960/84843 (11%)]\tLoss: 0.296647\n",
      "Train Epoch: 6 [9600/84843 (11%)]\tLoss: 0.490979\n",
      "Train Epoch: 6 [10240/84843 (12%)]\tLoss: 0.222886\n",
      "Train Epoch: 6 [10880/84843 (13%)]\tLoss: 0.153351\n",
      "Train Epoch: 6 [11520/84843 (14%)]\tLoss: 0.399829\n",
      "Train Epoch: 6 [12160/84843 (14%)]\tLoss: 0.444786\n",
      "Train Epoch: 6 [12800/84843 (15%)]\tLoss: 0.170058\n",
      "Train Epoch: 6 [13440/84843 (16%)]\tLoss: 0.376825\n",
      "Train Epoch: 6 [14080/84843 (17%)]\tLoss: 0.260832\n",
      "Train Epoch: 6 [14720/84843 (17%)]\tLoss: 0.086632\n",
      "Train Epoch: 6 [15360/84843 (18%)]\tLoss: 0.237016\n",
      "Train Epoch: 6 [16000/84843 (19%)]\tLoss: 0.347761\n",
      "Train Epoch: 6 [16640/84843 (20%)]\tLoss: 0.324312\n",
      "Train Epoch: 6 [17280/84843 (20%)]\tLoss: 0.270537\n",
      "Train Epoch: 6 [17920/84843 (21%)]\tLoss: 0.334099\n",
      "Train Epoch: 6 [18560/84843 (22%)]\tLoss: 0.554731\n",
      "Train Epoch: 6 [19200/84843 (23%)]\tLoss: 0.214059\n",
      "Train Epoch: 6 [19840/84843 (23%)]\tLoss: 0.521540\n",
      "Train Epoch: 6 [20480/84843 (24%)]\tLoss: 0.175403\n",
      "Train Epoch: 6 [21120/84843 (25%)]\tLoss: 0.643137\n",
      "Train Epoch: 6 [21760/84843 (26%)]\tLoss: 0.202058\n",
      "Train Epoch: 6 [22400/84843 (26%)]\tLoss: 0.377249\n",
      "Train Epoch: 6 [23040/84843 (27%)]\tLoss: 0.532694\n",
      "Train Epoch: 6 [23680/84843 (28%)]\tLoss: 0.469349\n",
      "Train Epoch: 6 [24320/84843 (29%)]\tLoss: 0.449989\n",
      "Train Epoch: 6 [24960/84843 (29%)]\tLoss: 0.124694\n",
      "Train Epoch: 6 [25600/84843 (30%)]\tLoss: 0.487765\n",
      "Train Epoch: 6 [26240/84843 (31%)]\tLoss: 0.264188\n",
      "Train Epoch: 6 [26880/84843 (32%)]\tLoss: 0.452855\n",
      "Train Epoch: 6 [27520/84843 (32%)]\tLoss: 0.389564\n",
      "Train Epoch: 6 [28160/84843 (33%)]\tLoss: 0.230224\n",
      "Train Epoch: 6 [28800/84843 (34%)]\tLoss: 0.535418\n",
      "Train Epoch: 6 [29440/84843 (35%)]\tLoss: 0.402049\n",
      "Train Epoch: 6 [30080/84843 (35%)]\tLoss: 0.497082\n",
      "Train Epoch: 6 [30720/84843 (36%)]\tLoss: 0.408137\n",
      "Train Epoch: 6 [31360/84843 (37%)]\tLoss: 0.191029\n",
      "Train Epoch: 6 [32000/84843 (38%)]\tLoss: 0.163105\n",
      "Train Epoch: 6 [32640/84843 (38%)]\tLoss: 0.133844\n",
      "Train Epoch: 6 [33280/84843 (39%)]\tLoss: 0.591171\n",
      "Train Epoch: 6 [33920/84843 (40%)]\tLoss: 0.388865\n",
      "Train Epoch: 6 [34560/84843 (41%)]\tLoss: 0.361160\n",
      "Train Epoch: 6 [35200/84843 (41%)]\tLoss: 0.194035\n",
      "Train Epoch: 6 [35840/84843 (42%)]\tLoss: 0.500848\n",
      "Train Epoch: 6 [36480/84843 (43%)]\tLoss: 0.689550\n",
      "Train Epoch: 6 [37120/84843 (44%)]\tLoss: 0.469526\n",
      "Train Epoch: 6 [37760/84843 (44%)]\tLoss: 0.376732\n",
      "Train Epoch: 6 [38400/84843 (45%)]\tLoss: 0.240800\n",
      "Train Epoch: 6 [39040/84843 (46%)]\tLoss: 0.249453\n",
      "Train Epoch: 6 [39680/84843 (47%)]\tLoss: 0.311878\n",
      "Train Epoch: 6 [40320/84843 (48%)]\tLoss: 0.606853\n",
      "Train Epoch: 6 [40960/84843 (48%)]\tLoss: 0.928768\n",
      "Train Epoch: 6 [41600/84843 (49%)]\tLoss: 0.375414\n",
      "Train Epoch: 6 [42240/84843 (50%)]\tLoss: 0.277086\n",
      "Train Epoch: 6 [42880/84843 (51%)]\tLoss: 0.224678\n",
      "Train Epoch: 6 [43520/84843 (51%)]\tLoss: 0.382741\n",
      "Train Epoch: 6 [44160/84843 (52%)]\tLoss: 0.216317\n",
      "Train Epoch: 6 [44800/84843 (53%)]\tLoss: 0.292745\n",
      "Train Epoch: 6 [45440/84843 (54%)]\tLoss: 0.402274\n",
      "Train Epoch: 6 [46080/84843 (54%)]\tLoss: 0.199085\n",
      "Train Epoch: 6 [46720/84843 (55%)]\tLoss: 0.273027\n",
      "Train Epoch: 6 [47360/84843 (56%)]\tLoss: 0.355199\n",
      "Train Epoch: 6 [48000/84843 (57%)]\tLoss: 0.227090\n",
      "Train Epoch: 6 [48640/84843 (57%)]\tLoss: 0.090578\n",
      "Train Epoch: 6 [49280/84843 (58%)]\tLoss: 0.648919\n",
      "Train Epoch: 6 [49920/84843 (59%)]\tLoss: 0.344255\n",
      "Train Epoch: 6 [50560/84843 (60%)]\tLoss: 0.382073\n",
      "Train Epoch: 6 [51200/84843 (60%)]\tLoss: 0.595718\n",
      "Train Epoch: 6 [51840/84843 (61%)]\tLoss: 0.556429\n",
      "Train Epoch: 6 [52480/84843 (62%)]\tLoss: 0.269629\n",
      "Train Epoch: 6 [53120/84843 (63%)]\tLoss: 0.198947\n",
      "Train Epoch: 6 [53760/84843 (63%)]\tLoss: 0.464077\n",
      "Train Epoch: 6 [54400/84843 (64%)]\tLoss: 0.194691\n",
      "Train Epoch: 6 [55040/84843 (65%)]\tLoss: 0.199989\n",
      "Train Epoch: 6 [55680/84843 (66%)]\tLoss: 0.623578\n",
      "Train Epoch: 6 [56320/84843 (66%)]\tLoss: 0.753417\n",
      "Train Epoch: 6 [56960/84843 (67%)]\tLoss: 0.459244\n",
      "Train Epoch: 6 [57600/84843 (68%)]\tLoss: 0.490154\n",
      "Train Epoch: 6 [58240/84843 (69%)]\tLoss: 0.887315\n",
      "Train Epoch: 6 [58880/84843 (69%)]\tLoss: 0.343453\n",
      "Train Epoch: 6 [59520/84843 (70%)]\tLoss: 0.371686\n",
      "Train Epoch: 6 [60160/84843 (71%)]\tLoss: 0.263930\n",
      "Train Epoch: 6 [60800/84843 (72%)]\tLoss: 0.200980\n",
      "Train Epoch: 6 [61440/84843 (72%)]\tLoss: 0.251292\n",
      "Train Epoch: 6 [62080/84843 (73%)]\tLoss: 0.389378\n",
      "Train Epoch: 6 [62720/84843 (74%)]\tLoss: 0.393280\n",
      "Train Epoch: 6 [63360/84843 (75%)]\tLoss: 0.608845\n",
      "Train Epoch: 6 [64000/84843 (75%)]\tLoss: 0.532094\n",
      "Train Epoch: 6 [64640/84843 (76%)]\tLoss: 0.650666\n",
      "Train Epoch: 6 [65280/84843 (77%)]\tLoss: 0.369074\n",
      "Train Epoch: 6 [65920/84843 (78%)]\tLoss: 0.191423\n",
      "Train Epoch: 6 [66560/84843 (78%)]\tLoss: 0.345603\n",
      "Train Epoch: 6 [67200/84843 (79%)]\tLoss: 0.224662\n",
      "Train Epoch: 6 [67840/84843 (80%)]\tLoss: 0.334459\n",
      "Train Epoch: 6 [68480/84843 (81%)]\tLoss: 0.337861\n",
      "Train Epoch: 6 [69120/84843 (81%)]\tLoss: 0.419339\n",
      "Train Epoch: 6 [69760/84843 (82%)]\tLoss: 0.351147\n",
      "Train Epoch: 6 [70400/84843 (83%)]\tLoss: 0.408212\n",
      "Train Epoch: 6 [71040/84843 (84%)]\tLoss: 0.287552\n",
      "Train Epoch: 6 [71680/84843 (84%)]\tLoss: 0.766717\n",
      "Train Epoch: 6 [72320/84843 (85%)]\tLoss: 0.238127\n",
      "Train Epoch: 6 [72960/84843 (86%)]\tLoss: 0.234553\n",
      "Train Epoch: 6 [73600/84843 (87%)]\tLoss: 0.424329\n",
      "Train Epoch: 6 [74240/84843 (87%)]\tLoss: 0.151795\n",
      "Train Epoch: 6 [74880/84843 (88%)]\tLoss: 0.172975\n",
      "Train Epoch: 6 [75520/84843 (89%)]\tLoss: 0.386514\n",
      "Train Epoch: 6 [76160/84843 (90%)]\tLoss: 0.878424\n",
      "Train Epoch: 6 [76800/84843 (90%)]\tLoss: 0.442984\n",
      "Train Epoch: 6 [77440/84843 (91%)]\tLoss: 0.497414\n",
      "Train Epoch: 6 [78080/84843 (92%)]\tLoss: 0.155535\n",
      "Train Epoch: 6 [78720/84843 (93%)]\tLoss: 0.389031\n",
      "Train Epoch: 6 [79360/84843 (94%)]\tLoss: 0.333973\n",
      "Train Epoch: 6 [80000/84843 (94%)]\tLoss: 0.348837\n",
      "Train Epoch: 6 [80640/84843 (95%)]\tLoss: 0.241346\n",
      "Train Epoch: 6 [81280/84843 (96%)]\tLoss: 0.620431\n",
      "Train Epoch: 6 [81920/84843 (97%)]\tLoss: 0.140611\n",
      "Train Epoch: 6 [82560/84843 (97%)]\tLoss: 0.170714\n",
      "Train Epoch: 6 [83200/84843 (98%)]\tLoss: 0.530644\n",
      "Train Epoch: 6 [83840/84843 (99%)]\tLoss: 0.513383\n",
      "Train Epoch: 6 [84480/84843 (100%)]\tLoss: 0.436019\n",
      "Accuracy: 9425/11005 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/84843 (0%)]\tLoss: 0.176500\n",
      "Train Epoch: 7 [640/84843 (1%)]\tLoss: 0.262228\n",
      "Train Epoch: 7 [1280/84843 (2%)]\tLoss: 0.358946\n",
      "Train Epoch: 7 [1920/84843 (2%)]\tLoss: 0.357881\n",
      "Train Epoch: 7 [2560/84843 (3%)]\tLoss: 0.357640\n",
      "Train Epoch: 7 [3200/84843 (4%)]\tLoss: 0.422843\n",
      "Train Epoch: 7 [3840/84843 (5%)]\tLoss: 0.518145\n",
      "Train Epoch: 7 [4480/84843 (5%)]\tLoss: 0.134142\n",
      "Train Epoch: 7 [5120/84843 (6%)]\tLoss: 0.306030\n",
      "Train Epoch: 7 [5760/84843 (7%)]\tLoss: 0.144054\n",
      "Train Epoch: 7 [6400/84843 (8%)]\tLoss: 0.285317\n",
      "Train Epoch: 7 [7040/84843 (8%)]\tLoss: 0.714283\n",
      "Train Epoch: 7 [7680/84843 (9%)]\tLoss: 0.233288\n",
      "Train Epoch: 7 [8320/84843 (10%)]\tLoss: 0.221029\n",
      "Train Epoch: 7 [8960/84843 (11%)]\tLoss: 0.310723\n",
      "Train Epoch: 7 [9600/84843 (11%)]\tLoss: 0.296750\n",
      "Train Epoch: 7 [10240/84843 (12%)]\tLoss: 0.389835\n",
      "Train Epoch: 7 [10880/84843 (13%)]\tLoss: 0.529928\n",
      "Train Epoch: 7 [11520/84843 (14%)]\tLoss: 0.221842\n",
      "Train Epoch: 7 [12160/84843 (14%)]\tLoss: 0.150243\n",
      "Train Epoch: 7 [12800/84843 (15%)]\tLoss: 0.746233\n",
      "Train Epoch: 7 [13440/84843 (16%)]\tLoss: 0.477555\n",
      "Train Epoch: 7 [14080/84843 (17%)]\tLoss: 0.461754\n",
      "Train Epoch: 7 [14720/84843 (17%)]\tLoss: 0.745427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [15360/84843 (18%)]\tLoss: 0.514492\n",
      "Train Epoch: 7 [16000/84843 (19%)]\tLoss: 0.455166\n",
      "Train Epoch: 7 [16640/84843 (20%)]\tLoss: 0.344913\n",
      "Train Epoch: 7 [17280/84843 (20%)]\tLoss: 0.072831\n",
      "Train Epoch: 7 [17920/84843 (21%)]\tLoss: 0.298927\n",
      "Train Epoch: 7 [18560/84843 (22%)]\tLoss: 0.700186\n",
      "Train Epoch: 7 [19200/84843 (23%)]\tLoss: 0.242693\n",
      "Train Epoch: 7 [19840/84843 (23%)]\tLoss: 0.763389\n",
      "Train Epoch: 7 [20480/84843 (24%)]\tLoss: 0.347165\n",
      "Train Epoch: 7 [21120/84843 (25%)]\tLoss: 0.219904\n",
      "Train Epoch: 7 [21760/84843 (26%)]\tLoss: 0.300617\n",
      "Train Epoch: 7 [22400/84843 (26%)]\tLoss: 0.430664\n",
      "Train Epoch: 7 [23040/84843 (27%)]\tLoss: 0.502159\n",
      "Train Epoch: 7 [23680/84843 (28%)]\tLoss: 0.427699\n",
      "Train Epoch: 7 [24320/84843 (29%)]\tLoss: 0.592617\n",
      "Train Epoch: 7 [24960/84843 (29%)]\tLoss: 0.088074\n",
      "Train Epoch: 7 [25600/84843 (30%)]\tLoss: 0.326965\n",
      "Train Epoch: 7 [26240/84843 (31%)]\tLoss: 0.346354\n",
      "Train Epoch: 7 [26880/84843 (32%)]\tLoss: 0.218178\n",
      "Train Epoch: 7 [27520/84843 (32%)]\tLoss: 0.538195\n",
      "Train Epoch: 7 [28160/84843 (33%)]\tLoss: 0.302753\n",
      "Train Epoch: 7 [28800/84843 (34%)]\tLoss: 0.122546\n",
      "Train Epoch: 7 [29440/84843 (35%)]\tLoss: 0.479504\n",
      "Train Epoch: 7 [30080/84843 (35%)]\tLoss: 0.473583\n",
      "Train Epoch: 7 [30720/84843 (36%)]\tLoss: 0.383454\n",
      "Train Epoch: 7 [31360/84843 (37%)]\tLoss: 0.414744\n",
      "Train Epoch: 7 [32000/84843 (38%)]\tLoss: 0.151548\n",
      "Train Epoch: 7 [32640/84843 (38%)]\tLoss: 0.674948\n",
      "Train Epoch: 7 [33280/84843 (39%)]\tLoss: 0.172937\n",
      "Train Epoch: 7 [33920/84843 (40%)]\tLoss: 0.179398\n",
      "Train Epoch: 7 [34560/84843 (41%)]\tLoss: 0.409741\n",
      "Train Epoch: 7 [35200/84843 (41%)]\tLoss: 0.622431\n",
      "Train Epoch: 7 [35840/84843 (42%)]\tLoss: 0.277827\n",
      "Train Epoch: 7 [36480/84843 (43%)]\tLoss: 0.349830\n",
      "Train Epoch: 7 [37120/84843 (44%)]\tLoss: 0.278413\n",
      "Train Epoch: 7 [37760/84843 (44%)]\tLoss: 0.379687\n",
      "Train Epoch: 7 [38400/84843 (45%)]\tLoss: 0.588674\n",
      "Train Epoch: 7 [39040/84843 (46%)]\tLoss: 0.182708\n",
      "Train Epoch: 7 [39680/84843 (47%)]\tLoss: 0.240469\n",
      "Train Epoch: 7 [40320/84843 (48%)]\tLoss: 0.297197\n",
      "Train Epoch: 7 [40960/84843 (48%)]\tLoss: 0.505186\n",
      "Train Epoch: 7 [41600/84843 (49%)]\tLoss: 0.556124\n",
      "Train Epoch: 7 [42240/84843 (50%)]\tLoss: 0.449243\n",
      "Train Epoch: 7 [42880/84843 (51%)]\tLoss: 0.438353\n",
      "Train Epoch: 7 [43520/84843 (51%)]\tLoss: 0.180883\n",
      "Train Epoch: 7 [44160/84843 (52%)]\tLoss: 0.144419\n",
      "Train Epoch: 7 [44800/84843 (53%)]\tLoss: 0.173566\n",
      "Train Epoch: 7 [45440/84843 (54%)]\tLoss: 0.572658\n",
      "Train Epoch: 7 [46080/84843 (54%)]\tLoss: 0.340020\n",
      "Train Epoch: 7 [46720/84843 (55%)]\tLoss: 0.415906\n",
      "Train Epoch: 7 [47360/84843 (56%)]\tLoss: 0.261589\n",
      "Train Epoch: 7 [48000/84843 (57%)]\tLoss: 0.378525\n",
      "Train Epoch: 7 [48640/84843 (57%)]\tLoss: 0.988950\n",
      "Train Epoch: 7 [49280/84843 (58%)]\tLoss: 0.474782\n",
      "Train Epoch: 7 [49920/84843 (59%)]\tLoss: 0.267693\n",
      "Train Epoch: 7 [50560/84843 (60%)]\tLoss: 0.111316\n",
      "Train Epoch: 7 [51200/84843 (60%)]\tLoss: 0.179155\n",
      "Train Epoch: 7 [51840/84843 (61%)]\tLoss: 0.532242\n",
      "Train Epoch: 7 [52480/84843 (62%)]\tLoss: 0.453022\n",
      "Train Epoch: 7 [53120/84843 (63%)]\tLoss: 0.244594\n",
      "Train Epoch: 7 [53760/84843 (63%)]\tLoss: 0.365458\n",
      "Train Epoch: 7 [54400/84843 (64%)]\tLoss: 0.313980\n",
      "Train Epoch: 7 [55040/84843 (65%)]\tLoss: 0.440416\n",
      "Train Epoch: 7 [55680/84843 (66%)]\tLoss: 0.079049\n",
      "Train Epoch: 7 [56320/84843 (66%)]\tLoss: 0.276866\n",
      "Train Epoch: 7 [56960/84843 (67%)]\tLoss: 0.398978\n",
      "Train Epoch: 7 [57600/84843 (68%)]\tLoss: 0.432176\n",
      "Train Epoch: 7 [58240/84843 (69%)]\tLoss: 0.323614\n",
      "Train Epoch: 7 [58880/84843 (69%)]\tLoss: 0.668913\n",
      "Train Epoch: 7 [59520/84843 (70%)]\tLoss: 0.165527\n",
      "Train Epoch: 7 [60160/84843 (71%)]\tLoss: 0.659042\n",
      "Train Epoch: 7 [60800/84843 (72%)]\tLoss: 0.247334\n",
      "Train Epoch: 7 [61440/84843 (72%)]\tLoss: 0.258718\n",
      "Train Epoch: 7 [62080/84843 (73%)]\tLoss: 0.439378\n",
      "Train Epoch: 7 [62720/84843 (74%)]\tLoss: 0.442836\n",
      "Train Epoch: 7 [63360/84843 (75%)]\tLoss: 0.557214\n",
      "Train Epoch: 7 [64000/84843 (75%)]\tLoss: 0.489925\n",
      "Train Epoch: 7 [64640/84843 (76%)]\tLoss: 0.331699\n",
      "Train Epoch: 7 [65280/84843 (77%)]\tLoss: 0.226661\n",
      "Train Epoch: 7 [65920/84843 (78%)]\tLoss: 0.350313\n",
      "Train Epoch: 7 [66560/84843 (78%)]\tLoss: 0.646073\n",
      "Train Epoch: 7 [67200/84843 (79%)]\tLoss: 0.876919\n",
      "Train Epoch: 7 [67840/84843 (80%)]\tLoss: 0.395828\n",
      "Train Epoch: 7 [68480/84843 (81%)]\tLoss: 0.627853\n",
      "Train Epoch: 7 [69120/84843 (81%)]\tLoss: 0.526311\n",
      "Train Epoch: 7 [69760/84843 (82%)]\tLoss: 0.237820\n",
      "Train Epoch: 7 [70400/84843 (83%)]\tLoss: 0.351563\n",
      "Train Epoch: 7 [71040/84843 (84%)]\tLoss: 0.434736\n",
      "Train Epoch: 7 [71680/84843 (84%)]\tLoss: 0.431942\n",
      "Train Epoch: 7 [72320/84843 (85%)]\tLoss: 0.668834\n",
      "Train Epoch: 7 [72960/84843 (86%)]\tLoss: 0.410392\n",
      "Train Epoch: 7 [73600/84843 (87%)]\tLoss: 0.258799\n",
      "Train Epoch: 7 [74240/84843 (87%)]\tLoss: 0.247237\n",
      "Train Epoch: 7 [74880/84843 (88%)]\tLoss: 0.462183\n",
      "Train Epoch: 7 [75520/84843 (89%)]\tLoss: 0.718784\n",
      "Train Epoch: 7 [76160/84843 (90%)]\tLoss: 0.513402\n",
      "Train Epoch: 7 [76800/84843 (90%)]\tLoss: 0.596350\n",
      "Train Epoch: 7 [77440/84843 (91%)]\tLoss: 0.520101\n",
      "Train Epoch: 7 [78080/84843 (92%)]\tLoss: 0.341115\n",
      "Train Epoch: 7 [78720/84843 (93%)]\tLoss: 0.185755\n",
      "Train Epoch: 7 [79360/84843 (94%)]\tLoss: 0.190244\n",
      "Train Epoch: 7 [80000/84843 (94%)]\tLoss: 0.872646\n",
      "Train Epoch: 7 [80640/84843 (95%)]\tLoss: 0.246698\n",
      "Train Epoch: 7 [81280/84843 (96%)]\tLoss: 0.437279\n",
      "Train Epoch: 7 [81920/84843 (97%)]\tLoss: 0.548468\n",
      "Train Epoch: 7 [82560/84843 (97%)]\tLoss: 0.158184\n",
      "Train Epoch: 7 [83200/84843 (98%)]\tLoss: 0.953523\n",
      "Train Epoch: 7 [83840/84843 (99%)]\tLoss: 0.381990\n",
      "Train Epoch: 7 [84480/84843 (100%)]\tLoss: 0.421709\n",
      "Accuracy: 9313/11005 (85%)\n",
      "\n",
      "Train Epoch: 8 [0/84843 (0%)]\tLoss: 0.601739\n",
      "Train Epoch: 8 [640/84843 (1%)]\tLoss: 0.084050\n",
      "Train Epoch: 8 [1280/84843 (2%)]\tLoss: 0.263174\n",
      "Train Epoch: 8 [1920/84843 (2%)]\tLoss: 0.153999\n",
      "Train Epoch: 8 [2560/84843 (3%)]\tLoss: 0.237093\n",
      "Train Epoch: 8 [3200/84843 (4%)]\tLoss: 0.261663\n",
      "Train Epoch: 8 [3840/84843 (5%)]\tLoss: 0.182395\n",
      "Train Epoch: 8 [4480/84843 (5%)]\tLoss: 0.421704\n",
      "Train Epoch: 8 [5120/84843 (6%)]\tLoss: 0.338279\n",
      "Train Epoch: 8 [5760/84843 (7%)]\tLoss: 0.463381\n",
      "Train Epoch: 8 [6400/84843 (8%)]\tLoss: 0.079821\n",
      "Train Epoch: 8 [7040/84843 (8%)]\tLoss: 0.225087\n",
      "Train Epoch: 8 [7680/84843 (9%)]\tLoss: 0.378046\n",
      "Train Epoch: 8 [8320/84843 (10%)]\tLoss: 0.152575\n",
      "Train Epoch: 8 [8960/84843 (11%)]\tLoss: 0.291169\n",
      "Train Epoch: 8 [9600/84843 (11%)]\tLoss: 0.161189\n",
      "Train Epoch: 8 [10240/84843 (12%)]\tLoss: 0.401740\n",
      "Train Epoch: 8 [10880/84843 (13%)]\tLoss: 0.141714\n",
      "Train Epoch: 8 [11520/84843 (14%)]\tLoss: 0.642208\n",
      "Train Epoch: 8 [12160/84843 (14%)]\tLoss: 0.377644\n",
      "Train Epoch: 8 [12800/84843 (15%)]\tLoss: 0.288285\n",
      "Train Epoch: 8 [13440/84843 (16%)]\tLoss: 0.419307\n",
      "Train Epoch: 8 [14080/84843 (17%)]\tLoss: 0.249252\n",
      "Train Epoch: 8 [14720/84843 (17%)]\tLoss: 0.508801\n",
      "Train Epoch: 8 [15360/84843 (18%)]\tLoss: 0.455490\n",
      "Train Epoch: 8 [16000/84843 (19%)]\tLoss: 0.471695\n",
      "Train Epoch: 8 [16640/84843 (20%)]\tLoss: 0.060825\n",
      "Train Epoch: 8 [17280/84843 (20%)]\tLoss: 0.268253\n",
      "Train Epoch: 8 [17920/84843 (21%)]\tLoss: 0.077461\n",
      "Train Epoch: 8 [18560/84843 (22%)]\tLoss: 0.721895\n",
      "Train Epoch: 8 [19200/84843 (23%)]\tLoss: 0.457393\n",
      "Train Epoch: 8 [19840/84843 (23%)]\tLoss: 0.179696\n",
      "Train Epoch: 8 [20480/84843 (24%)]\tLoss: 0.227334\n",
      "Train Epoch: 8 [21120/84843 (25%)]\tLoss: 0.276376\n",
      "Train Epoch: 8 [21760/84843 (26%)]\tLoss: 0.349648\n",
      "Train Epoch: 8 [22400/84843 (26%)]\tLoss: 0.288163\n",
      "Train Epoch: 8 [23040/84843 (27%)]\tLoss: 0.583571\n",
      "Train Epoch: 8 [23680/84843 (28%)]\tLoss: 0.605491\n",
      "Train Epoch: 8 [24320/84843 (29%)]\tLoss: 0.155065\n",
      "Train Epoch: 8 [24960/84843 (29%)]\tLoss: 0.115809\n",
      "Train Epoch: 8 [25600/84843 (30%)]\tLoss: 0.484553\n",
      "Train Epoch: 8 [26240/84843 (31%)]\tLoss: 0.323005\n",
      "Train Epoch: 8 [26880/84843 (32%)]\tLoss: 0.195693\n",
      "Train Epoch: 8 [27520/84843 (32%)]\tLoss: 0.256121\n",
      "Train Epoch: 8 [28160/84843 (33%)]\tLoss: 0.441887\n",
      "Train Epoch: 8 [28800/84843 (34%)]\tLoss: 0.149179\n",
      "Train Epoch: 8 [29440/84843 (35%)]\tLoss: 0.468092\n",
      "Train Epoch: 8 [30080/84843 (35%)]\tLoss: 0.588054\n",
      "Train Epoch: 8 [30720/84843 (36%)]\tLoss: 0.377728\n",
      "Train Epoch: 8 [31360/84843 (37%)]\tLoss: 0.414827\n",
      "Train Epoch: 8 [32000/84843 (38%)]\tLoss: 0.390515\n",
      "Train Epoch: 8 [32640/84843 (38%)]\tLoss: 0.697267\n",
      "Train Epoch: 8 [33280/84843 (39%)]\tLoss: 0.201402\n",
      "Train Epoch: 8 [33920/84843 (40%)]\tLoss: 0.114943\n",
      "Train Epoch: 8 [34560/84843 (41%)]\tLoss: 0.581994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [35200/84843 (41%)]\tLoss: 0.342253\n",
      "Train Epoch: 8 [35840/84843 (42%)]\tLoss: 0.349971\n",
      "Train Epoch: 8 [36480/84843 (43%)]\tLoss: 0.158677\n",
      "Train Epoch: 8 [37120/84843 (44%)]\tLoss: 0.513398\n",
      "Train Epoch: 8 [37760/84843 (44%)]\tLoss: 0.409590\n",
      "Train Epoch: 8 [38400/84843 (45%)]\tLoss: 0.322341\n",
      "Train Epoch: 8 [39040/84843 (46%)]\tLoss: 0.531336\n",
      "Train Epoch: 8 [39680/84843 (47%)]\tLoss: 0.514387\n",
      "Train Epoch: 8 [40320/84843 (48%)]\tLoss: 0.315151\n",
      "Train Epoch: 8 [40960/84843 (48%)]\tLoss: 0.263945\n",
      "Train Epoch: 8 [41600/84843 (49%)]\tLoss: 0.258560\n",
      "Train Epoch: 8 [42240/84843 (50%)]\tLoss: 0.388564\n",
      "Train Epoch: 8 [42880/84843 (51%)]\tLoss: 0.351803\n",
      "Train Epoch: 8 [43520/84843 (51%)]\tLoss: 0.653758\n",
      "Train Epoch: 8 [44160/84843 (52%)]\tLoss: 0.323043\n",
      "Train Epoch: 8 [44800/84843 (53%)]\tLoss: 0.598970\n",
      "Train Epoch: 8 [45440/84843 (54%)]\tLoss: 0.319212\n",
      "Train Epoch: 8 [46080/84843 (54%)]\tLoss: 0.153154\n",
      "Train Epoch: 8 [46720/84843 (55%)]\tLoss: 0.324718\n",
      "Train Epoch: 8 [47360/84843 (56%)]\tLoss: 0.320953\n",
      "Train Epoch: 8 [48000/84843 (57%)]\tLoss: 0.338239\n",
      "Train Epoch: 8 [48640/84843 (57%)]\tLoss: 0.462908\n",
      "Train Epoch: 8 [49280/84843 (58%)]\tLoss: 0.241039\n",
      "Train Epoch: 8 [49920/84843 (59%)]\tLoss: 0.094773\n",
      "Train Epoch: 8 [50560/84843 (60%)]\tLoss: 0.688545\n",
      "Train Epoch: 8 [51200/84843 (60%)]\tLoss: 0.232981\n",
      "Train Epoch: 8 [51840/84843 (61%)]\tLoss: 0.406116\n",
      "Train Epoch: 8 [52480/84843 (62%)]\tLoss: 0.441133\n",
      "Train Epoch: 8 [53120/84843 (63%)]\tLoss: 0.435691\n",
      "Train Epoch: 8 [53760/84843 (63%)]\tLoss: 0.453832\n",
      "Train Epoch: 8 [54400/84843 (64%)]\tLoss: 0.266646\n",
      "Train Epoch: 8 [55040/84843 (65%)]\tLoss: 0.363363\n",
      "Train Epoch: 8 [55680/84843 (66%)]\tLoss: 0.274330\n",
      "Train Epoch: 8 [56320/84843 (66%)]\tLoss: 0.493485\n",
      "Train Epoch: 8 [56960/84843 (67%)]\tLoss: 0.125131\n",
      "Train Epoch: 8 [57600/84843 (68%)]\tLoss: 0.586176\n",
      "Train Epoch: 8 [58240/84843 (69%)]\tLoss: 0.453722\n",
      "Train Epoch: 8 [58880/84843 (69%)]\tLoss: 0.108983\n",
      "Train Epoch: 8 [59520/84843 (70%)]\tLoss: 0.517403\n",
      "Train Epoch: 8 [60160/84843 (71%)]\tLoss: 0.338496\n",
      "Train Epoch: 8 [60800/84843 (72%)]\tLoss: 0.325914\n",
      "Train Epoch: 8 [61440/84843 (72%)]\tLoss: 0.275840\n",
      "Train Epoch: 8 [62080/84843 (73%)]\tLoss: 0.238576\n",
      "Train Epoch: 8 [62720/84843 (74%)]\tLoss: 0.383061\n",
      "Train Epoch: 8 [63360/84843 (75%)]\tLoss: 0.509624\n",
      "Train Epoch: 8 [64000/84843 (75%)]\tLoss: 0.123558\n",
      "Train Epoch: 8 [64640/84843 (76%)]\tLoss: 0.429077\n",
      "Train Epoch: 8 [65280/84843 (77%)]\tLoss: 0.350696\n",
      "Train Epoch: 8 [65920/84843 (78%)]\tLoss: 0.337588\n",
      "Train Epoch: 8 [66560/84843 (78%)]\tLoss: 0.536318\n",
      "Train Epoch: 8 [67200/84843 (79%)]\tLoss: 0.600249\n",
      "Train Epoch: 8 [67840/84843 (80%)]\tLoss: 0.509241\n",
      "Train Epoch: 8 [68480/84843 (81%)]\tLoss: 0.451242\n",
      "Train Epoch: 8 [69120/84843 (81%)]\tLoss: 0.521189\n",
      "Train Epoch: 8 [69760/84843 (82%)]\tLoss: 0.252174\n",
      "Train Epoch: 8 [70400/84843 (83%)]\tLoss: 0.278791\n",
      "Train Epoch: 8 [71040/84843 (84%)]\tLoss: 0.607213\n",
      "Train Epoch: 8 [71680/84843 (84%)]\tLoss: 0.437751\n",
      "Train Epoch: 8 [72320/84843 (85%)]\tLoss: 0.282464\n",
      "Train Epoch: 8 [72960/84843 (86%)]\tLoss: 0.564071\n",
      "Train Epoch: 8 [73600/84843 (87%)]\tLoss: 0.316576\n",
      "Train Epoch: 8 [74240/84843 (87%)]\tLoss: 0.400464\n",
      "Train Epoch: 8 [74880/84843 (88%)]\tLoss: 0.936126\n",
      "Train Epoch: 8 [75520/84843 (89%)]\tLoss: 0.147415\n",
      "Train Epoch: 8 [76160/84843 (90%)]\tLoss: 0.287193\n",
      "Train Epoch: 8 [76800/84843 (90%)]\tLoss: 0.430268\n",
      "Train Epoch: 8 [77440/84843 (91%)]\tLoss: 0.328542\n",
      "Train Epoch: 8 [78080/84843 (92%)]\tLoss: 0.248598\n",
      "Train Epoch: 8 [78720/84843 (93%)]\tLoss: 0.656041\n",
      "Train Epoch: 8 [79360/84843 (94%)]\tLoss: 0.565840\n",
      "Train Epoch: 8 [80000/84843 (94%)]\tLoss: 0.429996\n",
      "Train Epoch: 8 [80640/84843 (95%)]\tLoss: 0.265349\n",
      "Train Epoch: 8 [81280/84843 (96%)]\tLoss: 0.455121\n",
      "Train Epoch: 8 [81920/84843 (97%)]\tLoss: 0.569032\n",
      "Train Epoch: 8 [82560/84843 (97%)]\tLoss: 0.456987\n",
      "Train Epoch: 8 [83200/84843 (98%)]\tLoss: 0.242797\n",
      "Train Epoch: 8 [83840/84843 (99%)]\tLoss: 0.409415\n",
      "Train Epoch: 8 [84480/84843 (100%)]\tLoss: 0.126247\n",
      "Accuracy: 9480/11005 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/84843 (0%)]\tLoss: 0.320068\n",
      "Train Epoch: 9 [640/84843 (1%)]\tLoss: 0.187122\n",
      "Train Epoch: 9 [1280/84843 (2%)]\tLoss: 0.138902\n",
      "Train Epoch: 9 [1920/84843 (2%)]\tLoss: 0.187417\n",
      "Train Epoch: 9 [2560/84843 (3%)]\tLoss: 0.167323\n",
      "Train Epoch: 9 [3200/84843 (4%)]\tLoss: 0.216750\n",
      "Train Epoch: 9 [3840/84843 (5%)]\tLoss: 0.193968\n",
      "Train Epoch: 9 [4480/84843 (5%)]\tLoss: 0.107674\n",
      "Train Epoch: 9 [5120/84843 (6%)]\tLoss: 0.238984\n",
      "Train Epoch: 9 [5760/84843 (7%)]\tLoss: 0.918764\n",
      "Train Epoch: 9 [6400/84843 (8%)]\tLoss: 0.168768\n",
      "Train Epoch: 9 [7040/84843 (8%)]\tLoss: 0.435514\n",
      "Train Epoch: 9 [7680/84843 (9%)]\tLoss: 0.123892\n",
      "Train Epoch: 9 [8320/84843 (10%)]\tLoss: 0.288309\n",
      "Train Epoch: 9 [8960/84843 (11%)]\tLoss: 0.239906\n",
      "Train Epoch: 9 [9600/84843 (11%)]\tLoss: 0.413980\n",
      "Train Epoch: 9 [10240/84843 (12%)]\tLoss: 0.243110\n",
      "Train Epoch: 9 [10880/84843 (13%)]\tLoss: 0.291534\n",
      "Train Epoch: 9 [11520/84843 (14%)]\tLoss: 0.236795\n",
      "Train Epoch: 9 [12160/84843 (14%)]\tLoss: 0.261546\n",
      "Train Epoch: 9 [12800/84843 (15%)]\tLoss: 0.237705\n",
      "Train Epoch: 9 [13440/84843 (16%)]\tLoss: 0.643895\n",
      "Train Epoch: 9 [14080/84843 (17%)]\tLoss: 0.555997\n",
      "Train Epoch: 9 [14720/84843 (17%)]\tLoss: 0.303446\n",
      "Train Epoch: 9 [15360/84843 (18%)]\tLoss: 0.405728\n",
      "Train Epoch: 9 [16000/84843 (19%)]\tLoss: 0.178577\n",
      "Train Epoch: 9 [16640/84843 (20%)]\tLoss: 0.312093\n",
      "Train Epoch: 9 [17280/84843 (20%)]\tLoss: 0.396857\n",
      "Train Epoch: 9 [17920/84843 (21%)]\tLoss: 0.323028\n",
      "Train Epoch: 9 [18560/84843 (22%)]\tLoss: 0.476438\n",
      "Train Epoch: 9 [19200/84843 (23%)]\tLoss: 0.322031\n",
      "Train Epoch: 9 [19840/84843 (23%)]\tLoss: 0.521464\n",
      "Train Epoch: 9 [20480/84843 (24%)]\tLoss: 0.260318\n",
      "Train Epoch: 9 [21120/84843 (25%)]\tLoss: 0.315792\n",
      "Train Epoch: 9 [21760/84843 (26%)]\tLoss: 0.542976\n",
      "Train Epoch: 9 [22400/84843 (26%)]\tLoss: 0.555087\n",
      "Train Epoch: 9 [23040/84843 (27%)]\tLoss: 0.317761\n",
      "Train Epoch: 9 [23680/84843 (28%)]\tLoss: 0.623487\n",
      "Train Epoch: 9 [24320/84843 (29%)]\tLoss: 0.240079\n",
      "Train Epoch: 9 [24960/84843 (29%)]\tLoss: 0.482356\n",
      "Train Epoch: 9 [25600/84843 (30%)]\tLoss: 0.341380\n",
      "Train Epoch: 9 [26240/84843 (31%)]\tLoss: 0.270599\n",
      "Train Epoch: 9 [26880/84843 (32%)]\tLoss: 0.323065\n",
      "Train Epoch: 9 [27520/84843 (32%)]\tLoss: 0.279825\n",
      "Train Epoch: 9 [28160/84843 (33%)]\tLoss: 0.072046\n",
      "Train Epoch: 9 [28800/84843 (34%)]\tLoss: 0.370851\n",
      "Train Epoch: 9 [29440/84843 (35%)]\tLoss: 0.403878\n",
      "Train Epoch: 9 [30080/84843 (35%)]\tLoss: 0.387362\n",
      "Train Epoch: 9 [30720/84843 (36%)]\tLoss: 0.369177\n",
      "Train Epoch: 9 [31360/84843 (37%)]\tLoss: 0.541932\n",
      "Train Epoch: 9 [32000/84843 (38%)]\tLoss: 0.135747\n",
      "Train Epoch: 9 [32640/84843 (38%)]\tLoss: 0.236275\n",
      "Train Epoch: 9 [33280/84843 (39%)]\tLoss: 0.189825\n",
      "Train Epoch: 9 [33920/84843 (40%)]\tLoss: 0.387897\n",
      "Train Epoch: 9 [34560/84843 (41%)]\tLoss: 0.144524\n",
      "Train Epoch: 9 [35200/84843 (41%)]\tLoss: 0.694650\n",
      "Train Epoch: 9 [35840/84843 (42%)]\tLoss: 0.314508\n",
      "Train Epoch: 9 [36480/84843 (43%)]\tLoss: 0.651653\n",
      "Train Epoch: 9 [37120/84843 (44%)]\tLoss: 0.341878\n",
      "Train Epoch: 9 [37760/84843 (44%)]\tLoss: 0.146840\n",
      "Train Epoch: 9 [38400/84843 (45%)]\tLoss: 0.357087\n",
      "Train Epoch: 9 [39040/84843 (46%)]\tLoss: 0.331428\n",
      "Train Epoch: 9 [39680/84843 (47%)]\tLoss: 0.424125\n",
      "Train Epoch: 9 [40320/84843 (48%)]\tLoss: 0.623581\n",
      "Train Epoch: 9 [40960/84843 (48%)]\tLoss: 0.109604\n",
      "Train Epoch: 9 [41600/84843 (49%)]\tLoss: 0.382459\n",
      "Train Epoch: 9 [42240/84843 (50%)]\tLoss: 0.179247\n",
      "Train Epoch: 9 [42880/84843 (51%)]\tLoss: 0.411590\n",
      "Train Epoch: 9 [43520/84843 (51%)]\tLoss: 0.366355\n",
      "Train Epoch: 9 [44160/84843 (52%)]\tLoss: 0.283169\n",
      "Train Epoch: 9 [44800/84843 (53%)]\tLoss: 0.483931\n",
      "Train Epoch: 9 [45440/84843 (54%)]\tLoss: 0.215864\n",
      "Train Epoch: 9 [46080/84843 (54%)]\tLoss: 0.185880\n",
      "Train Epoch: 9 [46720/84843 (55%)]\tLoss: 0.316259\n",
      "Train Epoch: 9 [47360/84843 (56%)]\tLoss: 0.404702\n",
      "Train Epoch: 9 [48000/84843 (57%)]\tLoss: 0.469701\n",
      "Train Epoch: 9 [48640/84843 (57%)]\tLoss: 0.171171\n",
      "Train Epoch: 9 [49280/84843 (58%)]\tLoss: 0.128943\n",
      "Train Epoch: 9 [49920/84843 (59%)]\tLoss: 0.265470\n",
      "Train Epoch: 9 [50560/84843 (60%)]\tLoss: 0.390461\n",
      "Train Epoch: 9 [51200/84843 (60%)]\tLoss: 0.525444\n",
      "Train Epoch: 9 [51840/84843 (61%)]\tLoss: 0.311893\n",
      "Train Epoch: 9 [52480/84843 (62%)]\tLoss: 0.506583\n",
      "Train Epoch: 9 [53120/84843 (63%)]\tLoss: 0.198315\n",
      "Train Epoch: 9 [53760/84843 (63%)]\tLoss: 0.470857\n",
      "Train Epoch: 9 [54400/84843 (64%)]\tLoss: 0.453576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [55040/84843 (65%)]\tLoss: 0.688950\n",
      "Train Epoch: 9 [55680/84843 (66%)]\tLoss: 0.715418\n",
      "Train Epoch: 9 [56320/84843 (66%)]\tLoss: 0.222106\n",
      "Train Epoch: 9 [56960/84843 (67%)]\tLoss: 0.554668\n",
      "Train Epoch: 9 [57600/84843 (68%)]\tLoss: 0.252369\n",
      "Train Epoch: 9 [58240/84843 (69%)]\tLoss: 0.388328\n",
      "Train Epoch: 9 [58880/84843 (69%)]\tLoss: 0.331477\n",
      "Train Epoch: 9 [59520/84843 (70%)]\tLoss: 0.501346\n",
      "Train Epoch: 9 [60160/84843 (71%)]\tLoss: 0.147419\n",
      "Train Epoch: 9 [60800/84843 (72%)]\tLoss: 0.477601\n",
      "Train Epoch: 9 [61440/84843 (72%)]\tLoss: 0.383733\n",
      "Train Epoch: 9 [62080/84843 (73%)]\tLoss: 0.187526\n",
      "Train Epoch: 9 [62720/84843 (74%)]\tLoss: 0.264233\n",
      "Train Epoch: 9 [63360/84843 (75%)]\tLoss: 0.327858\n",
      "Train Epoch: 9 [64000/84843 (75%)]\tLoss: 0.362753\n",
      "Train Epoch: 9 [64640/84843 (76%)]\tLoss: 0.322493\n",
      "Train Epoch: 9 [65280/84843 (77%)]\tLoss: 0.217771\n",
      "Train Epoch: 9 [65920/84843 (78%)]\tLoss: 0.782282\n",
      "Train Epoch: 9 [66560/84843 (78%)]\tLoss: 0.286254\n",
      "Train Epoch: 9 [67200/84843 (79%)]\tLoss: 0.708295\n",
      "Train Epoch: 9 [67840/84843 (80%)]\tLoss: 0.414276\n",
      "Train Epoch: 9 [68480/84843 (81%)]\tLoss: 0.432944\n",
      "Train Epoch: 9 [69120/84843 (81%)]\tLoss: 0.500136\n",
      "Train Epoch: 9 [69760/84843 (82%)]\tLoss: 0.533017\n",
      "Train Epoch: 9 [70400/84843 (83%)]\tLoss: 0.524352\n",
      "Train Epoch: 9 [71040/84843 (84%)]\tLoss: 0.494676\n",
      "Train Epoch: 9 [71680/84843 (84%)]\tLoss: 0.620061\n",
      "Train Epoch: 9 [72320/84843 (85%)]\tLoss: 0.328423\n",
      "Train Epoch: 9 [72960/84843 (86%)]\tLoss: 0.533239\n",
      "Train Epoch: 9 [73600/84843 (87%)]\tLoss: 0.267557\n",
      "Train Epoch: 9 [74240/84843 (87%)]\tLoss: 0.289231\n",
      "Train Epoch: 9 [74880/84843 (88%)]\tLoss: 0.350180\n",
      "Train Epoch: 9 [75520/84843 (89%)]\tLoss: 0.207146\n",
      "Train Epoch: 9 [76160/84843 (90%)]\tLoss: 0.224327\n",
      "Train Epoch: 9 [76800/84843 (90%)]\tLoss: 0.558979\n",
      "Train Epoch: 9 [77440/84843 (91%)]\tLoss: 0.674331\n",
      "Train Epoch: 9 [78080/84843 (92%)]\tLoss: 0.287156\n",
      "Train Epoch: 9 [78720/84843 (93%)]\tLoss: 0.449807\n",
      "Train Epoch: 9 [79360/84843 (94%)]\tLoss: 0.097482\n",
      "Train Epoch: 9 [80000/84843 (94%)]\tLoss: 0.533352\n",
      "Train Epoch: 9 [80640/84843 (95%)]\tLoss: 0.443873\n",
      "Train Epoch: 9 [81280/84843 (96%)]\tLoss: 0.528967\n",
      "Train Epoch: 9 [81920/84843 (97%)]\tLoss: 0.657186\n",
      "Train Epoch: 9 [82560/84843 (97%)]\tLoss: 0.245606\n",
      "Train Epoch: 9 [83200/84843 (98%)]\tLoss: 0.395932\n",
      "Train Epoch: 9 [83840/84843 (99%)]\tLoss: 0.449092\n",
      "Train Epoch: 9 [84480/84843 (100%)]\tLoss: 0.417664\n",
      "Accuracy: 9442/11005 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/84843 (0%)]\tLoss: 0.481850\n",
      "Train Epoch: 10 [640/84843 (1%)]\tLoss: 0.267916\n",
      "Train Epoch: 10 [1280/84843 (2%)]\tLoss: 0.635692\n",
      "Train Epoch: 10 [1920/84843 (2%)]\tLoss: 0.451723\n",
      "Train Epoch: 10 [2560/84843 (3%)]\tLoss: 0.298357\n",
      "Train Epoch: 10 [3200/84843 (4%)]\tLoss: 0.599096\n",
      "Train Epoch: 10 [3840/84843 (5%)]\tLoss: 0.217061\n",
      "Train Epoch: 10 [4480/84843 (5%)]\tLoss: 0.542934\n",
      "Train Epoch: 10 [5120/84843 (6%)]\tLoss: 0.448370\n",
      "Train Epoch: 10 [5760/84843 (7%)]\tLoss: 0.565467\n",
      "Train Epoch: 10 [6400/84843 (8%)]\tLoss: 0.364380\n",
      "Train Epoch: 10 [7040/84843 (8%)]\tLoss: 0.330765\n",
      "Train Epoch: 10 [7680/84843 (9%)]\tLoss: 0.251681\n",
      "Train Epoch: 10 [8320/84843 (10%)]\tLoss: 0.309583\n",
      "Train Epoch: 10 [8960/84843 (11%)]\tLoss: 0.294952\n",
      "Train Epoch: 10 [9600/84843 (11%)]\tLoss: 0.241992\n",
      "Train Epoch: 10 [10240/84843 (12%)]\tLoss: 0.224026\n",
      "Train Epoch: 10 [10880/84843 (13%)]\tLoss: 0.439019\n",
      "Train Epoch: 10 [11520/84843 (14%)]\tLoss: 0.279499\n",
      "Train Epoch: 10 [12160/84843 (14%)]\tLoss: 0.278735\n",
      "Train Epoch: 10 [12800/84843 (15%)]\tLoss: 0.109274\n",
      "Train Epoch: 10 [13440/84843 (16%)]\tLoss: 0.620889\n",
      "Train Epoch: 10 [14080/84843 (17%)]\tLoss: 0.088169\n",
      "Train Epoch: 10 [14720/84843 (17%)]\tLoss: 0.134040\n",
      "Train Epoch: 10 [15360/84843 (18%)]\tLoss: 0.287763\n",
      "Train Epoch: 10 [16000/84843 (19%)]\tLoss: 0.417828\n",
      "Train Epoch: 10 [16640/84843 (20%)]\tLoss: 0.540845\n",
      "Train Epoch: 10 [17280/84843 (20%)]\tLoss: 0.337266\n",
      "Train Epoch: 10 [17920/84843 (21%)]\tLoss: 0.330733\n",
      "Train Epoch: 10 [18560/84843 (22%)]\tLoss: 0.434891\n",
      "Train Epoch: 10 [19200/84843 (23%)]\tLoss: 0.268952\n",
      "Train Epoch: 10 [19840/84843 (23%)]\tLoss: 0.276065\n",
      "Train Epoch: 10 [20480/84843 (24%)]\tLoss: 0.094592\n",
      "Train Epoch: 10 [21120/84843 (25%)]\tLoss: 0.222025\n",
      "Train Epoch: 10 [21760/84843 (26%)]\tLoss: 0.385423\n",
      "Train Epoch: 10 [22400/84843 (26%)]\tLoss: 0.238346\n",
      "Train Epoch: 10 [23040/84843 (27%)]\tLoss: 0.159571\n",
      "Train Epoch: 10 [23680/84843 (28%)]\tLoss: 0.297377\n",
      "Train Epoch: 10 [24320/84843 (29%)]\tLoss: 0.455901\n",
      "Train Epoch: 10 [24960/84843 (29%)]\tLoss: 0.134043\n",
      "Train Epoch: 10 [25600/84843 (30%)]\tLoss: 0.526476\n",
      "Train Epoch: 10 [26240/84843 (31%)]\tLoss: 0.251126\n",
      "Train Epoch: 10 [26880/84843 (32%)]\tLoss: 0.393955\n",
      "Train Epoch: 10 [27520/84843 (32%)]\tLoss: 0.463720\n",
      "Train Epoch: 10 [28160/84843 (33%)]\tLoss: 0.317556\n",
      "Train Epoch: 10 [28800/84843 (34%)]\tLoss: 0.290672\n",
      "Train Epoch: 10 [29440/84843 (35%)]\tLoss: 0.391382\n",
      "Train Epoch: 10 [30080/84843 (35%)]\tLoss: 0.211861\n",
      "Train Epoch: 10 [30720/84843 (36%)]\tLoss: 0.208598\n",
      "Train Epoch: 10 [31360/84843 (37%)]\tLoss: 0.648055\n",
      "Train Epoch: 10 [32000/84843 (38%)]\tLoss: 0.267511\n",
      "Train Epoch: 10 [32640/84843 (38%)]\tLoss: 0.273879\n",
      "Train Epoch: 10 [33280/84843 (39%)]\tLoss: 0.361388\n",
      "Train Epoch: 10 [33920/84843 (40%)]\tLoss: 0.433269\n",
      "Train Epoch: 10 [34560/84843 (41%)]\tLoss: 0.627546\n",
      "Train Epoch: 10 [35200/84843 (41%)]\tLoss: 0.350613\n",
      "Train Epoch: 10 [35840/84843 (42%)]\tLoss: 0.280276\n",
      "Train Epoch: 10 [36480/84843 (43%)]\tLoss: 0.735333\n",
      "Train Epoch: 10 [37120/84843 (44%)]\tLoss: 0.169048\n",
      "Train Epoch: 10 [37760/84843 (44%)]\tLoss: 0.247454\n",
      "Train Epoch: 10 [38400/84843 (45%)]\tLoss: 0.376546\n",
      "Train Epoch: 10 [39040/84843 (46%)]\tLoss: 0.454539\n",
      "Train Epoch: 10 [39680/84843 (47%)]\tLoss: 0.316888\n",
      "Train Epoch: 10 [40320/84843 (48%)]\tLoss: 0.243700\n",
      "Train Epoch: 10 [40960/84843 (48%)]\tLoss: 0.418838\n",
      "Train Epoch: 10 [41600/84843 (49%)]\tLoss: 0.289281\n",
      "Train Epoch: 10 [42240/84843 (50%)]\tLoss: 0.349854\n",
      "Train Epoch: 10 [42880/84843 (51%)]\tLoss: 0.685653\n",
      "Train Epoch: 10 [43520/84843 (51%)]\tLoss: 0.610446\n",
      "Train Epoch: 10 [44160/84843 (52%)]\tLoss: 0.250953\n",
      "Train Epoch: 10 [44800/84843 (53%)]\tLoss: 0.387922\n",
      "Train Epoch: 10 [45440/84843 (54%)]\tLoss: 0.279832\n",
      "Train Epoch: 10 [46080/84843 (54%)]\tLoss: 0.287614\n",
      "Train Epoch: 10 [46720/84843 (55%)]\tLoss: 0.617304\n",
      "Train Epoch: 10 [47360/84843 (56%)]\tLoss: 0.443636\n",
      "Train Epoch: 10 [48000/84843 (57%)]\tLoss: 0.223621\n",
      "Train Epoch: 10 [48640/84843 (57%)]\tLoss: 0.152670\n",
      "Train Epoch: 10 [49280/84843 (58%)]\tLoss: 0.444598\n",
      "Train Epoch: 10 [49920/84843 (59%)]\tLoss: 0.596875\n",
      "Train Epoch: 10 [50560/84843 (60%)]\tLoss: 0.326943\n",
      "Train Epoch: 10 [51200/84843 (60%)]\tLoss: 0.228405\n",
      "Train Epoch: 10 [51840/84843 (61%)]\tLoss: 0.329162\n",
      "Train Epoch: 10 [52480/84843 (62%)]\tLoss: 0.371706\n",
      "Train Epoch: 10 [53120/84843 (63%)]\tLoss: 0.432395\n",
      "Train Epoch: 10 [53760/84843 (63%)]\tLoss: 0.281043\n",
      "Train Epoch: 10 [54400/84843 (64%)]\tLoss: 0.469033\n",
      "Train Epoch: 10 [55040/84843 (65%)]\tLoss: 0.293677\n",
      "Train Epoch: 10 [55680/84843 (66%)]\tLoss: 0.164293\n",
      "Train Epoch: 10 [56320/84843 (66%)]\tLoss: 0.442277\n",
      "Train Epoch: 10 [56960/84843 (67%)]\tLoss: 0.324607\n",
      "Train Epoch: 10 [57600/84843 (68%)]\tLoss: 0.181117\n",
      "Train Epoch: 10 [58240/84843 (69%)]\tLoss: 0.265291\n",
      "Train Epoch: 10 [58880/84843 (69%)]\tLoss: 0.365889\n",
      "Train Epoch: 10 [59520/84843 (70%)]\tLoss: 0.236111\n",
      "Train Epoch: 10 [60160/84843 (71%)]\tLoss: 0.725607\n",
      "Train Epoch: 10 [60800/84843 (72%)]\tLoss: 0.259313\n",
      "Train Epoch: 10 [61440/84843 (72%)]\tLoss: 0.096621\n",
      "Train Epoch: 10 [62080/84843 (73%)]\tLoss: 0.366235\n",
      "Train Epoch: 10 [62720/84843 (74%)]\tLoss: 0.447157\n",
      "Train Epoch: 10 [63360/84843 (75%)]\tLoss: 0.456785\n",
      "Train Epoch: 10 [64000/84843 (75%)]\tLoss: 0.243045\n",
      "Train Epoch: 10 [64640/84843 (76%)]\tLoss: 0.360460\n",
      "Train Epoch: 10 [65280/84843 (77%)]\tLoss: 0.312701\n",
      "Train Epoch: 10 [65920/84843 (78%)]\tLoss: 0.318594\n",
      "Train Epoch: 10 [66560/84843 (78%)]\tLoss: 0.335965\n",
      "Train Epoch: 10 [67200/84843 (79%)]\tLoss: 0.376789\n",
      "Train Epoch: 10 [67840/84843 (80%)]\tLoss: 0.250100\n",
      "Train Epoch: 10 [68480/84843 (81%)]\tLoss: 0.429021\n",
      "Train Epoch: 10 [69120/84843 (81%)]\tLoss: 0.290355\n",
      "Train Epoch: 10 [69760/84843 (82%)]\tLoss: 0.283521\n",
      "Train Epoch: 10 [70400/84843 (83%)]\tLoss: 0.319654\n",
      "Train Epoch: 10 [71040/84843 (84%)]\tLoss: 0.538164\n",
      "Train Epoch: 10 [71680/84843 (84%)]\tLoss: 0.151092\n",
      "Train Epoch: 10 [72320/84843 (85%)]\tLoss: 0.279924\n",
      "Train Epoch: 10 [72960/84843 (86%)]\tLoss: 0.434932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [73600/84843 (87%)]\tLoss: 0.080323\n",
      "Train Epoch: 10 [74240/84843 (87%)]\tLoss: 0.190559\n",
      "Train Epoch: 10 [74880/84843 (88%)]\tLoss: 0.392957\n",
      "Train Epoch: 10 [75520/84843 (89%)]\tLoss: 0.922044\n",
      "Train Epoch: 10 [76160/84843 (90%)]\tLoss: 0.711955\n",
      "Train Epoch: 10 [76800/84843 (90%)]\tLoss: 0.475930\n",
      "Train Epoch: 10 [77440/84843 (91%)]\tLoss: 0.441277\n",
      "Train Epoch: 10 [78080/84843 (92%)]\tLoss: 0.222717\n",
      "Train Epoch: 10 [78720/84843 (93%)]\tLoss: 0.528855\n",
      "Train Epoch: 10 [79360/84843 (94%)]\tLoss: 0.340084\n",
      "Train Epoch: 10 [80000/84843 (94%)]\tLoss: 0.226427\n",
      "Train Epoch: 10 [80640/84843 (95%)]\tLoss: 0.538827\n",
      "Train Epoch: 10 [81280/84843 (96%)]\tLoss: 0.147996\n",
      "Train Epoch: 10 [81920/84843 (97%)]\tLoss: 0.718560\n",
      "Train Epoch: 10 [82560/84843 (97%)]\tLoss: 0.265547\n",
      "Train Epoch: 10 [83200/84843 (98%)]\tLoss: 0.324607\n",
      "Train Epoch: 10 [83840/84843 (99%)]\tLoss: 0.299517\n",
      "Train Epoch: 10 [84480/84843 (100%)]\tLoss: 0.361898\n",
      "Accuracy: 9452/11005 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/84843 (0%)]\tLoss: 0.738963\n",
      "Train Epoch: 11 [640/84843 (1%)]\tLoss: 0.272298\n",
      "Train Epoch: 11 [1280/84843 (2%)]\tLoss: 0.574294\n",
      "Train Epoch: 11 [1920/84843 (2%)]\tLoss: 0.083093\n",
      "Train Epoch: 11 [2560/84843 (3%)]\tLoss: 0.040583\n",
      "Train Epoch: 11 [3200/84843 (4%)]\tLoss: 0.161692\n",
      "Train Epoch: 11 [3840/84843 (5%)]\tLoss: 0.414310\n",
      "Train Epoch: 11 [4480/84843 (5%)]\tLoss: 0.120803\n",
      "Train Epoch: 11 [5120/84843 (6%)]\tLoss: 0.286212\n",
      "Train Epoch: 11 [5760/84843 (7%)]\tLoss: 0.291270\n",
      "Train Epoch: 11 [6400/84843 (8%)]\tLoss: 0.307333\n",
      "Train Epoch: 11 [7040/84843 (8%)]\tLoss: 0.160659\n",
      "Train Epoch: 11 [7680/84843 (9%)]\tLoss: 0.158676\n",
      "Train Epoch: 11 [8320/84843 (10%)]\tLoss: 0.461154\n",
      "Train Epoch: 11 [8960/84843 (11%)]\tLoss: 0.524922\n",
      "Train Epoch: 11 [9600/84843 (11%)]\tLoss: 0.545344\n",
      "Train Epoch: 11 [10240/84843 (12%)]\tLoss: 0.577867\n",
      "Train Epoch: 11 [10880/84843 (13%)]\tLoss: 0.315216\n",
      "Train Epoch: 11 [11520/84843 (14%)]\tLoss: 0.339114\n",
      "Train Epoch: 11 [12160/84843 (14%)]\tLoss: 0.115844\n",
      "Train Epoch: 11 [12800/84843 (15%)]\tLoss: 0.324144\n",
      "Train Epoch: 11 [13440/84843 (16%)]\tLoss: 0.215689\n",
      "Train Epoch: 11 [14080/84843 (17%)]\tLoss: 0.055529\n",
      "Train Epoch: 11 [14720/84843 (17%)]\tLoss: 0.283785\n",
      "Train Epoch: 11 [15360/84843 (18%)]\tLoss: 0.330689\n",
      "Train Epoch: 11 [16000/84843 (19%)]\tLoss: 0.419604\n",
      "Train Epoch: 11 [16640/84843 (20%)]\tLoss: 0.459118\n",
      "Train Epoch: 11 [17280/84843 (20%)]\tLoss: 0.231039\n",
      "Train Epoch: 11 [17920/84843 (21%)]\tLoss: 0.361541\n",
      "Train Epoch: 11 [18560/84843 (22%)]\tLoss: 0.315439\n",
      "Train Epoch: 11 [19200/84843 (23%)]\tLoss: 0.188797\n",
      "Train Epoch: 11 [19840/84843 (23%)]\tLoss: 0.228911\n",
      "Train Epoch: 11 [20480/84843 (24%)]\tLoss: 0.351590\n",
      "Train Epoch: 11 [21120/84843 (25%)]\tLoss: 0.036071\n",
      "Train Epoch: 11 [21760/84843 (26%)]\tLoss: 0.584296\n",
      "Train Epoch: 11 [22400/84843 (26%)]\tLoss: 0.230161\n",
      "Train Epoch: 11 [23040/84843 (27%)]\tLoss: 0.334632\n",
      "Train Epoch: 11 [23680/84843 (28%)]\tLoss: 0.332778\n",
      "Train Epoch: 11 [24320/84843 (29%)]\tLoss: 0.268962\n",
      "Train Epoch: 11 [24960/84843 (29%)]\tLoss: 0.341951\n",
      "Train Epoch: 11 [25600/84843 (30%)]\tLoss: 0.180316\n",
      "Train Epoch: 11 [26240/84843 (31%)]\tLoss: 0.160628\n",
      "Train Epoch: 11 [26880/84843 (32%)]\tLoss: 0.398617\n",
      "Train Epoch: 11 [27520/84843 (32%)]\tLoss: 0.444112\n",
      "Train Epoch: 11 [28160/84843 (33%)]\tLoss: 0.414352\n",
      "Train Epoch: 11 [28800/84843 (34%)]\tLoss: 0.189206\n",
      "Train Epoch: 11 [29440/84843 (35%)]\tLoss: 0.247761\n",
      "Train Epoch: 11 [30080/84843 (35%)]\tLoss: 0.541249\n",
      "Train Epoch: 11 [30720/84843 (36%)]\tLoss: 0.574588\n",
      "Train Epoch: 11 [31360/84843 (37%)]\tLoss: 0.369949\n",
      "Train Epoch: 11 [32000/84843 (38%)]\tLoss: 0.481466\n",
      "Train Epoch: 11 [32640/84843 (38%)]\tLoss: 0.390168\n",
      "Train Epoch: 11 [33280/84843 (39%)]\tLoss: 0.287582\n",
      "Train Epoch: 11 [33920/84843 (40%)]\tLoss: 0.338408\n",
      "Train Epoch: 11 [34560/84843 (41%)]\tLoss: 0.551549\n",
      "Train Epoch: 11 [35200/84843 (41%)]\tLoss: 0.512837\n",
      "Train Epoch: 11 [35840/84843 (42%)]\tLoss: 0.145462\n",
      "Train Epoch: 11 [36480/84843 (43%)]\tLoss: 0.173058\n",
      "Train Epoch: 11 [37120/84843 (44%)]\tLoss: 0.285595\n",
      "Train Epoch: 11 [37760/84843 (44%)]\tLoss: 0.466875\n",
      "Train Epoch: 11 [38400/84843 (45%)]\tLoss: 0.256150\n",
      "Train Epoch: 11 [39040/84843 (46%)]\tLoss: 0.634782\n",
      "Train Epoch: 11 [39680/84843 (47%)]\tLoss: 0.343915\n",
      "Train Epoch: 11 [40320/84843 (48%)]\tLoss: 0.321081\n",
      "Train Epoch: 11 [40960/84843 (48%)]\tLoss: 0.389420\n",
      "Train Epoch: 11 [41600/84843 (49%)]\tLoss: 0.269316\n",
      "Train Epoch: 11 [42240/84843 (50%)]\tLoss: 0.474815\n",
      "Train Epoch: 11 [42880/84843 (51%)]\tLoss: 0.289618\n",
      "Train Epoch: 11 [43520/84843 (51%)]\tLoss: 0.401630\n",
      "Train Epoch: 11 [44160/84843 (52%)]\tLoss: 0.456008\n",
      "Train Epoch: 11 [44800/84843 (53%)]\tLoss: 0.392690\n",
      "Train Epoch: 11 [45440/84843 (54%)]\tLoss: 0.391148\n",
      "Train Epoch: 11 [46080/84843 (54%)]\tLoss: 0.370076\n",
      "Train Epoch: 11 [46720/84843 (55%)]\tLoss: 0.245221\n",
      "Train Epoch: 11 [47360/84843 (56%)]\tLoss: 0.330057\n",
      "Train Epoch: 11 [48000/84843 (57%)]\tLoss: 0.549039\n",
      "Train Epoch: 11 [48640/84843 (57%)]\tLoss: 0.460481\n",
      "Train Epoch: 11 [49280/84843 (58%)]\tLoss: 0.426625\n",
      "Train Epoch: 11 [49920/84843 (59%)]\tLoss: 0.493908\n",
      "Train Epoch: 11 [50560/84843 (60%)]\tLoss: 0.157764\n",
      "Train Epoch: 11 [51200/84843 (60%)]\tLoss: 0.384320\n",
      "Train Epoch: 11 [51840/84843 (61%)]\tLoss: 0.219427\n",
      "Train Epoch: 11 [52480/84843 (62%)]\tLoss: 0.120849\n",
      "Train Epoch: 11 [53120/84843 (63%)]\tLoss: 0.179639\n",
      "Train Epoch: 11 [53760/84843 (63%)]\tLoss: 0.239408\n",
      "Train Epoch: 11 [54400/84843 (64%)]\tLoss: 0.297273\n",
      "Train Epoch: 11 [55040/84843 (65%)]\tLoss: 0.536902\n",
      "Train Epoch: 11 [55680/84843 (66%)]\tLoss: 0.473662\n",
      "Train Epoch: 11 [56320/84843 (66%)]\tLoss: 0.165715\n",
      "Train Epoch: 11 [56960/84843 (67%)]\tLoss: 0.329364\n",
      "Train Epoch: 11 [57600/84843 (68%)]\tLoss: 0.168357\n",
      "Train Epoch: 11 [58240/84843 (69%)]\tLoss: 0.512776\n",
      "Train Epoch: 11 [58880/84843 (69%)]\tLoss: 0.501672\n",
      "Train Epoch: 11 [59520/84843 (70%)]\tLoss: 0.412232\n",
      "Train Epoch: 11 [60160/84843 (71%)]\tLoss: 0.540030\n",
      "Train Epoch: 11 [60800/84843 (72%)]\tLoss: 0.182197\n",
      "Train Epoch: 11 [61440/84843 (72%)]\tLoss: 0.341506\n",
      "Train Epoch: 11 [62080/84843 (73%)]\tLoss: 0.362854\n",
      "Train Epoch: 11 [62720/84843 (74%)]\tLoss: 0.223454\n",
      "Train Epoch: 11 [63360/84843 (75%)]\tLoss: 0.624956\n",
      "Train Epoch: 11 [64000/84843 (75%)]\tLoss: 0.435635\n",
      "Train Epoch: 11 [64640/84843 (76%)]\tLoss: 0.449196\n",
      "Train Epoch: 11 [65280/84843 (77%)]\tLoss: 0.212995\n",
      "Train Epoch: 11 [65920/84843 (78%)]\tLoss: 0.258968\n",
      "Train Epoch: 11 [66560/84843 (78%)]\tLoss: 0.284497\n",
      "Train Epoch: 11 [67200/84843 (79%)]\tLoss: 0.373363\n",
      "Train Epoch: 11 [67840/84843 (80%)]\tLoss: 0.624804\n",
      "Train Epoch: 11 [68480/84843 (81%)]\tLoss: 0.329326\n",
      "Train Epoch: 11 [69120/84843 (81%)]\tLoss: 0.143202\n",
      "Train Epoch: 11 [69760/84843 (82%)]\tLoss: 0.179228\n",
      "Train Epoch: 11 [70400/84843 (83%)]\tLoss: 0.317621\n",
      "Train Epoch: 11 [71040/84843 (84%)]\tLoss: 0.150451\n",
      "Train Epoch: 11 [71680/84843 (84%)]\tLoss: 0.219579\n",
      "Train Epoch: 11 [72320/84843 (85%)]\tLoss: 0.266171\n",
      "Train Epoch: 11 [72960/84843 (86%)]\tLoss: 0.289044\n",
      "Train Epoch: 11 [73600/84843 (87%)]\tLoss: 0.619955\n",
      "Train Epoch: 11 [74240/84843 (87%)]\tLoss: 0.434668\n",
      "Train Epoch: 11 [74880/84843 (88%)]\tLoss: 0.597089\n",
      "Train Epoch: 11 [75520/84843 (89%)]\tLoss: 0.285169\n",
      "Train Epoch: 11 [76160/84843 (90%)]\tLoss: 0.413315\n",
      "Train Epoch: 11 [76800/84843 (90%)]\tLoss: 0.260900\n",
      "Train Epoch: 11 [77440/84843 (91%)]\tLoss: 0.429447\n",
      "Train Epoch: 11 [78080/84843 (92%)]\tLoss: 0.678266\n",
      "Train Epoch: 11 [78720/84843 (93%)]\tLoss: 0.178317\n",
      "Train Epoch: 11 [79360/84843 (94%)]\tLoss: 0.409110\n",
      "Train Epoch: 11 [80000/84843 (94%)]\tLoss: 0.251678\n",
      "Train Epoch: 11 [80640/84843 (95%)]\tLoss: 0.803760\n",
      "Train Epoch: 11 [81280/84843 (96%)]\tLoss: 0.419069\n",
      "Train Epoch: 11 [81920/84843 (97%)]\tLoss: 0.455052\n",
      "Train Epoch: 11 [82560/84843 (97%)]\tLoss: 0.228329\n",
      "Train Epoch: 11 [83200/84843 (98%)]\tLoss: 0.401968\n",
      "Train Epoch: 11 [83840/84843 (99%)]\tLoss: 0.279628\n",
      "Train Epoch: 11 [84480/84843 (100%)]\tLoss: 0.354178\n",
      "Accuracy: 9452/11005 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/84843 (0%)]\tLoss: 0.053446\n",
      "Train Epoch: 12 [640/84843 (1%)]\tLoss: 0.430423\n",
      "Train Epoch: 12 [1280/84843 (2%)]\tLoss: 0.704010\n",
      "Train Epoch: 12 [1920/84843 (2%)]\tLoss: 0.356947\n",
      "Train Epoch: 12 [2560/84843 (3%)]\tLoss: 0.469247\n",
      "Train Epoch: 12 [3200/84843 (4%)]\tLoss: 0.553883\n",
      "Train Epoch: 12 [3840/84843 (5%)]\tLoss: 0.170279\n",
      "Train Epoch: 12 [4480/84843 (5%)]\tLoss: 0.154562\n",
      "Train Epoch: 12 [5120/84843 (6%)]\tLoss: 0.303552\n",
      "Train Epoch: 12 [5760/84843 (7%)]\tLoss: 0.340497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [6400/84843 (8%)]\tLoss: 0.267076\n",
      "Train Epoch: 12 [7040/84843 (8%)]\tLoss: 0.471940\n",
      "Train Epoch: 12 [7680/84843 (9%)]\tLoss: 0.473481\n",
      "Train Epoch: 12 [8320/84843 (10%)]\tLoss: 0.246946\n",
      "Train Epoch: 12 [8960/84843 (11%)]\tLoss: 0.608434\n",
      "Train Epoch: 12 [9600/84843 (11%)]\tLoss: 0.490033\n",
      "Train Epoch: 12 [10240/84843 (12%)]\tLoss: 0.104276\n",
      "Train Epoch: 12 [10880/84843 (13%)]\tLoss: 0.384093\n",
      "Train Epoch: 12 [11520/84843 (14%)]\tLoss: 0.588289\n",
      "Train Epoch: 12 [12160/84843 (14%)]\tLoss: 0.460213\n",
      "Train Epoch: 12 [12800/84843 (15%)]\tLoss: 0.267579\n",
      "Train Epoch: 12 [13440/84843 (16%)]\tLoss: 0.091568\n",
      "Train Epoch: 12 [14080/84843 (17%)]\tLoss: 0.218010\n",
      "Train Epoch: 12 [14720/84843 (17%)]\tLoss: 0.245130\n",
      "Train Epoch: 12 [15360/84843 (18%)]\tLoss: 0.248024\n",
      "Train Epoch: 12 [16000/84843 (19%)]\tLoss: 0.234472\n",
      "Train Epoch: 12 [16640/84843 (20%)]\tLoss: 0.340858\n",
      "Train Epoch: 12 [17280/84843 (20%)]\tLoss: 0.414149\n",
      "Train Epoch: 12 [17920/84843 (21%)]\tLoss: 0.207280\n",
      "Train Epoch: 12 [18560/84843 (22%)]\tLoss: 0.288460\n",
      "Train Epoch: 12 [19200/84843 (23%)]\tLoss: 0.253154\n",
      "Train Epoch: 12 [19840/84843 (23%)]\tLoss: 0.114232\n",
      "Train Epoch: 12 [20480/84843 (24%)]\tLoss: 0.429712\n",
      "Train Epoch: 12 [21120/84843 (25%)]\tLoss: 0.431718\n",
      "Train Epoch: 12 [21760/84843 (26%)]\tLoss: 0.207231\n",
      "Train Epoch: 12 [22400/84843 (26%)]\tLoss: 0.330265\n",
      "Train Epoch: 12 [23040/84843 (27%)]\tLoss: 0.187480\n",
      "Train Epoch: 12 [23680/84843 (28%)]\tLoss: 0.241623\n",
      "Train Epoch: 12 [24320/84843 (29%)]\tLoss: 0.356323\n",
      "Train Epoch: 12 [24960/84843 (29%)]\tLoss: 0.437043\n",
      "Train Epoch: 12 [25600/84843 (30%)]\tLoss: 0.202116\n",
      "Train Epoch: 12 [26240/84843 (31%)]\tLoss: 0.416851\n",
      "Train Epoch: 12 [26880/84843 (32%)]\tLoss: 0.235657\n",
      "Train Epoch: 12 [27520/84843 (32%)]\tLoss: 0.441736\n",
      "Train Epoch: 12 [28160/84843 (33%)]\tLoss: 0.926525\n",
      "Train Epoch: 12 [28800/84843 (34%)]\tLoss: 0.257489\n",
      "Train Epoch: 12 [29440/84843 (35%)]\tLoss: 0.836579\n",
      "Train Epoch: 12 [30080/84843 (35%)]\tLoss: 0.273630\n",
      "Train Epoch: 12 [30720/84843 (36%)]\tLoss: 0.162738\n",
      "Train Epoch: 12 [31360/84843 (37%)]\tLoss: 0.135283\n",
      "Train Epoch: 12 [32000/84843 (38%)]\tLoss: 0.444021\n",
      "Train Epoch: 12 [32640/84843 (38%)]\tLoss: 0.332265\n",
      "Train Epoch: 12 [33280/84843 (39%)]\tLoss: 0.184365\n",
      "Train Epoch: 12 [33920/84843 (40%)]\tLoss: 0.613352\n",
      "Train Epoch: 12 [34560/84843 (41%)]\tLoss: 0.631984\n",
      "Train Epoch: 12 [35200/84843 (41%)]\tLoss: 0.333409\n",
      "Train Epoch: 12 [35840/84843 (42%)]\tLoss: 0.302627\n",
      "Train Epoch: 12 [36480/84843 (43%)]\tLoss: 0.218713\n",
      "Train Epoch: 12 [37120/84843 (44%)]\tLoss: 0.268999\n",
      "Train Epoch: 12 [37760/84843 (44%)]\tLoss: 0.227297\n",
      "Train Epoch: 12 [38400/84843 (45%)]\tLoss: 0.279155\n",
      "Train Epoch: 12 [39040/84843 (46%)]\tLoss: 0.476212\n",
      "Train Epoch: 12 [39680/84843 (47%)]\tLoss: 0.139308\n",
      "Train Epoch: 12 [40320/84843 (48%)]\tLoss: 0.203743\n",
      "Train Epoch: 12 [40960/84843 (48%)]\tLoss: 0.502967\n",
      "Train Epoch: 12 [41600/84843 (49%)]\tLoss: 0.313857\n",
      "Train Epoch: 12 [42240/84843 (50%)]\tLoss: 0.453365\n",
      "Train Epoch: 12 [42880/84843 (51%)]\tLoss: 0.520420\n",
      "Train Epoch: 12 [43520/84843 (51%)]\tLoss: 0.225741\n",
      "Train Epoch: 12 [44160/84843 (52%)]\tLoss: 0.254740\n",
      "Train Epoch: 12 [44800/84843 (53%)]\tLoss: 0.315795\n",
      "Train Epoch: 12 [45440/84843 (54%)]\tLoss: 0.485619\n",
      "Train Epoch: 12 [46080/84843 (54%)]\tLoss: 0.645790\n",
      "Train Epoch: 12 [46720/84843 (55%)]\tLoss: 0.415025\n",
      "Train Epoch: 12 [47360/84843 (56%)]\tLoss: 0.566091\n",
      "Train Epoch: 12 [48000/84843 (57%)]\tLoss: 0.664904\n",
      "Train Epoch: 12 [48640/84843 (57%)]\tLoss: 0.502973\n",
      "Train Epoch: 12 [49280/84843 (58%)]\tLoss: 0.280765\n",
      "Train Epoch: 12 [49920/84843 (59%)]\tLoss: 0.280684\n",
      "Train Epoch: 12 [50560/84843 (60%)]\tLoss: 0.312457\n",
      "Train Epoch: 12 [51200/84843 (60%)]\tLoss: 0.277919\n",
      "Train Epoch: 12 [51840/84843 (61%)]\tLoss: 0.303793\n",
      "Train Epoch: 12 [52480/84843 (62%)]\tLoss: 0.309954\n",
      "Train Epoch: 12 [53120/84843 (63%)]\tLoss: 0.352070\n",
      "Train Epoch: 12 [53760/84843 (63%)]\tLoss: 0.286307\n",
      "Train Epoch: 12 [54400/84843 (64%)]\tLoss: 0.537287\n",
      "Train Epoch: 12 [55040/84843 (65%)]\tLoss: 0.448934\n",
      "Train Epoch: 12 [55680/84843 (66%)]\tLoss: 0.346778\n",
      "Train Epoch: 12 [56320/84843 (66%)]\tLoss: 0.346592\n",
      "Train Epoch: 12 [56960/84843 (67%)]\tLoss: 0.534375\n",
      "Train Epoch: 12 [57600/84843 (68%)]\tLoss: 0.105342\n",
      "Train Epoch: 12 [58240/84843 (69%)]\tLoss: 0.556116\n",
      "Train Epoch: 12 [58880/84843 (69%)]\tLoss: 0.569766\n",
      "Train Epoch: 12 [59520/84843 (70%)]\tLoss: 0.581012\n",
      "Train Epoch: 12 [60160/84843 (71%)]\tLoss: 0.282456\n",
      "Train Epoch: 12 [60800/84843 (72%)]\tLoss: 0.287912\n",
      "Train Epoch: 12 [61440/84843 (72%)]\tLoss: 0.314186\n",
      "Train Epoch: 12 [62080/84843 (73%)]\tLoss: 0.271502\n",
      "Train Epoch: 12 [62720/84843 (74%)]\tLoss: 0.543031\n",
      "Train Epoch: 12 [63360/84843 (75%)]\tLoss: 0.264032\n",
      "Train Epoch: 12 [64000/84843 (75%)]\tLoss: 0.118938\n",
      "Train Epoch: 12 [64640/84843 (76%)]\tLoss: 0.118587\n",
      "Train Epoch: 12 [65280/84843 (77%)]\tLoss: 0.393561\n",
      "Train Epoch: 12 [65920/84843 (78%)]\tLoss: 0.481433\n",
      "Train Epoch: 12 [66560/84843 (78%)]\tLoss: 0.185097\n",
      "Train Epoch: 12 [67200/84843 (79%)]\tLoss: 0.536256\n",
      "Train Epoch: 12 [67840/84843 (80%)]\tLoss: 0.207467\n",
      "Train Epoch: 12 [68480/84843 (81%)]\tLoss: 0.659985\n",
      "Train Epoch: 12 [69120/84843 (81%)]\tLoss: 0.387365\n",
      "Train Epoch: 12 [69760/84843 (82%)]\tLoss: 0.391093\n",
      "Train Epoch: 12 [70400/84843 (83%)]\tLoss: 0.315104\n",
      "Train Epoch: 12 [71040/84843 (84%)]\tLoss: 0.240034\n",
      "Train Epoch: 12 [71680/84843 (84%)]\tLoss: 0.531163\n",
      "Train Epoch: 12 [72320/84843 (85%)]\tLoss: 0.457832\n",
      "Train Epoch: 12 [72960/84843 (86%)]\tLoss: 0.178433\n",
      "Train Epoch: 12 [73600/84843 (87%)]\tLoss: 0.561680\n",
      "Train Epoch: 12 [74240/84843 (87%)]\tLoss: 0.243281\n",
      "Train Epoch: 12 [74880/84843 (88%)]\tLoss: 0.225162\n",
      "Train Epoch: 12 [75520/84843 (89%)]\tLoss: 0.049149\n",
      "Train Epoch: 12 [76160/84843 (90%)]\tLoss: 0.486791\n",
      "Train Epoch: 12 [76800/84843 (90%)]\tLoss: 0.447223\n",
      "Train Epoch: 12 [77440/84843 (91%)]\tLoss: 0.207876\n",
      "Train Epoch: 12 [78080/84843 (92%)]\tLoss: 0.191132\n",
      "Train Epoch: 12 [78720/84843 (93%)]\tLoss: 0.295026\n",
      "Train Epoch: 12 [79360/84843 (94%)]\tLoss: 0.571303\n",
      "Train Epoch: 12 [80000/84843 (94%)]\tLoss: 0.347988\n",
      "Train Epoch: 12 [80640/84843 (95%)]\tLoss: 0.663282\n",
      "Train Epoch: 12 [81280/84843 (96%)]\tLoss: 0.251869\n",
      "Train Epoch: 12 [81920/84843 (97%)]\tLoss: 0.807093\n",
      "Train Epoch: 12 [82560/84843 (97%)]\tLoss: 0.484167\n",
      "Train Epoch: 12 [83200/84843 (98%)]\tLoss: 0.425738\n",
      "Train Epoch: 12 [83840/84843 (99%)]\tLoss: 0.534249\n",
      "Train Epoch: 12 [84480/84843 (100%)]\tLoss: 0.407145\n",
      "Accuracy: 9455/11005 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/84843 (0%)]\tLoss: 0.136376\n",
      "Train Epoch: 13 [640/84843 (1%)]\tLoss: 0.205598\n",
      "Train Epoch: 13 [1280/84843 (2%)]\tLoss: 0.643725\n",
      "Train Epoch: 13 [1920/84843 (2%)]\tLoss: 0.287506\n",
      "Train Epoch: 13 [2560/84843 (3%)]\tLoss: 0.345915\n",
      "Train Epoch: 13 [3200/84843 (4%)]\tLoss: 0.296101\n",
      "Train Epoch: 13 [3840/84843 (5%)]\tLoss: 0.147480\n",
      "Train Epoch: 13 [4480/84843 (5%)]\tLoss: 0.608148\n",
      "Train Epoch: 13 [5120/84843 (6%)]\tLoss: 0.325366\n",
      "Train Epoch: 13 [5760/84843 (7%)]\tLoss: 0.233399\n",
      "Train Epoch: 13 [6400/84843 (8%)]\tLoss: 0.268561\n",
      "Train Epoch: 13 [7040/84843 (8%)]\tLoss: 0.336507\n",
      "Train Epoch: 13 [7680/84843 (9%)]\tLoss: 0.458769\n",
      "Train Epoch: 13 [8320/84843 (10%)]\tLoss: 0.067829\n",
      "Train Epoch: 13 [8960/84843 (11%)]\tLoss: 0.416911\n",
      "Train Epoch: 13 [9600/84843 (11%)]\tLoss: 0.232545\n",
      "Train Epoch: 13 [10240/84843 (12%)]\tLoss: 0.338506\n",
      "Train Epoch: 13 [10880/84843 (13%)]\tLoss: 0.392881\n",
      "Train Epoch: 13 [11520/84843 (14%)]\tLoss: 0.402816\n",
      "Train Epoch: 13 [12160/84843 (14%)]\tLoss: 0.326101\n",
      "Train Epoch: 13 [12800/84843 (15%)]\tLoss: 0.322797\n",
      "Train Epoch: 13 [13440/84843 (16%)]\tLoss: 0.430571\n",
      "Train Epoch: 13 [14080/84843 (17%)]\tLoss: 0.384614\n",
      "Train Epoch: 13 [14720/84843 (17%)]\tLoss: 0.385349\n",
      "Train Epoch: 13 [15360/84843 (18%)]\tLoss: 0.419817\n",
      "Train Epoch: 13 [16000/84843 (19%)]\tLoss: 0.391273\n",
      "Train Epoch: 13 [16640/84843 (20%)]\tLoss: 0.266563\n",
      "Train Epoch: 13 [17280/84843 (20%)]\tLoss: 0.538159\n",
      "Train Epoch: 13 [17920/84843 (21%)]\tLoss: 0.190555\n",
      "Train Epoch: 13 [18560/84843 (22%)]\tLoss: 0.130553\n",
      "Train Epoch: 13 [19200/84843 (23%)]\tLoss: 0.980868\n",
      "Train Epoch: 13 [19840/84843 (23%)]\tLoss: 0.276313\n",
      "Train Epoch: 13 [20480/84843 (24%)]\tLoss: 0.543251\n",
      "Train Epoch: 13 [21120/84843 (25%)]\tLoss: 0.739715\n",
      "Train Epoch: 13 [21760/84843 (26%)]\tLoss: 0.109190\n",
      "Train Epoch: 13 [22400/84843 (26%)]\tLoss: 0.411036\n",
      "Train Epoch: 13 [23040/84843 (27%)]\tLoss: 0.435966\n",
      "Train Epoch: 13 [23680/84843 (28%)]\tLoss: 0.245889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [24320/84843 (29%)]\tLoss: 0.555120\n",
      "Train Epoch: 13 [24960/84843 (29%)]\tLoss: 0.550892\n",
      "Train Epoch: 13 [25600/84843 (30%)]\tLoss: 0.568348\n",
      "Train Epoch: 13 [26240/84843 (31%)]\tLoss: 0.558735\n",
      "Train Epoch: 13 [26880/84843 (32%)]\tLoss: 0.640348\n",
      "Train Epoch: 13 [27520/84843 (32%)]\tLoss: 0.291958\n",
      "Train Epoch: 13 [28160/84843 (33%)]\tLoss: 0.245088\n",
      "Train Epoch: 13 [28800/84843 (34%)]\tLoss: 0.677209\n",
      "Train Epoch: 13 [29440/84843 (35%)]\tLoss: 0.486524\n",
      "Train Epoch: 13 [30080/84843 (35%)]\tLoss: 0.454171\n",
      "Train Epoch: 13 [30720/84843 (36%)]\tLoss: 0.651723\n",
      "Train Epoch: 13 [31360/84843 (37%)]\tLoss: 0.324878\n",
      "Train Epoch: 13 [32000/84843 (38%)]\tLoss: 0.298557\n",
      "Train Epoch: 13 [32640/84843 (38%)]\tLoss: 0.227159\n",
      "Train Epoch: 13 [33280/84843 (39%)]\tLoss: 0.197538\n",
      "Train Epoch: 13 [33920/84843 (40%)]\tLoss: 0.391917\n",
      "Train Epoch: 13 [34560/84843 (41%)]\tLoss: 0.368197\n",
      "Train Epoch: 13 [35200/84843 (41%)]\tLoss: 0.244806\n",
      "Train Epoch: 13 [35840/84843 (42%)]\tLoss: 0.387623\n",
      "Train Epoch: 13 [36480/84843 (43%)]\tLoss: 0.141439\n",
      "Train Epoch: 13 [37120/84843 (44%)]\tLoss: 0.357538\n",
      "Train Epoch: 13 [37760/84843 (44%)]\tLoss: 0.633134\n",
      "Train Epoch: 13 [38400/84843 (45%)]\tLoss: 0.401595\n",
      "Train Epoch: 13 [39040/84843 (46%)]\tLoss: 0.380563\n",
      "Train Epoch: 13 [39680/84843 (47%)]\tLoss: 0.323510\n",
      "Train Epoch: 13 [40320/84843 (48%)]\tLoss: 0.488671\n",
      "Train Epoch: 13 [40960/84843 (48%)]\tLoss: 0.317895\n",
      "Train Epoch: 13 [41600/84843 (49%)]\tLoss: 0.207720\n",
      "Train Epoch: 13 [42240/84843 (50%)]\tLoss: 0.532244\n",
      "Train Epoch: 13 [42880/84843 (51%)]\tLoss: 0.348072\n",
      "Train Epoch: 13 [43520/84843 (51%)]\tLoss: 0.374657\n",
      "Train Epoch: 13 [44160/84843 (52%)]\tLoss: 0.314181\n",
      "Train Epoch: 13 [44800/84843 (53%)]\tLoss: 0.286005\n",
      "Train Epoch: 13 [45440/84843 (54%)]\tLoss: 0.404194\n",
      "Train Epoch: 13 [46080/84843 (54%)]\tLoss: 0.562828\n",
      "Train Epoch: 13 [46720/84843 (55%)]\tLoss: 0.285412\n",
      "Train Epoch: 13 [47360/84843 (56%)]\tLoss: 0.444467\n",
      "Train Epoch: 13 [48000/84843 (57%)]\tLoss: 0.417768\n",
      "Train Epoch: 13 [48640/84843 (57%)]\tLoss: 0.207454\n",
      "Train Epoch: 13 [49280/84843 (58%)]\tLoss: 0.402903\n",
      "Train Epoch: 13 [49920/84843 (59%)]\tLoss: 0.252699\n",
      "Train Epoch: 13 [50560/84843 (60%)]\tLoss: 0.638083\n",
      "Train Epoch: 13 [51200/84843 (60%)]\tLoss: 0.394903\n",
      "Train Epoch: 13 [51840/84843 (61%)]\tLoss: 0.481659\n",
      "Train Epoch: 13 [52480/84843 (62%)]\tLoss: 0.324984\n",
      "Train Epoch: 13 [53120/84843 (63%)]\tLoss: 0.304008\n",
      "Train Epoch: 13 [53760/84843 (63%)]\tLoss: 0.326330\n",
      "Train Epoch: 13 [54400/84843 (64%)]\tLoss: 0.536209\n",
      "Train Epoch: 13 [55040/84843 (65%)]\tLoss: 0.362903\n",
      "Train Epoch: 13 [55680/84843 (66%)]\tLoss: 0.633888\n",
      "Train Epoch: 13 [56320/84843 (66%)]\tLoss: 0.089903\n",
      "Train Epoch: 13 [56960/84843 (67%)]\tLoss: 0.325178\n",
      "Train Epoch: 13 [57600/84843 (68%)]\tLoss: 0.177402\n",
      "Train Epoch: 13 [58240/84843 (69%)]\tLoss: 0.480431\n",
      "Train Epoch: 13 [58880/84843 (69%)]\tLoss: 0.566294\n",
      "Train Epoch: 13 [59520/84843 (70%)]\tLoss: 0.282752\n",
      "Train Epoch: 13 [60160/84843 (71%)]\tLoss: 0.481640\n",
      "Train Epoch: 13 [60800/84843 (72%)]\tLoss: 0.233995\n",
      "Train Epoch: 13 [61440/84843 (72%)]\tLoss: 0.406778\n",
      "Train Epoch: 13 [62080/84843 (73%)]\tLoss: 0.224199\n",
      "Train Epoch: 13 [62720/84843 (74%)]\tLoss: 0.097297\n",
      "Train Epoch: 13 [63360/84843 (75%)]\tLoss: 0.500425\n",
      "Train Epoch: 13 [64000/84843 (75%)]\tLoss: 0.253187\n",
      "Train Epoch: 13 [64640/84843 (76%)]\tLoss: 0.480969\n",
      "Train Epoch: 13 [65280/84843 (77%)]\tLoss: 0.551418\n",
      "Train Epoch: 13 [65920/84843 (78%)]\tLoss: 0.266248\n",
      "Train Epoch: 13 [66560/84843 (78%)]\tLoss: 0.424209\n",
      "Train Epoch: 13 [67200/84843 (79%)]\tLoss: 0.174565\n",
      "Train Epoch: 13 [67840/84843 (80%)]\tLoss: 0.399709\n",
      "Train Epoch: 13 [68480/84843 (81%)]\tLoss: 0.339839\n",
      "Train Epoch: 13 [69120/84843 (81%)]\tLoss: 0.664833\n",
      "Train Epoch: 13 [69760/84843 (82%)]\tLoss: 0.355047\n",
      "Train Epoch: 13 [70400/84843 (83%)]\tLoss: 0.850883\n",
      "Train Epoch: 13 [71040/84843 (84%)]\tLoss: 0.159814\n",
      "Train Epoch: 13 [71680/84843 (84%)]\tLoss: 0.194843\n",
      "Train Epoch: 13 [72320/84843 (85%)]\tLoss: 0.209238\n",
      "Train Epoch: 13 [72960/84843 (86%)]\tLoss: 0.732813\n",
      "Train Epoch: 13 [73600/84843 (87%)]\tLoss: 0.421140\n",
      "Train Epoch: 13 [74240/84843 (87%)]\tLoss: 0.538813\n",
      "Train Epoch: 13 [74880/84843 (88%)]\tLoss: 0.529022\n",
      "Train Epoch: 13 [75520/84843 (89%)]\tLoss: 0.271156\n",
      "Train Epoch: 13 [76160/84843 (90%)]\tLoss: 0.383578\n",
      "Train Epoch: 13 [76800/84843 (90%)]\tLoss: 0.508171\n",
      "Train Epoch: 13 [77440/84843 (91%)]\tLoss: 0.429324\n",
      "Train Epoch: 13 [78080/84843 (92%)]\tLoss: 0.484268\n",
      "Train Epoch: 13 [78720/84843 (93%)]\tLoss: 0.419339\n",
      "Train Epoch: 13 [79360/84843 (94%)]\tLoss: 0.550207\n",
      "Train Epoch: 13 [80000/84843 (94%)]\tLoss: 0.134993\n",
      "Train Epoch: 13 [80640/84843 (95%)]\tLoss: 0.282724\n",
      "Train Epoch: 13 [81280/84843 (96%)]\tLoss: 0.511771\n",
      "Train Epoch: 13 [81920/84843 (97%)]\tLoss: 0.358987\n",
      "Train Epoch: 13 [82560/84843 (97%)]\tLoss: 0.317712\n",
      "Train Epoch: 13 [83200/84843 (98%)]\tLoss: 0.602387\n",
      "Train Epoch: 13 [83840/84843 (99%)]\tLoss: 0.351596\n",
      "Train Epoch: 13 [84480/84843 (100%)]\tLoss: 0.203188\n",
      "Accuracy: 9437/11005 (86%)\n",
      "\n",
      "Train Epoch: 14 [0/84843 (0%)]\tLoss: 0.190296\n",
      "Train Epoch: 14 [640/84843 (1%)]\tLoss: 0.389769\n",
      "Train Epoch: 14 [1280/84843 (2%)]\tLoss: 0.195477\n",
      "Train Epoch: 14 [1920/84843 (2%)]\tLoss: 0.522992\n",
      "Train Epoch: 14 [2560/84843 (3%)]\tLoss: 0.130844\n",
      "Train Epoch: 14 [3200/84843 (4%)]\tLoss: 0.357784\n",
      "Train Epoch: 14 [3840/84843 (5%)]\tLoss: 0.596462\n",
      "Train Epoch: 14 [4480/84843 (5%)]\tLoss: 0.221802\n",
      "Train Epoch: 14 [5120/84843 (6%)]\tLoss: 0.300359\n",
      "Train Epoch: 14 [5760/84843 (7%)]\tLoss: 0.257310\n",
      "Train Epoch: 14 [6400/84843 (8%)]\tLoss: 0.185988\n",
      "Train Epoch: 14 [7040/84843 (8%)]\tLoss: 0.635650\n",
      "Train Epoch: 14 [7680/84843 (9%)]\tLoss: 0.700364\n",
      "Train Epoch: 14 [8320/84843 (10%)]\tLoss: 0.119962\n",
      "Train Epoch: 14 [8960/84843 (11%)]\tLoss: 0.219056\n",
      "Train Epoch: 14 [9600/84843 (11%)]\tLoss: 0.687224\n",
      "Train Epoch: 14 [10240/84843 (12%)]\tLoss: 0.146073\n",
      "Train Epoch: 14 [10880/84843 (13%)]\tLoss: 0.394245\n",
      "Train Epoch: 14 [11520/84843 (14%)]\tLoss: 0.390001\n",
      "Train Epoch: 14 [12160/84843 (14%)]\tLoss: 0.448319\n",
      "Train Epoch: 14 [12800/84843 (15%)]\tLoss: 0.374568\n",
      "Train Epoch: 14 [13440/84843 (16%)]\tLoss: 0.207772\n",
      "Train Epoch: 14 [14080/84843 (17%)]\tLoss: 0.405713\n",
      "Train Epoch: 14 [14720/84843 (17%)]\tLoss: 0.092075\n",
      "Train Epoch: 14 [15360/84843 (18%)]\tLoss: 0.484259\n",
      "Train Epoch: 14 [16000/84843 (19%)]\tLoss: 0.241231\n",
      "Train Epoch: 14 [16640/84843 (20%)]\tLoss: 0.165894\n",
      "Train Epoch: 14 [17280/84843 (20%)]\tLoss: 0.423560\n",
      "Train Epoch: 14 [17920/84843 (21%)]\tLoss: 0.543964\n",
      "Train Epoch: 14 [18560/84843 (22%)]\tLoss: 0.241214\n",
      "Train Epoch: 14 [19200/84843 (23%)]\tLoss: 0.199905\n",
      "Train Epoch: 14 [19840/84843 (23%)]\tLoss: 0.654089\n",
      "Train Epoch: 14 [20480/84843 (24%)]\tLoss: 0.432458\n",
      "Train Epoch: 14 [21120/84843 (25%)]\tLoss: 0.581762\n",
      "Train Epoch: 14 [21760/84843 (26%)]\tLoss: 0.334129\n",
      "Train Epoch: 14 [22400/84843 (26%)]\tLoss: 0.178803\n",
      "Train Epoch: 14 [23040/84843 (27%)]\tLoss: 0.109242\n",
      "Train Epoch: 14 [23680/84843 (28%)]\tLoss: 0.415836\n",
      "Train Epoch: 14 [24320/84843 (29%)]\tLoss: 0.273064\n",
      "Train Epoch: 14 [24960/84843 (29%)]\tLoss: 0.500944\n",
      "Train Epoch: 14 [25600/84843 (30%)]\tLoss: 0.337503\n",
      "Train Epoch: 14 [26240/84843 (31%)]\tLoss: 0.184119\n",
      "Train Epoch: 14 [26880/84843 (32%)]\tLoss: 0.296789\n",
      "Train Epoch: 14 [27520/84843 (32%)]\tLoss: 0.391078\n",
      "Train Epoch: 14 [28160/84843 (33%)]\tLoss: 0.342422\n",
      "Train Epoch: 14 [28800/84843 (34%)]\tLoss: 0.766208\n",
      "Train Epoch: 14 [29440/84843 (35%)]\tLoss: 0.195718\n",
      "Train Epoch: 14 [30080/84843 (35%)]\tLoss: 0.348398\n",
      "Train Epoch: 14 [30720/84843 (36%)]\tLoss: 0.228827\n",
      "Train Epoch: 14 [31360/84843 (37%)]\tLoss: 0.137312\n",
      "Train Epoch: 14 [32000/84843 (38%)]\tLoss: 0.685182\n",
      "Train Epoch: 14 [32640/84843 (38%)]\tLoss: 0.192238\n",
      "Train Epoch: 14 [33280/84843 (39%)]\tLoss: 0.292943\n",
      "Train Epoch: 14 [33920/84843 (40%)]\tLoss: 0.370746\n",
      "Train Epoch: 14 [34560/84843 (41%)]\tLoss: 0.434191\n",
      "Train Epoch: 14 [35200/84843 (41%)]\tLoss: 0.389962\n",
      "Train Epoch: 14 [35840/84843 (42%)]\tLoss: 0.454545\n",
      "Train Epoch: 14 [36480/84843 (43%)]\tLoss: 0.370610\n",
      "Train Epoch: 14 [37120/84843 (44%)]\tLoss: 0.309472\n",
      "Train Epoch: 14 [37760/84843 (44%)]\tLoss: 0.306655\n",
      "Train Epoch: 14 [38400/84843 (45%)]\tLoss: 0.136896\n",
      "Train Epoch: 14 [39040/84843 (46%)]\tLoss: 0.393256\n",
      "Train Epoch: 14 [39680/84843 (47%)]\tLoss: 0.429610\n",
      "Train Epoch: 14 [40320/84843 (48%)]\tLoss: 0.243581\n",
      "Train Epoch: 14 [40960/84843 (48%)]\tLoss: 0.364113\n",
      "Train Epoch: 14 [41600/84843 (49%)]\tLoss: 0.415692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [42240/84843 (50%)]\tLoss: 0.256870\n",
      "Train Epoch: 14 [42880/84843 (51%)]\tLoss: 0.324905\n",
      "Train Epoch: 14 [43520/84843 (51%)]\tLoss: 0.276383\n",
      "Train Epoch: 14 [44160/84843 (52%)]\tLoss: 0.326358\n",
      "Train Epoch: 14 [44800/84843 (53%)]\tLoss: 0.616642\n",
      "Train Epoch: 14 [45440/84843 (54%)]\tLoss: 0.376374\n",
      "Train Epoch: 14 [46080/84843 (54%)]\tLoss: 0.356239\n",
      "Train Epoch: 14 [46720/84843 (55%)]\tLoss: 0.394843\n",
      "Train Epoch: 14 [47360/84843 (56%)]\tLoss: 0.745967\n",
      "Train Epoch: 14 [48000/84843 (57%)]\tLoss: 0.314118\n",
      "Train Epoch: 14 [48640/84843 (57%)]\tLoss: 0.249843\n",
      "Train Epoch: 14 [49280/84843 (58%)]\tLoss: 0.188661\n",
      "Train Epoch: 14 [49920/84843 (59%)]\tLoss: 0.167086\n",
      "Train Epoch: 14 [50560/84843 (60%)]\tLoss: 0.344614\n",
      "Train Epoch: 14 [51200/84843 (60%)]\tLoss: 0.526718\n",
      "Train Epoch: 14 [51840/84843 (61%)]\tLoss: 0.145025\n",
      "Train Epoch: 14 [52480/84843 (62%)]\tLoss: 0.374585\n",
      "Train Epoch: 14 [53120/84843 (63%)]\tLoss: 0.487038\n",
      "Train Epoch: 14 [53760/84843 (63%)]\tLoss: 0.396742\n",
      "Train Epoch: 14 [54400/84843 (64%)]\tLoss: 0.157137\n",
      "Train Epoch: 14 [55040/84843 (65%)]\tLoss: 0.241143\n",
      "Train Epoch: 14 [55680/84843 (66%)]\tLoss: 0.133522\n",
      "Train Epoch: 14 [56320/84843 (66%)]\tLoss: 0.259024\n",
      "Train Epoch: 14 [56960/84843 (67%)]\tLoss: 0.251212\n",
      "Train Epoch: 14 [57600/84843 (68%)]\tLoss: 0.591233\n",
      "Train Epoch: 14 [58240/84843 (69%)]\tLoss: 0.318909\n",
      "Train Epoch: 14 [58880/84843 (69%)]\tLoss: 0.412912\n",
      "Train Epoch: 14 [59520/84843 (70%)]\tLoss: 0.532747\n",
      "Train Epoch: 14 [60160/84843 (71%)]\tLoss: 0.122977\n",
      "Train Epoch: 14 [60800/84843 (72%)]\tLoss: 0.166926\n",
      "Train Epoch: 14 [61440/84843 (72%)]\tLoss: 0.431655\n",
      "Train Epoch: 14 [62080/84843 (73%)]\tLoss: 0.422431\n",
      "Train Epoch: 14 [62720/84843 (74%)]\tLoss: 0.393063\n",
      "Train Epoch: 14 [63360/84843 (75%)]\tLoss: 0.656884\n",
      "Train Epoch: 14 [64000/84843 (75%)]\tLoss: 0.313385\n",
      "Train Epoch: 14 [64640/84843 (76%)]\tLoss: 0.203283\n",
      "Train Epoch: 14 [65280/84843 (77%)]\tLoss: 0.275627\n",
      "Train Epoch: 14 [65920/84843 (78%)]\tLoss: 0.467834\n",
      "Train Epoch: 14 [66560/84843 (78%)]\tLoss: 0.481943\n",
      "Train Epoch: 14 [67200/84843 (79%)]\tLoss: 0.426095\n",
      "Train Epoch: 14 [67840/84843 (80%)]\tLoss: 0.638800\n",
      "Train Epoch: 14 [68480/84843 (81%)]\tLoss: 0.469102\n",
      "Train Epoch: 14 [69120/84843 (81%)]\tLoss: 0.449942\n",
      "Train Epoch: 14 [69760/84843 (82%)]\tLoss: 0.259837\n",
      "Train Epoch: 14 [70400/84843 (83%)]\tLoss: 0.454858\n",
      "Train Epoch: 14 [71040/84843 (84%)]\tLoss: 0.291999\n",
      "Train Epoch: 14 [71680/84843 (84%)]\tLoss: 0.629302\n",
      "Train Epoch: 14 [72320/84843 (85%)]\tLoss: 0.327084\n",
      "Train Epoch: 14 [72960/84843 (86%)]\tLoss: 0.313508\n",
      "Train Epoch: 14 [73600/84843 (87%)]\tLoss: 0.522757\n",
      "Train Epoch: 14 [74240/84843 (87%)]\tLoss: 0.422552\n",
      "Train Epoch: 14 [74880/84843 (88%)]\tLoss: 0.420823\n",
      "Train Epoch: 14 [75520/84843 (89%)]\tLoss: 0.307143\n",
      "Train Epoch: 14 [76160/84843 (90%)]\tLoss: 0.251671\n",
      "Train Epoch: 14 [76800/84843 (90%)]\tLoss: 0.238371\n",
      "Train Epoch: 14 [77440/84843 (91%)]\tLoss: 0.490437\n",
      "Train Epoch: 14 [78080/84843 (92%)]\tLoss: 0.301265\n",
      "Train Epoch: 14 [78720/84843 (93%)]\tLoss: 0.376971\n",
      "Train Epoch: 14 [79360/84843 (94%)]\tLoss: 0.795134\n",
      "Train Epoch: 14 [80000/84843 (94%)]\tLoss: 0.507633\n",
      "Train Epoch: 14 [80640/84843 (95%)]\tLoss: 0.409974\n",
      "Train Epoch: 14 [81280/84843 (96%)]\tLoss: 0.236890\n",
      "Train Epoch: 14 [81920/84843 (97%)]\tLoss: 0.322436\n",
      "Train Epoch: 14 [82560/84843 (97%)]\tLoss: 0.543057\n",
      "Train Epoch: 14 [83200/84843 (98%)]\tLoss: 0.504019\n",
      "Train Epoch: 14 [83840/84843 (99%)]\tLoss: 0.394840\n",
      "Train Epoch: 14 [84480/84843 (100%)]\tLoss: 0.200598\n",
      "Accuracy: 9474/11005 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/84843 (0%)]\tLoss: 0.264276\n",
      "Train Epoch: 15 [640/84843 (1%)]\tLoss: 0.390709\n",
      "Train Epoch: 15 [1280/84843 (2%)]\tLoss: 0.311775\n",
      "Train Epoch: 15 [1920/84843 (2%)]\tLoss: 0.111192\n",
      "Train Epoch: 15 [2560/84843 (3%)]\tLoss: 0.115481\n",
      "Train Epoch: 15 [3200/84843 (4%)]\tLoss: 0.244586\n",
      "Train Epoch: 15 [3840/84843 (5%)]\tLoss: 0.186494\n",
      "Train Epoch: 15 [4480/84843 (5%)]\tLoss: 0.303341\n",
      "Train Epoch: 15 [5120/84843 (6%)]\tLoss: 0.183308\n",
      "Train Epoch: 15 [5760/84843 (7%)]\tLoss: 0.331179\n",
      "Train Epoch: 15 [6400/84843 (8%)]\tLoss: 0.316088\n",
      "Train Epoch: 15 [7040/84843 (8%)]\tLoss: 0.282561\n",
      "Train Epoch: 15 [7680/84843 (9%)]\tLoss: 0.439638\n",
      "Train Epoch: 15 [8320/84843 (10%)]\tLoss: 0.603883\n",
      "Train Epoch: 15 [8960/84843 (11%)]\tLoss: 0.159036\n",
      "Train Epoch: 15 [9600/84843 (11%)]\tLoss: 0.544210\n",
      "Train Epoch: 15 [10240/84843 (12%)]\tLoss: 0.602589\n",
      "Train Epoch: 15 [10880/84843 (13%)]\tLoss: 0.461151\n",
      "Train Epoch: 15 [11520/84843 (14%)]\tLoss: 0.608240\n",
      "Train Epoch: 15 [12160/84843 (14%)]\tLoss: 0.294507\n",
      "Train Epoch: 15 [12800/84843 (15%)]\tLoss: 0.438546\n",
      "Train Epoch: 15 [13440/84843 (16%)]\tLoss: 0.349472\n",
      "Train Epoch: 15 [14080/84843 (17%)]\tLoss: 0.383315\n",
      "Train Epoch: 15 [14720/84843 (17%)]\tLoss: 0.198133\n",
      "Train Epoch: 15 [15360/84843 (18%)]\tLoss: 0.474159\n",
      "Train Epoch: 15 [16000/84843 (19%)]\tLoss: 0.846271\n",
      "Train Epoch: 15 [16640/84843 (20%)]\tLoss: 0.214970\n",
      "Train Epoch: 15 [17280/84843 (20%)]\tLoss: 0.330883\n",
      "Train Epoch: 15 [17920/84843 (21%)]\tLoss: 0.445592\n",
      "Train Epoch: 15 [18560/84843 (22%)]\tLoss: 0.531041\n",
      "Train Epoch: 15 [19200/84843 (23%)]\tLoss: 0.301525\n",
      "Train Epoch: 15 [19840/84843 (23%)]\tLoss: 0.307506\n",
      "Train Epoch: 15 [20480/84843 (24%)]\tLoss: 0.267606\n",
      "Train Epoch: 15 [21120/84843 (25%)]\tLoss: 0.415759\n",
      "Train Epoch: 15 [21760/84843 (26%)]\tLoss: 0.775304\n",
      "Train Epoch: 15 [22400/84843 (26%)]\tLoss: 0.593086\n",
      "Train Epoch: 15 [23040/84843 (27%)]\tLoss: 0.106168\n",
      "Train Epoch: 15 [23680/84843 (28%)]\tLoss: 0.261963\n",
      "Train Epoch: 15 [24320/84843 (29%)]\tLoss: 0.243203\n",
      "Train Epoch: 15 [24960/84843 (29%)]\tLoss: 0.303101\n",
      "Train Epoch: 15 [25600/84843 (30%)]\tLoss: 0.164625\n",
      "Train Epoch: 15 [26240/84843 (31%)]\tLoss: 0.329926\n",
      "Train Epoch: 15 [26880/84843 (32%)]\tLoss: 0.541644\n",
      "Train Epoch: 15 [27520/84843 (32%)]\tLoss: 0.262034\n",
      "Train Epoch: 15 [28160/84843 (33%)]\tLoss: 0.298432\n",
      "Train Epoch: 15 [28800/84843 (34%)]\tLoss: 0.449415\n",
      "Train Epoch: 15 [29440/84843 (35%)]\tLoss: 0.059540\n",
      "Train Epoch: 15 [30080/84843 (35%)]\tLoss: 0.454145\n",
      "Train Epoch: 15 [30720/84843 (36%)]\tLoss: 0.241605\n",
      "Train Epoch: 15 [31360/84843 (37%)]\tLoss: 0.442693\n",
      "Train Epoch: 15 [32000/84843 (38%)]\tLoss: 0.722494\n",
      "Train Epoch: 15 [32640/84843 (38%)]\tLoss: 0.924255\n",
      "Train Epoch: 15 [33280/84843 (39%)]\tLoss: 0.399998\n",
      "Train Epoch: 15 [33920/84843 (40%)]\tLoss: 0.222450\n",
      "Train Epoch: 15 [34560/84843 (41%)]\tLoss: 0.102112\n",
      "Train Epoch: 15 [35200/84843 (41%)]\tLoss: 0.258821\n",
      "Train Epoch: 15 [35840/84843 (42%)]\tLoss: 0.288477\n",
      "Train Epoch: 15 [36480/84843 (43%)]\tLoss: 0.439618\n",
      "Train Epoch: 15 [37120/84843 (44%)]\tLoss: 0.352269\n",
      "Train Epoch: 15 [37760/84843 (44%)]\tLoss: 0.426419\n",
      "Train Epoch: 15 [38400/84843 (45%)]\tLoss: 0.295600\n",
      "Train Epoch: 15 [39040/84843 (46%)]\tLoss: 0.198062\n",
      "Train Epoch: 15 [39680/84843 (47%)]\tLoss: 0.804965\n",
      "Train Epoch: 15 [40320/84843 (48%)]\tLoss: 0.415466\n",
      "Train Epoch: 15 [40960/84843 (48%)]\tLoss: 0.094076\n",
      "Train Epoch: 15 [41600/84843 (49%)]\tLoss: 0.168672\n",
      "Train Epoch: 15 [42240/84843 (50%)]\tLoss: 0.515490\n",
      "Train Epoch: 15 [42880/84843 (51%)]\tLoss: 0.244782\n",
      "Train Epoch: 15 [43520/84843 (51%)]\tLoss: 0.349490\n",
      "Train Epoch: 15 [44160/84843 (52%)]\tLoss: 0.338114\n",
      "Train Epoch: 15 [44800/84843 (53%)]\tLoss: 0.310527\n",
      "Train Epoch: 15 [45440/84843 (54%)]\tLoss: 0.381942\n",
      "Train Epoch: 15 [46080/84843 (54%)]\tLoss: 0.262155\n",
      "Train Epoch: 15 [46720/84843 (55%)]\tLoss: 0.296747\n",
      "Train Epoch: 15 [47360/84843 (56%)]\tLoss: 0.585199\n",
      "Train Epoch: 15 [48000/84843 (57%)]\tLoss: 0.221297\n",
      "Train Epoch: 15 [48640/84843 (57%)]\tLoss: 0.404516\n",
      "Train Epoch: 15 [49280/84843 (58%)]\tLoss: 0.363518\n",
      "Train Epoch: 15 [49920/84843 (59%)]\tLoss: 0.501815\n",
      "Train Epoch: 15 [50560/84843 (60%)]\tLoss: 0.190415\n",
      "Train Epoch: 15 [51200/84843 (60%)]\tLoss: 0.413815\n",
      "Train Epoch: 15 [51840/84843 (61%)]\tLoss: 0.106133\n",
      "Train Epoch: 15 [52480/84843 (62%)]\tLoss: 0.265823\n",
      "Train Epoch: 15 [53120/84843 (63%)]\tLoss: 0.227380\n",
      "Train Epoch: 15 [53760/84843 (63%)]\tLoss: 0.434610\n",
      "Train Epoch: 15 [54400/84843 (64%)]\tLoss: 0.305611\n",
      "Train Epoch: 15 [55040/84843 (65%)]\tLoss: 0.404776\n",
      "Train Epoch: 15 [55680/84843 (66%)]\tLoss: 0.287282\n",
      "Train Epoch: 15 [56320/84843 (66%)]\tLoss: 0.443005\n",
      "Train Epoch: 15 [56960/84843 (67%)]\tLoss: 0.389031\n",
      "Train Epoch: 15 [57600/84843 (68%)]\tLoss: 0.398876\n",
      "Train Epoch: 15 [58240/84843 (69%)]\tLoss: 0.522075\n",
      "Train Epoch: 15 [58880/84843 (69%)]\tLoss: 0.548591\n",
      "Train Epoch: 15 [59520/84843 (70%)]\tLoss: 0.558477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [60160/84843 (71%)]\tLoss: 0.275001\n",
      "Train Epoch: 15 [60800/84843 (72%)]\tLoss: 0.455115\n",
      "Train Epoch: 15 [61440/84843 (72%)]\tLoss: 0.196725\n",
      "Train Epoch: 15 [62080/84843 (73%)]\tLoss: 0.639591\n",
      "Train Epoch: 15 [62720/84843 (74%)]\tLoss: 0.574570\n",
      "Train Epoch: 15 [63360/84843 (75%)]\tLoss: 0.481678\n",
      "Train Epoch: 15 [64000/84843 (75%)]\tLoss: 0.182982\n",
      "Train Epoch: 15 [64640/84843 (76%)]\tLoss: 0.295791\n",
      "Train Epoch: 15 [65280/84843 (77%)]\tLoss: 0.764922\n",
      "Train Epoch: 15 [65920/84843 (78%)]\tLoss: 0.346879\n",
      "Train Epoch: 15 [66560/84843 (78%)]\tLoss: 0.282804\n",
      "Train Epoch: 15 [67200/84843 (79%)]\tLoss: 0.170866\n",
      "Train Epoch: 15 [67840/84843 (80%)]\tLoss: 0.606143\n",
      "Train Epoch: 15 [68480/84843 (81%)]\tLoss: 0.358077\n",
      "Train Epoch: 15 [69120/84843 (81%)]\tLoss: 0.250214\n",
      "Train Epoch: 15 [69760/84843 (82%)]\tLoss: 0.745799\n",
      "Train Epoch: 15 [70400/84843 (83%)]\tLoss: 0.762015\n",
      "Train Epoch: 15 [71040/84843 (84%)]\tLoss: 0.329979\n",
      "Train Epoch: 15 [71680/84843 (84%)]\tLoss: 0.430071\n",
      "Train Epoch: 15 [72320/84843 (85%)]\tLoss: 0.096214\n",
      "Train Epoch: 15 [72960/84843 (86%)]\tLoss: 0.231300\n",
      "Train Epoch: 15 [73600/84843 (87%)]\tLoss: 0.184638\n",
      "Train Epoch: 15 [74240/84843 (87%)]\tLoss: 0.327532\n",
      "Train Epoch: 15 [74880/84843 (88%)]\tLoss: 0.274974\n",
      "Train Epoch: 15 [75520/84843 (89%)]\tLoss: 0.497201\n",
      "Train Epoch: 15 [76160/84843 (90%)]\tLoss: 0.445075\n",
      "Train Epoch: 15 [76800/84843 (90%)]\tLoss: 0.162360\n",
      "Train Epoch: 15 [77440/84843 (91%)]\tLoss: 0.430954\n",
      "Train Epoch: 15 [78080/84843 (92%)]\tLoss: 0.371916\n",
      "Train Epoch: 15 [78720/84843 (93%)]\tLoss: 0.455900\n",
      "Train Epoch: 15 [79360/84843 (94%)]\tLoss: 0.447790\n",
      "Train Epoch: 15 [80000/84843 (94%)]\tLoss: 0.196594\n",
      "Train Epoch: 15 [80640/84843 (95%)]\tLoss: 0.495473\n",
      "Train Epoch: 15 [81280/84843 (96%)]\tLoss: 0.304845\n",
      "Train Epoch: 15 [81920/84843 (97%)]\tLoss: 0.690748\n",
      "Train Epoch: 15 [82560/84843 (97%)]\tLoss: 0.401809\n",
      "Train Epoch: 15 [83200/84843 (98%)]\tLoss: 0.213074\n",
      "Train Epoch: 15 [83840/84843 (99%)]\tLoss: 0.108244\n",
      "Train Epoch: 15 [84480/84843 (100%)]\tLoss: 0.244246\n",
      "Accuracy: 9363/11005 (85%)\n",
      "\n",
      "Train Epoch: 16 [0/84843 (0%)]\tLoss: 0.241250\n",
      "Train Epoch: 16 [640/84843 (1%)]\tLoss: 0.571697\n",
      "Train Epoch: 16 [1280/84843 (2%)]\tLoss: 0.409071\n",
      "Train Epoch: 16 [1920/84843 (2%)]\tLoss: 0.166891\n",
      "Train Epoch: 16 [2560/84843 (3%)]\tLoss: 0.216448\n",
      "Train Epoch: 16 [3200/84843 (4%)]\tLoss: 0.277586\n",
      "Train Epoch: 16 [3840/84843 (5%)]\tLoss: 0.160441\n",
      "Train Epoch: 16 [4480/84843 (5%)]\tLoss: 0.364386\n",
      "Train Epoch: 16 [5120/84843 (6%)]\tLoss: 0.330441\n",
      "Train Epoch: 16 [5760/84843 (7%)]\tLoss: 0.360494\n",
      "Train Epoch: 16 [6400/84843 (8%)]\tLoss: 0.469568\n",
      "Train Epoch: 16 [7040/84843 (8%)]\tLoss: 0.487666\n",
      "Train Epoch: 16 [7680/84843 (9%)]\tLoss: 0.435131\n",
      "Train Epoch: 16 [8320/84843 (10%)]\tLoss: 0.712556\n",
      "Train Epoch: 16 [8960/84843 (11%)]\tLoss: 0.349718\n",
      "Train Epoch: 16 [9600/84843 (11%)]\tLoss: 0.140923\n",
      "Train Epoch: 16 [10240/84843 (12%)]\tLoss: 0.216916\n",
      "Train Epoch: 16 [10880/84843 (13%)]\tLoss: 0.607835\n",
      "Train Epoch: 16 [11520/84843 (14%)]\tLoss: 0.336457\n",
      "Train Epoch: 16 [12160/84843 (14%)]\tLoss: 0.565492\n",
      "Train Epoch: 16 [12800/84843 (15%)]\tLoss: 0.338097\n",
      "Train Epoch: 16 [13440/84843 (16%)]\tLoss: 0.563262\n",
      "Train Epoch: 16 [14080/84843 (17%)]\tLoss: 0.222592\n",
      "Train Epoch: 16 [14720/84843 (17%)]\tLoss: 0.358820\n",
      "Train Epoch: 16 [15360/84843 (18%)]\tLoss: 0.308100\n",
      "Train Epoch: 16 [16000/84843 (19%)]\tLoss: 0.257821\n",
      "Train Epoch: 16 [16640/84843 (20%)]\tLoss: 0.343552\n",
      "Train Epoch: 16 [17280/84843 (20%)]\tLoss: 0.384210\n",
      "Train Epoch: 16 [17920/84843 (21%)]\tLoss: 0.294391\n",
      "Train Epoch: 16 [18560/84843 (22%)]\tLoss: 0.731347\n",
      "Train Epoch: 16 [19200/84843 (23%)]\tLoss: 0.293553\n",
      "Train Epoch: 16 [19840/84843 (23%)]\tLoss: 0.922019\n",
      "Train Epoch: 16 [20480/84843 (24%)]\tLoss: 0.429021\n",
      "Train Epoch: 16 [21120/84843 (25%)]\tLoss: 0.449609\n",
      "Train Epoch: 16 [21760/84843 (26%)]\tLoss: 0.321312\n",
      "Train Epoch: 16 [22400/84843 (26%)]\tLoss: 0.493101\n",
      "Train Epoch: 16 [23040/84843 (27%)]\tLoss: 0.219893\n",
      "Train Epoch: 16 [23680/84843 (28%)]\tLoss: 0.281872\n",
      "Train Epoch: 16 [24320/84843 (29%)]\tLoss: 0.441577\n",
      "Train Epoch: 16 [24960/84843 (29%)]\tLoss: 0.335046\n",
      "Train Epoch: 16 [25600/84843 (30%)]\tLoss: 0.215929\n",
      "Train Epoch: 16 [26240/84843 (31%)]\tLoss: 0.432176\n",
      "Train Epoch: 16 [26880/84843 (32%)]\tLoss: 0.426080\n",
      "Train Epoch: 16 [27520/84843 (32%)]\tLoss: 0.350351\n",
      "Train Epoch: 16 [28160/84843 (33%)]\tLoss: 0.428073\n",
      "Train Epoch: 16 [28800/84843 (34%)]\tLoss: 0.184452\n",
      "Train Epoch: 16 [29440/84843 (35%)]\tLoss: 0.208978\n",
      "Train Epoch: 16 [30080/84843 (35%)]\tLoss: 0.289398\n",
      "Train Epoch: 16 [30720/84843 (36%)]\tLoss: 0.622017\n",
      "Train Epoch: 16 [31360/84843 (37%)]\tLoss: 0.175396\n",
      "Train Epoch: 16 [32000/84843 (38%)]\tLoss: 0.208065\n",
      "Train Epoch: 16 [32640/84843 (38%)]\tLoss: 0.268606\n",
      "Train Epoch: 16 [33280/84843 (39%)]\tLoss: 0.072296\n",
      "Train Epoch: 16 [33920/84843 (40%)]\tLoss: 0.389349\n",
      "Train Epoch: 16 [34560/84843 (41%)]\tLoss: 0.329223\n",
      "Train Epoch: 16 [35200/84843 (41%)]\tLoss: 0.433160\n",
      "Train Epoch: 16 [35840/84843 (42%)]\tLoss: 0.150218\n",
      "Train Epoch: 16 [36480/84843 (43%)]\tLoss: 0.431366\n",
      "Train Epoch: 16 [37120/84843 (44%)]\tLoss: 0.302254\n",
      "Train Epoch: 16 [37760/84843 (44%)]\tLoss: 0.232580\n",
      "Train Epoch: 16 [38400/84843 (45%)]\tLoss: 0.398318\n",
      "Train Epoch: 16 [39040/84843 (46%)]\tLoss: 0.209851\n",
      "Train Epoch: 16 [39680/84843 (47%)]\tLoss: 0.176822\n",
      "Train Epoch: 16 [40320/84843 (48%)]\tLoss: 0.178413\n",
      "Train Epoch: 16 [40960/84843 (48%)]\tLoss: 0.414699\n",
      "Train Epoch: 16 [41600/84843 (49%)]\tLoss: 0.149611\n",
      "Train Epoch: 16 [42240/84843 (50%)]\tLoss: 0.692728\n",
      "Train Epoch: 16 [42880/84843 (51%)]\tLoss: 0.216380\n",
      "Train Epoch: 16 [43520/84843 (51%)]\tLoss: 0.369258\n",
      "Train Epoch: 16 [44160/84843 (52%)]\tLoss: 0.378670\n",
      "Train Epoch: 16 [44800/84843 (53%)]\tLoss: 0.569044\n",
      "Train Epoch: 16 [45440/84843 (54%)]\tLoss: 0.383725\n",
      "Train Epoch: 16 [46080/84843 (54%)]\tLoss: 0.365409\n",
      "Train Epoch: 16 [46720/84843 (55%)]\tLoss: 0.268129\n",
      "Train Epoch: 16 [47360/84843 (56%)]\tLoss: 0.588092\n",
      "Train Epoch: 16 [48000/84843 (57%)]\tLoss: 0.743246\n",
      "Train Epoch: 16 [48640/84843 (57%)]\tLoss: 0.178077\n",
      "Train Epoch: 16 [49280/84843 (58%)]\tLoss: 0.399682\n",
      "Train Epoch: 16 [49920/84843 (59%)]\tLoss: 0.512892\n",
      "Train Epoch: 16 [50560/84843 (60%)]\tLoss: 0.480314\n",
      "Train Epoch: 16 [51200/84843 (60%)]\tLoss: 0.548140\n",
      "Train Epoch: 16 [51840/84843 (61%)]\tLoss: 0.095092\n",
      "Train Epoch: 16 [52480/84843 (62%)]\tLoss: 0.169155\n",
      "Train Epoch: 16 [53120/84843 (63%)]\tLoss: 0.516245\n",
      "Train Epoch: 16 [53760/84843 (63%)]\tLoss: 0.231749\n",
      "Train Epoch: 16 [54400/84843 (64%)]\tLoss: 0.231342\n",
      "Train Epoch: 16 [55040/84843 (65%)]\tLoss: 0.805196\n",
      "Train Epoch: 16 [55680/84843 (66%)]\tLoss: 0.644915\n",
      "Train Epoch: 16 [56320/84843 (66%)]\tLoss: 0.127755\n",
      "Train Epoch: 16 [56960/84843 (67%)]\tLoss: 0.449125\n",
      "Train Epoch: 16 [57600/84843 (68%)]\tLoss: 0.253172\n",
      "Train Epoch: 16 [58240/84843 (69%)]\tLoss: 0.617802\n",
      "Train Epoch: 16 [58880/84843 (69%)]\tLoss: 0.172159\n",
      "Train Epoch: 16 [59520/84843 (70%)]\tLoss: 0.349980\n",
      "Train Epoch: 16 [60160/84843 (71%)]\tLoss: 0.154111\n",
      "Train Epoch: 16 [60800/84843 (72%)]\tLoss: 0.134603\n",
      "Train Epoch: 16 [61440/84843 (72%)]\tLoss: 0.901290\n",
      "Train Epoch: 16 [62080/84843 (73%)]\tLoss: 0.271600\n",
      "Train Epoch: 16 [62720/84843 (74%)]\tLoss: 0.247770\n",
      "Train Epoch: 16 [63360/84843 (75%)]\tLoss: 0.303066\n",
      "Train Epoch: 16 [64000/84843 (75%)]\tLoss: 0.231994\n",
      "Train Epoch: 16 [64640/84843 (76%)]\tLoss: 0.360187\n",
      "Train Epoch: 16 [65280/84843 (77%)]\tLoss: 0.500897\n",
      "Train Epoch: 16 [65920/84843 (78%)]\tLoss: 0.675792\n",
      "Train Epoch: 16 [66560/84843 (78%)]\tLoss: 0.543990\n",
      "Train Epoch: 16 [67200/84843 (79%)]\tLoss: 0.299996\n",
      "Train Epoch: 16 [67840/84843 (80%)]\tLoss: 0.404425\n",
      "Train Epoch: 16 [68480/84843 (81%)]\tLoss: 0.571140\n",
      "Train Epoch: 16 [69120/84843 (81%)]\tLoss: 0.237551\n",
      "Train Epoch: 16 [69760/84843 (82%)]\tLoss: 0.483070\n",
      "Train Epoch: 16 [70400/84843 (83%)]\tLoss: 0.363470\n",
      "Train Epoch: 16 [71040/84843 (84%)]\tLoss: 0.334973\n",
      "Train Epoch: 16 [71680/84843 (84%)]\tLoss: 0.125968\n",
      "Train Epoch: 16 [72320/84843 (85%)]\tLoss: 0.825040\n",
      "Train Epoch: 16 [72960/84843 (86%)]\tLoss: 0.216525\n",
      "Train Epoch: 16 [73600/84843 (87%)]\tLoss: 0.708987\n",
      "Train Epoch: 16 [74240/84843 (87%)]\tLoss: 0.114441\n",
      "Train Epoch: 16 [74880/84843 (88%)]\tLoss: 0.358306\n",
      "Train Epoch: 16 [75520/84843 (89%)]\tLoss: 0.327587\n",
      "Train Epoch: 16 [76160/84843 (90%)]\tLoss: 0.133853\n",
      "Train Epoch: 16 [76800/84843 (90%)]\tLoss: 0.223569\n",
      "Train Epoch: 16 [77440/84843 (91%)]\tLoss: 0.335884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [78080/84843 (92%)]\tLoss: 0.256224\n",
      "Train Epoch: 16 [78720/84843 (93%)]\tLoss: 0.213423\n",
      "Train Epoch: 16 [79360/84843 (94%)]\tLoss: 0.322353\n",
      "Train Epoch: 16 [80000/84843 (94%)]\tLoss: 0.463690\n",
      "Train Epoch: 16 [80640/84843 (95%)]\tLoss: 0.162790\n",
      "Train Epoch: 16 [81280/84843 (96%)]\tLoss: 0.537612\n",
      "Train Epoch: 16 [81920/84843 (97%)]\tLoss: 0.338891\n",
      "Train Epoch: 16 [82560/84843 (97%)]\tLoss: 0.520378\n",
      "Train Epoch: 16 [83200/84843 (98%)]\tLoss: 0.320870\n",
      "Train Epoch: 16 [83840/84843 (99%)]\tLoss: 0.557906\n",
      "Train Epoch: 16 [84480/84843 (100%)]\tLoss: 0.412961\n",
      "Accuracy: 9357/11005 (85%)\n",
      "\n",
      "Train Epoch: 17 [0/84843 (0%)]\tLoss: 0.527753\n",
      "Train Epoch: 17 [640/84843 (1%)]\tLoss: 0.282886\n",
      "Train Epoch: 17 [1280/84843 (2%)]\tLoss: 0.580876\n",
      "Train Epoch: 17 [1920/84843 (2%)]\tLoss: 0.115019\n",
      "Train Epoch: 17 [2560/84843 (3%)]\tLoss: 0.451497\n",
      "Train Epoch: 17 [3200/84843 (4%)]\tLoss: 0.420330\n",
      "Train Epoch: 17 [3840/84843 (5%)]\tLoss: 0.430610\n",
      "Train Epoch: 17 [4480/84843 (5%)]\tLoss: 0.192281\n",
      "Train Epoch: 17 [5120/84843 (6%)]\tLoss: 0.257073\n",
      "Train Epoch: 17 [5760/84843 (7%)]\tLoss: 0.463109\n",
      "Train Epoch: 17 [6400/84843 (8%)]\tLoss: 0.407493\n",
      "Train Epoch: 17 [7040/84843 (8%)]\tLoss: 0.312352\n",
      "Train Epoch: 17 [7680/84843 (9%)]\tLoss: 0.369390\n",
      "Train Epoch: 17 [8320/84843 (10%)]\tLoss: 0.608343\n",
      "Train Epoch: 17 [8960/84843 (11%)]\tLoss: 0.289219\n",
      "Train Epoch: 17 [9600/84843 (11%)]\tLoss: 0.180433\n",
      "Train Epoch: 17 [10240/84843 (12%)]\tLoss: 0.606681\n",
      "Train Epoch: 17 [10880/84843 (13%)]\tLoss: 0.136276\n",
      "Train Epoch: 17 [11520/84843 (14%)]\tLoss: 0.250080\n",
      "Train Epoch: 17 [12160/84843 (14%)]\tLoss: 0.266067\n",
      "Train Epoch: 17 [12800/84843 (15%)]\tLoss: 0.300710\n",
      "Train Epoch: 17 [13440/84843 (16%)]\tLoss: 0.617033\n",
      "Train Epoch: 17 [14080/84843 (17%)]\tLoss: 0.294291\n",
      "Train Epoch: 17 [14720/84843 (17%)]\tLoss: 0.378319\n",
      "Train Epoch: 17 [15360/84843 (18%)]\tLoss: 0.380859\n",
      "Train Epoch: 17 [16000/84843 (19%)]\tLoss: 0.284344\n",
      "Train Epoch: 17 [16640/84843 (20%)]\tLoss: 0.165295\n",
      "Train Epoch: 17 [17280/84843 (20%)]\tLoss: 0.376183\n",
      "Train Epoch: 17 [17920/84843 (21%)]\tLoss: 0.428307\n",
      "Train Epoch: 17 [18560/84843 (22%)]\tLoss: 0.199458\n",
      "Train Epoch: 17 [19200/84843 (23%)]\tLoss: 0.371555\n",
      "Train Epoch: 17 [19840/84843 (23%)]\tLoss: 0.431722\n",
      "Train Epoch: 17 [20480/84843 (24%)]\tLoss: 0.465104\n",
      "Train Epoch: 17 [21120/84843 (25%)]\tLoss: 0.232070\n",
      "Train Epoch: 17 [21760/84843 (26%)]\tLoss: 0.219147\n",
      "Train Epoch: 17 [22400/84843 (26%)]\tLoss: 0.688629\n",
      "Train Epoch: 17 [23040/84843 (27%)]\tLoss: 0.170338\n",
      "Train Epoch: 17 [23680/84843 (28%)]\tLoss: 0.171607\n",
      "Train Epoch: 17 [24320/84843 (29%)]\tLoss: 0.530724\n",
      "Train Epoch: 17 [24960/84843 (29%)]\tLoss: 0.275015\n",
      "Train Epoch: 17 [25600/84843 (30%)]\tLoss: 0.290343\n",
      "Train Epoch: 17 [26240/84843 (31%)]\tLoss: 0.580933\n",
      "Train Epoch: 17 [26880/84843 (32%)]\tLoss: 0.180869\n",
      "Train Epoch: 17 [27520/84843 (32%)]\tLoss: 0.510628\n",
      "Train Epoch: 17 [28160/84843 (33%)]\tLoss: 0.153436\n",
      "Train Epoch: 17 [28800/84843 (34%)]\tLoss: 0.307400\n",
      "Train Epoch: 17 [29440/84843 (35%)]\tLoss: 0.175682\n",
      "Train Epoch: 17 [30080/84843 (35%)]\tLoss: 0.198372\n",
      "Train Epoch: 17 [30720/84843 (36%)]\tLoss: 0.214526\n",
      "Train Epoch: 17 [31360/84843 (37%)]\tLoss: 0.242384\n",
      "Train Epoch: 17 [32000/84843 (38%)]\tLoss: 0.316342\n",
      "Train Epoch: 17 [32640/84843 (38%)]\tLoss: 0.268554\n",
      "Train Epoch: 17 [33280/84843 (39%)]\tLoss: 0.286307\n",
      "Train Epoch: 17 [33920/84843 (40%)]\tLoss: 0.340227\n",
      "Train Epoch: 17 [34560/84843 (41%)]\tLoss: 0.147945\n",
      "Train Epoch: 17 [35200/84843 (41%)]\tLoss: 0.468781\n",
      "Train Epoch: 17 [35840/84843 (42%)]\tLoss: 0.443430\n",
      "Train Epoch: 17 [36480/84843 (43%)]\tLoss: 0.347623\n",
      "Train Epoch: 17 [37120/84843 (44%)]\tLoss: 0.158903\n",
      "Train Epoch: 17 [37760/84843 (44%)]\tLoss: 0.646752\n",
      "Train Epoch: 17 [38400/84843 (45%)]\tLoss: 0.240298\n",
      "Train Epoch: 17 [39040/84843 (46%)]\tLoss: 0.770203\n",
      "Train Epoch: 17 [39680/84843 (47%)]\tLoss: 0.470227\n",
      "Train Epoch: 17 [40320/84843 (48%)]\tLoss: 0.069104\n",
      "Train Epoch: 17 [40960/84843 (48%)]\tLoss: 0.314999\n",
      "Train Epoch: 17 [41600/84843 (49%)]\tLoss: 0.414188\n",
      "Train Epoch: 17 [42240/84843 (50%)]\tLoss: 0.580954\n",
      "Train Epoch: 17 [42880/84843 (51%)]\tLoss: 0.052043\n",
      "Train Epoch: 17 [43520/84843 (51%)]\tLoss: 0.265359\n",
      "Train Epoch: 17 [44160/84843 (52%)]\tLoss: 0.122944\n",
      "Train Epoch: 17 [44800/84843 (53%)]\tLoss: 0.500191\n",
      "Train Epoch: 17 [45440/84843 (54%)]\tLoss: 0.359217\n",
      "Train Epoch: 17 [46080/84843 (54%)]\tLoss: 0.427969\n",
      "Train Epoch: 17 [46720/84843 (55%)]\tLoss: 0.529169\n",
      "Train Epoch: 17 [47360/84843 (56%)]\tLoss: 0.207442\n",
      "Train Epoch: 17 [48000/84843 (57%)]\tLoss: 0.265535\n",
      "Train Epoch: 17 [48640/84843 (57%)]\tLoss: 0.595337\n",
      "Train Epoch: 17 [49280/84843 (58%)]\tLoss: 0.376412\n",
      "Train Epoch: 17 [49920/84843 (59%)]\tLoss: 0.351621\n",
      "Train Epoch: 17 [50560/84843 (60%)]\tLoss: 0.402421\n",
      "Train Epoch: 17 [51200/84843 (60%)]\tLoss: 0.400659\n",
      "Train Epoch: 17 [51840/84843 (61%)]\tLoss: 0.390029\n",
      "Train Epoch: 17 [52480/84843 (62%)]\tLoss: 0.236207\n",
      "Train Epoch: 17 [53120/84843 (63%)]\tLoss: 0.447474\n",
      "Train Epoch: 17 [53760/84843 (63%)]\tLoss: 0.259304\n",
      "Train Epoch: 17 [54400/84843 (64%)]\tLoss: 0.472954\n",
      "Train Epoch: 17 [55040/84843 (65%)]\tLoss: 0.195892\n",
      "Train Epoch: 17 [55680/84843 (66%)]\tLoss: 0.135631\n",
      "Train Epoch: 17 [56320/84843 (66%)]\tLoss: 0.270470\n",
      "Train Epoch: 17 [56960/84843 (67%)]\tLoss: 0.189060\n",
      "Train Epoch: 17 [57600/84843 (68%)]\tLoss: 0.586072\n",
      "Train Epoch: 17 [58240/84843 (69%)]\tLoss: 0.155247\n",
      "Train Epoch: 17 [58880/84843 (69%)]\tLoss: 0.497093\n",
      "Train Epoch: 17 [59520/84843 (70%)]\tLoss: 0.575151\n",
      "Train Epoch: 17 [60160/84843 (71%)]\tLoss: 0.214935\n",
      "Train Epoch: 17 [60800/84843 (72%)]\tLoss: 0.508002\n",
      "Train Epoch: 17 [61440/84843 (72%)]\tLoss: 0.370798\n",
      "Train Epoch: 17 [62080/84843 (73%)]\tLoss: 0.051595\n",
      "Train Epoch: 17 [62720/84843 (74%)]\tLoss: 0.353632\n",
      "Train Epoch: 17 [63360/84843 (75%)]\tLoss: 0.537107\n",
      "Train Epoch: 17 [64000/84843 (75%)]\tLoss: 0.314202\n",
      "Train Epoch: 17 [64640/84843 (76%)]\tLoss: 0.291941\n",
      "Train Epoch: 17 [65280/84843 (77%)]\tLoss: 0.227742\n",
      "Train Epoch: 17 [65920/84843 (78%)]\tLoss: 0.582832\n",
      "Train Epoch: 17 [66560/84843 (78%)]\tLoss: 0.422530\n",
      "Train Epoch: 17 [67200/84843 (79%)]\tLoss: 0.135171\n",
      "Train Epoch: 17 [67840/84843 (80%)]\tLoss: 0.279127\n",
      "Train Epoch: 17 [68480/84843 (81%)]\tLoss: 0.521594\n",
      "Train Epoch: 17 [69120/84843 (81%)]\tLoss: 0.253530\n",
      "Train Epoch: 17 [69760/84843 (82%)]\tLoss: 0.120924\n",
      "Train Epoch: 17 [70400/84843 (83%)]\tLoss: 0.805158\n",
      "Train Epoch: 17 [71040/84843 (84%)]\tLoss: 0.194813\n",
      "Train Epoch: 17 [71680/84843 (84%)]\tLoss: 0.209613\n",
      "Train Epoch: 17 [72320/84843 (85%)]\tLoss: 0.344513\n",
      "Train Epoch: 17 [72960/84843 (86%)]\tLoss: 0.242744\n",
      "Train Epoch: 17 [73600/84843 (87%)]\tLoss: 0.086770\n",
      "Train Epoch: 17 [74240/84843 (87%)]\tLoss: 0.315533\n",
      "Train Epoch: 17 [74880/84843 (88%)]\tLoss: 0.183003\n",
      "Train Epoch: 17 [75520/84843 (89%)]\tLoss: 0.967338\n",
      "Train Epoch: 17 [76160/84843 (90%)]\tLoss: 0.502554\n",
      "Train Epoch: 17 [76800/84843 (90%)]\tLoss: 0.525287\n",
      "Train Epoch: 17 [77440/84843 (91%)]\tLoss: 0.272817\n",
      "Train Epoch: 17 [78080/84843 (92%)]\tLoss: 0.380274\n",
      "Train Epoch: 17 [78720/84843 (93%)]\tLoss: 0.177013\n",
      "Train Epoch: 17 [79360/84843 (94%)]\tLoss: 0.533788\n",
      "Train Epoch: 17 [80000/84843 (94%)]\tLoss: 0.528520\n",
      "Train Epoch: 17 [80640/84843 (95%)]\tLoss: 0.420181\n",
      "Train Epoch: 17 [81280/84843 (96%)]\tLoss: 0.171234\n",
      "Train Epoch: 17 [81920/84843 (97%)]\tLoss: 0.471484\n",
      "Train Epoch: 17 [82560/84843 (97%)]\tLoss: 0.239316\n",
      "Train Epoch: 17 [83200/84843 (98%)]\tLoss: 0.465216\n",
      "Train Epoch: 17 [83840/84843 (99%)]\tLoss: 0.327361\n",
      "Train Epoch: 17 [84480/84843 (100%)]\tLoss: 0.675978\n",
      "Accuracy: 9439/11005 (86%)\n",
      "\n",
      "Train Epoch: 18 [0/84843 (0%)]\tLoss: 0.502796\n",
      "Train Epoch: 18 [640/84843 (1%)]\tLoss: 0.296689\n",
      "Train Epoch: 18 [1280/84843 (2%)]\tLoss: 0.230431\n",
      "Train Epoch: 18 [1920/84843 (2%)]\tLoss: 0.484731\n",
      "Train Epoch: 18 [2560/84843 (3%)]\tLoss: 0.722713\n",
      "Train Epoch: 18 [3200/84843 (4%)]\tLoss: 0.279047\n",
      "Train Epoch: 18 [3840/84843 (5%)]\tLoss: 0.164220\n",
      "Train Epoch: 18 [4480/84843 (5%)]\tLoss: 0.530812\n",
      "Train Epoch: 18 [5120/84843 (6%)]\tLoss: 0.152808\n",
      "Train Epoch: 18 [5760/84843 (7%)]\tLoss: 0.532897\n",
      "Train Epoch: 18 [6400/84843 (8%)]\tLoss: 0.224617\n",
      "Train Epoch: 18 [7040/84843 (8%)]\tLoss: 0.274594\n",
      "Train Epoch: 18 [7680/84843 (9%)]\tLoss: 0.385478\n",
      "Train Epoch: 18 [8320/84843 (10%)]\tLoss: 0.121891\n",
      "Train Epoch: 18 [8960/84843 (11%)]\tLoss: 0.242911\n",
      "Train Epoch: 18 [9600/84843 (11%)]\tLoss: 0.568646\n",
      "Train Epoch: 18 [10240/84843 (12%)]\tLoss: 0.479619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [10880/84843 (13%)]\tLoss: 0.069417\n",
      "Train Epoch: 18 [11520/84843 (14%)]\tLoss: 0.248217\n",
      "Train Epoch: 18 [12160/84843 (14%)]\tLoss: 0.120106\n",
      "Train Epoch: 18 [12800/84843 (15%)]\tLoss: 0.343798\n",
      "Train Epoch: 18 [13440/84843 (16%)]\tLoss: 0.304883\n",
      "Train Epoch: 18 [14080/84843 (17%)]\tLoss: 0.205198\n",
      "Train Epoch: 18 [14720/84843 (17%)]\tLoss: 0.198573\n",
      "Train Epoch: 18 [15360/84843 (18%)]\tLoss: 0.176611\n",
      "Train Epoch: 18 [16000/84843 (19%)]\tLoss: 0.310666\n",
      "Train Epoch: 18 [16640/84843 (20%)]\tLoss: 0.193736\n",
      "Train Epoch: 18 [17280/84843 (20%)]\tLoss: 0.168214\n",
      "Train Epoch: 18 [17920/84843 (21%)]\tLoss: 0.186374\n",
      "Train Epoch: 18 [18560/84843 (22%)]\tLoss: 0.412592\n",
      "Train Epoch: 18 [19200/84843 (23%)]\tLoss: 0.368831\n",
      "Train Epoch: 18 [19840/84843 (23%)]\tLoss: 0.602192\n",
      "Train Epoch: 18 [20480/84843 (24%)]\tLoss: 0.157655\n",
      "Train Epoch: 18 [21120/84843 (25%)]\tLoss: 0.364258\n",
      "Train Epoch: 18 [21760/84843 (26%)]\tLoss: 0.495273\n",
      "Train Epoch: 18 [22400/84843 (26%)]\tLoss: 0.180019\n",
      "Train Epoch: 18 [23040/84843 (27%)]\tLoss: 0.531844\n",
      "Train Epoch: 18 [23680/84843 (28%)]\tLoss: 0.662307\n",
      "Train Epoch: 18 [24320/84843 (29%)]\tLoss: 0.432745\n",
      "Train Epoch: 18 [24960/84843 (29%)]\tLoss: 0.170730\n",
      "Train Epoch: 18 [25600/84843 (30%)]\tLoss: 0.197180\n",
      "Train Epoch: 18 [26240/84843 (31%)]\tLoss: 0.542562\n",
      "Train Epoch: 18 [26880/84843 (32%)]\tLoss: 0.333152\n",
      "Train Epoch: 18 [27520/84843 (32%)]\tLoss: 0.411092\n",
      "Train Epoch: 18 [28160/84843 (33%)]\tLoss: 0.418091\n",
      "Train Epoch: 18 [28800/84843 (34%)]\tLoss: 0.236934\n",
      "Train Epoch: 18 [29440/84843 (35%)]\tLoss: 0.108158\n",
      "Train Epoch: 18 [30080/84843 (35%)]\tLoss: 0.255940\n",
      "Train Epoch: 18 [30720/84843 (36%)]\tLoss: 0.195526\n",
      "Train Epoch: 18 [31360/84843 (37%)]\tLoss: 0.335200\n",
      "Train Epoch: 18 [32000/84843 (38%)]\tLoss: 0.362927\n",
      "Train Epoch: 18 [32640/84843 (38%)]\tLoss: 0.331330\n",
      "Train Epoch: 18 [33280/84843 (39%)]\tLoss: 0.570430\n",
      "Train Epoch: 18 [33920/84843 (40%)]\tLoss: 0.239870\n",
      "Train Epoch: 18 [34560/84843 (41%)]\tLoss: 0.176763\n",
      "Train Epoch: 18 [35200/84843 (41%)]\tLoss: 0.413282\n",
      "Train Epoch: 18 [35840/84843 (42%)]\tLoss: 0.307386\n",
      "Train Epoch: 18 [36480/84843 (43%)]\tLoss: 0.301740\n",
      "Train Epoch: 18 [37120/84843 (44%)]\tLoss: 0.404465\n",
      "Train Epoch: 18 [37760/84843 (44%)]\tLoss: 0.235983\n",
      "Train Epoch: 18 [38400/84843 (45%)]\tLoss: 0.482093\n",
      "Train Epoch: 18 [39040/84843 (46%)]\tLoss: 0.372121\n",
      "Train Epoch: 18 [39680/84843 (47%)]\tLoss: 0.567370\n",
      "Train Epoch: 18 [40320/84843 (48%)]\tLoss: 0.575559\n",
      "Train Epoch: 18 [40960/84843 (48%)]\tLoss: 0.395729\n",
      "Train Epoch: 18 [41600/84843 (49%)]\tLoss: 0.263264\n",
      "Train Epoch: 18 [42240/84843 (50%)]\tLoss: 0.285240\n",
      "Train Epoch: 18 [42880/84843 (51%)]\tLoss: 0.293665\n",
      "Train Epoch: 18 [43520/84843 (51%)]\tLoss: 0.408126\n",
      "Train Epoch: 18 [44160/84843 (52%)]\tLoss: 0.178388\n",
      "Train Epoch: 18 [44800/84843 (53%)]\tLoss: 0.404961\n",
      "Train Epoch: 18 [45440/84843 (54%)]\tLoss: 0.227898\n",
      "Train Epoch: 18 [46080/84843 (54%)]\tLoss: 0.449602\n",
      "Train Epoch: 18 [46720/84843 (55%)]\tLoss: 0.817756\n",
      "Train Epoch: 18 [47360/84843 (56%)]\tLoss: 0.300986\n",
      "Train Epoch: 18 [48000/84843 (57%)]\tLoss: 0.249781\n",
      "Train Epoch: 18 [48640/84843 (57%)]\tLoss: 0.205151\n",
      "Train Epoch: 18 [49280/84843 (58%)]\tLoss: 0.643065\n",
      "Train Epoch: 18 [49920/84843 (59%)]\tLoss: 0.373497\n",
      "Train Epoch: 18 [50560/84843 (60%)]\tLoss: 0.361781\n",
      "Train Epoch: 18 [51200/84843 (60%)]\tLoss: 0.335148\n",
      "Train Epoch: 18 [51840/84843 (61%)]\tLoss: 0.316125\n",
      "Train Epoch: 18 [52480/84843 (62%)]\tLoss: 0.233002\n",
      "Train Epoch: 18 [53120/84843 (63%)]\tLoss: 0.499836\n",
      "Train Epoch: 18 [53760/84843 (63%)]\tLoss: 0.397966\n",
      "Train Epoch: 18 [54400/84843 (64%)]\tLoss: 0.465071\n",
      "Train Epoch: 18 [55040/84843 (65%)]\tLoss: 0.240060\n",
      "Train Epoch: 18 [55680/84843 (66%)]\tLoss: 0.518543\n",
      "Train Epoch: 18 [56320/84843 (66%)]\tLoss: 0.145825\n",
      "Train Epoch: 18 [56960/84843 (67%)]\tLoss: 0.405434\n",
      "Train Epoch: 18 [57600/84843 (68%)]\tLoss: 0.126396\n",
      "Train Epoch: 18 [58240/84843 (69%)]\tLoss: 0.277181\n",
      "Train Epoch: 18 [58880/84843 (69%)]\tLoss: 0.736278\n",
      "Train Epoch: 18 [59520/84843 (70%)]\tLoss: 0.615787\n",
      "Train Epoch: 18 [60160/84843 (71%)]\tLoss: 0.182936\n",
      "Train Epoch: 18 [60800/84843 (72%)]\tLoss: 0.477220\n",
      "Train Epoch: 18 [61440/84843 (72%)]\tLoss: 0.354178\n",
      "Train Epoch: 18 [62080/84843 (73%)]\tLoss: 0.560263\n",
      "Train Epoch: 18 [62720/84843 (74%)]\tLoss: 0.316527\n",
      "Train Epoch: 18 [63360/84843 (75%)]\tLoss: 0.197916\n",
      "Train Epoch: 18 [64000/84843 (75%)]\tLoss: 0.331129\n",
      "Train Epoch: 18 [64640/84843 (76%)]\tLoss: 0.453011\n",
      "Train Epoch: 18 [65280/84843 (77%)]\tLoss: 0.486995\n",
      "Train Epoch: 18 [65920/84843 (78%)]\tLoss: 0.572931\n",
      "Train Epoch: 18 [66560/84843 (78%)]\tLoss: 0.065471\n",
      "Train Epoch: 18 [67200/84843 (79%)]\tLoss: 0.263355\n",
      "Train Epoch: 18 [67840/84843 (80%)]\tLoss: 0.601334\n",
      "Train Epoch: 18 [68480/84843 (81%)]\tLoss: 0.605288\n",
      "Train Epoch: 18 [69120/84843 (81%)]\tLoss: 0.155627\n",
      "Train Epoch: 18 [69760/84843 (82%)]\tLoss: 0.320657\n",
      "Train Epoch: 18 [70400/84843 (83%)]\tLoss: 0.205749\n",
      "Train Epoch: 18 [71040/84843 (84%)]\tLoss: 0.580306\n",
      "Train Epoch: 18 [71680/84843 (84%)]\tLoss: 0.594765\n",
      "Train Epoch: 18 [72320/84843 (85%)]\tLoss: 0.293076\n",
      "Train Epoch: 18 [72960/84843 (86%)]\tLoss: 0.374216\n",
      "Train Epoch: 18 [73600/84843 (87%)]\tLoss: 0.290694\n",
      "Train Epoch: 18 [74240/84843 (87%)]\tLoss: 0.316026\n",
      "Train Epoch: 18 [74880/84843 (88%)]\tLoss: 0.262404\n",
      "Train Epoch: 18 [75520/84843 (89%)]\tLoss: 0.446916\n",
      "Train Epoch: 18 [76160/84843 (90%)]\tLoss: 0.394998\n",
      "Train Epoch: 18 [76800/84843 (90%)]\tLoss: 0.259536\n",
      "Train Epoch: 18 [77440/84843 (91%)]\tLoss: 0.505584\n",
      "Train Epoch: 18 [78080/84843 (92%)]\tLoss: 0.353161\n",
      "Train Epoch: 18 [78720/84843 (93%)]\tLoss: 0.296872\n",
      "Train Epoch: 18 [79360/84843 (94%)]\tLoss: 0.261413\n",
      "Train Epoch: 18 [80000/84843 (94%)]\tLoss: 0.321921\n",
      "Train Epoch: 18 [80640/84843 (95%)]\tLoss: 0.214897\n",
      "Train Epoch: 18 [81280/84843 (96%)]\tLoss: 0.591835\n",
      "Train Epoch: 18 [81920/84843 (97%)]\tLoss: 0.370749\n",
      "Train Epoch: 18 [82560/84843 (97%)]\tLoss: 0.339142\n",
      "Train Epoch: 18 [83200/84843 (98%)]\tLoss: 0.487057\n",
      "Train Epoch: 18 [83840/84843 (99%)]\tLoss: 0.418569\n",
      "Train Epoch: 18 [84480/84843 (100%)]\tLoss: 0.424171\n",
      "Accuracy: 9463/11005 (86%)\n",
      "\n",
      "Train Epoch: 19 [0/84843 (0%)]\tLoss: 0.694186\n",
      "Train Epoch: 19 [640/84843 (1%)]\tLoss: 0.506357\n",
      "Train Epoch: 19 [1280/84843 (2%)]\tLoss: 0.364706\n",
      "Train Epoch: 19 [1920/84843 (2%)]\tLoss: 0.787195\n",
      "Train Epoch: 19 [2560/84843 (3%)]\tLoss: 0.413072\n",
      "Train Epoch: 19 [3200/84843 (4%)]\tLoss: 0.237846\n",
      "Train Epoch: 19 [3840/84843 (5%)]\tLoss: 0.675477\n",
      "Train Epoch: 19 [4480/84843 (5%)]\tLoss: 0.197722\n",
      "Train Epoch: 19 [5120/84843 (6%)]\tLoss: 0.541727\n",
      "Train Epoch: 19 [5760/84843 (7%)]\tLoss: 0.257378\n",
      "Train Epoch: 19 [6400/84843 (8%)]\tLoss: 0.364834\n",
      "Train Epoch: 19 [7040/84843 (8%)]\tLoss: 0.277180\n",
      "Train Epoch: 19 [7680/84843 (9%)]\tLoss: 0.310509\n",
      "Train Epoch: 19 [8320/84843 (10%)]\tLoss: 0.201657\n",
      "Train Epoch: 19 [8960/84843 (11%)]\tLoss: 0.374591\n",
      "Train Epoch: 19 [9600/84843 (11%)]\tLoss: 0.463215\n",
      "Train Epoch: 19 [10240/84843 (12%)]\tLoss: 0.138947\n",
      "Train Epoch: 19 [10880/84843 (13%)]\tLoss: 0.413564\n",
      "Train Epoch: 19 [11520/84843 (14%)]\tLoss: 0.239720\n",
      "Train Epoch: 19 [12160/84843 (14%)]\tLoss: 0.248064\n",
      "Train Epoch: 19 [12800/84843 (15%)]\tLoss: 0.282768\n",
      "Train Epoch: 19 [13440/84843 (16%)]\tLoss: 0.214534\n",
      "Train Epoch: 19 [14080/84843 (17%)]\tLoss: 0.534175\n",
      "Train Epoch: 19 [14720/84843 (17%)]\tLoss: 0.339342\n",
      "Train Epoch: 19 [15360/84843 (18%)]\tLoss: 0.536046\n",
      "Train Epoch: 19 [16000/84843 (19%)]\tLoss: 0.739705\n",
      "Train Epoch: 19 [16640/84843 (20%)]\tLoss: 0.179953\n",
      "Train Epoch: 19 [17280/84843 (20%)]\tLoss: 0.455357\n",
      "Train Epoch: 19 [17920/84843 (21%)]\tLoss: 0.646635\n",
      "Train Epoch: 19 [18560/84843 (22%)]\tLoss: 0.283849\n",
      "Train Epoch: 19 [19200/84843 (23%)]\tLoss: 0.463613\n",
      "Train Epoch: 19 [19840/84843 (23%)]\tLoss: 0.641379\n",
      "Train Epoch: 19 [20480/84843 (24%)]\tLoss: 0.340240\n",
      "Train Epoch: 19 [21120/84843 (25%)]\tLoss: 0.538896\n",
      "Train Epoch: 19 [21760/84843 (26%)]\tLoss: 0.197226\n",
      "Train Epoch: 19 [22400/84843 (26%)]\tLoss: 0.699527\n",
      "Train Epoch: 19 [23040/84843 (27%)]\tLoss: 0.257994\n",
      "Train Epoch: 19 [23680/84843 (28%)]\tLoss: 0.120881\n",
      "Train Epoch: 19 [24320/84843 (29%)]\tLoss: 0.377458\n",
      "Train Epoch: 19 [24960/84843 (29%)]\tLoss: 0.336807\n",
      "Train Epoch: 19 [25600/84843 (30%)]\tLoss: 0.305950\n",
      "Train Epoch: 19 [26240/84843 (31%)]\tLoss: 0.229679\n",
      "Train Epoch: 19 [26880/84843 (32%)]\tLoss: 0.602402\n",
      "Train Epoch: 19 [27520/84843 (32%)]\tLoss: 0.208205\n",
      "Train Epoch: 19 [28160/84843 (33%)]\tLoss: 0.411000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [28800/84843 (34%)]\tLoss: 0.243838\n",
      "Train Epoch: 19 [29440/84843 (35%)]\tLoss: 0.290296\n",
      "Train Epoch: 19 [30080/84843 (35%)]\tLoss: 0.292455\n",
      "Train Epoch: 19 [30720/84843 (36%)]\tLoss: 0.205404\n",
      "Train Epoch: 19 [31360/84843 (37%)]\tLoss: 0.291556\n",
      "Train Epoch: 19 [32000/84843 (38%)]\tLoss: 0.481737\n",
      "Train Epoch: 19 [32640/84843 (38%)]\tLoss: 0.249778\n",
      "Train Epoch: 19 [33280/84843 (39%)]\tLoss: 0.463232\n",
      "Train Epoch: 19 [33920/84843 (40%)]\tLoss: 0.270764\n",
      "Train Epoch: 19 [34560/84843 (41%)]\tLoss: 0.633805\n",
      "Train Epoch: 19 [35200/84843 (41%)]\tLoss: 0.235580\n",
      "Train Epoch: 19 [35840/84843 (42%)]\tLoss: 0.908579\n",
      "Train Epoch: 19 [36480/84843 (43%)]\tLoss: 0.149851\n",
      "Train Epoch: 19 [37120/84843 (44%)]\tLoss: 0.414472\n",
      "Train Epoch: 19 [37760/84843 (44%)]\tLoss: 0.298670\n",
      "Train Epoch: 19 [38400/84843 (45%)]\tLoss: 0.315312\n",
      "Train Epoch: 19 [39040/84843 (46%)]\tLoss: 0.206627\n",
      "Train Epoch: 19 [39680/84843 (47%)]\tLoss: 0.399773\n",
      "Train Epoch: 19 [40320/84843 (48%)]\tLoss: 0.377848\n",
      "Train Epoch: 19 [40960/84843 (48%)]\tLoss: 0.035277\n",
      "Train Epoch: 19 [41600/84843 (49%)]\tLoss: 0.332939\n",
      "Train Epoch: 19 [42240/84843 (50%)]\tLoss: 0.477877\n",
      "Train Epoch: 19 [42880/84843 (51%)]\tLoss: 0.631964\n",
      "Train Epoch: 19 [43520/84843 (51%)]\tLoss: 0.481700\n",
      "Train Epoch: 19 [44160/84843 (52%)]\tLoss: 0.336064\n",
      "Train Epoch: 19 [44800/84843 (53%)]\tLoss: 0.699647\n",
      "Train Epoch: 19 [45440/84843 (54%)]\tLoss: 0.226527\n",
      "Train Epoch: 19 [46080/84843 (54%)]\tLoss: 0.231304\n",
      "Train Epoch: 19 [46720/84843 (55%)]\tLoss: 0.202755\n",
      "Train Epoch: 19 [47360/84843 (56%)]\tLoss: 0.424820\n",
      "Train Epoch: 19 [48000/84843 (57%)]\tLoss: 0.277112\n",
      "Train Epoch: 19 [48640/84843 (57%)]\tLoss: 0.083669\n",
      "Train Epoch: 19 [49280/84843 (58%)]\tLoss: 0.458262\n",
      "Train Epoch: 19 [49920/84843 (59%)]\tLoss: 0.216351\n",
      "Train Epoch: 19 [50560/84843 (60%)]\tLoss: 0.432351\n",
      "Train Epoch: 19 [51200/84843 (60%)]\tLoss: 0.569886\n",
      "Train Epoch: 19 [51840/84843 (61%)]\tLoss: 0.310546\n",
      "Train Epoch: 19 [52480/84843 (62%)]\tLoss: 0.292315\n",
      "Train Epoch: 19 [53120/84843 (63%)]\tLoss: 0.489296\n",
      "Train Epoch: 19 [53760/84843 (63%)]\tLoss: 0.341055\n",
      "Train Epoch: 19 [54400/84843 (64%)]\tLoss: 0.504749\n",
      "Train Epoch: 19 [55040/84843 (65%)]\tLoss: 0.256719\n",
      "Train Epoch: 19 [55680/84843 (66%)]\tLoss: 0.407912\n",
      "Train Epoch: 19 [56320/84843 (66%)]\tLoss: 0.673114\n",
      "Train Epoch: 19 [56960/84843 (67%)]\tLoss: 0.318490\n",
      "Train Epoch: 19 [57600/84843 (68%)]\tLoss: 0.238132\n",
      "Train Epoch: 19 [58240/84843 (69%)]\tLoss: 0.752760\n",
      "Train Epoch: 19 [58880/84843 (69%)]\tLoss: 0.444365\n",
      "Train Epoch: 19 [59520/84843 (70%)]\tLoss: 0.555274\n",
      "Train Epoch: 19 [60160/84843 (71%)]\tLoss: 0.158384\n",
      "Train Epoch: 19 [60800/84843 (72%)]\tLoss: 0.668957\n",
      "Train Epoch: 19 [61440/84843 (72%)]\tLoss: 0.459468\n",
      "Train Epoch: 19 [62080/84843 (73%)]\tLoss: 0.195466\n",
      "Train Epoch: 19 [62720/84843 (74%)]\tLoss: 0.222592\n",
      "Train Epoch: 19 [63360/84843 (75%)]\tLoss: 0.499816\n",
      "Train Epoch: 19 [64000/84843 (75%)]\tLoss: 0.805364\n",
      "Train Epoch: 19 [64640/84843 (76%)]\tLoss: 0.477513\n",
      "Train Epoch: 19 [65280/84843 (77%)]\tLoss: 0.159387\n",
      "Train Epoch: 19 [65920/84843 (78%)]\tLoss: 0.566009\n",
      "Train Epoch: 19 [66560/84843 (78%)]\tLoss: 0.277637\n",
      "Train Epoch: 19 [67200/84843 (79%)]\tLoss: 0.246698\n",
      "Train Epoch: 19 [67840/84843 (80%)]\tLoss: 0.096181\n",
      "Train Epoch: 19 [68480/84843 (81%)]\tLoss: 0.674967\n",
      "Train Epoch: 19 [69120/84843 (81%)]\tLoss: 0.228990\n",
      "Train Epoch: 19 [69760/84843 (82%)]\tLoss: 0.454797\n",
      "Train Epoch: 19 [70400/84843 (83%)]\tLoss: 0.352383\n",
      "Train Epoch: 19 [71040/84843 (84%)]\tLoss: 0.447103\n",
      "Train Epoch: 19 [71680/84843 (84%)]\tLoss: 0.476210\n",
      "Train Epoch: 19 [72320/84843 (85%)]\tLoss: 0.783925\n",
      "Train Epoch: 19 [72960/84843 (86%)]\tLoss: 0.359693\n",
      "Train Epoch: 19 [73600/84843 (87%)]\tLoss: 0.404750\n",
      "Train Epoch: 19 [74240/84843 (87%)]\tLoss: 0.564514\n",
      "Train Epoch: 19 [74880/84843 (88%)]\tLoss: 0.296505\n",
      "Train Epoch: 19 [75520/84843 (89%)]\tLoss: 0.265790\n",
      "Train Epoch: 19 [76160/84843 (90%)]\tLoss: 0.256166\n",
      "Train Epoch: 19 [76800/84843 (90%)]\tLoss: 0.177419\n",
      "Train Epoch: 19 [77440/84843 (91%)]\tLoss: 0.552189\n",
      "Train Epoch: 19 [78080/84843 (92%)]\tLoss: 0.612998\n",
      "Train Epoch: 19 [78720/84843 (93%)]\tLoss: 0.918383\n",
      "Train Epoch: 19 [79360/84843 (94%)]\tLoss: 0.390353\n",
      "Train Epoch: 19 [80000/84843 (94%)]\tLoss: 0.552687\n",
      "Train Epoch: 19 [80640/84843 (95%)]\tLoss: 0.382161\n",
      "Train Epoch: 19 [81280/84843 (96%)]\tLoss: 0.177764\n",
      "Train Epoch: 19 [81920/84843 (97%)]\tLoss: 0.492737\n",
      "Train Epoch: 19 [82560/84843 (97%)]\tLoss: 0.424641\n",
      "Train Epoch: 19 [83200/84843 (98%)]\tLoss: 0.297561\n",
      "Train Epoch: 19 [83840/84843 (99%)]\tLoss: 0.514087\n",
      "Train Epoch: 19 [84480/84843 (100%)]\tLoss: 0.282392\n",
      "Accuracy: 9452/11005 (86%)\n",
      "\n",
      "Train Epoch: 20 [0/84843 (0%)]\tLoss: 0.284002\n",
      "Train Epoch: 20 [640/84843 (1%)]\tLoss: 0.552900\n",
      "Train Epoch: 20 [1280/84843 (2%)]\tLoss: 0.494797\n",
      "Train Epoch: 20 [1920/84843 (2%)]\tLoss: 0.412539\n",
      "Train Epoch: 20 [2560/84843 (3%)]\tLoss: 0.223630\n",
      "Train Epoch: 20 [3200/84843 (4%)]\tLoss: 0.441288\n",
      "Train Epoch: 20 [3840/84843 (5%)]\tLoss: 0.243161\n",
      "Train Epoch: 20 [4480/84843 (5%)]\tLoss: 0.205686\n",
      "Train Epoch: 20 [5120/84843 (6%)]\tLoss: 0.620586\n",
      "Train Epoch: 20 [5760/84843 (7%)]\tLoss: 0.210912\n",
      "Train Epoch: 20 [6400/84843 (8%)]\tLoss: 0.589122\n",
      "Train Epoch: 20 [7040/84843 (8%)]\tLoss: 0.338180\n",
      "Train Epoch: 20 [7680/84843 (9%)]\tLoss: 0.439562\n",
      "Train Epoch: 20 [8320/84843 (10%)]\tLoss: 0.366478\n",
      "Train Epoch: 20 [8960/84843 (11%)]\tLoss: 0.234316\n",
      "Train Epoch: 20 [9600/84843 (11%)]\tLoss: 0.298472\n",
      "Train Epoch: 20 [10240/84843 (12%)]\tLoss: 0.176223\n",
      "Train Epoch: 20 [10880/84843 (13%)]\tLoss: 0.347115\n",
      "Train Epoch: 20 [11520/84843 (14%)]\tLoss: 0.392343\n",
      "Train Epoch: 20 [12160/84843 (14%)]\tLoss: 0.236601\n",
      "Train Epoch: 20 [12800/84843 (15%)]\tLoss: 0.050126\n",
      "Train Epoch: 20 [13440/84843 (16%)]\tLoss: 0.233957\n",
      "Train Epoch: 20 [14080/84843 (17%)]\tLoss: 0.255955\n",
      "Train Epoch: 20 [14720/84843 (17%)]\tLoss: 0.514906\n",
      "Train Epoch: 20 [15360/84843 (18%)]\tLoss: 0.458323\n",
      "Train Epoch: 20 [16000/84843 (19%)]\tLoss: 0.263418\n",
      "Train Epoch: 20 [16640/84843 (20%)]\tLoss: 0.155043\n",
      "Train Epoch: 20 [17280/84843 (20%)]\tLoss: 0.497215\n",
      "Train Epoch: 20 [17920/84843 (21%)]\tLoss: 0.548778\n",
      "Train Epoch: 20 [18560/84843 (22%)]\tLoss: 0.611208\n",
      "Train Epoch: 20 [19200/84843 (23%)]\tLoss: 0.443682\n",
      "Train Epoch: 20 [19840/84843 (23%)]\tLoss: 0.480331\n",
      "Train Epoch: 20 [20480/84843 (24%)]\tLoss: 0.404511\n",
      "Train Epoch: 20 [21120/84843 (25%)]\tLoss: 0.412142\n",
      "Train Epoch: 20 [21760/84843 (26%)]\tLoss: 0.239385\n",
      "Train Epoch: 20 [22400/84843 (26%)]\tLoss: 0.279349\n",
      "Train Epoch: 20 [23040/84843 (27%)]\tLoss: 0.329729\n",
      "Train Epoch: 20 [23680/84843 (28%)]\tLoss: 0.361989\n",
      "Train Epoch: 20 [24320/84843 (29%)]\tLoss: 0.717990\n",
      "Train Epoch: 20 [24960/84843 (29%)]\tLoss: 0.489525\n",
      "Train Epoch: 20 [25600/84843 (30%)]\tLoss: 0.455415\n",
      "Train Epoch: 20 [26240/84843 (31%)]\tLoss: 0.448108\n",
      "Train Epoch: 20 [26880/84843 (32%)]\tLoss: 0.418988\n",
      "Train Epoch: 20 [27520/84843 (32%)]\tLoss: 0.313944\n",
      "Train Epoch: 20 [28160/84843 (33%)]\tLoss: 0.447300\n",
      "Train Epoch: 20 [28800/84843 (34%)]\tLoss: 0.478137\n",
      "Train Epoch: 20 [29440/84843 (35%)]\tLoss: 0.175060\n",
      "Train Epoch: 20 [30080/84843 (35%)]\tLoss: 0.300155\n",
      "Train Epoch: 20 [30720/84843 (36%)]\tLoss: 0.196796\n",
      "Train Epoch: 20 [31360/84843 (37%)]\tLoss: 0.250629\n",
      "Train Epoch: 20 [32000/84843 (38%)]\tLoss: 0.624524\n",
      "Train Epoch: 20 [32640/84843 (38%)]\tLoss: 0.422611\n",
      "Train Epoch: 20 [33280/84843 (39%)]\tLoss: 0.862393\n",
      "Train Epoch: 20 [33920/84843 (40%)]\tLoss: 0.173370\n",
      "Train Epoch: 20 [34560/84843 (41%)]\tLoss: 0.259397\n",
      "Train Epoch: 20 [35200/84843 (41%)]\tLoss: 0.568895\n",
      "Train Epoch: 20 [35840/84843 (42%)]\tLoss: 0.851445\n",
      "Train Epoch: 20 [36480/84843 (43%)]\tLoss: 0.386214\n",
      "Train Epoch: 20 [37120/84843 (44%)]\tLoss: 0.516363\n",
      "Train Epoch: 20 [37760/84843 (44%)]\tLoss: 0.535571\n",
      "Train Epoch: 20 [38400/84843 (45%)]\tLoss: 0.392160\n",
      "Train Epoch: 20 [39040/84843 (46%)]\tLoss: 0.352084\n",
      "Train Epoch: 20 [39680/84843 (47%)]\tLoss: 0.165753\n",
      "Train Epoch: 20 [40320/84843 (48%)]\tLoss: 0.489710\n",
      "Train Epoch: 20 [40960/84843 (48%)]\tLoss: 0.533560\n",
      "Train Epoch: 20 [41600/84843 (49%)]\tLoss: 0.212960\n",
      "Train Epoch: 20 [42240/84843 (50%)]\tLoss: 0.367624\n",
      "Train Epoch: 20 [42880/84843 (51%)]\tLoss: 0.294097\n",
      "Train Epoch: 20 [43520/84843 (51%)]\tLoss: 0.264451\n",
      "Train Epoch: 20 [44160/84843 (52%)]\tLoss: 0.278113\n",
      "Train Epoch: 20 [44800/84843 (53%)]\tLoss: 0.328235\n",
      "Train Epoch: 20 [45440/84843 (54%)]\tLoss: 0.427443\n",
      "Train Epoch: 20 [46080/84843 (54%)]\tLoss: 0.382163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [46720/84843 (55%)]\tLoss: 0.302222\n",
      "Train Epoch: 20 [47360/84843 (56%)]\tLoss: 0.603949\n",
      "Train Epoch: 20 [48000/84843 (57%)]\tLoss: 0.410103\n",
      "Train Epoch: 20 [48640/84843 (57%)]\tLoss: 0.207785\n",
      "Train Epoch: 20 [49280/84843 (58%)]\tLoss: 0.278977\n",
      "Train Epoch: 20 [49920/84843 (59%)]\tLoss: 0.155995\n",
      "Train Epoch: 20 [50560/84843 (60%)]\tLoss: 0.152485\n",
      "Train Epoch: 20 [51200/84843 (60%)]\tLoss: 0.603697\n",
      "Train Epoch: 20 [51840/84843 (61%)]\tLoss: 0.348126\n",
      "Train Epoch: 20 [52480/84843 (62%)]\tLoss: 0.232560\n",
      "Train Epoch: 20 [53120/84843 (63%)]\tLoss: 0.305229\n",
      "Train Epoch: 20 [53760/84843 (63%)]\tLoss: 0.237900\n",
      "Train Epoch: 20 [54400/84843 (64%)]\tLoss: 0.246291\n",
      "Train Epoch: 20 [55040/84843 (65%)]\tLoss: 0.693885\n",
      "Train Epoch: 20 [55680/84843 (66%)]\tLoss: 0.760421\n",
      "Train Epoch: 20 [56320/84843 (66%)]\tLoss: 0.304576\n",
      "Train Epoch: 20 [56960/84843 (67%)]\tLoss: 0.371361\n",
      "Train Epoch: 20 [57600/84843 (68%)]\tLoss: 0.146503\n",
      "Train Epoch: 20 [58240/84843 (69%)]\tLoss: 0.630251\n",
      "Train Epoch: 20 [58880/84843 (69%)]\tLoss: 0.508673\n",
      "Train Epoch: 20 [59520/84843 (70%)]\tLoss: 0.063985\n",
      "Train Epoch: 20 [60160/84843 (71%)]\tLoss: 0.221155\n",
      "Train Epoch: 20 [60800/84843 (72%)]\tLoss: 0.474195\n",
      "Train Epoch: 20 [61440/84843 (72%)]\tLoss: 0.232220\n",
      "Train Epoch: 20 [62080/84843 (73%)]\tLoss: 0.313062\n",
      "Train Epoch: 20 [62720/84843 (74%)]\tLoss: 0.433072\n",
      "Train Epoch: 20 [63360/84843 (75%)]\tLoss: 0.309246\n",
      "Train Epoch: 20 [64000/84843 (75%)]\tLoss: 0.329687\n",
      "Train Epoch: 20 [64640/84843 (76%)]\tLoss: 0.668155\n",
      "Train Epoch: 20 [65280/84843 (77%)]\tLoss: 0.294271\n",
      "Train Epoch: 20 [65920/84843 (78%)]\tLoss: 0.290016\n",
      "Train Epoch: 20 [66560/84843 (78%)]\tLoss: 0.271504\n",
      "Train Epoch: 20 [67200/84843 (79%)]\tLoss: 0.147509\n",
      "Train Epoch: 20 [67840/84843 (80%)]\tLoss: 0.400978\n",
      "Train Epoch: 20 [68480/84843 (81%)]\tLoss: 0.487504\n",
      "Train Epoch: 20 [69120/84843 (81%)]\tLoss: 0.121842\n",
      "Train Epoch: 20 [69760/84843 (82%)]\tLoss: 0.354971\n",
      "Train Epoch: 20 [70400/84843 (83%)]\tLoss: 0.384833\n",
      "Train Epoch: 20 [71040/84843 (84%)]\tLoss: 0.516489\n",
      "Train Epoch: 20 [71680/84843 (84%)]\tLoss: 0.422810\n",
      "Train Epoch: 20 [72320/84843 (85%)]\tLoss: 0.590912\n",
      "Train Epoch: 20 [72960/84843 (86%)]\tLoss: 0.283784\n",
      "Train Epoch: 20 [73600/84843 (87%)]\tLoss: 0.441723\n",
      "Train Epoch: 20 [74240/84843 (87%)]\tLoss: 0.114140\n",
      "Train Epoch: 20 [74880/84843 (88%)]\tLoss: 0.181372\n",
      "Train Epoch: 20 [75520/84843 (89%)]\tLoss: 0.046268\n",
      "Train Epoch: 20 [76160/84843 (90%)]\tLoss: 0.173610\n",
      "Train Epoch: 20 [76800/84843 (90%)]\tLoss: 0.734951\n",
      "Train Epoch: 20 [77440/84843 (91%)]\tLoss: 0.422239\n",
      "Train Epoch: 20 [78080/84843 (92%)]\tLoss: 0.689329\n",
      "Train Epoch: 20 [78720/84843 (93%)]\tLoss: 0.576559\n",
      "Train Epoch: 20 [79360/84843 (94%)]\tLoss: 0.561107\n",
      "Train Epoch: 20 [80000/84843 (94%)]\tLoss: 0.296685\n",
      "Train Epoch: 20 [80640/84843 (95%)]\tLoss: 0.343708\n",
      "Train Epoch: 20 [81280/84843 (96%)]\tLoss: 0.543184\n",
      "Train Epoch: 20 [81920/84843 (97%)]\tLoss: 0.359730\n",
      "Train Epoch: 20 [82560/84843 (97%)]\tLoss: 0.304412\n",
      "Train Epoch: 20 [83200/84843 (98%)]\tLoss: 0.445942\n",
      "Train Epoch: 20 [83840/84843 (99%)]\tLoss: 0.388758\n",
      "Train Epoch: 20 [84480/84843 (100%)]\tLoss: 0.191471\n",
      "Accuracy: 9411/11005 (86%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# longer retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 20\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(long_retrained_converted_model, epoch, log_interval)\n",
    "        test(long_retrained_converted_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e726316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77561/84843 (91%)\n",
      "\n",
      "Accuracy: 8726/9981 (87%)\n",
      "\n",
      "Accuracy: 9411/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(long_retrained_converted_model, train_loader)\n",
    "test(long_retrained_converted_model, val_loader)\n",
    "test(long_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdfcbf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model sample_FGN_converted_model_SPEECHCOMMANDS in ../Experiments/sample_SPEECHCOMMANDS_models/\n"
     ]
    }
   ],
   "source": [
    "# # ### save models\n",
    "\n",
    "# model_name = 'sample_FGN_converted_model_SPEECHCOMMANDS'\n",
    "# save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c0ef9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model sample_FGN_converted_fast_retrained_model_SPEECHCOMMANDS in ../Experiments/sample_SPEECHCOMMANDS_models/\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'sample_FGN_converted_fast_retrained_model_SPEECHCOMMANDS'\n",
    "\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(fast_retrained_converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(fast_retrained_converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eace12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model sample_FGN_converted_long_retrained_model_SPEECHCOMMANDS in ../Experiments/sample_SPEECHCOMMANDS_models/\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'sample_FGN_converted_long_retrained_model_SPEECHCOMMANDS'\n",
    "\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(long_retrained_converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(long_retrained_converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54fa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
