{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce12f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of various conv1d models on the SPEECHCOMMANDS dataset\n",
    "# classic / fgn trained from scratch / converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f16bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c81a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb27928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad07c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110be973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b60f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_loader, val_loader, test_loader) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "                                                                          batch_size = 32,\n",
    "                                                                          batchsize_for_val =32,\n",
    "                                                                          num_workers=5, \n",
    "                                                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4570dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to test models\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "    print(f\"Accuracy: {correct}/{len(loader.dataset)} ({100. * correct / len(loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b27576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model classes\n",
    "\n",
    "## classic model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "    \n",
    "# FGN model    \n",
    "class FGN_M5(nn.Module):\n",
    "    \n",
    "    # changes:\n",
    "    # nn.Conv1d -> fgnl.FGN_Conv1d\n",
    "    # added g to conv inputs and outputs\n",
    "    # make sure you pass g through the same pooling steps as x\n",
    "    \n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.fgn_conv1 = fgnl.FGN_Conv1d(in_channels=n_input, out_channels=n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv2 = fgnl.FGN_Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv3 = fgnl.FGN_Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv4 = fgnl.FGN_Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        \n",
    "        #TODO change to self.pool1d_fgn() for each pooling of Gs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, g = self.fgn_conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        g = self.pool1(g)\n",
    "        x, g = self.fgn_conv2(x, g)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        g = self.pool2(g)\n",
    "        x, g = self.fgn_conv3(x ,g)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        g = self.pool3(g)\n",
    "        x, _ = self.fgn_conv4(x, g)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570df71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "\n",
    "classic_model_name= 'sample_classic_model_SPEECHCOMMANDS'\n",
    "fgn_model_name = 'sample_FGN_model_SPEECHCOMMANDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b733ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M5(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_model = M5()\n",
    "classic_model.load_state_dict(torch.load(save_path+classic_model_name+'_state_dict.pth'))\n",
    "classic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d421b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgn_model = FGN_M5()\n",
    "fgn_model.load_state_dict(torch.load(save_path+fgn_model_name+'_state_dict.pth'))\n",
    "fgn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d6c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test models\n",
    "test(classic_model, train_loader)\n",
    "test(classic_model, val_loader)\n",
    "test(classic_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26887222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(fgn_model, train_loader)\n",
    "test(fgn_model, val_loader)\n",
    "test(fgn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579deba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb16bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_model = copy.deepcopy(fgn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b624a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n"
     ]
    }
   ],
   "source": [
    "for classic_model_layer,fgn_model_layer in zip(classic_model.children(), converted_model.children()):\n",
    "\n",
    "    if type(fgn_model_layer)==fgnl.FGN_Conv1d:\n",
    "        print('converting conv layer')\n",
    "        fgnl.convert_layer_conv1D_to_fgn(classic_model_layer,fgn_model_layer)\n",
    "    else:\n",
    "        print('transfering state_dicts')\n",
    "        fgn_model_layer.load_state_dict(classic_model_layer.state_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d5ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the converted model matches classic behavior\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5be4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the original model hasn't changed\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74b9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eefd8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d73f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb71cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target) + lmbda_sigma*fgnl.sigmas_loss(model, covar_type='sphere')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a99b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_retrained_converted_model = copy.deepcopy(converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3856c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda_sigma = 1e-5\n",
    "optimizer = optim.Adam(fast_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# note LR is 10x smaller because the models have already beenm trained for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5ee78a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc83a5140de4c0aa81304a3b7db1817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 569473.437500\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.628793\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.644300\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.780621\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.536376\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.837728\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.442479\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.655623\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.628965\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.740122\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.767567\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 0.576215\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.557323\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.729879\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.667062\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.607314\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 0.752884\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.613645\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.605123\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.660557\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.520015\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.773104\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 0.547678\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 0.819693\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.644803\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.407157\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.891174\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 0.599172\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.720981\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 1.212733\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 0.833329\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.965299\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.576119\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.655588\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.930856\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 1.162552\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.704104\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 1.025325\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.901432\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.849801\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 0.672855\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.820431\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.646255\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 0.591949\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.898123\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 0.573451\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.842764\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.649334\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.794145\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.506980\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.590531\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.755484\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.638960\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 0.783786\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.688346\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.699413\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.477277\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.899326\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.907497\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.824247\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.666113\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.387211\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.743241\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 0.661630\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 0.863989\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.635097\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.803559\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.583133\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.788667\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.541337\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.770473\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.531622\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.818030\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.555602\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.693510\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.750521\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.882852\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.680060\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.532762\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.565120\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.692124\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 0.808185\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.708898\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.545384\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.520288\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.785992\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.786421\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.850992\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.653685\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.611645\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.943993\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.471369\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.731509\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.973978\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.707977\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.734526\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.757264\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 0.853097\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.799042\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.564322\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.629600\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.559675\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.530085\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.625657\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.623674\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.771244\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.594173\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.616183\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.564262\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 1.025118\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.572704\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.767637\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.764835\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.502761\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.480398\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.508707\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.382962\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.677986\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 0.775587\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.781640\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.619667\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 0.506536\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 0.365819\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.683072\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 0.601104\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 1.205585\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.753741\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.968113\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 0.996748\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 1.279429\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.475270\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.402855\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.609854\n",
      "Accuracy: 9422/11005 (86%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 1\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(fast_retrained_converted_model, epoch, log_interval)\n",
    "        test(fast_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ff4596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76121/84843 (90%)\n",
      "\n",
      "Accuracy: 8687/9981 (87%)\n",
      "\n",
      "Accuracy: 9422/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(fast_retrained_converted_model, train_loader)\n",
    "test(fast_retrained_converted_model, val_loader)\n",
    "test(fast_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d7c6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c75a837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_retrained_converted_model = copy.deepcopy(fast_retrained_converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "381ed0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(long_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faf2ad61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3153cfdc8c345dd980a2e11aa20c8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 0.759155\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.252511\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.373392\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.307572\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.424764\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.406423\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.835204\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.179899\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.740609\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.429581\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.445819\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 0.259833\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.245413\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.399233\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.549836\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.439092\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 0.345250\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.379441\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.646546\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.451731\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.494187\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.478646\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 0.221495\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 0.699067\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.233673\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.298986\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.697665\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 0.332417\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.454377\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 0.323063\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 0.570758\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.455248\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.440266\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.607904\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.209239\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 0.355448\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.586148\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 0.379366\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.452206\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.482602\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 0.434544\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.583147\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.144587\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 0.342974\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.642444\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 0.301470\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.203037\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.332512\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.612827\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.412612\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.420111\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.354639\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.263167\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 0.144417\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.412871\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.583315\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.543050\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.210708\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.122212\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.300775\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.334526\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.592260\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.474326\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 0.680871\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 0.286695\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.263896\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.338913\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.956332\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.610624\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.138205\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.440862\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.507753\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.179039\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.280739\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.340649\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.349332\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.306048\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.401114\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.597809\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.427823\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.471650\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 0.212322\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.353380\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.231711\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.571617\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.548637\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.401903\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.504244\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.458674\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.442849\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.597868\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.543056\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.589328\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.618951\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.309564\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.299148\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.357993\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 0.360848\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.450943\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.259897\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.426466\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.856031\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.513227\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.968265\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.261994\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.633969\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.226929\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.776168\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.203501\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 1.089866\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.189928\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.716253\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.187442\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.247201\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.559155\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.683593\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.442456\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.564374\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 0.331710\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.369216\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.351590\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 0.599475\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 0.390028\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.192027\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 0.617533\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 0.420172\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.437607\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.181725\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 0.334712\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 0.438746\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.340761\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.346515\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.330611\n",
      "Accuracy: 9478/11005 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/84843 (0%)]\tLoss: 0.444730\n",
      "Train Epoch: 2 [640/84843 (1%)]\tLoss: 0.337608\n",
      "Train Epoch: 2 [1280/84843 (2%)]\tLoss: 0.451899\n",
      "Train Epoch: 2 [1920/84843 (2%)]\tLoss: 0.449372\n",
      "Train Epoch: 2 [2560/84843 (3%)]\tLoss: 0.557535\n",
      "Train Epoch: 2 [3200/84843 (4%)]\tLoss: 0.251631\n",
      "Train Epoch: 2 [3840/84843 (5%)]\tLoss: 0.240854\n",
      "Train Epoch: 2 [4480/84843 (5%)]\tLoss: 0.174769\n",
      "Train Epoch: 2 [5120/84843 (6%)]\tLoss: 0.344629\n",
      "Train Epoch: 2 [5760/84843 (7%)]\tLoss: 0.517433\n",
      "Train Epoch: 2 [6400/84843 (8%)]\tLoss: 0.367829\n",
      "Train Epoch: 2 [7040/84843 (8%)]\tLoss: 0.218946\n",
      "Train Epoch: 2 [7680/84843 (9%)]\tLoss: 0.242456\n",
      "Train Epoch: 2 [8320/84843 (10%)]\tLoss: 0.472581\n",
      "Train Epoch: 2 [8960/84843 (11%)]\tLoss: 0.248373\n",
      "Train Epoch: 2 [9600/84843 (11%)]\tLoss: 0.164308\n",
      "Train Epoch: 2 [10240/84843 (12%)]\tLoss: 0.511699\n",
      "Train Epoch: 2 [10880/84843 (13%)]\tLoss: 0.745067\n",
      "Train Epoch: 2 [11520/84843 (14%)]\tLoss: 0.381923\n",
      "Train Epoch: 2 [12160/84843 (14%)]\tLoss: 0.338228\n",
      "Train Epoch: 2 [12800/84843 (15%)]\tLoss: 0.686904\n",
      "Train Epoch: 2 [13440/84843 (16%)]\tLoss: 0.330928\n",
      "Train Epoch: 2 [14080/84843 (17%)]\tLoss: 0.549177\n",
      "Train Epoch: 2 [14720/84843 (17%)]\tLoss: 0.395175\n",
      "Train Epoch: 2 [15360/84843 (18%)]\tLoss: 0.741215\n",
      "Train Epoch: 2 [16000/84843 (19%)]\tLoss: 0.359355\n",
      "Train Epoch: 2 [16640/84843 (20%)]\tLoss: 0.792477\n",
      "Train Epoch: 2 [17280/84843 (20%)]\tLoss: 0.415931\n",
      "Train Epoch: 2 [17920/84843 (21%)]\tLoss: 0.289497\n",
      "Train Epoch: 2 [18560/84843 (22%)]\tLoss: 0.499583\n",
      "Train Epoch: 2 [19200/84843 (23%)]\tLoss: 0.904402\n",
      "Train Epoch: 2 [19840/84843 (23%)]\tLoss: 0.803952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [20480/84843 (24%)]\tLoss: 0.573640\n",
      "Train Epoch: 2 [21120/84843 (25%)]\tLoss: 0.506166\n",
      "Train Epoch: 2 [21760/84843 (26%)]\tLoss: 0.400668\n",
      "Train Epoch: 2 [22400/84843 (26%)]\tLoss: 0.271863\n",
      "Train Epoch: 2 [23040/84843 (27%)]\tLoss: 0.507545\n",
      "Train Epoch: 2 [23680/84843 (28%)]\tLoss: 0.479954\n",
      "Train Epoch: 2 [24320/84843 (29%)]\tLoss: 0.758438\n",
      "Train Epoch: 2 [24960/84843 (29%)]\tLoss: 0.554884\n",
      "Train Epoch: 2 [25600/84843 (30%)]\tLoss: 0.418424\n",
      "Train Epoch: 2 [26240/84843 (31%)]\tLoss: 0.438241\n",
      "Train Epoch: 2 [26880/84843 (32%)]\tLoss: 0.359236\n",
      "Train Epoch: 2 [27520/84843 (32%)]\tLoss: 0.364366\n",
      "Train Epoch: 2 [28160/84843 (33%)]\tLoss: 0.472508\n",
      "Train Epoch: 2 [28800/84843 (34%)]\tLoss: 0.366748\n",
      "Train Epoch: 2 [29440/84843 (35%)]\tLoss: 0.229097\n",
      "Train Epoch: 2 [30080/84843 (35%)]\tLoss: 0.290334\n",
      "Train Epoch: 2 [30720/84843 (36%)]\tLoss: 0.435716\n",
      "Train Epoch: 2 [31360/84843 (37%)]\tLoss: 0.635519\n",
      "Train Epoch: 2 [32000/84843 (38%)]\tLoss: 0.426257\n",
      "Train Epoch: 2 [32640/84843 (38%)]\tLoss: 0.307621\n",
      "Train Epoch: 2 [33280/84843 (39%)]\tLoss: 0.134411\n",
      "Train Epoch: 2 [33920/84843 (40%)]\tLoss: 0.278154\n",
      "Train Epoch: 2 [34560/84843 (41%)]\tLoss: 0.458144\n",
      "Train Epoch: 2 [35200/84843 (41%)]\tLoss: 0.300561\n",
      "Train Epoch: 2 [35840/84843 (42%)]\tLoss: 0.258502\n",
      "Train Epoch: 2 [36480/84843 (43%)]\tLoss: 0.374829\n",
      "Train Epoch: 2 [37120/84843 (44%)]\tLoss: 0.553605\n",
      "Train Epoch: 2 [37760/84843 (44%)]\tLoss: 0.211077\n",
      "Train Epoch: 2 [38400/84843 (45%)]\tLoss: 0.438075\n",
      "Train Epoch: 2 [39040/84843 (46%)]\tLoss: 0.325726\n",
      "Train Epoch: 2 [39680/84843 (47%)]\tLoss: 0.448616\n",
      "Train Epoch: 2 [40320/84843 (48%)]\tLoss: 0.296917\n",
      "Train Epoch: 2 [40960/84843 (48%)]\tLoss: 0.401690\n",
      "Train Epoch: 2 [41600/84843 (49%)]\tLoss: 0.282114\n",
      "Train Epoch: 2 [42240/84843 (50%)]\tLoss: 0.343030\n",
      "Train Epoch: 2 [42880/84843 (51%)]\tLoss: 0.301085\n",
      "Train Epoch: 2 [43520/84843 (51%)]\tLoss: 0.487571\n",
      "Train Epoch: 2 [44160/84843 (52%)]\tLoss: 0.465568\n",
      "Train Epoch: 2 [44800/84843 (53%)]\tLoss: 0.420672\n",
      "Train Epoch: 2 [45440/84843 (54%)]\tLoss: 0.597952\n",
      "Train Epoch: 2 [46080/84843 (54%)]\tLoss: 0.365886\n",
      "Train Epoch: 2 [46720/84843 (55%)]\tLoss: 0.369472\n",
      "Train Epoch: 2 [47360/84843 (56%)]\tLoss: 0.429995\n",
      "Train Epoch: 2 [48000/84843 (57%)]\tLoss: 0.381546\n",
      "Train Epoch: 2 [48640/84843 (57%)]\tLoss: 0.214628\n",
      "Train Epoch: 2 [49280/84843 (58%)]\tLoss: 0.327292\n",
      "Train Epoch: 2 [49920/84843 (59%)]\tLoss: 0.591138\n",
      "Train Epoch: 2 [50560/84843 (60%)]\tLoss: 0.597275\n",
      "Train Epoch: 2 [51200/84843 (60%)]\tLoss: 0.288224\n",
      "Train Epoch: 2 [51840/84843 (61%)]\tLoss: 0.516260\n",
      "Train Epoch: 2 [52480/84843 (62%)]\tLoss: 0.163865\n",
      "Train Epoch: 2 [53120/84843 (63%)]\tLoss: 0.572090\n",
      "Train Epoch: 2 [53760/84843 (63%)]\tLoss: 0.387870\n",
      "Train Epoch: 2 [54400/84843 (64%)]\tLoss: 0.319457\n",
      "Train Epoch: 2 [55040/84843 (65%)]\tLoss: 0.552225\n",
      "Train Epoch: 2 [55680/84843 (66%)]\tLoss: 0.574641\n",
      "Train Epoch: 2 [56320/84843 (66%)]\tLoss: 0.317868\n",
      "Train Epoch: 2 [56960/84843 (67%)]\tLoss: 0.303959\n",
      "Train Epoch: 2 [57600/84843 (68%)]\tLoss: 0.561254\n",
      "Train Epoch: 2 [58240/84843 (69%)]\tLoss: 0.105829\n",
      "Train Epoch: 2 [58880/84843 (69%)]\tLoss: 0.612819\n",
      "Train Epoch: 2 [59520/84843 (70%)]\tLoss: 0.274844\n",
      "Train Epoch: 2 [60160/84843 (71%)]\tLoss: 0.113294\n",
      "Train Epoch: 2 [60800/84843 (72%)]\tLoss: 0.720549\n",
      "Train Epoch: 2 [61440/84843 (72%)]\tLoss: 0.359494\n",
      "Train Epoch: 2 [62080/84843 (73%)]\tLoss: 0.539278\n",
      "Train Epoch: 2 [62720/84843 (74%)]\tLoss: 0.213808\n",
      "Train Epoch: 2 [63360/84843 (75%)]\tLoss: 0.707532\n",
      "Train Epoch: 2 [64000/84843 (75%)]\tLoss: 0.268852\n",
      "Train Epoch: 2 [64640/84843 (76%)]\tLoss: 0.442484\n",
      "Train Epoch: 2 [65280/84843 (77%)]\tLoss: 0.405199\n",
      "Train Epoch: 2 [65920/84843 (78%)]\tLoss: 0.459760\n",
      "Train Epoch: 2 [66560/84843 (78%)]\tLoss: 0.610762\n",
      "Train Epoch: 2 [67200/84843 (79%)]\tLoss: 0.528848\n",
      "Train Epoch: 2 [67840/84843 (80%)]\tLoss: 0.268859\n",
      "Train Epoch: 2 [68480/84843 (81%)]\tLoss: 0.380033\n",
      "Train Epoch: 2 [69120/84843 (81%)]\tLoss: 0.368956\n",
      "Train Epoch: 2 [69760/84843 (82%)]\tLoss: 0.093179\n",
      "Train Epoch: 2 [70400/84843 (83%)]\tLoss: 0.410611\n",
      "Train Epoch: 2 [71040/84843 (84%)]\tLoss: 0.436068\n",
      "Train Epoch: 2 [71680/84843 (84%)]\tLoss: 0.197840\n",
      "Train Epoch: 2 [72320/84843 (85%)]\tLoss: 0.230996\n",
      "Train Epoch: 2 [72960/84843 (86%)]\tLoss: 0.397675\n",
      "Train Epoch: 2 [73600/84843 (87%)]\tLoss: 0.449482\n",
      "Train Epoch: 2 [74240/84843 (87%)]\tLoss: 0.198358\n",
      "Train Epoch: 2 [74880/84843 (88%)]\tLoss: 0.493285\n",
      "Train Epoch: 2 [75520/84843 (89%)]\tLoss: 0.553313\n",
      "Train Epoch: 2 [76160/84843 (90%)]\tLoss: 0.304967\n",
      "Train Epoch: 2 [76800/84843 (90%)]\tLoss: 0.378787\n",
      "Train Epoch: 2 [77440/84843 (91%)]\tLoss: 0.749012\n",
      "Train Epoch: 2 [78080/84843 (92%)]\tLoss: 0.689655\n",
      "Train Epoch: 2 [78720/84843 (93%)]\tLoss: 0.288765\n",
      "Train Epoch: 2 [79360/84843 (94%)]\tLoss: 0.505328\n",
      "Train Epoch: 2 [80000/84843 (94%)]\tLoss: 1.074512\n",
      "Train Epoch: 2 [80640/84843 (95%)]\tLoss: 0.575282\n",
      "Train Epoch: 2 [81280/84843 (96%)]\tLoss: 0.415739\n",
      "Train Epoch: 2 [81920/84843 (97%)]\tLoss: 0.445412\n",
      "Train Epoch: 2 [82560/84843 (97%)]\tLoss: 0.478192\n",
      "Train Epoch: 2 [83200/84843 (98%)]\tLoss: 0.412044\n",
      "Train Epoch: 2 [83840/84843 (99%)]\tLoss: 0.420075\n",
      "Train Epoch: 2 [84480/84843 (100%)]\tLoss: 0.568555\n",
      "Accuracy: 9455/11005 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/84843 (0%)]\tLoss: 0.311809\n",
      "Train Epoch: 3 [640/84843 (1%)]\tLoss: 0.363248\n",
      "Train Epoch: 3 [1280/84843 (2%)]\tLoss: 0.327395\n",
      "Train Epoch: 3 [1920/84843 (2%)]\tLoss: 0.418859\n",
      "Train Epoch: 3 [2560/84843 (3%)]\tLoss: 0.486616\n",
      "Train Epoch: 3 [3200/84843 (4%)]\tLoss: 0.364683\n",
      "Train Epoch: 3 [3840/84843 (5%)]\tLoss: 0.594810\n",
      "Train Epoch: 3 [4480/84843 (5%)]\tLoss: 0.621865\n",
      "Train Epoch: 3 [5120/84843 (6%)]\tLoss: 0.415195\n",
      "Train Epoch: 3 [5760/84843 (7%)]\tLoss: 0.418774\n",
      "Train Epoch: 3 [6400/84843 (8%)]\tLoss: 0.612215\n",
      "Train Epoch: 3 [7040/84843 (8%)]\tLoss: 0.143163\n",
      "Train Epoch: 3 [7680/84843 (9%)]\tLoss: 0.443693\n",
      "Train Epoch: 3 [8320/84843 (10%)]\tLoss: 0.305070\n",
      "Train Epoch: 3 [8960/84843 (11%)]\tLoss: 0.273376\n",
      "Train Epoch: 3 [9600/84843 (11%)]\tLoss: 0.826943\n",
      "Train Epoch: 3 [10240/84843 (12%)]\tLoss: 0.246089\n",
      "Train Epoch: 3 [10880/84843 (13%)]\tLoss: 0.240365\n",
      "Train Epoch: 3 [11520/84843 (14%)]\tLoss: 0.354426\n",
      "Train Epoch: 3 [12160/84843 (14%)]\tLoss: 0.506856\n",
      "Train Epoch: 3 [12800/84843 (15%)]\tLoss: 0.347143\n",
      "Train Epoch: 3 [13440/84843 (16%)]\tLoss: 0.289631\n",
      "Train Epoch: 3 [14080/84843 (17%)]\tLoss: 0.268586\n",
      "Train Epoch: 3 [14720/84843 (17%)]\tLoss: 0.442460\n",
      "Train Epoch: 3 [15360/84843 (18%)]\tLoss: 0.852503\n",
      "Train Epoch: 3 [16000/84843 (19%)]\tLoss: 0.513006\n",
      "Train Epoch: 3 [16640/84843 (20%)]\tLoss: 0.203309\n",
      "Train Epoch: 3 [17280/84843 (20%)]\tLoss: 0.377546\n",
      "Train Epoch: 3 [17920/84843 (21%)]\tLoss: 0.564304\n",
      "Train Epoch: 3 [18560/84843 (22%)]\tLoss: 0.347109\n",
      "Train Epoch: 3 [19200/84843 (23%)]\tLoss: 0.491103\n",
      "Train Epoch: 3 [19840/84843 (23%)]\tLoss: 0.322450\n",
      "Train Epoch: 3 [20480/84843 (24%)]\tLoss: 0.290989\n",
      "Train Epoch: 3 [21120/84843 (25%)]\tLoss: 0.150975\n",
      "Train Epoch: 3 [21760/84843 (26%)]\tLoss: 0.374287\n",
      "Train Epoch: 3 [22400/84843 (26%)]\tLoss: 0.417983\n",
      "Train Epoch: 3 [23040/84843 (27%)]\tLoss: 0.279969\n",
      "Train Epoch: 3 [23680/84843 (28%)]\tLoss: 0.249830\n",
      "Train Epoch: 3 [24320/84843 (29%)]\tLoss: 0.292620\n",
      "Train Epoch: 3 [24960/84843 (29%)]\tLoss: 0.213545\n",
      "Train Epoch: 3 [25600/84843 (30%)]\tLoss: 0.480727\n",
      "Train Epoch: 3 [26240/84843 (31%)]\tLoss: 0.537945\n",
      "Train Epoch: 3 [26880/84843 (32%)]\tLoss: 0.288559\n",
      "Train Epoch: 3 [27520/84843 (32%)]\tLoss: 0.327809\n",
      "Train Epoch: 3 [28160/84843 (33%)]\tLoss: 0.327602\n",
      "Train Epoch: 3 [28800/84843 (34%)]\tLoss: 0.331723\n",
      "Train Epoch: 3 [29440/84843 (35%)]\tLoss: 0.434082\n",
      "Train Epoch: 3 [30080/84843 (35%)]\tLoss: 0.529571\n",
      "Train Epoch: 3 [30720/84843 (36%)]\tLoss: 0.424881\n",
      "Train Epoch: 3 [31360/84843 (37%)]\tLoss: 0.264485\n",
      "Train Epoch: 3 [32000/84843 (38%)]\tLoss: 0.564930\n",
      "Train Epoch: 3 [32640/84843 (38%)]\tLoss: 0.260673\n",
      "Train Epoch: 3 [33280/84843 (39%)]\tLoss: 0.489514\n",
      "Train Epoch: 3 [33920/84843 (40%)]\tLoss: 0.288097\n",
      "Train Epoch: 3 [34560/84843 (41%)]\tLoss: 0.285677\n",
      "Train Epoch: 3 [35200/84843 (41%)]\tLoss: 0.313346\n",
      "Train Epoch: 3 [35840/84843 (42%)]\tLoss: 0.566792\n",
      "Train Epoch: 3 [36480/84843 (43%)]\tLoss: 0.462196\n",
      "Train Epoch: 3 [37120/84843 (44%)]\tLoss: 0.312211\n",
      "Train Epoch: 3 [37760/84843 (44%)]\tLoss: 0.500059\n",
      "Train Epoch: 3 [38400/84843 (45%)]\tLoss: 0.392670\n",
      "Train Epoch: 3 [39040/84843 (46%)]\tLoss: 0.320176\n",
      "Train Epoch: 3 [39680/84843 (47%)]\tLoss: 0.257803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [40320/84843 (48%)]\tLoss: 0.552607\n",
      "Train Epoch: 3 [40960/84843 (48%)]\tLoss: 0.238592\n",
      "Train Epoch: 3 [41600/84843 (49%)]\tLoss: 0.210868\n",
      "Train Epoch: 3 [42240/84843 (50%)]\tLoss: 0.151025\n",
      "Train Epoch: 3 [42880/84843 (51%)]\tLoss: 0.415208\n",
      "Train Epoch: 3 [43520/84843 (51%)]\tLoss: 0.817350\n",
      "Train Epoch: 3 [44160/84843 (52%)]\tLoss: 0.566665\n",
      "Train Epoch: 3 [44800/84843 (53%)]\tLoss: 0.403705\n",
      "Train Epoch: 3 [45440/84843 (54%)]\tLoss: 0.271976\n",
      "Train Epoch: 3 [46080/84843 (54%)]\tLoss: 0.087232\n",
      "Train Epoch: 3 [46720/84843 (55%)]\tLoss: 0.311925\n",
      "Train Epoch: 3 [47360/84843 (56%)]\tLoss: 0.270397\n",
      "Train Epoch: 3 [48000/84843 (57%)]\tLoss: 0.201671\n",
      "Train Epoch: 3 [48640/84843 (57%)]\tLoss: 0.222735\n",
      "Train Epoch: 3 [49280/84843 (58%)]\tLoss: 0.621256\n",
      "Train Epoch: 3 [49920/84843 (59%)]\tLoss: 0.268777\n",
      "Train Epoch: 3 [50560/84843 (60%)]\tLoss: 0.510050\n",
      "Train Epoch: 3 [51200/84843 (60%)]\tLoss: 0.362784\n",
      "Train Epoch: 3 [51840/84843 (61%)]\tLoss: 0.448192\n",
      "Train Epoch: 3 [52480/84843 (62%)]\tLoss: 0.253372\n",
      "Train Epoch: 3 [53120/84843 (63%)]\tLoss: 0.475640\n",
      "Train Epoch: 3 [53760/84843 (63%)]\tLoss: 0.584782\n",
      "Train Epoch: 3 [54400/84843 (64%)]\tLoss: 0.467715\n",
      "Train Epoch: 3 [55040/84843 (65%)]\tLoss: 0.391796\n",
      "Train Epoch: 3 [55680/84843 (66%)]\tLoss: 0.368279\n",
      "Train Epoch: 3 [56320/84843 (66%)]\tLoss: 0.264546\n",
      "Train Epoch: 3 [56960/84843 (67%)]\tLoss: 0.381752\n",
      "Train Epoch: 3 [57600/84843 (68%)]\tLoss: 0.353580\n",
      "Train Epoch: 3 [58240/84843 (69%)]\tLoss: 0.485891\n",
      "Train Epoch: 3 [58880/84843 (69%)]\tLoss: 0.693142\n",
      "Train Epoch: 3 [59520/84843 (70%)]\tLoss: 0.247892\n",
      "Train Epoch: 3 [60160/84843 (71%)]\tLoss: 0.146314\n",
      "Train Epoch: 3 [60800/84843 (72%)]\tLoss: 0.492440\n",
      "Train Epoch: 3 [61440/84843 (72%)]\tLoss: 0.365615\n",
      "Train Epoch: 3 [62080/84843 (73%)]\tLoss: 0.461105\n",
      "Train Epoch: 3 [62720/84843 (74%)]\tLoss: 0.265388\n",
      "Train Epoch: 3 [63360/84843 (75%)]\tLoss: 0.446584\n",
      "Train Epoch: 3 [64000/84843 (75%)]\tLoss: 0.236860\n",
      "Train Epoch: 3 [64640/84843 (76%)]\tLoss: 0.350404\n",
      "Train Epoch: 3 [65280/84843 (77%)]\tLoss: 0.474301\n",
      "Train Epoch: 3 [65920/84843 (78%)]\tLoss: 0.210101\n",
      "Train Epoch: 3 [66560/84843 (78%)]\tLoss: 0.411310\n",
      "Train Epoch: 3 [67200/84843 (79%)]\tLoss: 0.290537\n",
      "Train Epoch: 3 [67840/84843 (80%)]\tLoss: 0.244103\n",
      "Train Epoch: 3 [68480/84843 (81%)]\tLoss: 0.409417\n",
      "Train Epoch: 3 [69120/84843 (81%)]\tLoss: 0.475034\n",
      "Train Epoch: 3 [69760/84843 (82%)]\tLoss: 0.269318\n",
      "Train Epoch: 3 [70400/84843 (83%)]\tLoss: 0.261315\n",
      "Train Epoch: 3 [71040/84843 (84%)]\tLoss: 0.571603\n",
      "Train Epoch: 3 [71680/84843 (84%)]\tLoss: 0.262668\n",
      "Train Epoch: 3 [72320/84843 (85%)]\tLoss: 0.182014\n",
      "Train Epoch: 3 [72960/84843 (86%)]\tLoss: 0.379865\n",
      "Train Epoch: 3 [73600/84843 (87%)]\tLoss: 0.459451\n",
      "Train Epoch: 3 [74240/84843 (87%)]\tLoss: 0.357633\n",
      "Train Epoch: 3 [74880/84843 (88%)]\tLoss: 0.439574\n",
      "Train Epoch: 3 [75520/84843 (89%)]\tLoss: 0.441580\n",
      "Train Epoch: 3 [76160/84843 (90%)]\tLoss: 0.680681\n",
      "Train Epoch: 3 [76800/84843 (90%)]\tLoss: 0.475085\n",
      "Train Epoch: 3 [77440/84843 (91%)]\tLoss: 0.826851\n",
      "Train Epoch: 3 [78080/84843 (92%)]\tLoss: 0.677668\n",
      "Train Epoch: 3 [78720/84843 (93%)]\tLoss: 0.259404\n",
      "Train Epoch: 3 [79360/84843 (94%)]\tLoss: 0.733855\n",
      "Train Epoch: 3 [80000/84843 (94%)]\tLoss: 0.337927\n",
      "Train Epoch: 3 [80640/84843 (95%)]\tLoss: 0.331615\n",
      "Train Epoch: 3 [81280/84843 (96%)]\tLoss: 0.735103\n",
      "Train Epoch: 3 [81920/84843 (97%)]\tLoss: 0.607425\n",
      "Train Epoch: 3 [82560/84843 (97%)]\tLoss: 0.406328\n",
      "Train Epoch: 3 [83200/84843 (98%)]\tLoss: 0.243417\n",
      "Train Epoch: 3 [83840/84843 (99%)]\tLoss: 0.503681\n",
      "Train Epoch: 3 [84480/84843 (100%)]\tLoss: 0.458597\n",
      "Accuracy: 9436/11005 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/84843 (0%)]\tLoss: 0.198784\n",
      "Train Epoch: 4 [640/84843 (1%)]\tLoss: 0.418886\n",
      "Train Epoch: 4 [1280/84843 (2%)]\tLoss: 0.591374\n",
      "Train Epoch: 4 [1920/84843 (2%)]\tLoss: 0.433440\n",
      "Train Epoch: 4 [2560/84843 (3%)]\tLoss: 0.471654\n",
      "Train Epoch: 4 [3200/84843 (4%)]\tLoss: 0.407882\n",
      "Train Epoch: 4 [3840/84843 (5%)]\tLoss: 0.218338\n",
      "Train Epoch: 4 [4480/84843 (5%)]\tLoss: 0.531916\n",
      "Train Epoch: 4 [5120/84843 (6%)]\tLoss: 0.298057\n",
      "Train Epoch: 4 [5760/84843 (7%)]\tLoss: 0.392030\n",
      "Train Epoch: 4 [6400/84843 (8%)]\tLoss: 0.270056\n",
      "Train Epoch: 4 [7040/84843 (8%)]\tLoss: 0.262511\n",
      "Train Epoch: 4 [7680/84843 (9%)]\tLoss: 0.594659\n",
      "Train Epoch: 4 [8320/84843 (10%)]\tLoss: 0.436820\n",
      "Train Epoch: 4 [8960/84843 (11%)]\tLoss: 0.410405\n",
      "Train Epoch: 4 [9600/84843 (11%)]\tLoss: 0.288163\n",
      "Train Epoch: 4 [10240/84843 (12%)]\tLoss: 0.342155\n",
      "Train Epoch: 4 [10880/84843 (13%)]\tLoss: 0.684774\n",
      "Train Epoch: 4 [11520/84843 (14%)]\tLoss: 0.133570\n",
      "Train Epoch: 4 [12160/84843 (14%)]\tLoss: 0.133275\n",
      "Train Epoch: 4 [12800/84843 (15%)]\tLoss: 0.334929\n",
      "Train Epoch: 4 [13440/84843 (16%)]\tLoss: 0.231609\n",
      "Train Epoch: 4 [14080/84843 (17%)]\tLoss: 0.155847\n",
      "Train Epoch: 4 [14720/84843 (17%)]\tLoss: 0.495345\n",
      "Train Epoch: 4 [15360/84843 (18%)]\tLoss: 0.277116\n",
      "Train Epoch: 4 [16000/84843 (19%)]\tLoss: 0.255370\n",
      "Train Epoch: 4 [16640/84843 (20%)]\tLoss: 0.400787\n",
      "Train Epoch: 4 [17280/84843 (20%)]\tLoss: 0.092089\n",
      "Train Epoch: 4 [17920/84843 (21%)]\tLoss: 0.380199\n",
      "Train Epoch: 4 [18560/84843 (22%)]\tLoss: 0.324289\n",
      "Train Epoch: 4 [19200/84843 (23%)]\tLoss: 0.216399\n",
      "Train Epoch: 4 [19840/84843 (23%)]\tLoss: 0.332889\n",
      "Train Epoch: 4 [20480/84843 (24%)]\tLoss: 0.359020\n",
      "Train Epoch: 4 [21120/84843 (25%)]\tLoss: 0.438939\n",
      "Train Epoch: 4 [21760/84843 (26%)]\tLoss: 0.305844\n",
      "Train Epoch: 4 [22400/84843 (26%)]\tLoss: 0.232991\n",
      "Train Epoch: 4 [23040/84843 (27%)]\tLoss: 0.340213\n",
      "Train Epoch: 4 [23680/84843 (28%)]\tLoss: 0.359734\n",
      "Train Epoch: 4 [24320/84843 (29%)]\tLoss: 0.544559\n",
      "Train Epoch: 4 [24960/84843 (29%)]\tLoss: 0.209054\n",
      "Train Epoch: 4 [25600/84843 (30%)]\tLoss: 0.343024\n",
      "Train Epoch: 4 [26240/84843 (31%)]\tLoss: 0.184309\n",
      "Train Epoch: 4 [26880/84843 (32%)]\tLoss: 0.210481\n",
      "Train Epoch: 4 [27520/84843 (32%)]\tLoss: 0.355544\n",
      "Train Epoch: 4 [28160/84843 (33%)]\tLoss: 0.216021\n",
      "Train Epoch: 4 [28800/84843 (34%)]\tLoss: 0.317587\n",
      "Train Epoch: 4 [29440/84843 (35%)]\tLoss: 0.653307\n",
      "Train Epoch: 4 [30080/84843 (35%)]\tLoss: 0.197016\n",
      "Train Epoch: 4 [30720/84843 (36%)]\tLoss: 0.393033\n",
      "Train Epoch: 4 [31360/84843 (37%)]\tLoss: 0.415987\n",
      "Train Epoch: 4 [32000/84843 (38%)]\tLoss: 0.602833\n",
      "Train Epoch: 4 [32640/84843 (38%)]\tLoss: 0.744021\n",
      "Train Epoch: 4 [33280/84843 (39%)]\tLoss: 0.239649\n",
      "Train Epoch: 4 [33920/84843 (40%)]\tLoss: 0.399041\n",
      "Train Epoch: 4 [34560/84843 (41%)]\tLoss: 0.762481\n",
      "Train Epoch: 4 [35200/84843 (41%)]\tLoss: 0.300364\n",
      "Train Epoch: 4 [35840/84843 (42%)]\tLoss: 0.914772\n",
      "Train Epoch: 4 [36480/84843 (43%)]\tLoss: 0.519648\n",
      "Train Epoch: 4 [37120/84843 (44%)]\tLoss: 0.457751\n",
      "Train Epoch: 4 [37760/84843 (44%)]\tLoss: 0.351956\n",
      "Train Epoch: 4 [38400/84843 (45%)]\tLoss: 0.657675\n",
      "Train Epoch: 4 [39040/84843 (46%)]\tLoss: 0.400686\n",
      "Train Epoch: 4 [39680/84843 (47%)]\tLoss: 0.356470\n",
      "Train Epoch: 4 [40320/84843 (48%)]\tLoss: 0.160534\n",
      "Train Epoch: 4 [40960/84843 (48%)]\tLoss: 0.545600\n",
      "Train Epoch: 4 [41600/84843 (49%)]\tLoss: 0.481016\n",
      "Train Epoch: 4 [42240/84843 (50%)]\tLoss: 0.455010\n",
      "Train Epoch: 4 [42880/84843 (51%)]\tLoss: 0.425158\n",
      "Train Epoch: 4 [43520/84843 (51%)]\tLoss: 0.564396\n",
      "Train Epoch: 4 [44160/84843 (52%)]\tLoss: 0.319458\n",
      "Train Epoch: 4 [44800/84843 (53%)]\tLoss: 0.298525\n",
      "Train Epoch: 4 [45440/84843 (54%)]\tLoss: 0.402575\n",
      "Train Epoch: 4 [46080/84843 (54%)]\tLoss: 0.239508\n",
      "Train Epoch: 4 [46720/84843 (55%)]\tLoss: 0.282494\n",
      "Train Epoch: 4 [47360/84843 (56%)]\tLoss: 0.465105\n",
      "Train Epoch: 4 [48000/84843 (57%)]\tLoss: 0.269214\n",
      "Train Epoch: 4 [48640/84843 (57%)]\tLoss: 0.293669\n",
      "Train Epoch: 4 [49280/84843 (58%)]\tLoss: 0.476451\n",
      "Train Epoch: 4 [49920/84843 (59%)]\tLoss: 0.315433\n",
      "Train Epoch: 4 [50560/84843 (60%)]\tLoss: 0.309041\n",
      "Train Epoch: 4 [51200/84843 (60%)]\tLoss: 0.375706\n",
      "Train Epoch: 4 [51840/84843 (61%)]\tLoss: 0.452941\n",
      "Train Epoch: 4 [52480/84843 (62%)]\tLoss: 0.205168\n",
      "Train Epoch: 4 [53120/84843 (63%)]\tLoss: 0.311700\n",
      "Train Epoch: 4 [53760/84843 (63%)]\tLoss: 0.506603\n",
      "Train Epoch: 4 [54400/84843 (64%)]\tLoss: 0.556540\n",
      "Train Epoch: 4 [55040/84843 (65%)]\tLoss: 0.124821\n",
      "Train Epoch: 4 [55680/84843 (66%)]\tLoss: 0.441658\n",
      "Train Epoch: 4 [56320/84843 (66%)]\tLoss: 0.251441\n",
      "Train Epoch: 4 [56960/84843 (67%)]\tLoss: 0.382718\n",
      "Train Epoch: 4 [57600/84843 (68%)]\tLoss: 0.709058\n",
      "Train Epoch: 4 [58240/84843 (69%)]\tLoss: 0.534200\n",
      "Train Epoch: 4 [58880/84843 (69%)]\tLoss: 0.390158\n",
      "Train Epoch: 4 [59520/84843 (70%)]\tLoss: 0.189847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [60160/84843 (71%)]\tLoss: 0.203678\n",
      "Train Epoch: 4 [60800/84843 (72%)]\tLoss: 0.092860\n",
      "Train Epoch: 4 [61440/84843 (72%)]\tLoss: 0.526929\n",
      "Train Epoch: 4 [62080/84843 (73%)]\tLoss: 0.325101\n",
      "Train Epoch: 4 [62720/84843 (74%)]\tLoss: 0.504524\n",
      "Train Epoch: 4 [63360/84843 (75%)]\tLoss: 0.274383\n",
      "Train Epoch: 4 [64000/84843 (75%)]\tLoss: 0.213330\n",
      "Train Epoch: 4 [64640/84843 (76%)]\tLoss: 0.740426\n",
      "Train Epoch: 4 [65280/84843 (77%)]\tLoss: 0.504172\n",
      "Train Epoch: 4 [65920/84843 (78%)]\tLoss: 0.307395\n",
      "Train Epoch: 4 [66560/84843 (78%)]\tLoss: 0.870459\n",
      "Train Epoch: 4 [67200/84843 (79%)]\tLoss: 0.477396\n",
      "Train Epoch: 4 [67840/84843 (80%)]\tLoss: 0.147742\n",
      "Train Epoch: 4 [68480/84843 (81%)]\tLoss: 0.362520\n",
      "Train Epoch: 4 [69120/84843 (81%)]\tLoss: 0.143349\n",
      "Train Epoch: 4 [69760/84843 (82%)]\tLoss: 0.605306\n",
      "Train Epoch: 4 [70400/84843 (83%)]\tLoss: 0.459675\n",
      "Train Epoch: 4 [71040/84843 (84%)]\tLoss: 0.517581\n",
      "Train Epoch: 4 [71680/84843 (84%)]\tLoss: 0.255985\n",
      "Train Epoch: 4 [72320/84843 (85%)]\tLoss: 0.497531\n",
      "Train Epoch: 4 [72960/84843 (86%)]\tLoss: 0.311592\n",
      "Train Epoch: 4 [73600/84843 (87%)]\tLoss: 0.510917\n",
      "Train Epoch: 4 [74240/84843 (87%)]\tLoss: 0.456304\n",
      "Train Epoch: 4 [74880/84843 (88%)]\tLoss: 0.217999\n",
      "Train Epoch: 4 [75520/84843 (89%)]\tLoss: 0.364349\n",
      "Train Epoch: 4 [76160/84843 (90%)]\tLoss: 0.576142\n",
      "Train Epoch: 4 [76800/84843 (90%)]\tLoss: 0.460698\n",
      "Train Epoch: 4 [77440/84843 (91%)]\tLoss: 0.473602\n",
      "Train Epoch: 4 [78080/84843 (92%)]\tLoss: 0.416611\n",
      "Train Epoch: 4 [78720/84843 (93%)]\tLoss: 0.273543\n",
      "Train Epoch: 4 [79360/84843 (94%)]\tLoss: 0.147752\n",
      "Train Epoch: 4 [80000/84843 (94%)]\tLoss: 0.247537\n",
      "Train Epoch: 4 [80640/84843 (95%)]\tLoss: 0.271036\n",
      "Train Epoch: 4 [81280/84843 (96%)]\tLoss: 0.322173\n",
      "Train Epoch: 4 [81920/84843 (97%)]\tLoss: 0.333189\n",
      "Train Epoch: 4 [82560/84843 (97%)]\tLoss: 0.425706\n",
      "Train Epoch: 4 [83200/84843 (98%)]\tLoss: 1.135927\n",
      "Train Epoch: 4 [83840/84843 (99%)]\tLoss: 0.129316\n",
      "Train Epoch: 4 [84480/84843 (100%)]\tLoss: 0.812161\n",
      "Accuracy: 9482/11005 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/84843 (0%)]\tLoss: 0.462833\n",
      "Train Epoch: 5 [640/84843 (1%)]\tLoss: 0.879086\n",
      "Train Epoch: 5 [1280/84843 (2%)]\tLoss: 0.374543\n",
      "Train Epoch: 5 [1920/84843 (2%)]\tLoss: 0.429366\n",
      "Train Epoch: 5 [2560/84843 (3%)]\tLoss: 0.720290\n",
      "Train Epoch: 5 [3200/84843 (4%)]\tLoss: 0.197245\n",
      "Train Epoch: 5 [3840/84843 (5%)]\tLoss: 0.204616\n",
      "Train Epoch: 5 [4480/84843 (5%)]\tLoss: 0.394076\n",
      "Train Epoch: 5 [5120/84843 (6%)]\tLoss: 0.519263\n",
      "Train Epoch: 5 [5760/84843 (7%)]\tLoss: 0.201322\n",
      "Train Epoch: 5 [6400/84843 (8%)]\tLoss: 0.215069\n",
      "Train Epoch: 5 [7040/84843 (8%)]\tLoss: 0.219400\n",
      "Train Epoch: 5 [7680/84843 (9%)]\tLoss: 0.279618\n",
      "Train Epoch: 5 [8320/84843 (10%)]\tLoss: 0.470368\n",
      "Train Epoch: 5 [8960/84843 (11%)]\tLoss: 0.434827\n",
      "Train Epoch: 5 [9600/84843 (11%)]\tLoss: 0.449947\n",
      "Train Epoch: 5 [10240/84843 (12%)]\tLoss: 0.311951\n",
      "Train Epoch: 5 [10880/84843 (13%)]\tLoss: 0.556733\n",
      "Train Epoch: 5 [11520/84843 (14%)]\tLoss: 0.456167\n",
      "Train Epoch: 5 [12160/84843 (14%)]\tLoss: 0.656511\n",
      "Train Epoch: 5 [12800/84843 (15%)]\tLoss: 0.294536\n",
      "Train Epoch: 5 [13440/84843 (16%)]\tLoss: 0.455560\n",
      "Train Epoch: 5 [14080/84843 (17%)]\tLoss: 0.298843\n",
      "Train Epoch: 5 [14720/84843 (17%)]\tLoss: 0.321191\n",
      "Train Epoch: 5 [15360/84843 (18%)]\tLoss: 0.280322\n",
      "Train Epoch: 5 [16000/84843 (19%)]\tLoss: 0.152017\n",
      "Train Epoch: 5 [16640/84843 (20%)]\tLoss: 0.582574\n",
      "Train Epoch: 5 [17280/84843 (20%)]\tLoss: 0.175723\n",
      "Train Epoch: 5 [17920/84843 (21%)]\tLoss: 0.218421\n",
      "Train Epoch: 5 [18560/84843 (22%)]\tLoss: 0.206690\n",
      "Train Epoch: 5 [19200/84843 (23%)]\tLoss: 0.313767\n",
      "Train Epoch: 5 [19840/84843 (23%)]\tLoss: 0.330551\n",
      "Train Epoch: 5 [20480/84843 (24%)]\tLoss: 0.114563\n",
      "Train Epoch: 5 [21120/84843 (25%)]\tLoss: 0.704120\n",
      "Train Epoch: 5 [21760/84843 (26%)]\tLoss: 0.892145\n",
      "Train Epoch: 5 [22400/84843 (26%)]\tLoss: 0.602771\n",
      "Train Epoch: 5 [23040/84843 (27%)]\tLoss: 0.314686\n",
      "Train Epoch: 5 [23680/84843 (28%)]\tLoss: 0.709129\n",
      "Train Epoch: 5 [24320/84843 (29%)]\tLoss: 0.266963\n",
      "Train Epoch: 5 [24960/84843 (29%)]\tLoss: 0.529747\n",
      "Train Epoch: 5 [25600/84843 (30%)]\tLoss: 0.419571\n",
      "Train Epoch: 5 [26240/84843 (31%)]\tLoss: 0.437836\n",
      "Train Epoch: 5 [26880/84843 (32%)]\tLoss: 0.342500\n",
      "Train Epoch: 5 [27520/84843 (32%)]\tLoss: 0.343088\n",
      "Train Epoch: 5 [28160/84843 (33%)]\tLoss: 0.346117\n",
      "Train Epoch: 5 [28800/84843 (34%)]\tLoss: 0.247020\n",
      "Train Epoch: 5 [29440/84843 (35%)]\tLoss: 0.353290\n",
      "Train Epoch: 5 [30080/84843 (35%)]\tLoss: 0.384820\n",
      "Train Epoch: 5 [30720/84843 (36%)]\tLoss: 0.382311\n",
      "Train Epoch: 5 [31360/84843 (37%)]\tLoss: 0.276718\n",
      "Train Epoch: 5 [32000/84843 (38%)]\tLoss: 0.350815\n",
      "Train Epoch: 5 [32640/84843 (38%)]\tLoss: 0.313387\n",
      "Train Epoch: 5 [33280/84843 (39%)]\tLoss: 0.683521\n",
      "Train Epoch: 5 [33920/84843 (40%)]\tLoss: 0.404366\n",
      "Train Epoch: 5 [34560/84843 (41%)]\tLoss: 0.462561\n",
      "Train Epoch: 5 [35200/84843 (41%)]\tLoss: 0.426483\n",
      "Train Epoch: 5 [35840/84843 (42%)]\tLoss: 0.460334\n",
      "Train Epoch: 5 [36480/84843 (43%)]\tLoss: 0.496887\n",
      "Train Epoch: 5 [37120/84843 (44%)]\tLoss: 0.559685\n",
      "Train Epoch: 5 [37760/84843 (44%)]\tLoss: 0.049603\n",
      "Train Epoch: 5 [38400/84843 (45%)]\tLoss: 0.655038\n",
      "Train Epoch: 5 [39040/84843 (46%)]\tLoss: 0.646953\n",
      "Train Epoch: 5 [39680/84843 (47%)]\tLoss: 0.283300\n",
      "Train Epoch: 5 [40320/84843 (48%)]\tLoss: 0.444828\n",
      "Train Epoch: 5 [40960/84843 (48%)]\tLoss: 0.204588\n",
      "Train Epoch: 5 [41600/84843 (49%)]\tLoss: 0.361346\n",
      "Train Epoch: 5 [42240/84843 (50%)]\tLoss: 0.281097\n",
      "Train Epoch: 5 [42880/84843 (51%)]\tLoss: 0.285069\n",
      "Train Epoch: 5 [43520/84843 (51%)]\tLoss: 0.286026\n",
      "Train Epoch: 5 [44160/84843 (52%)]\tLoss: 0.217858\n",
      "Train Epoch: 5 [44800/84843 (53%)]\tLoss: 0.624495\n",
      "Train Epoch: 5 [45440/84843 (54%)]\tLoss: 0.465754\n",
      "Train Epoch: 5 [46080/84843 (54%)]\tLoss: 0.361774\n",
      "Train Epoch: 5 [46720/84843 (55%)]\tLoss: 0.515861\n",
      "Train Epoch: 5 [47360/84843 (56%)]\tLoss: 0.460094\n",
      "Train Epoch: 5 [48000/84843 (57%)]\tLoss: 0.342313\n",
      "Train Epoch: 5 [48640/84843 (57%)]\tLoss: 0.167197\n",
      "Train Epoch: 5 [49280/84843 (58%)]\tLoss: 0.415005\n",
      "Train Epoch: 5 [49920/84843 (59%)]\tLoss: 0.321191\n",
      "Train Epoch: 5 [50560/84843 (60%)]\tLoss: 0.427881\n",
      "Train Epoch: 5 [51200/84843 (60%)]\tLoss: 0.807066\n",
      "Train Epoch: 5 [51840/84843 (61%)]\tLoss: 0.219286\n",
      "Train Epoch: 5 [52480/84843 (62%)]\tLoss: 0.237109\n",
      "Train Epoch: 5 [53120/84843 (63%)]\tLoss: 0.598791\n",
      "Train Epoch: 5 [53760/84843 (63%)]\tLoss: 0.341817\n",
      "Train Epoch: 5 [54400/84843 (64%)]\tLoss: 0.368910\n",
      "Train Epoch: 5 [55040/84843 (65%)]\tLoss: 0.250570\n",
      "Train Epoch: 5 [55680/84843 (66%)]\tLoss: 0.445839\n",
      "Train Epoch: 5 [56320/84843 (66%)]\tLoss: 0.475713\n",
      "Train Epoch: 5 [56960/84843 (67%)]\tLoss: 0.389088\n",
      "Train Epoch: 5 [57600/84843 (68%)]\tLoss: 0.525777\n",
      "Train Epoch: 5 [58240/84843 (69%)]\tLoss: 0.413040\n",
      "Train Epoch: 5 [58880/84843 (69%)]\tLoss: 0.401720\n",
      "Train Epoch: 5 [59520/84843 (70%)]\tLoss: 0.246477\n",
      "Train Epoch: 5 [60160/84843 (71%)]\tLoss: 0.196815\n",
      "Train Epoch: 5 [60800/84843 (72%)]\tLoss: 0.491492\n",
      "Train Epoch: 5 [61440/84843 (72%)]\tLoss: 0.278489\n",
      "Train Epoch: 5 [62080/84843 (73%)]\tLoss: 0.495718\n",
      "Train Epoch: 5 [62720/84843 (74%)]\tLoss: 0.337867\n",
      "Train Epoch: 5 [63360/84843 (75%)]\tLoss: 0.329735\n",
      "Train Epoch: 5 [64000/84843 (75%)]\tLoss: 0.616570\n",
      "Train Epoch: 5 [64640/84843 (76%)]\tLoss: 0.235192\n",
      "Train Epoch: 5 [65280/84843 (77%)]\tLoss: 0.513601\n",
      "Train Epoch: 5 [65920/84843 (78%)]\tLoss: 0.245219\n",
      "Train Epoch: 5 [66560/84843 (78%)]\tLoss: 0.162591\n",
      "Train Epoch: 5 [67200/84843 (79%)]\tLoss: 0.371005\n",
      "Train Epoch: 5 [67840/84843 (80%)]\tLoss: 0.258924\n",
      "Train Epoch: 5 [68480/84843 (81%)]\tLoss: 0.305560\n",
      "Train Epoch: 5 [69120/84843 (81%)]\tLoss: 0.276253\n",
      "Train Epoch: 5 [69760/84843 (82%)]\tLoss: 0.548611\n",
      "Train Epoch: 5 [70400/84843 (83%)]\tLoss: 0.351386\n",
      "Train Epoch: 5 [71040/84843 (84%)]\tLoss: 0.554862\n",
      "Train Epoch: 5 [71680/84843 (84%)]\tLoss: 0.145019\n",
      "Train Epoch: 5 [72320/84843 (85%)]\tLoss: 0.235740\n",
      "Train Epoch: 5 [72960/84843 (86%)]\tLoss: 0.362067\n",
      "Train Epoch: 5 [73600/84843 (87%)]\tLoss: 0.214490\n",
      "Train Epoch: 5 [74240/84843 (87%)]\tLoss: 0.407496\n",
      "Train Epoch: 5 [74880/84843 (88%)]\tLoss: 0.438816\n",
      "Train Epoch: 5 [75520/84843 (89%)]\tLoss: 0.359140\n",
      "Train Epoch: 5 [76160/84843 (90%)]\tLoss: 0.588198\n",
      "Train Epoch: 5 [76800/84843 (90%)]\tLoss: 0.365778\n",
      "Train Epoch: 5 [77440/84843 (91%)]\tLoss: 0.250280\n",
      "Train Epoch: 5 [78080/84843 (92%)]\tLoss: 0.537143\n",
      "Train Epoch: 5 [78720/84843 (93%)]\tLoss: 0.496995\n",
      "Train Epoch: 5 [79360/84843 (94%)]\tLoss: 0.470061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [80000/84843 (94%)]\tLoss: 0.455690\n",
      "Train Epoch: 5 [80640/84843 (95%)]\tLoss: 0.466225\n",
      "Train Epoch: 5 [81280/84843 (96%)]\tLoss: 0.233212\n",
      "Train Epoch: 5 [81920/84843 (97%)]\tLoss: 0.463883\n",
      "Train Epoch: 5 [82560/84843 (97%)]\tLoss: 0.574283\n",
      "Train Epoch: 5 [83200/84843 (98%)]\tLoss: 0.421111\n",
      "Train Epoch: 5 [83840/84843 (99%)]\tLoss: 0.600136\n",
      "Train Epoch: 5 [84480/84843 (100%)]\tLoss: 0.280031\n",
      "Accuracy: 9446/11005 (86%)\n",
      "\n",
      "Train Epoch: 6 [0/84843 (0%)]\tLoss: 0.273857\n",
      "Train Epoch: 6 [640/84843 (1%)]\tLoss: 0.268012\n",
      "Train Epoch: 6 [1280/84843 (2%)]\tLoss: 0.220747\n",
      "Train Epoch: 6 [1920/84843 (2%)]\tLoss: 0.362594\n",
      "Train Epoch: 6 [2560/84843 (3%)]\tLoss: 0.356912\n",
      "Train Epoch: 6 [3200/84843 (4%)]\tLoss: 0.502520\n",
      "Train Epoch: 6 [3840/84843 (5%)]\tLoss: 0.540419\n",
      "Train Epoch: 6 [4480/84843 (5%)]\tLoss: 0.330759\n",
      "Train Epoch: 6 [5120/84843 (6%)]\tLoss: 0.340926\n",
      "Train Epoch: 6 [5760/84843 (7%)]\tLoss: 0.224527\n",
      "Train Epoch: 6 [6400/84843 (8%)]\tLoss: 0.360593\n",
      "Train Epoch: 6 [7040/84843 (8%)]\tLoss: 0.345960\n",
      "Train Epoch: 6 [7680/84843 (9%)]\tLoss: 0.572821\n",
      "Train Epoch: 6 [8320/84843 (10%)]\tLoss: 0.316761\n",
      "Train Epoch: 6 [8960/84843 (11%)]\tLoss: 0.596053\n",
      "Train Epoch: 6 [9600/84843 (11%)]\tLoss: 0.481688\n",
      "Train Epoch: 6 [10240/84843 (12%)]\tLoss: 0.186863\n",
      "Train Epoch: 6 [10880/84843 (13%)]\tLoss: 0.379484\n",
      "Train Epoch: 6 [11520/84843 (14%)]\tLoss: 0.263207\n",
      "Train Epoch: 6 [12160/84843 (14%)]\tLoss: 0.167818\n",
      "Train Epoch: 6 [12800/84843 (15%)]\tLoss: 0.288989\n",
      "Train Epoch: 6 [13440/84843 (16%)]\tLoss: 0.572272\n",
      "Train Epoch: 6 [14080/84843 (17%)]\tLoss: 0.318045\n",
      "Train Epoch: 6 [14720/84843 (17%)]\tLoss: 0.476388\n",
      "Train Epoch: 6 [15360/84843 (18%)]\tLoss: 0.457039\n",
      "Train Epoch: 6 [16000/84843 (19%)]\tLoss: 0.244170\n",
      "Train Epoch: 6 [16640/84843 (20%)]\tLoss: 0.362873\n",
      "Train Epoch: 6 [17280/84843 (20%)]\tLoss: 0.412485\n",
      "Train Epoch: 6 [17920/84843 (21%)]\tLoss: 0.249058\n",
      "Train Epoch: 6 [18560/84843 (22%)]\tLoss: 0.228870\n",
      "Train Epoch: 6 [19200/84843 (23%)]\tLoss: 0.151924\n",
      "Train Epoch: 6 [19840/84843 (23%)]\tLoss: 0.537382\n",
      "Train Epoch: 6 [20480/84843 (24%)]\tLoss: 0.573912\n",
      "Train Epoch: 6 [21120/84843 (25%)]\tLoss: 0.523250\n",
      "Train Epoch: 6 [21760/84843 (26%)]\tLoss: 0.330015\n",
      "Train Epoch: 6 [22400/84843 (26%)]\tLoss: 0.309408\n",
      "Train Epoch: 6 [23040/84843 (27%)]\tLoss: 0.277562\n",
      "Train Epoch: 6 [23680/84843 (28%)]\tLoss: 0.445674\n",
      "Train Epoch: 6 [24320/84843 (29%)]\tLoss: 0.369555\n",
      "Train Epoch: 6 [24960/84843 (29%)]\tLoss: 0.310990\n",
      "Train Epoch: 6 [25600/84843 (30%)]\tLoss: 0.078757\n",
      "Train Epoch: 6 [26240/84843 (31%)]\tLoss: 0.425193\n",
      "Train Epoch: 6 [26880/84843 (32%)]\tLoss: 0.507240\n",
      "Train Epoch: 6 [27520/84843 (32%)]\tLoss: 0.468837\n",
      "Train Epoch: 6 [28160/84843 (33%)]\tLoss: 0.425157\n",
      "Train Epoch: 6 [28800/84843 (34%)]\tLoss: 0.650988\n",
      "Train Epoch: 6 [29440/84843 (35%)]\tLoss: 0.477793\n",
      "Train Epoch: 6 [30080/84843 (35%)]\tLoss: 0.410562\n",
      "Train Epoch: 6 [30720/84843 (36%)]\tLoss: 0.481674\n",
      "Train Epoch: 6 [31360/84843 (37%)]\tLoss: 0.328418\n",
      "Train Epoch: 6 [32000/84843 (38%)]\tLoss: 0.493745\n",
      "Train Epoch: 6 [32640/84843 (38%)]\tLoss: 0.399628\n",
      "Train Epoch: 6 [33280/84843 (39%)]\tLoss: 0.268482\n",
      "Train Epoch: 6 [33920/84843 (40%)]\tLoss: 0.442062\n",
      "Train Epoch: 6 [34560/84843 (41%)]\tLoss: 0.549866\n",
      "Train Epoch: 6 [35200/84843 (41%)]\tLoss: 0.295611\n",
      "Train Epoch: 6 [35840/84843 (42%)]\tLoss: 0.369671\n",
      "Train Epoch: 6 [36480/84843 (43%)]\tLoss: 0.093986\n",
      "Train Epoch: 6 [37120/84843 (44%)]\tLoss: 0.302319\n",
      "Train Epoch: 6 [37760/84843 (44%)]\tLoss: 0.343528\n",
      "Train Epoch: 6 [38400/84843 (45%)]\tLoss: 0.318247\n",
      "Train Epoch: 6 [39040/84843 (46%)]\tLoss: 0.284018\n",
      "Train Epoch: 6 [39680/84843 (47%)]\tLoss: 0.409481\n",
      "Train Epoch: 6 [40320/84843 (48%)]\tLoss: 0.146429\n",
      "Train Epoch: 6 [40960/84843 (48%)]\tLoss: 0.309259\n",
      "Train Epoch: 6 [41600/84843 (49%)]\tLoss: 0.396034\n",
      "Train Epoch: 6 [42240/84843 (50%)]\tLoss: 0.630114\n",
      "Train Epoch: 6 [42880/84843 (51%)]\tLoss: 0.440407\n",
      "Train Epoch: 6 [43520/84843 (51%)]\tLoss: 0.151807\n",
      "Train Epoch: 6 [44160/84843 (52%)]\tLoss: 0.295156\n",
      "Train Epoch: 6 [44800/84843 (53%)]\tLoss: 0.379902\n",
      "Train Epoch: 6 [45440/84843 (54%)]\tLoss: 0.472205\n",
      "Train Epoch: 6 [46080/84843 (54%)]\tLoss: 0.325537\n",
      "Train Epoch: 6 [46720/84843 (55%)]\tLoss: 0.313751\n",
      "Train Epoch: 6 [47360/84843 (56%)]\tLoss: 0.104991\n",
      "Train Epoch: 6 [48000/84843 (57%)]\tLoss: 0.119042\n",
      "Train Epoch: 6 [48640/84843 (57%)]\tLoss: 0.683510\n",
      "Train Epoch: 6 [49280/84843 (58%)]\tLoss: 0.286172\n",
      "Train Epoch: 6 [49920/84843 (59%)]\tLoss: 0.540485\n",
      "Train Epoch: 6 [50560/84843 (60%)]\tLoss: 0.449403\n",
      "Train Epoch: 6 [51200/84843 (60%)]\tLoss: 0.359490\n",
      "Train Epoch: 6 [51840/84843 (61%)]\tLoss: 0.502874\n",
      "Train Epoch: 6 [52480/84843 (62%)]\tLoss: 0.447540\n",
      "Train Epoch: 6 [53120/84843 (63%)]\tLoss: 0.334168\n",
      "Train Epoch: 6 [53760/84843 (63%)]\tLoss: 0.291892\n",
      "Train Epoch: 6 [54400/84843 (64%)]\tLoss: 0.308029\n",
      "Train Epoch: 6 [55040/84843 (65%)]\tLoss: 0.263223\n",
      "Train Epoch: 6 [55680/84843 (66%)]\tLoss: 0.591055\n",
      "Train Epoch: 6 [56320/84843 (66%)]\tLoss: 0.420085\n",
      "Train Epoch: 6 [56960/84843 (67%)]\tLoss: 0.505625\n",
      "Train Epoch: 6 [57600/84843 (68%)]\tLoss: 0.358751\n",
      "Train Epoch: 6 [58240/84843 (69%)]\tLoss: 0.290467\n",
      "Train Epoch: 6 [58880/84843 (69%)]\tLoss: 0.503671\n",
      "Train Epoch: 6 [59520/84843 (70%)]\tLoss: 0.309432\n",
      "Train Epoch: 6 [60160/84843 (71%)]\tLoss: 0.594501\n",
      "Train Epoch: 6 [60800/84843 (72%)]\tLoss: 0.601244\n",
      "Train Epoch: 6 [61440/84843 (72%)]\tLoss: 0.498573\n",
      "Train Epoch: 6 [62080/84843 (73%)]\tLoss: 0.311987\n",
      "Train Epoch: 6 [62720/84843 (74%)]\tLoss: 0.769618\n",
      "Train Epoch: 6 [63360/84843 (75%)]\tLoss: 0.394955\n",
      "Train Epoch: 6 [64000/84843 (75%)]\tLoss: 0.494165\n",
      "Train Epoch: 6 [64640/84843 (76%)]\tLoss: 0.855509\n",
      "Train Epoch: 6 [65280/84843 (77%)]\tLoss: 0.363559\n",
      "Train Epoch: 6 [65920/84843 (78%)]\tLoss: 0.426048\n",
      "Train Epoch: 6 [66560/84843 (78%)]\tLoss: 0.193851\n",
      "Train Epoch: 6 [67200/84843 (79%)]\tLoss: 0.672212\n",
      "Train Epoch: 6 [67840/84843 (80%)]\tLoss: 0.403988\n",
      "Train Epoch: 6 [68480/84843 (81%)]\tLoss: 0.271181\n",
      "Train Epoch: 6 [69120/84843 (81%)]\tLoss: 0.161911\n",
      "Train Epoch: 6 [69760/84843 (82%)]\tLoss: 0.520221\n",
      "Train Epoch: 6 [70400/84843 (83%)]\tLoss: 0.371979\n",
      "Train Epoch: 6 [71040/84843 (84%)]\tLoss: 0.421141\n",
      "Train Epoch: 6 [71680/84843 (84%)]\tLoss: 0.364287\n",
      "Train Epoch: 6 [72320/84843 (85%)]\tLoss: 0.136873\n",
      "Train Epoch: 6 [72960/84843 (86%)]\tLoss: 0.163862\n",
      "Train Epoch: 6 [73600/84843 (87%)]\tLoss: 0.389534\n",
      "Train Epoch: 6 [74240/84843 (87%)]\tLoss: 0.323803\n",
      "Train Epoch: 6 [74880/84843 (88%)]\tLoss: 0.210840\n",
      "Train Epoch: 6 [75520/84843 (89%)]\tLoss: 0.321950\n",
      "Train Epoch: 6 [76160/84843 (90%)]\tLoss: 0.218394\n",
      "Train Epoch: 6 [76800/84843 (90%)]\tLoss: 0.277721\n",
      "Train Epoch: 6 [77440/84843 (91%)]\tLoss: 0.123495\n",
      "Train Epoch: 6 [78080/84843 (92%)]\tLoss: 0.364769\n",
      "Train Epoch: 6 [78720/84843 (93%)]\tLoss: 0.527548\n",
      "Train Epoch: 6 [79360/84843 (94%)]\tLoss: 0.165652\n",
      "Train Epoch: 6 [80000/84843 (94%)]\tLoss: 0.296932\n",
      "Train Epoch: 6 [80640/84843 (95%)]\tLoss: 0.373766\n",
      "Train Epoch: 6 [81280/84843 (96%)]\tLoss: 0.673911\n",
      "Train Epoch: 6 [81920/84843 (97%)]\tLoss: 0.345924\n",
      "Train Epoch: 6 [82560/84843 (97%)]\tLoss: 0.513198\n",
      "Train Epoch: 6 [83200/84843 (98%)]\tLoss: 0.211254\n",
      "Train Epoch: 6 [83840/84843 (99%)]\tLoss: 0.153892\n",
      "Train Epoch: 6 [84480/84843 (100%)]\tLoss: 0.287459\n",
      "Accuracy: 9401/11005 (85%)\n",
      "\n",
      "Train Epoch: 7 [0/84843 (0%)]\tLoss: 0.346959\n",
      "Train Epoch: 7 [640/84843 (1%)]\tLoss: 0.219327\n",
      "Train Epoch: 7 [1280/84843 (2%)]\tLoss: 0.493089\n",
      "Train Epoch: 7 [1920/84843 (2%)]\tLoss: 0.441469\n",
      "Train Epoch: 7 [2560/84843 (3%)]\tLoss: 0.517410\n",
      "Train Epoch: 7 [3200/84843 (4%)]\tLoss: 0.254579\n",
      "Train Epoch: 7 [3840/84843 (5%)]\tLoss: 0.241447\n",
      "Train Epoch: 7 [4480/84843 (5%)]\tLoss: 0.362407\n",
      "Train Epoch: 7 [5120/84843 (6%)]\tLoss: 0.256560\n",
      "Train Epoch: 7 [5760/84843 (7%)]\tLoss: 0.194168\n",
      "Train Epoch: 7 [6400/84843 (8%)]\tLoss: 0.386375\n",
      "Train Epoch: 7 [7040/84843 (8%)]\tLoss: 0.448748\n",
      "Train Epoch: 7 [7680/84843 (9%)]\tLoss: 0.232756\n",
      "Train Epoch: 7 [8320/84843 (10%)]\tLoss: 0.602272\n",
      "Train Epoch: 7 [8960/84843 (11%)]\tLoss: 0.234877\n",
      "Train Epoch: 7 [9600/84843 (11%)]\tLoss: 0.395547\n",
      "Train Epoch: 7 [10240/84843 (12%)]\tLoss: 0.314321\n",
      "Train Epoch: 7 [10880/84843 (13%)]\tLoss: 0.463633\n",
      "Train Epoch: 7 [11520/84843 (14%)]\tLoss: 0.331974\n",
      "Train Epoch: 7 [12160/84843 (14%)]\tLoss: 0.398277\n",
      "Train Epoch: 7 [12800/84843 (15%)]\tLoss: 0.154302\n",
      "Train Epoch: 7 [13440/84843 (16%)]\tLoss: 0.277897\n",
      "Train Epoch: 7 [14080/84843 (17%)]\tLoss: 0.290098\n",
      "Train Epoch: 7 [14720/84843 (17%)]\tLoss: 0.404474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [15360/84843 (18%)]\tLoss: 0.392183\n",
      "Train Epoch: 7 [16000/84843 (19%)]\tLoss: 0.245708\n",
      "Train Epoch: 7 [16640/84843 (20%)]\tLoss: 0.425656\n",
      "Train Epoch: 7 [17280/84843 (20%)]\tLoss: 0.221704\n",
      "Train Epoch: 7 [17920/84843 (21%)]\tLoss: 0.169777\n",
      "Train Epoch: 7 [18560/84843 (22%)]\tLoss: 0.745857\n",
      "Train Epoch: 7 [19200/84843 (23%)]\tLoss: 0.246156\n",
      "Train Epoch: 7 [19840/84843 (23%)]\tLoss: 0.265560\n",
      "Train Epoch: 7 [20480/84843 (24%)]\tLoss: 0.480786\n",
      "Train Epoch: 7 [21120/84843 (25%)]\tLoss: 0.341321\n",
      "Train Epoch: 7 [21760/84843 (26%)]\tLoss: 0.287649\n",
      "Train Epoch: 7 [22400/84843 (26%)]\tLoss: 0.258035\n",
      "Train Epoch: 7 [23040/84843 (27%)]\tLoss: 0.189516\n",
      "Train Epoch: 7 [23680/84843 (28%)]\tLoss: 0.124249\n",
      "Train Epoch: 7 [24320/84843 (29%)]\tLoss: 0.155617\n",
      "Train Epoch: 7 [24960/84843 (29%)]\tLoss: 0.368239\n",
      "Train Epoch: 7 [25600/84843 (30%)]\tLoss: 0.183111\n",
      "Train Epoch: 7 [26240/84843 (31%)]\tLoss: 0.165426\n",
      "Train Epoch: 7 [26880/84843 (32%)]\tLoss: 0.535328\n",
      "Train Epoch: 7 [27520/84843 (32%)]\tLoss: 0.342647\n",
      "Train Epoch: 7 [28160/84843 (33%)]\tLoss: 0.428575\n",
      "Train Epoch: 7 [28800/84843 (34%)]\tLoss: 0.537122\n",
      "Train Epoch: 7 [29440/84843 (35%)]\tLoss: 0.244775\n",
      "Train Epoch: 7 [30080/84843 (35%)]\tLoss: 0.405033\n",
      "Train Epoch: 7 [30720/84843 (36%)]\tLoss: 0.589333\n",
      "Train Epoch: 7 [31360/84843 (37%)]\tLoss: 0.819863\n",
      "Train Epoch: 7 [32000/84843 (38%)]\tLoss: 0.936249\n",
      "Train Epoch: 7 [32640/84843 (38%)]\tLoss: 0.480208\n",
      "Train Epoch: 7 [33280/84843 (39%)]\tLoss: 0.192868\n",
      "Train Epoch: 7 [33920/84843 (40%)]\tLoss: 0.611267\n",
      "Train Epoch: 7 [34560/84843 (41%)]\tLoss: 0.269388\n",
      "Train Epoch: 7 [35200/84843 (41%)]\tLoss: 0.346368\n",
      "Train Epoch: 7 [35840/84843 (42%)]\tLoss: 0.310638\n",
      "Train Epoch: 7 [36480/84843 (43%)]\tLoss: 0.493222\n",
      "Train Epoch: 7 [37120/84843 (44%)]\tLoss: 0.456352\n",
      "Train Epoch: 7 [37760/84843 (44%)]\tLoss: 0.351079\n",
      "Train Epoch: 7 [38400/84843 (45%)]\tLoss: 0.207525\n",
      "Train Epoch: 7 [39040/84843 (46%)]\tLoss: 0.372005\n",
      "Train Epoch: 7 [39680/84843 (47%)]\tLoss: 0.359459\n",
      "Train Epoch: 7 [40320/84843 (48%)]\tLoss: 0.489686\n",
      "Train Epoch: 7 [40960/84843 (48%)]\tLoss: 0.672382\n",
      "Train Epoch: 7 [41600/84843 (49%)]\tLoss: 0.243907\n",
      "Train Epoch: 7 [42240/84843 (50%)]\tLoss: 0.311727\n",
      "Train Epoch: 7 [42880/84843 (51%)]\tLoss: 0.518426\n",
      "Train Epoch: 7 [43520/84843 (51%)]\tLoss: 0.508191\n",
      "Train Epoch: 7 [44160/84843 (52%)]\tLoss: 0.876445\n",
      "Train Epoch: 7 [44800/84843 (53%)]\tLoss: 0.236703\n",
      "Train Epoch: 7 [45440/84843 (54%)]\tLoss: 0.428482\n",
      "Train Epoch: 7 [46080/84843 (54%)]\tLoss: 0.634087\n",
      "Train Epoch: 7 [46720/84843 (55%)]\tLoss: 0.441697\n",
      "Train Epoch: 7 [47360/84843 (56%)]\tLoss: 0.532329\n",
      "Train Epoch: 7 [48000/84843 (57%)]\tLoss: 0.291043\n",
      "Train Epoch: 7 [48640/84843 (57%)]\tLoss: 0.451427\n",
      "Train Epoch: 7 [49280/84843 (58%)]\tLoss: 0.660628\n",
      "Train Epoch: 7 [49920/84843 (59%)]\tLoss: 0.543124\n",
      "Train Epoch: 7 [50560/84843 (60%)]\tLoss: 0.462225\n",
      "Train Epoch: 7 [51200/84843 (60%)]\tLoss: 0.179949\n",
      "Train Epoch: 7 [51840/84843 (61%)]\tLoss: 0.229918\n",
      "Train Epoch: 7 [52480/84843 (62%)]\tLoss: 0.356190\n",
      "Train Epoch: 7 [53120/84843 (63%)]\tLoss: 0.316879\n",
      "Train Epoch: 7 [53760/84843 (63%)]\tLoss: 0.409157\n",
      "Train Epoch: 7 [54400/84843 (64%)]\tLoss: 0.307754\n",
      "Train Epoch: 7 [55040/84843 (65%)]\tLoss: 0.360209\n",
      "Train Epoch: 7 [55680/84843 (66%)]\tLoss: 0.334396\n",
      "Train Epoch: 7 [56320/84843 (66%)]\tLoss: 0.676684\n",
      "Train Epoch: 7 [56960/84843 (67%)]\tLoss: 0.610317\n",
      "Train Epoch: 7 [57600/84843 (68%)]\tLoss: 0.496192\n",
      "Train Epoch: 7 [58240/84843 (69%)]\tLoss: 0.663550\n",
      "Train Epoch: 7 [58880/84843 (69%)]\tLoss: 0.348091\n",
      "Train Epoch: 7 [59520/84843 (70%)]\tLoss: 0.258865\n",
      "Train Epoch: 7 [60160/84843 (71%)]\tLoss: 0.406842\n",
      "Train Epoch: 7 [60800/84843 (72%)]\tLoss: 0.387556\n",
      "Train Epoch: 7 [61440/84843 (72%)]\tLoss: 0.467422\n",
      "Train Epoch: 7 [62080/84843 (73%)]\tLoss: 0.313148\n",
      "Train Epoch: 7 [62720/84843 (74%)]\tLoss: 0.471361\n",
      "Train Epoch: 7 [63360/84843 (75%)]\tLoss: 0.296804\n",
      "Train Epoch: 7 [64000/84843 (75%)]\tLoss: 0.269937\n",
      "Train Epoch: 7 [64640/84843 (76%)]\tLoss: 0.878238\n",
      "Train Epoch: 7 [65280/84843 (77%)]\tLoss: 0.220844\n",
      "Train Epoch: 7 [65920/84843 (78%)]\tLoss: 0.424626\n",
      "Train Epoch: 7 [66560/84843 (78%)]\tLoss: 0.176289\n",
      "Train Epoch: 7 [67200/84843 (79%)]\tLoss: 0.633514\n",
      "Train Epoch: 7 [67840/84843 (80%)]\tLoss: 0.332213\n",
      "Train Epoch: 7 [68480/84843 (81%)]\tLoss: 0.293963\n",
      "Train Epoch: 7 [69120/84843 (81%)]\tLoss: 0.085370\n",
      "Train Epoch: 7 [69760/84843 (82%)]\tLoss: 0.393223\n",
      "Train Epoch: 7 [70400/84843 (83%)]\tLoss: 0.396180\n",
      "Train Epoch: 7 [71040/84843 (84%)]\tLoss: 0.292621\n",
      "Train Epoch: 7 [71680/84843 (84%)]\tLoss: 0.127644\n",
      "Train Epoch: 7 [72320/84843 (85%)]\tLoss: 0.397765\n",
      "Train Epoch: 7 [72960/84843 (86%)]\tLoss: 0.542862\n",
      "Train Epoch: 7 [73600/84843 (87%)]\tLoss: 0.265283\n",
      "Train Epoch: 7 [74240/84843 (87%)]\tLoss: 0.381594\n",
      "Train Epoch: 7 [74880/84843 (88%)]\tLoss: 0.431504\n",
      "Train Epoch: 7 [75520/84843 (89%)]\tLoss: 0.136462\n",
      "Train Epoch: 7 [76160/84843 (90%)]\tLoss: 0.465424\n",
      "Train Epoch: 7 [76800/84843 (90%)]\tLoss: 0.392030\n",
      "Train Epoch: 7 [77440/84843 (91%)]\tLoss: 0.161992\n",
      "Train Epoch: 7 [78080/84843 (92%)]\tLoss: 0.404195\n",
      "Train Epoch: 7 [78720/84843 (93%)]\tLoss: 0.359051\n",
      "Train Epoch: 7 [79360/84843 (94%)]\tLoss: 0.197183\n",
      "Train Epoch: 7 [80000/84843 (94%)]\tLoss: 0.222674\n",
      "Train Epoch: 7 [80640/84843 (95%)]\tLoss: 0.383411\n",
      "Train Epoch: 7 [81280/84843 (96%)]\tLoss: 0.428912\n",
      "Train Epoch: 7 [81920/84843 (97%)]\tLoss: 0.310100\n",
      "Train Epoch: 7 [82560/84843 (97%)]\tLoss: 0.317511\n",
      "Train Epoch: 7 [83200/84843 (98%)]\tLoss: 0.300680\n",
      "Train Epoch: 7 [83840/84843 (99%)]\tLoss: 0.227098\n",
      "Train Epoch: 7 [84480/84843 (100%)]\tLoss: 0.239395\n",
      "Accuracy: 9432/11005 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/84843 (0%)]\tLoss: 0.368934\n",
      "Train Epoch: 8 [640/84843 (1%)]\tLoss: 0.300840\n",
      "Train Epoch: 8 [1280/84843 (2%)]\tLoss: 0.818685\n",
      "Train Epoch: 8 [1920/84843 (2%)]\tLoss: 0.181873\n",
      "Train Epoch: 8 [2560/84843 (3%)]\tLoss: 0.432574\n",
      "Train Epoch: 8 [3200/84843 (4%)]\tLoss: 0.210676\n",
      "Train Epoch: 8 [3840/84843 (5%)]\tLoss: 0.344965\n",
      "Train Epoch: 8 [4480/84843 (5%)]\tLoss: 0.312692\n",
      "Train Epoch: 8 [5120/84843 (6%)]\tLoss: 0.485033\n",
      "Train Epoch: 8 [5760/84843 (7%)]\tLoss: 0.366146\n",
      "Train Epoch: 8 [6400/84843 (8%)]\tLoss: 0.190616\n",
      "Train Epoch: 8 [7040/84843 (8%)]\tLoss: 0.503460\n",
      "Train Epoch: 8 [7680/84843 (9%)]\tLoss: 0.242557\n",
      "Train Epoch: 8 [8320/84843 (10%)]\tLoss: 0.629219\n",
      "Train Epoch: 8 [8960/84843 (11%)]\tLoss: 0.426740\n",
      "Train Epoch: 8 [9600/84843 (11%)]\tLoss: 0.867814\n",
      "Train Epoch: 8 [10240/84843 (12%)]\tLoss: 0.170896\n",
      "Train Epoch: 8 [10880/84843 (13%)]\tLoss: 0.243323\n",
      "Train Epoch: 8 [11520/84843 (14%)]\tLoss: 0.226152\n",
      "Train Epoch: 8 [12160/84843 (14%)]\tLoss: 0.208012\n",
      "Train Epoch: 8 [12800/84843 (15%)]\tLoss: 0.360149\n",
      "Train Epoch: 8 [13440/84843 (16%)]\tLoss: 0.188354\n",
      "Train Epoch: 8 [14080/84843 (17%)]\tLoss: 0.266534\n",
      "Train Epoch: 8 [14720/84843 (17%)]\tLoss: 0.506304\n",
      "Train Epoch: 8 [15360/84843 (18%)]\tLoss: 0.285131\n",
      "Train Epoch: 8 [16000/84843 (19%)]\tLoss: 0.542697\n",
      "Train Epoch: 8 [16640/84843 (20%)]\tLoss: 0.469474\n",
      "Train Epoch: 8 [17280/84843 (20%)]\tLoss: 0.304352\n",
      "Train Epoch: 8 [17920/84843 (21%)]\tLoss: 0.433250\n",
      "Train Epoch: 8 [18560/84843 (22%)]\tLoss: 0.282460\n",
      "Train Epoch: 8 [19200/84843 (23%)]\tLoss: 0.377009\n",
      "Train Epoch: 8 [19840/84843 (23%)]\tLoss: 0.284703\n",
      "Train Epoch: 8 [20480/84843 (24%)]\tLoss: 0.161706\n",
      "Train Epoch: 8 [21120/84843 (25%)]\tLoss: 0.236448\n",
      "Train Epoch: 8 [21760/84843 (26%)]\tLoss: 0.535833\n",
      "Train Epoch: 8 [22400/84843 (26%)]\tLoss: 0.064522\n",
      "Train Epoch: 8 [23040/84843 (27%)]\tLoss: 0.413724\n",
      "Train Epoch: 8 [23680/84843 (28%)]\tLoss: 0.297060\n",
      "Train Epoch: 8 [24320/84843 (29%)]\tLoss: 0.286466\n",
      "Train Epoch: 8 [24960/84843 (29%)]\tLoss: 0.379230\n",
      "Train Epoch: 8 [25600/84843 (30%)]\tLoss: 0.209885\n",
      "Train Epoch: 8 [26240/84843 (31%)]\tLoss: 0.479364\n",
      "Train Epoch: 8 [26880/84843 (32%)]\tLoss: 0.534245\n",
      "Train Epoch: 8 [27520/84843 (32%)]\tLoss: 0.277482\n",
      "Train Epoch: 8 [28160/84843 (33%)]\tLoss: 0.385195\n",
      "Train Epoch: 8 [28800/84843 (34%)]\tLoss: 0.313367\n",
      "Train Epoch: 8 [29440/84843 (35%)]\tLoss: 0.466939\n",
      "Train Epoch: 8 [30080/84843 (35%)]\tLoss: 0.321962\n",
      "Train Epoch: 8 [30720/84843 (36%)]\tLoss: 0.106521\n",
      "Train Epoch: 8 [31360/84843 (37%)]\tLoss: 0.327354\n",
      "Train Epoch: 8 [32000/84843 (38%)]\tLoss: 0.251981\n",
      "Train Epoch: 8 [32640/84843 (38%)]\tLoss: 0.579384\n",
      "Train Epoch: 8 [33280/84843 (39%)]\tLoss: 0.365742\n",
      "Train Epoch: 8 [33920/84843 (40%)]\tLoss: 0.147538\n",
      "Train Epoch: 8 [34560/84843 (41%)]\tLoss: 0.148487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [35200/84843 (41%)]\tLoss: 0.487224\n",
      "Train Epoch: 8 [35840/84843 (42%)]\tLoss: 0.426331\n",
      "Train Epoch: 8 [36480/84843 (43%)]\tLoss: 0.382984\n",
      "Train Epoch: 8 [37120/84843 (44%)]\tLoss: 0.359030\n",
      "Train Epoch: 8 [37760/84843 (44%)]\tLoss: 0.176756\n",
      "Train Epoch: 8 [38400/84843 (45%)]\tLoss: 0.454585\n",
      "Train Epoch: 8 [39040/84843 (46%)]\tLoss: 0.403731\n",
      "Train Epoch: 8 [39680/84843 (47%)]\tLoss: 0.560589\n",
      "Train Epoch: 8 [40320/84843 (48%)]\tLoss: 0.343747\n",
      "Train Epoch: 8 [40960/84843 (48%)]\tLoss: 0.461027\n",
      "Train Epoch: 8 [41600/84843 (49%)]\tLoss: 0.473077\n",
      "Train Epoch: 8 [42240/84843 (50%)]\tLoss: 0.283456\n",
      "Train Epoch: 8 [42880/84843 (51%)]\tLoss: 0.120898\n",
      "Train Epoch: 8 [43520/84843 (51%)]\tLoss: 0.529207\n",
      "Train Epoch: 8 [44160/84843 (52%)]\tLoss: 0.878238\n",
      "Train Epoch: 8 [44800/84843 (53%)]\tLoss: 0.463783\n",
      "Train Epoch: 8 [45440/84843 (54%)]\tLoss: 0.349607\n",
      "Train Epoch: 8 [46080/84843 (54%)]\tLoss: 0.530751\n",
      "Train Epoch: 8 [46720/84843 (55%)]\tLoss: 0.252423\n",
      "Train Epoch: 8 [47360/84843 (56%)]\tLoss: 0.051702\n",
      "Train Epoch: 8 [48000/84843 (57%)]\tLoss: 0.347616\n",
      "Train Epoch: 8 [48640/84843 (57%)]\tLoss: 0.307201\n",
      "Train Epoch: 8 [49280/84843 (58%)]\tLoss: 0.578304\n",
      "Train Epoch: 8 [49920/84843 (59%)]\tLoss: 0.497185\n",
      "Train Epoch: 8 [50560/84843 (60%)]\tLoss: 0.535203\n",
      "Train Epoch: 8 [51200/84843 (60%)]\tLoss: 0.507280\n",
      "Train Epoch: 8 [51840/84843 (61%)]\tLoss: 0.335963\n",
      "Train Epoch: 8 [52480/84843 (62%)]\tLoss: 0.362000\n",
      "Train Epoch: 8 [53120/84843 (63%)]\tLoss: 0.224626\n",
      "Train Epoch: 8 [53760/84843 (63%)]\tLoss: 0.574024\n",
      "Train Epoch: 8 [54400/84843 (64%)]\tLoss: 0.390286\n",
      "Train Epoch: 8 [55040/84843 (65%)]\tLoss: 0.409549\n",
      "Train Epoch: 8 [55680/84843 (66%)]\tLoss: 0.560942\n",
      "Train Epoch: 8 [56320/84843 (66%)]\tLoss: 0.751916\n",
      "Train Epoch: 8 [56960/84843 (67%)]\tLoss: 0.432997\n",
      "Train Epoch: 8 [57600/84843 (68%)]\tLoss: 0.367181\n",
      "Train Epoch: 8 [58240/84843 (69%)]\tLoss: 0.549644\n",
      "Train Epoch: 8 [58880/84843 (69%)]\tLoss: 0.590890\n",
      "Train Epoch: 8 [59520/84843 (70%)]\tLoss: 0.616718\n",
      "Train Epoch: 8 [60160/84843 (71%)]\tLoss: 0.323110\n",
      "Train Epoch: 8 [60800/84843 (72%)]\tLoss: 0.393181\n",
      "Train Epoch: 8 [61440/84843 (72%)]\tLoss: 0.368119\n",
      "Train Epoch: 8 [62080/84843 (73%)]\tLoss: 0.603853\n",
      "Train Epoch: 8 [62720/84843 (74%)]\tLoss: 0.621453\n",
      "Train Epoch: 8 [63360/84843 (75%)]\tLoss: 0.950235\n",
      "Train Epoch: 8 [64000/84843 (75%)]\tLoss: 0.329544\n",
      "Train Epoch: 8 [64640/84843 (76%)]\tLoss: 0.477847\n",
      "Train Epoch: 8 [65280/84843 (77%)]\tLoss: 0.270456\n",
      "Train Epoch: 8 [65920/84843 (78%)]\tLoss: 0.580014\n",
      "Train Epoch: 8 [66560/84843 (78%)]\tLoss: 0.329630\n",
      "Train Epoch: 8 [67200/84843 (79%)]\tLoss: 0.426071\n",
      "Train Epoch: 8 [67840/84843 (80%)]\tLoss: 0.576110\n",
      "Train Epoch: 8 [68480/84843 (81%)]\tLoss: 0.655104\n",
      "Train Epoch: 8 [69120/84843 (81%)]\tLoss: 0.359003\n",
      "Train Epoch: 8 [69760/84843 (82%)]\tLoss: 0.880729\n",
      "Train Epoch: 8 [70400/84843 (83%)]\tLoss: 0.216320\n",
      "Train Epoch: 8 [71040/84843 (84%)]\tLoss: 0.595945\n",
      "Train Epoch: 8 [71680/84843 (84%)]\tLoss: 0.438986\n",
      "Train Epoch: 8 [72320/84843 (85%)]\tLoss: 0.601183\n",
      "Train Epoch: 8 [72960/84843 (86%)]\tLoss: 0.457226\n",
      "Train Epoch: 8 [73600/84843 (87%)]\tLoss: 0.465134\n",
      "Train Epoch: 8 [74240/84843 (87%)]\tLoss: 0.315120\n",
      "Train Epoch: 8 [74880/84843 (88%)]\tLoss: 0.946946\n",
      "Train Epoch: 8 [75520/84843 (89%)]\tLoss: 0.479909\n",
      "Train Epoch: 8 [76160/84843 (90%)]\tLoss: 0.544274\n",
      "Train Epoch: 8 [76800/84843 (90%)]\tLoss: 0.458241\n",
      "Train Epoch: 8 [77440/84843 (91%)]\tLoss: 0.386409\n",
      "Train Epoch: 8 [78080/84843 (92%)]\tLoss: 0.435238\n",
      "Train Epoch: 8 [78720/84843 (93%)]\tLoss: 0.280367\n",
      "Train Epoch: 8 [79360/84843 (94%)]\tLoss: 0.271519\n",
      "Train Epoch: 8 [80000/84843 (94%)]\tLoss: 0.652173\n",
      "Train Epoch: 8 [80640/84843 (95%)]\tLoss: 0.291575\n",
      "Train Epoch: 8 [81280/84843 (96%)]\tLoss: 0.371041\n",
      "Train Epoch: 8 [81920/84843 (97%)]\tLoss: 0.624827\n",
      "Train Epoch: 8 [82560/84843 (97%)]\tLoss: 0.360999\n",
      "Train Epoch: 8 [83200/84843 (98%)]\tLoss: 0.170690\n",
      "Train Epoch: 8 [83840/84843 (99%)]\tLoss: 0.663237\n",
      "Train Epoch: 8 [84480/84843 (100%)]\tLoss: 0.247093\n",
      "Accuracy: 9464/11005 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/84843 (0%)]\tLoss: 0.477873\n",
      "Train Epoch: 9 [640/84843 (1%)]\tLoss: 0.312407\n",
      "Train Epoch: 9 [1280/84843 (2%)]\tLoss: 0.456393\n",
      "Train Epoch: 9 [1920/84843 (2%)]\tLoss: 0.210888\n",
      "Train Epoch: 9 [2560/84843 (3%)]\tLoss: 0.124912\n",
      "Train Epoch: 9 [3200/84843 (4%)]\tLoss: 0.511872\n",
      "Train Epoch: 9 [3840/84843 (5%)]\tLoss: 0.081617\n",
      "Train Epoch: 9 [4480/84843 (5%)]\tLoss: 0.387464\n",
      "Train Epoch: 9 [5120/84843 (6%)]\tLoss: 0.339635\n",
      "Train Epoch: 9 [5760/84843 (7%)]\tLoss: 0.264846\n",
      "Train Epoch: 9 [6400/84843 (8%)]\tLoss: 0.193955\n",
      "Train Epoch: 9 [7040/84843 (8%)]\tLoss: 0.099437\n",
      "Train Epoch: 9 [7680/84843 (9%)]\tLoss: 0.161844\n",
      "Train Epoch: 9 [8320/84843 (10%)]\tLoss: 0.538739\n",
      "Train Epoch: 9 [8960/84843 (11%)]\tLoss: 0.180205\n",
      "Train Epoch: 9 [9600/84843 (11%)]\tLoss: 0.342388\n",
      "Train Epoch: 9 [10240/84843 (12%)]\tLoss: 0.608438\n",
      "Train Epoch: 9 [10880/84843 (13%)]\tLoss: 0.260745\n",
      "Train Epoch: 9 [11520/84843 (14%)]\tLoss: 0.273414\n",
      "Train Epoch: 9 [12160/84843 (14%)]\tLoss: 0.116282\n",
      "Train Epoch: 9 [12800/84843 (15%)]\tLoss: 0.443188\n",
      "Train Epoch: 9 [13440/84843 (16%)]\tLoss: 0.289269\n",
      "Train Epoch: 9 [14080/84843 (17%)]\tLoss: 0.508483\n",
      "Train Epoch: 9 [14720/84843 (17%)]\tLoss: 0.633280\n",
      "Train Epoch: 9 [15360/84843 (18%)]\tLoss: 0.389711\n",
      "Train Epoch: 9 [16000/84843 (19%)]\tLoss: 0.222130\n",
      "Train Epoch: 9 [16640/84843 (20%)]\tLoss: 0.439309\n",
      "Train Epoch: 9 [17280/84843 (20%)]\tLoss: 0.268854\n",
      "Train Epoch: 9 [17920/84843 (21%)]\tLoss: 0.428948\n",
      "Train Epoch: 9 [18560/84843 (22%)]\tLoss: 0.644436\n",
      "Train Epoch: 9 [19200/84843 (23%)]\tLoss: 0.368125\n",
      "Train Epoch: 9 [19840/84843 (23%)]\tLoss: 0.483639\n",
      "Train Epoch: 9 [20480/84843 (24%)]\tLoss: 0.350337\n",
      "Train Epoch: 9 [21120/84843 (25%)]\tLoss: 0.515166\n",
      "Train Epoch: 9 [21760/84843 (26%)]\tLoss: 0.233364\n",
      "Train Epoch: 9 [22400/84843 (26%)]\tLoss: 0.708710\n",
      "Train Epoch: 9 [23040/84843 (27%)]\tLoss: 0.188105\n",
      "Train Epoch: 9 [23680/84843 (28%)]\tLoss: 0.313870\n",
      "Train Epoch: 9 [24320/84843 (29%)]\tLoss: 0.247712\n",
      "Train Epoch: 9 [24960/84843 (29%)]\tLoss: 0.265308\n",
      "Train Epoch: 9 [25600/84843 (30%)]\tLoss: 0.134785\n",
      "Train Epoch: 9 [26240/84843 (31%)]\tLoss: 0.367088\n",
      "Train Epoch: 9 [26880/84843 (32%)]\tLoss: 0.267975\n",
      "Train Epoch: 9 [27520/84843 (32%)]\tLoss: 0.594501\n",
      "Train Epoch: 9 [28160/84843 (33%)]\tLoss: 0.079957\n",
      "Train Epoch: 9 [28800/84843 (34%)]\tLoss: 0.447863\n",
      "Train Epoch: 9 [29440/84843 (35%)]\tLoss: 0.146713\n",
      "Train Epoch: 9 [30080/84843 (35%)]\tLoss: 0.466535\n",
      "Train Epoch: 9 [30720/84843 (36%)]\tLoss: 0.538865\n",
      "Train Epoch: 9 [31360/84843 (37%)]\tLoss: 0.455380\n",
      "Train Epoch: 9 [32000/84843 (38%)]\tLoss: 0.573842\n",
      "Train Epoch: 9 [32640/84843 (38%)]\tLoss: 0.428354\n",
      "Train Epoch: 9 [33280/84843 (39%)]\tLoss: 0.307751\n",
      "Train Epoch: 9 [33920/84843 (40%)]\tLoss: 0.223078\n",
      "Train Epoch: 9 [34560/84843 (41%)]\tLoss: 0.327569\n",
      "Train Epoch: 9 [35200/84843 (41%)]\tLoss: 0.274895\n",
      "Train Epoch: 9 [35840/84843 (42%)]\tLoss: 0.370428\n",
      "Train Epoch: 9 [36480/84843 (43%)]\tLoss: 0.359432\n",
      "Train Epoch: 9 [37120/84843 (44%)]\tLoss: 0.400435\n",
      "Train Epoch: 9 [37760/84843 (44%)]\tLoss: 0.552071\n",
      "Train Epoch: 9 [38400/84843 (45%)]\tLoss: 0.265586\n",
      "Train Epoch: 9 [39040/84843 (46%)]\tLoss: 0.255871\n",
      "Train Epoch: 9 [39680/84843 (47%)]\tLoss: 0.316213\n",
      "Train Epoch: 9 [40320/84843 (48%)]\tLoss: 0.267797\n",
      "Train Epoch: 9 [40960/84843 (48%)]\tLoss: 0.630628\n",
      "Train Epoch: 9 [41600/84843 (49%)]\tLoss: 0.390380\n",
      "Train Epoch: 9 [42240/84843 (50%)]\tLoss: 0.461568\n",
      "Train Epoch: 9 [42880/84843 (51%)]\tLoss: 0.396433\n",
      "Train Epoch: 9 [43520/84843 (51%)]\tLoss: 0.439440\n",
      "Train Epoch: 9 [44160/84843 (52%)]\tLoss: 0.141431\n",
      "Train Epoch: 9 [44800/84843 (53%)]\tLoss: 0.114534\n",
      "Train Epoch: 9 [45440/84843 (54%)]\tLoss: 0.320494\n",
      "Train Epoch: 9 [46080/84843 (54%)]\tLoss: 0.434388\n",
      "Train Epoch: 9 [46720/84843 (55%)]\tLoss: 0.159100\n",
      "Train Epoch: 9 [47360/84843 (56%)]\tLoss: 0.351077\n",
      "Train Epoch: 9 [48000/84843 (57%)]\tLoss: 0.166247\n",
      "Train Epoch: 9 [48640/84843 (57%)]\tLoss: 0.479669\n",
      "Train Epoch: 9 [49280/84843 (58%)]\tLoss: 0.274117\n",
      "Train Epoch: 9 [49920/84843 (59%)]\tLoss: 0.467134\n",
      "Train Epoch: 9 [50560/84843 (60%)]\tLoss: 0.182494\n",
      "Train Epoch: 9 [51200/84843 (60%)]\tLoss: 0.216616\n",
      "Train Epoch: 9 [51840/84843 (61%)]\tLoss: 0.261023\n",
      "Train Epoch: 9 [52480/84843 (62%)]\tLoss: 0.288152\n",
      "Train Epoch: 9 [53120/84843 (63%)]\tLoss: 0.196855\n",
      "Train Epoch: 9 [53760/84843 (63%)]\tLoss: 0.238876\n",
      "Train Epoch: 9 [54400/84843 (64%)]\tLoss: 0.212643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [55040/84843 (65%)]\tLoss: 0.242288\n",
      "Train Epoch: 9 [55680/84843 (66%)]\tLoss: 0.440702\n",
      "Train Epoch: 9 [56320/84843 (66%)]\tLoss: 0.285697\n",
      "Train Epoch: 9 [56960/84843 (67%)]\tLoss: 0.172988\n",
      "Train Epoch: 9 [57600/84843 (68%)]\tLoss: 0.546296\n",
      "Train Epoch: 9 [58240/84843 (69%)]\tLoss: 0.758369\n",
      "Train Epoch: 9 [58880/84843 (69%)]\tLoss: 0.398695\n",
      "Train Epoch: 9 [59520/84843 (70%)]\tLoss: 0.265210\n",
      "Train Epoch: 9 [60160/84843 (71%)]\tLoss: 0.332438\n",
      "Train Epoch: 9 [60800/84843 (72%)]\tLoss: 0.698869\n",
      "Train Epoch: 9 [61440/84843 (72%)]\tLoss: 0.674271\n",
      "Train Epoch: 9 [62080/84843 (73%)]\tLoss: 0.565185\n",
      "Train Epoch: 9 [62720/84843 (74%)]\tLoss: 0.538131\n",
      "Train Epoch: 9 [63360/84843 (75%)]\tLoss: 0.369107\n",
      "Train Epoch: 9 [64000/84843 (75%)]\tLoss: 0.457373\n",
      "Train Epoch: 9 [64640/84843 (76%)]\tLoss: 0.159606\n",
      "Train Epoch: 9 [65280/84843 (77%)]\tLoss: 0.403646\n",
      "Train Epoch: 9 [65920/84843 (78%)]\tLoss: 0.496614\n",
      "Train Epoch: 9 [66560/84843 (78%)]\tLoss: 0.397038\n",
      "Train Epoch: 9 [67200/84843 (79%)]\tLoss: 0.228436\n",
      "Train Epoch: 9 [67840/84843 (80%)]\tLoss: 0.216016\n",
      "Train Epoch: 9 [68480/84843 (81%)]\tLoss: 0.536881\n",
      "Train Epoch: 9 [69120/84843 (81%)]\tLoss: 0.158386\n",
      "Train Epoch: 9 [69760/84843 (82%)]\tLoss: 0.298503\n",
      "Train Epoch: 9 [70400/84843 (83%)]\tLoss: 0.355082\n",
      "Train Epoch: 9 [71040/84843 (84%)]\tLoss: 0.314723\n",
      "Train Epoch: 9 [71680/84843 (84%)]\tLoss: 0.189048\n",
      "Train Epoch: 9 [72320/84843 (85%)]\tLoss: 0.385220\n",
      "Train Epoch: 9 [72960/84843 (86%)]\tLoss: 0.212621\n",
      "Train Epoch: 9 [73600/84843 (87%)]\tLoss: 0.148262\n",
      "Train Epoch: 9 [74240/84843 (87%)]\tLoss: 0.342178\n",
      "Train Epoch: 9 [74880/84843 (88%)]\tLoss: 0.482650\n",
      "Train Epoch: 9 [75520/84843 (89%)]\tLoss: 0.152685\n",
      "Train Epoch: 9 [76160/84843 (90%)]\tLoss: 0.162741\n",
      "Train Epoch: 9 [76800/84843 (90%)]\tLoss: 0.519264\n",
      "Train Epoch: 9 [77440/84843 (91%)]\tLoss: 0.426279\n",
      "Train Epoch: 9 [78080/84843 (92%)]\tLoss: 0.157734\n",
      "Train Epoch: 9 [78720/84843 (93%)]\tLoss: 0.325610\n",
      "Train Epoch: 9 [79360/84843 (94%)]\tLoss: 0.693218\n",
      "Train Epoch: 9 [80000/84843 (94%)]\tLoss: 0.771555\n",
      "Train Epoch: 9 [80640/84843 (95%)]\tLoss: 0.708445\n",
      "Train Epoch: 9 [81280/84843 (96%)]\tLoss: 0.392907\n",
      "Train Epoch: 9 [81920/84843 (97%)]\tLoss: 0.583166\n",
      "Train Epoch: 9 [82560/84843 (97%)]\tLoss: 0.381739\n",
      "Train Epoch: 9 [83200/84843 (98%)]\tLoss: 0.141871\n",
      "Train Epoch: 9 [83840/84843 (99%)]\tLoss: 0.170570\n",
      "Train Epoch: 9 [84480/84843 (100%)]\tLoss: 0.281928\n",
      "Accuracy: 9451/11005 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/84843 (0%)]\tLoss: 0.539510\n",
      "Train Epoch: 10 [640/84843 (1%)]\tLoss: 0.427053\n",
      "Train Epoch: 10 [1280/84843 (2%)]\tLoss: 0.446267\n",
      "Train Epoch: 10 [1920/84843 (2%)]\tLoss: 0.391586\n",
      "Train Epoch: 10 [2560/84843 (3%)]\tLoss: 0.341322\n",
      "Train Epoch: 10 [3200/84843 (4%)]\tLoss: 0.292578\n",
      "Train Epoch: 10 [3840/84843 (5%)]\tLoss: 0.181008\n",
      "Train Epoch: 10 [4480/84843 (5%)]\tLoss: 0.213500\n",
      "Train Epoch: 10 [5120/84843 (6%)]\tLoss: 0.333960\n",
      "Train Epoch: 10 [5760/84843 (7%)]\tLoss: 0.196203\n",
      "Train Epoch: 10 [6400/84843 (8%)]\tLoss: 0.067794\n",
      "Train Epoch: 10 [7040/84843 (8%)]\tLoss: 0.086191\n",
      "Train Epoch: 10 [7680/84843 (9%)]\tLoss: 0.337187\n",
      "Train Epoch: 10 [8320/84843 (10%)]\tLoss: 0.330753\n",
      "Train Epoch: 10 [8960/84843 (11%)]\tLoss: 0.435068\n",
      "Train Epoch: 10 [9600/84843 (11%)]\tLoss: 0.755964\n",
      "Train Epoch: 10 [10240/84843 (12%)]\tLoss: 0.247385\n",
      "Train Epoch: 10 [10880/84843 (13%)]\tLoss: 0.540857\n",
      "Train Epoch: 10 [11520/84843 (14%)]\tLoss: 0.216117\n",
      "Train Epoch: 10 [12160/84843 (14%)]\tLoss: 0.267910\n",
      "Train Epoch: 10 [12800/84843 (15%)]\tLoss: 0.597416\n",
      "Train Epoch: 10 [13440/84843 (16%)]\tLoss: 0.367839\n",
      "Train Epoch: 10 [14080/84843 (17%)]\tLoss: 0.334409\n",
      "Train Epoch: 10 [14720/84843 (17%)]\tLoss: 0.194982\n",
      "Train Epoch: 10 [15360/84843 (18%)]\tLoss: 0.455083\n",
      "Train Epoch: 10 [16000/84843 (19%)]\tLoss: 0.804871\n",
      "Train Epoch: 10 [16640/84843 (20%)]\tLoss: 0.274819\n",
      "Train Epoch: 10 [17280/84843 (20%)]\tLoss: 0.670299\n",
      "Train Epoch: 10 [17920/84843 (21%)]\tLoss: 0.120696\n",
      "Train Epoch: 10 [18560/84843 (22%)]\tLoss: 0.468050\n",
      "Train Epoch: 10 [19200/84843 (23%)]\tLoss: 0.552731\n",
      "Train Epoch: 10 [19840/84843 (23%)]\tLoss: 0.225423\n",
      "Train Epoch: 10 [20480/84843 (24%)]\tLoss: 0.278388\n",
      "Train Epoch: 10 [21120/84843 (25%)]\tLoss: 0.384184\n",
      "Train Epoch: 10 [21760/84843 (26%)]\tLoss: 0.533560\n",
      "Train Epoch: 10 [22400/84843 (26%)]\tLoss: 0.227699\n",
      "Train Epoch: 10 [23040/84843 (27%)]\tLoss: 0.291173\n",
      "Train Epoch: 10 [23680/84843 (28%)]\tLoss: 0.414953\n",
      "Train Epoch: 10 [24320/84843 (29%)]\tLoss: 0.295998\n",
      "Train Epoch: 10 [24960/84843 (29%)]\tLoss: 0.339927\n",
      "Train Epoch: 10 [25600/84843 (30%)]\tLoss: 0.229221\n",
      "Train Epoch: 10 [26240/84843 (31%)]\tLoss: 0.667924\n",
      "Train Epoch: 10 [26880/84843 (32%)]\tLoss: 0.235612\n",
      "Train Epoch: 10 [27520/84843 (32%)]\tLoss: 0.194704\n",
      "Train Epoch: 10 [28160/84843 (33%)]\tLoss: 0.431889\n",
      "Train Epoch: 10 [28800/84843 (34%)]\tLoss: 0.178117\n",
      "Train Epoch: 10 [29440/84843 (35%)]\tLoss: 0.455671\n",
      "Train Epoch: 10 [30080/84843 (35%)]\tLoss: 0.389900\n",
      "Train Epoch: 10 [30720/84843 (36%)]\tLoss: 0.212515\n",
      "Train Epoch: 10 [31360/84843 (37%)]\tLoss: 0.264069\n",
      "Train Epoch: 10 [32000/84843 (38%)]\tLoss: 0.277622\n",
      "Train Epoch: 10 [32640/84843 (38%)]\tLoss: 0.099145\n",
      "Train Epoch: 10 [33280/84843 (39%)]\tLoss: 0.592371\n",
      "Train Epoch: 10 [33920/84843 (40%)]\tLoss: 0.279023\n",
      "Train Epoch: 10 [34560/84843 (41%)]\tLoss: 0.285180\n",
      "Train Epoch: 10 [35200/84843 (41%)]\tLoss: 0.504940\n",
      "Train Epoch: 10 [35840/84843 (42%)]\tLoss: 0.544480\n",
      "Train Epoch: 10 [36480/84843 (43%)]\tLoss: 0.884518\n",
      "Train Epoch: 10 [37120/84843 (44%)]\tLoss: 0.337344\n",
      "Train Epoch: 10 [37760/84843 (44%)]\tLoss: 0.280051\n",
      "Train Epoch: 10 [38400/84843 (45%)]\tLoss: 0.206008\n",
      "Train Epoch: 10 [39040/84843 (46%)]\tLoss: 0.306936\n",
      "Train Epoch: 10 [39680/84843 (47%)]\tLoss: 0.496522\n",
      "Train Epoch: 10 [40320/84843 (48%)]\tLoss: 0.212986\n",
      "Train Epoch: 10 [40960/84843 (48%)]\tLoss: 0.282735\n",
      "Train Epoch: 10 [41600/84843 (49%)]\tLoss: 0.198039\n",
      "Train Epoch: 10 [42240/84843 (50%)]\tLoss: 0.399734\n",
      "Train Epoch: 10 [42880/84843 (51%)]\tLoss: 0.441020\n",
      "Train Epoch: 10 [43520/84843 (51%)]\tLoss: 0.548003\n",
      "Train Epoch: 10 [44160/84843 (52%)]\tLoss: 0.348940\n",
      "Train Epoch: 10 [44800/84843 (53%)]\tLoss: 0.580979\n",
      "Train Epoch: 10 [45440/84843 (54%)]\tLoss: 0.487197\n",
      "Train Epoch: 10 [46080/84843 (54%)]\tLoss: 0.346839\n",
      "Train Epoch: 10 [46720/84843 (55%)]\tLoss: 0.373433\n",
      "Train Epoch: 10 [47360/84843 (56%)]\tLoss: 0.317853\n",
      "Train Epoch: 10 [48000/84843 (57%)]\tLoss: 0.367336\n",
      "Train Epoch: 10 [48640/84843 (57%)]\tLoss: 0.284255\n",
      "Train Epoch: 10 [49280/84843 (58%)]\tLoss: 0.419242\n",
      "Train Epoch: 10 [49920/84843 (59%)]\tLoss: 0.415092\n",
      "Train Epoch: 10 [50560/84843 (60%)]\tLoss: 0.237866\n",
      "Train Epoch: 10 [51200/84843 (60%)]\tLoss: 0.110885\n",
      "Train Epoch: 10 [51840/84843 (61%)]\tLoss: 0.506937\n",
      "Train Epoch: 10 [52480/84843 (62%)]\tLoss: 0.321170\n",
      "Train Epoch: 10 [53120/84843 (63%)]\tLoss: 0.413049\n",
      "Train Epoch: 10 [53760/84843 (63%)]\tLoss: 0.298680\n",
      "Train Epoch: 10 [54400/84843 (64%)]\tLoss: 0.377370\n",
      "Train Epoch: 10 [55040/84843 (65%)]\tLoss: 0.417321\n",
      "Train Epoch: 10 [55680/84843 (66%)]\tLoss: 0.852900\n",
      "Train Epoch: 10 [56320/84843 (66%)]\tLoss: 0.484112\n",
      "Train Epoch: 10 [56960/84843 (67%)]\tLoss: 0.129450\n",
      "Train Epoch: 10 [57600/84843 (68%)]\tLoss: 0.508595\n",
      "Train Epoch: 10 [58240/84843 (69%)]\tLoss: 0.422268\n",
      "Train Epoch: 10 [58880/84843 (69%)]\tLoss: 0.611411\n",
      "Train Epoch: 10 [59520/84843 (70%)]\tLoss: 0.214961\n",
      "Train Epoch: 10 [60160/84843 (71%)]\tLoss: 0.504269\n",
      "Train Epoch: 10 [60800/84843 (72%)]\tLoss: 0.251914\n",
      "Train Epoch: 10 [61440/84843 (72%)]\tLoss: 0.354090\n",
      "Train Epoch: 10 [62080/84843 (73%)]\tLoss: 0.258133\n",
      "Train Epoch: 10 [62720/84843 (74%)]\tLoss: 0.459518\n",
      "Train Epoch: 10 [63360/84843 (75%)]\tLoss: 0.647430\n",
      "Train Epoch: 10 [64000/84843 (75%)]\tLoss: 0.470555\n",
      "Train Epoch: 10 [64640/84843 (76%)]\tLoss: 0.175850\n",
      "Train Epoch: 10 [65280/84843 (77%)]\tLoss: 0.286596\n",
      "Train Epoch: 10 [65920/84843 (78%)]\tLoss: 0.460761\n",
      "Train Epoch: 10 [66560/84843 (78%)]\tLoss: 0.249084\n",
      "Train Epoch: 10 [67200/84843 (79%)]\tLoss: 0.465222\n",
      "Train Epoch: 10 [67840/84843 (80%)]\tLoss: 0.364333\n",
      "Train Epoch: 10 [68480/84843 (81%)]\tLoss: 0.299178\n",
      "Train Epoch: 10 [69120/84843 (81%)]\tLoss: 0.475039\n",
      "Train Epoch: 10 [69760/84843 (82%)]\tLoss: 0.741503\n",
      "Train Epoch: 10 [70400/84843 (83%)]\tLoss: 0.188372\n",
      "Train Epoch: 10 [71040/84843 (84%)]\tLoss: 0.578988\n",
      "Train Epoch: 10 [71680/84843 (84%)]\tLoss: 0.404060\n",
      "Train Epoch: 10 [72320/84843 (85%)]\tLoss: 0.528071\n",
      "Train Epoch: 10 [72960/84843 (86%)]\tLoss: 0.431011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [73600/84843 (87%)]\tLoss: 0.362497\n",
      "Train Epoch: 10 [74240/84843 (87%)]\tLoss: 0.164907\n",
      "Train Epoch: 10 [74880/84843 (88%)]\tLoss: 0.509201\n",
      "Train Epoch: 10 [75520/84843 (89%)]\tLoss: 0.470932\n",
      "Train Epoch: 10 [76160/84843 (90%)]\tLoss: 0.629695\n",
      "Train Epoch: 10 [76800/84843 (90%)]\tLoss: 0.437848\n",
      "Train Epoch: 10 [77440/84843 (91%)]\tLoss: 0.202946\n",
      "Train Epoch: 10 [78080/84843 (92%)]\tLoss: 0.460057\n",
      "Train Epoch: 10 [78720/84843 (93%)]\tLoss: 0.525520\n",
      "Train Epoch: 10 [79360/84843 (94%)]\tLoss: 0.600434\n",
      "Train Epoch: 10 [80000/84843 (94%)]\tLoss: 0.279886\n",
      "Train Epoch: 10 [80640/84843 (95%)]\tLoss: 0.502171\n",
      "Train Epoch: 10 [81280/84843 (96%)]\tLoss: 0.158170\n",
      "Train Epoch: 10 [81920/84843 (97%)]\tLoss: 0.270922\n",
      "Train Epoch: 10 [82560/84843 (97%)]\tLoss: 0.354599\n",
      "Train Epoch: 10 [83200/84843 (98%)]\tLoss: 0.406948\n",
      "Train Epoch: 10 [83840/84843 (99%)]\tLoss: 0.579260\n",
      "Train Epoch: 10 [84480/84843 (100%)]\tLoss: 0.169264\n",
      "Accuracy: 9496/11005 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/84843 (0%)]\tLoss: 0.304456\n",
      "Train Epoch: 11 [640/84843 (1%)]\tLoss: 0.201885\n",
      "Train Epoch: 11 [1280/84843 (2%)]\tLoss: 0.393234\n",
      "Train Epoch: 11 [1920/84843 (2%)]\tLoss: 0.367226\n",
      "Train Epoch: 11 [2560/84843 (3%)]\tLoss: 0.335376\n",
      "Train Epoch: 11 [3200/84843 (4%)]\tLoss: 0.452621\n",
      "Train Epoch: 11 [3840/84843 (5%)]\tLoss: 0.076810\n",
      "Train Epoch: 11 [4480/84843 (5%)]\tLoss: 0.189936\n",
      "Train Epoch: 11 [5120/84843 (6%)]\tLoss: 0.450164\n",
      "Train Epoch: 11 [5760/84843 (7%)]\tLoss: 0.662068\n",
      "Train Epoch: 11 [6400/84843 (8%)]\tLoss: 0.256302\n",
      "Train Epoch: 11 [7040/84843 (8%)]\tLoss: 0.301334\n",
      "Train Epoch: 11 [7680/84843 (9%)]\tLoss: 0.371625\n",
      "Train Epoch: 11 [8320/84843 (10%)]\tLoss: 0.530386\n",
      "Train Epoch: 11 [8960/84843 (11%)]\tLoss: 0.318239\n",
      "Train Epoch: 11 [9600/84843 (11%)]\tLoss: 0.595857\n",
      "Train Epoch: 11 [10240/84843 (12%)]\tLoss: 0.152973\n",
      "Train Epoch: 11 [10880/84843 (13%)]\tLoss: 0.207343\n",
      "Train Epoch: 11 [11520/84843 (14%)]\tLoss: 0.673999\n",
      "Train Epoch: 11 [12160/84843 (14%)]\tLoss: 0.183914\n",
      "Train Epoch: 11 [12800/84843 (15%)]\tLoss: 0.136992\n",
      "Train Epoch: 11 [13440/84843 (16%)]\tLoss: 0.493072\n",
      "Train Epoch: 11 [14080/84843 (17%)]\tLoss: 0.307861\n",
      "Train Epoch: 11 [14720/84843 (17%)]\tLoss: 0.470228\n",
      "Train Epoch: 11 [15360/84843 (18%)]\tLoss: 0.289731\n",
      "Train Epoch: 11 [16000/84843 (19%)]\tLoss: 0.262336\n",
      "Train Epoch: 11 [16640/84843 (20%)]\tLoss: 0.419672\n",
      "Train Epoch: 11 [17280/84843 (20%)]\tLoss: 0.469257\n",
      "Train Epoch: 11 [17920/84843 (21%)]\tLoss: 0.611400\n",
      "Train Epoch: 11 [18560/84843 (22%)]\tLoss: 0.332451\n",
      "Train Epoch: 11 [19200/84843 (23%)]\tLoss: 0.268881\n",
      "Train Epoch: 11 [19840/84843 (23%)]\tLoss: 0.112785\n",
      "Train Epoch: 11 [20480/84843 (24%)]\tLoss: 0.527297\n",
      "Train Epoch: 11 [21120/84843 (25%)]\tLoss: 0.475814\n",
      "Train Epoch: 11 [21760/84843 (26%)]\tLoss: 0.193584\n",
      "Train Epoch: 11 [22400/84843 (26%)]\tLoss: 0.248505\n",
      "Train Epoch: 11 [23040/84843 (27%)]\tLoss: 0.342269\n",
      "Train Epoch: 11 [23680/84843 (28%)]\tLoss: 0.770923\n",
      "Train Epoch: 11 [24320/84843 (29%)]\tLoss: 0.297708\n",
      "Train Epoch: 11 [24960/84843 (29%)]\tLoss: 0.185541\n",
      "Train Epoch: 11 [25600/84843 (30%)]\tLoss: 0.515909\n",
      "Train Epoch: 11 [26240/84843 (31%)]\tLoss: 0.439825\n",
      "Train Epoch: 11 [26880/84843 (32%)]\tLoss: 0.523134\n",
      "Train Epoch: 11 [27520/84843 (32%)]\tLoss: 0.213117\n",
      "Train Epoch: 11 [28160/84843 (33%)]\tLoss: 0.269871\n",
      "Train Epoch: 11 [28800/84843 (34%)]\tLoss: 0.329428\n",
      "Train Epoch: 11 [29440/84843 (35%)]\tLoss: 0.352318\n",
      "Train Epoch: 11 [30080/84843 (35%)]\tLoss: 0.457922\n",
      "Train Epoch: 11 [30720/84843 (36%)]\tLoss: 0.344749\n",
      "Train Epoch: 11 [31360/84843 (37%)]\tLoss: 0.272100\n",
      "Train Epoch: 11 [32000/84843 (38%)]\tLoss: 0.192292\n",
      "Train Epoch: 11 [32640/84843 (38%)]\tLoss: 0.389852\n",
      "Train Epoch: 11 [33280/84843 (39%)]\tLoss: 0.428760\n",
      "Train Epoch: 11 [33920/84843 (40%)]\tLoss: 0.233996\n",
      "Train Epoch: 11 [34560/84843 (41%)]\tLoss: 0.309167\n",
      "Train Epoch: 11 [35200/84843 (41%)]\tLoss: 0.628422\n",
      "Train Epoch: 11 [35840/84843 (42%)]\tLoss: 0.320205\n",
      "Train Epoch: 11 [36480/84843 (43%)]\tLoss: 0.241817\n",
      "Train Epoch: 11 [37120/84843 (44%)]\tLoss: 0.166723\n",
      "Train Epoch: 11 [37760/84843 (44%)]\tLoss: 0.264515\n",
      "Train Epoch: 11 [38400/84843 (45%)]\tLoss: 0.079774\n",
      "Train Epoch: 11 [39040/84843 (46%)]\tLoss: 0.413029\n",
      "Train Epoch: 11 [39680/84843 (47%)]\tLoss: 0.368034\n",
      "Train Epoch: 11 [40320/84843 (48%)]\tLoss: 0.112759\n",
      "Train Epoch: 11 [40960/84843 (48%)]\tLoss: 0.376725\n",
      "Train Epoch: 11 [41600/84843 (49%)]\tLoss: 0.465558\n",
      "Train Epoch: 11 [42240/84843 (50%)]\tLoss: 0.077088\n",
      "Train Epoch: 11 [42880/84843 (51%)]\tLoss: 0.571793\n",
      "Train Epoch: 11 [43520/84843 (51%)]\tLoss: 0.287377\n",
      "Train Epoch: 11 [44160/84843 (52%)]\tLoss: 0.349090\n",
      "Train Epoch: 11 [44800/84843 (53%)]\tLoss: 0.437419\n",
      "Train Epoch: 11 [45440/84843 (54%)]\tLoss: 0.584301\n",
      "Train Epoch: 11 [46080/84843 (54%)]\tLoss: 0.262688\n",
      "Train Epoch: 11 [46720/84843 (55%)]\tLoss: 0.389195\n",
      "Train Epoch: 11 [47360/84843 (56%)]\tLoss: 0.428794\n",
      "Train Epoch: 11 [48000/84843 (57%)]\tLoss: 0.284321\n",
      "Train Epoch: 11 [48640/84843 (57%)]\tLoss: 0.347226\n",
      "Train Epoch: 11 [49280/84843 (58%)]\tLoss: 0.282121\n",
      "Train Epoch: 11 [49920/84843 (59%)]\tLoss: 0.425263\n",
      "Train Epoch: 11 [50560/84843 (60%)]\tLoss: 0.650522\n",
      "Train Epoch: 11 [51200/84843 (60%)]\tLoss: 0.373832\n",
      "Train Epoch: 11 [51840/84843 (61%)]\tLoss: 0.466267\n",
      "Train Epoch: 11 [52480/84843 (62%)]\tLoss: 0.840556\n",
      "Train Epoch: 11 [53120/84843 (63%)]\tLoss: 0.119315\n",
      "Train Epoch: 11 [53760/84843 (63%)]\tLoss: 0.171234\n",
      "Train Epoch: 11 [54400/84843 (64%)]\tLoss: 0.256784\n",
      "Train Epoch: 11 [55040/84843 (65%)]\tLoss: 0.081903\n",
      "Train Epoch: 11 [55680/84843 (66%)]\tLoss: 0.616494\n",
      "Train Epoch: 11 [56320/84843 (66%)]\tLoss: 0.380164\n",
      "Train Epoch: 11 [56960/84843 (67%)]\tLoss: 0.115160\n",
      "Train Epoch: 11 [57600/84843 (68%)]\tLoss: 0.169001\n",
      "Train Epoch: 11 [58240/84843 (69%)]\tLoss: 0.134660\n",
      "Train Epoch: 11 [58880/84843 (69%)]\tLoss: 0.503129\n",
      "Train Epoch: 11 [59520/84843 (70%)]\tLoss: 0.426969\n",
      "Train Epoch: 11 [60160/84843 (71%)]\tLoss: 0.331028\n",
      "Train Epoch: 11 [60800/84843 (72%)]\tLoss: 0.508592\n",
      "Train Epoch: 11 [61440/84843 (72%)]\tLoss: 0.301167\n",
      "Train Epoch: 11 [62080/84843 (73%)]\tLoss: 0.358505\n",
      "Train Epoch: 11 [62720/84843 (74%)]\tLoss: 0.500727\n",
      "Train Epoch: 11 [63360/84843 (75%)]\tLoss: 0.378498\n",
      "Train Epoch: 11 [64000/84843 (75%)]\tLoss: 0.269296\n",
      "Train Epoch: 11 [64640/84843 (76%)]\tLoss: 0.219646\n",
      "Train Epoch: 11 [65280/84843 (77%)]\tLoss: 0.435328\n",
      "Train Epoch: 11 [65920/84843 (78%)]\tLoss: 0.274319\n",
      "Train Epoch: 11 [66560/84843 (78%)]\tLoss: 0.283878\n",
      "Train Epoch: 11 [67200/84843 (79%)]\tLoss: 0.891668\n",
      "Train Epoch: 11 [67840/84843 (80%)]\tLoss: 0.373281\n",
      "Train Epoch: 11 [68480/84843 (81%)]\tLoss: 0.456733\n",
      "Train Epoch: 11 [69120/84843 (81%)]\tLoss: 0.598679\n",
      "Train Epoch: 11 [69760/84843 (82%)]\tLoss: 0.302678\n",
      "Train Epoch: 11 [70400/84843 (83%)]\tLoss: 0.472564\n",
      "Train Epoch: 11 [71040/84843 (84%)]\tLoss: 0.247749\n",
      "Train Epoch: 11 [71680/84843 (84%)]\tLoss: 0.630767\n",
      "Train Epoch: 11 [72320/84843 (85%)]\tLoss: 0.514615\n",
      "Train Epoch: 11 [72960/84843 (86%)]\tLoss: 0.546204\n",
      "Train Epoch: 11 [73600/84843 (87%)]\tLoss: 0.613450\n",
      "Train Epoch: 11 [74240/84843 (87%)]\tLoss: 0.383769\n",
      "Train Epoch: 11 [74880/84843 (88%)]\tLoss: 0.348860\n",
      "Train Epoch: 11 [75520/84843 (89%)]\tLoss: 0.289058\n",
      "Train Epoch: 11 [76160/84843 (90%)]\tLoss: 0.215526\n",
      "Train Epoch: 11 [76800/84843 (90%)]\tLoss: 0.664332\n",
      "Train Epoch: 11 [77440/84843 (91%)]\tLoss: 0.125376\n",
      "Train Epoch: 11 [78080/84843 (92%)]\tLoss: 0.229665\n",
      "Train Epoch: 11 [78720/84843 (93%)]\tLoss: 0.580317\n",
      "Train Epoch: 11 [79360/84843 (94%)]\tLoss: 0.194194\n",
      "Train Epoch: 11 [80000/84843 (94%)]\tLoss: 0.235853\n",
      "Train Epoch: 11 [80640/84843 (95%)]\tLoss: 0.641030\n",
      "Train Epoch: 11 [81280/84843 (96%)]\tLoss: 0.579444\n",
      "Train Epoch: 11 [81920/84843 (97%)]\tLoss: 0.563258\n",
      "Train Epoch: 11 [82560/84843 (97%)]\tLoss: 0.220593\n",
      "Train Epoch: 11 [83200/84843 (98%)]\tLoss: 0.259014\n",
      "Train Epoch: 11 [83840/84843 (99%)]\tLoss: 0.224832\n",
      "Train Epoch: 11 [84480/84843 (100%)]\tLoss: 0.304599\n",
      "Accuracy: 9441/11005 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/84843 (0%)]\tLoss: 0.577917\n",
      "Train Epoch: 12 [640/84843 (1%)]\tLoss: 0.407952\n",
      "Train Epoch: 12 [1280/84843 (2%)]\tLoss: 0.314090\n",
      "Train Epoch: 12 [1920/84843 (2%)]\tLoss: 0.391992\n",
      "Train Epoch: 12 [2560/84843 (3%)]\tLoss: 0.284943\n",
      "Train Epoch: 12 [3200/84843 (4%)]\tLoss: 0.656236\n",
      "Train Epoch: 12 [3840/84843 (5%)]\tLoss: 0.147683\n",
      "Train Epoch: 12 [4480/84843 (5%)]\tLoss: 0.332443\n",
      "Train Epoch: 12 [5120/84843 (6%)]\tLoss: 0.581647\n",
      "Train Epoch: 12 [5760/84843 (7%)]\tLoss: 0.349936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [6400/84843 (8%)]\tLoss: 0.575788\n",
      "Train Epoch: 12 [7040/84843 (8%)]\tLoss: 0.602112\n",
      "Train Epoch: 12 [7680/84843 (9%)]\tLoss: 0.137065\n",
      "Train Epoch: 12 [8320/84843 (10%)]\tLoss: 0.522616\n",
      "Train Epoch: 12 [8960/84843 (11%)]\tLoss: 0.428679\n",
      "Train Epoch: 12 [9600/84843 (11%)]\tLoss: 0.729344\n",
      "Train Epoch: 12 [10240/84843 (12%)]\tLoss: 0.303184\n",
      "Train Epoch: 12 [10880/84843 (13%)]\tLoss: 0.368265\n",
      "Train Epoch: 12 [11520/84843 (14%)]\tLoss: 0.501159\n",
      "Train Epoch: 12 [12160/84843 (14%)]\tLoss: 0.467048\n",
      "Train Epoch: 12 [12800/84843 (15%)]\tLoss: 0.381508\n",
      "Train Epoch: 12 [13440/84843 (16%)]\tLoss: 0.260035\n",
      "Train Epoch: 12 [14080/84843 (17%)]\tLoss: 0.320210\n",
      "Train Epoch: 12 [14720/84843 (17%)]\tLoss: 0.290833\n",
      "Train Epoch: 12 [15360/84843 (18%)]\tLoss: 0.206606\n",
      "Train Epoch: 12 [16000/84843 (19%)]\tLoss: 0.424451\n",
      "Train Epoch: 12 [16640/84843 (20%)]\tLoss: 0.407812\n",
      "Train Epoch: 12 [17280/84843 (20%)]\tLoss: 0.166232\n",
      "Train Epoch: 12 [17920/84843 (21%)]\tLoss: 0.271568\n",
      "Train Epoch: 12 [18560/84843 (22%)]\tLoss: 0.219888\n",
      "Train Epoch: 12 [19200/84843 (23%)]\tLoss: 0.344021\n",
      "Train Epoch: 12 [19840/84843 (23%)]\tLoss: 0.412539\n",
      "Train Epoch: 12 [20480/84843 (24%)]\tLoss: 0.177515\n",
      "Train Epoch: 12 [21120/84843 (25%)]\tLoss: 0.217747\n",
      "Train Epoch: 12 [21760/84843 (26%)]\tLoss: 0.320200\n",
      "Train Epoch: 12 [22400/84843 (26%)]\tLoss: 0.253303\n",
      "Train Epoch: 12 [23040/84843 (27%)]\tLoss: 0.264852\n",
      "Train Epoch: 12 [23680/84843 (28%)]\tLoss: 0.194248\n",
      "Train Epoch: 12 [24320/84843 (29%)]\tLoss: 0.204411\n",
      "Train Epoch: 12 [24960/84843 (29%)]\tLoss: 0.422235\n",
      "Train Epoch: 12 [25600/84843 (30%)]\tLoss: 0.092129\n",
      "Train Epoch: 12 [26240/84843 (31%)]\tLoss: 0.466000\n",
      "Train Epoch: 12 [26880/84843 (32%)]\tLoss: 0.122461\n",
      "Train Epoch: 12 [27520/84843 (32%)]\tLoss: 0.342118\n",
      "Train Epoch: 12 [28160/84843 (33%)]\tLoss: 0.394085\n",
      "Train Epoch: 12 [28800/84843 (34%)]\tLoss: 0.398292\n",
      "Train Epoch: 12 [29440/84843 (35%)]\tLoss: 0.163760\n",
      "Train Epoch: 12 [30080/84843 (35%)]\tLoss: 0.570158\n",
      "Train Epoch: 12 [30720/84843 (36%)]\tLoss: 0.452954\n",
      "Train Epoch: 12 [31360/84843 (37%)]\tLoss: 0.176623\n",
      "Train Epoch: 12 [32000/84843 (38%)]\tLoss: 0.437482\n",
      "Train Epoch: 12 [32640/84843 (38%)]\tLoss: 0.394650\n",
      "Train Epoch: 12 [33280/84843 (39%)]\tLoss: 0.258721\n",
      "Train Epoch: 12 [33920/84843 (40%)]\tLoss: 0.523290\n",
      "Train Epoch: 12 [34560/84843 (41%)]\tLoss: 0.207936\n",
      "Train Epoch: 12 [35200/84843 (41%)]\tLoss: 0.131074\n",
      "Train Epoch: 12 [35840/84843 (42%)]\tLoss: 0.663314\n",
      "Train Epoch: 12 [36480/84843 (43%)]\tLoss: 0.514858\n",
      "Train Epoch: 12 [37120/84843 (44%)]\tLoss: 0.504683\n",
      "Train Epoch: 12 [37760/84843 (44%)]\tLoss: 0.418228\n",
      "Train Epoch: 12 [38400/84843 (45%)]\tLoss: 0.391457\n",
      "Train Epoch: 12 [39040/84843 (46%)]\tLoss: 0.802552\n",
      "Train Epoch: 12 [39680/84843 (47%)]\tLoss: 0.416494\n",
      "Train Epoch: 12 [40320/84843 (48%)]\tLoss: 0.465278\n",
      "Train Epoch: 12 [40960/84843 (48%)]\tLoss: 0.094495\n",
      "Train Epoch: 12 [41600/84843 (49%)]\tLoss: 0.259541\n",
      "Train Epoch: 12 [42240/84843 (50%)]\tLoss: 0.255936\n",
      "Train Epoch: 12 [42880/84843 (51%)]\tLoss: 0.160171\n",
      "Train Epoch: 12 [43520/84843 (51%)]\tLoss: 0.280011\n",
      "Train Epoch: 12 [44160/84843 (52%)]\tLoss: 0.413579\n",
      "Train Epoch: 12 [44800/84843 (53%)]\tLoss: 0.485299\n",
      "Train Epoch: 12 [45440/84843 (54%)]\tLoss: 0.329299\n",
      "Train Epoch: 12 [46080/84843 (54%)]\tLoss: 0.325191\n",
      "Train Epoch: 12 [46720/84843 (55%)]\tLoss: 0.439777\n",
      "Train Epoch: 12 [47360/84843 (56%)]\tLoss: 0.200027\n",
      "Train Epoch: 12 [48000/84843 (57%)]\tLoss: 0.228566\n",
      "Train Epoch: 12 [48640/84843 (57%)]\tLoss: 0.425753\n",
      "Train Epoch: 12 [49280/84843 (58%)]\tLoss: 0.531875\n",
      "Train Epoch: 12 [49920/84843 (59%)]\tLoss: 0.390619\n",
      "Train Epoch: 12 [50560/84843 (60%)]\tLoss: 0.616583\n",
      "Train Epoch: 12 [51200/84843 (60%)]\tLoss: 0.496987\n",
      "Train Epoch: 12 [51840/84843 (61%)]\tLoss: 0.287975\n",
      "Train Epoch: 12 [52480/84843 (62%)]\tLoss: 0.325182\n",
      "Train Epoch: 12 [53120/84843 (63%)]\tLoss: 0.435737\n",
      "Train Epoch: 12 [53760/84843 (63%)]\tLoss: 0.198731\n",
      "Train Epoch: 12 [54400/84843 (64%)]\tLoss: 0.230960\n",
      "Train Epoch: 12 [55040/84843 (65%)]\tLoss: 0.308343\n",
      "Train Epoch: 12 [55680/84843 (66%)]\tLoss: 0.117926\n",
      "Train Epoch: 12 [56320/84843 (66%)]\tLoss: 0.401928\n",
      "Train Epoch: 12 [56960/84843 (67%)]\tLoss: 0.708869\n",
      "Train Epoch: 12 [57600/84843 (68%)]\tLoss: 0.388831\n",
      "Train Epoch: 12 [58240/84843 (69%)]\tLoss: 0.222287\n",
      "Train Epoch: 12 [58880/84843 (69%)]\tLoss: 0.623605\n",
      "Train Epoch: 12 [59520/84843 (70%)]\tLoss: 0.534690\n",
      "Train Epoch: 12 [60160/84843 (71%)]\tLoss: 0.315940\n",
      "Train Epoch: 12 [60800/84843 (72%)]\tLoss: 0.269241\n",
      "Train Epoch: 12 [61440/84843 (72%)]\tLoss: 0.345037\n",
      "Train Epoch: 12 [62080/84843 (73%)]\tLoss: 0.229449\n",
      "Train Epoch: 12 [62720/84843 (74%)]\tLoss: 0.479015\n",
      "Train Epoch: 12 [63360/84843 (75%)]\tLoss: 0.539325\n",
      "Train Epoch: 12 [64000/84843 (75%)]\tLoss: 0.544036\n",
      "Train Epoch: 12 [64640/84843 (76%)]\tLoss: 0.413203\n",
      "Train Epoch: 12 [65280/84843 (77%)]\tLoss: 0.267641\n",
      "Train Epoch: 12 [65920/84843 (78%)]\tLoss: 0.524384\n",
      "Train Epoch: 12 [66560/84843 (78%)]\tLoss: 0.532295\n",
      "Train Epoch: 12 [67200/84843 (79%)]\tLoss: 0.394032\n",
      "Train Epoch: 12 [67840/84843 (80%)]\tLoss: 0.813051\n",
      "Train Epoch: 12 [68480/84843 (81%)]\tLoss: 0.410864\n",
      "Train Epoch: 12 [69120/84843 (81%)]\tLoss: 0.226948\n",
      "Train Epoch: 12 [69760/84843 (82%)]\tLoss: 0.493018\n",
      "Train Epoch: 12 [70400/84843 (83%)]\tLoss: 0.543217\n",
      "Train Epoch: 12 [71040/84843 (84%)]\tLoss: 0.248766\n",
      "Train Epoch: 12 [71680/84843 (84%)]\tLoss: 0.533413\n",
      "Train Epoch: 12 [72320/84843 (85%)]\tLoss: 0.327087\n",
      "Train Epoch: 12 [72960/84843 (86%)]\tLoss: 0.373059\n",
      "Train Epoch: 12 [73600/84843 (87%)]\tLoss: 0.419479\n",
      "Train Epoch: 12 [74240/84843 (87%)]\tLoss: 0.387052\n",
      "Train Epoch: 12 [74880/84843 (88%)]\tLoss: 0.245369\n",
      "Train Epoch: 12 [75520/84843 (89%)]\tLoss: 0.479107\n",
      "Train Epoch: 12 [76160/84843 (90%)]\tLoss: 0.561765\n",
      "Train Epoch: 12 [76800/84843 (90%)]\tLoss: 0.118633\n",
      "Train Epoch: 12 [77440/84843 (91%)]\tLoss: 0.556769\n",
      "Train Epoch: 12 [78080/84843 (92%)]\tLoss: 0.214182\n",
      "Train Epoch: 12 [78720/84843 (93%)]\tLoss: 0.392832\n",
      "Train Epoch: 12 [79360/84843 (94%)]\tLoss: 0.307135\n",
      "Train Epoch: 12 [80000/84843 (94%)]\tLoss: 0.276364\n",
      "Train Epoch: 12 [80640/84843 (95%)]\tLoss: 0.361179\n",
      "Train Epoch: 12 [81280/84843 (96%)]\tLoss: 0.354869\n",
      "Train Epoch: 12 [81920/84843 (97%)]\tLoss: 0.365057\n",
      "Train Epoch: 12 [82560/84843 (97%)]\tLoss: 0.537527\n",
      "Train Epoch: 12 [83200/84843 (98%)]\tLoss: 0.398893\n",
      "Train Epoch: 12 [83840/84843 (99%)]\tLoss: 0.347423\n",
      "Train Epoch: 12 [84480/84843 (100%)]\tLoss: 0.421797\n",
      "Accuracy: 9411/11005 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/84843 (0%)]\tLoss: 0.226603\n",
      "Train Epoch: 13 [640/84843 (1%)]\tLoss: 0.235182\n",
      "Train Epoch: 13 [1280/84843 (2%)]\tLoss: 0.709347\n",
      "Train Epoch: 13 [1920/84843 (2%)]\tLoss: 0.579515\n",
      "Train Epoch: 13 [2560/84843 (3%)]\tLoss: 0.189640\n",
      "Train Epoch: 13 [3200/84843 (4%)]\tLoss: 0.547792\n",
      "Train Epoch: 13 [3840/84843 (5%)]\tLoss: 0.174225\n",
      "Train Epoch: 13 [4480/84843 (5%)]\tLoss: 0.489779\n",
      "Train Epoch: 13 [5120/84843 (6%)]\tLoss: 0.171381\n",
      "Train Epoch: 13 [5760/84843 (7%)]\tLoss: 0.400374\n",
      "Train Epoch: 13 [6400/84843 (8%)]\tLoss: 0.531157\n",
      "Train Epoch: 13 [7040/84843 (8%)]\tLoss: 0.236590\n",
      "Train Epoch: 13 [7680/84843 (9%)]\tLoss: 0.297363\n",
      "Train Epoch: 13 [8320/84843 (10%)]\tLoss: 0.422169\n",
      "Train Epoch: 13 [8960/84843 (11%)]\tLoss: 0.617754\n",
      "Train Epoch: 13 [9600/84843 (11%)]\tLoss: 0.408866\n",
      "Train Epoch: 13 [10240/84843 (12%)]\tLoss: 0.167591\n",
      "Train Epoch: 13 [10880/84843 (13%)]\tLoss: 0.230281\n",
      "Train Epoch: 13 [11520/84843 (14%)]\tLoss: 0.785893\n",
      "Train Epoch: 13 [12160/84843 (14%)]\tLoss: 0.444270\n",
      "Train Epoch: 13 [12800/84843 (15%)]\tLoss: 0.610771\n",
      "Train Epoch: 13 [13440/84843 (16%)]\tLoss: 0.509716\n",
      "Train Epoch: 13 [14080/84843 (17%)]\tLoss: 0.501716\n",
      "Train Epoch: 13 [14720/84843 (17%)]\tLoss: 0.288222\n",
      "Train Epoch: 13 [15360/84843 (18%)]\tLoss: 0.304733\n",
      "Train Epoch: 13 [16000/84843 (19%)]\tLoss: 0.320846\n",
      "Train Epoch: 13 [16640/84843 (20%)]\tLoss: 0.419046\n",
      "Train Epoch: 13 [17280/84843 (20%)]\tLoss: 0.216501\n",
      "Train Epoch: 13 [17920/84843 (21%)]\tLoss: 0.398937\n",
      "Train Epoch: 13 [18560/84843 (22%)]\tLoss: 0.378281\n",
      "Train Epoch: 13 [19200/84843 (23%)]\tLoss: 0.239920\n",
      "Train Epoch: 13 [19840/84843 (23%)]\tLoss: 0.532581\n",
      "Train Epoch: 13 [20480/84843 (24%)]\tLoss: 0.537237\n",
      "Train Epoch: 13 [21120/84843 (25%)]\tLoss: 0.217333\n",
      "Train Epoch: 13 [21760/84843 (26%)]\tLoss: 0.452841\n",
      "Train Epoch: 13 [22400/84843 (26%)]\tLoss: 0.299963\n",
      "Train Epoch: 13 [23040/84843 (27%)]\tLoss: 0.558302\n",
      "Train Epoch: 13 [23680/84843 (28%)]\tLoss: 0.513862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [24320/84843 (29%)]\tLoss: 0.213322\n",
      "Train Epoch: 13 [24960/84843 (29%)]\tLoss: 0.538286\n",
      "Train Epoch: 13 [25600/84843 (30%)]\tLoss: 0.415493\n",
      "Train Epoch: 13 [26240/84843 (31%)]\tLoss: 0.281698\n",
      "Train Epoch: 13 [26880/84843 (32%)]\tLoss: 0.175762\n",
      "Train Epoch: 13 [27520/84843 (32%)]\tLoss: 0.565035\n",
      "Train Epoch: 13 [28160/84843 (33%)]\tLoss: 0.618106\n",
      "Train Epoch: 13 [28800/84843 (34%)]\tLoss: 0.226029\n",
      "Train Epoch: 13 [29440/84843 (35%)]\tLoss: 0.691418\n",
      "Train Epoch: 13 [30080/84843 (35%)]\tLoss: 0.304988\n",
      "Train Epoch: 13 [30720/84843 (36%)]\tLoss: 0.617974\n",
      "Train Epoch: 13 [31360/84843 (37%)]\tLoss: 0.288944\n",
      "Train Epoch: 13 [32000/84843 (38%)]\tLoss: 0.118362\n",
      "Train Epoch: 13 [32640/84843 (38%)]\tLoss: 0.807717\n",
      "Train Epoch: 13 [33280/84843 (39%)]\tLoss: 0.125388\n",
      "Train Epoch: 13 [33920/84843 (40%)]\tLoss: 0.410060\n",
      "Train Epoch: 13 [34560/84843 (41%)]\tLoss: 0.224936\n",
      "Train Epoch: 13 [35200/84843 (41%)]\tLoss: 0.510470\n",
      "Train Epoch: 13 [35840/84843 (42%)]\tLoss: 0.475118\n",
      "Train Epoch: 13 [36480/84843 (43%)]\tLoss: 0.376875\n",
      "Train Epoch: 13 [37120/84843 (44%)]\tLoss: 0.218655\n",
      "Train Epoch: 13 [37760/84843 (44%)]\tLoss: 0.276343\n",
      "Train Epoch: 13 [38400/84843 (45%)]\tLoss: 0.459994\n",
      "Train Epoch: 13 [39040/84843 (46%)]\tLoss: 0.467979\n",
      "Train Epoch: 13 [39680/84843 (47%)]\tLoss: 0.503237\n",
      "Train Epoch: 13 [40320/84843 (48%)]\tLoss: 0.538652\n",
      "Train Epoch: 13 [40960/84843 (48%)]\tLoss: 0.033080\n",
      "Train Epoch: 13 [41600/84843 (49%)]\tLoss: 0.316771\n",
      "Train Epoch: 13 [42240/84843 (50%)]\tLoss: 0.404352\n",
      "Train Epoch: 13 [42880/84843 (51%)]\tLoss: 0.193054\n",
      "Train Epoch: 13 [43520/84843 (51%)]\tLoss: 0.418499\n",
      "Train Epoch: 13 [44160/84843 (52%)]\tLoss: 0.223091\n",
      "Train Epoch: 13 [44800/84843 (53%)]\tLoss: 0.184368\n",
      "Train Epoch: 13 [45440/84843 (54%)]\tLoss: 0.393843\n",
      "Train Epoch: 13 [46080/84843 (54%)]\tLoss: 0.339552\n",
      "Train Epoch: 13 [46720/84843 (55%)]\tLoss: 0.174821\n",
      "Train Epoch: 13 [47360/84843 (56%)]\tLoss: 0.322382\n",
      "Train Epoch: 13 [48000/84843 (57%)]\tLoss: 0.233552\n",
      "Train Epoch: 13 [48640/84843 (57%)]\tLoss: 0.128836\n",
      "Train Epoch: 13 [49280/84843 (58%)]\tLoss: 0.193743\n",
      "Train Epoch: 13 [49920/84843 (59%)]\tLoss: 0.278490\n",
      "Train Epoch: 13 [50560/84843 (60%)]\tLoss: 0.839172\n",
      "Train Epoch: 13 [51200/84843 (60%)]\tLoss: 0.466438\n",
      "Train Epoch: 13 [51840/84843 (61%)]\tLoss: 0.721877\n",
      "Train Epoch: 13 [52480/84843 (62%)]\tLoss: 0.346172\n",
      "Train Epoch: 13 [53120/84843 (63%)]\tLoss: 0.260638\n",
      "Train Epoch: 13 [53760/84843 (63%)]\tLoss: 0.985173\n",
      "Train Epoch: 13 [54400/84843 (64%)]\tLoss: 0.639603\n",
      "Train Epoch: 13 [55040/84843 (65%)]\tLoss: 0.768323\n",
      "Train Epoch: 13 [55680/84843 (66%)]\tLoss: 0.321754\n",
      "Train Epoch: 13 [56320/84843 (66%)]\tLoss: 0.212947\n",
      "Train Epoch: 13 [56960/84843 (67%)]\tLoss: 0.402187\n",
      "Train Epoch: 13 [57600/84843 (68%)]\tLoss: 0.637706\n",
      "Train Epoch: 13 [58240/84843 (69%)]\tLoss: 0.387411\n",
      "Train Epoch: 13 [58880/84843 (69%)]\tLoss: 0.475109\n",
      "Train Epoch: 13 [59520/84843 (70%)]\tLoss: 0.270950\n",
      "Train Epoch: 13 [60160/84843 (71%)]\tLoss: 0.584180\n",
      "Train Epoch: 13 [60800/84843 (72%)]\tLoss: 0.228656\n",
      "Train Epoch: 13 [61440/84843 (72%)]\tLoss: 0.088808\n",
      "Train Epoch: 13 [62080/84843 (73%)]\tLoss: 0.248127\n",
      "Train Epoch: 13 [62720/84843 (74%)]\tLoss: 0.243285\n",
      "Train Epoch: 13 [63360/84843 (75%)]\tLoss: 0.210153\n",
      "Train Epoch: 13 [64000/84843 (75%)]\tLoss: 0.722839\n",
      "Train Epoch: 13 [64640/84843 (76%)]\tLoss: 0.520961\n",
      "Train Epoch: 13 [65280/84843 (77%)]\tLoss: 0.305461\n",
      "Train Epoch: 13 [65920/84843 (78%)]\tLoss: 0.220025\n",
      "Train Epoch: 13 [66560/84843 (78%)]\tLoss: 0.587411\n",
      "Train Epoch: 13 [67200/84843 (79%)]\tLoss: 0.314717\n",
      "Train Epoch: 13 [67840/84843 (80%)]\tLoss: 0.357782\n",
      "Train Epoch: 13 [68480/84843 (81%)]\tLoss: 0.320500\n",
      "Train Epoch: 13 [69120/84843 (81%)]\tLoss: 0.219616\n",
      "Train Epoch: 13 [69760/84843 (82%)]\tLoss: 0.607526\n",
      "Train Epoch: 13 [70400/84843 (83%)]\tLoss: 0.530439\n",
      "Train Epoch: 13 [71040/84843 (84%)]\tLoss: 0.320693\n",
      "Train Epoch: 13 [71680/84843 (84%)]\tLoss: 0.182357\n",
      "Train Epoch: 13 [72320/84843 (85%)]\tLoss: 0.521855\n",
      "Train Epoch: 13 [72960/84843 (86%)]\tLoss: 0.752609\n",
      "Train Epoch: 13 [73600/84843 (87%)]\tLoss: 0.511124\n",
      "Train Epoch: 13 [74240/84843 (87%)]\tLoss: 0.327316\n",
      "Train Epoch: 13 [74880/84843 (88%)]\tLoss: 0.445032\n",
      "Train Epoch: 13 [75520/84843 (89%)]\tLoss: 0.535626\n",
      "Train Epoch: 13 [76160/84843 (90%)]\tLoss: 0.230518\n",
      "Train Epoch: 13 [76800/84843 (90%)]\tLoss: 0.408255\n",
      "Train Epoch: 13 [77440/84843 (91%)]\tLoss: 0.764939\n",
      "Train Epoch: 13 [78080/84843 (92%)]\tLoss: 0.186792\n",
      "Train Epoch: 13 [78720/84843 (93%)]\tLoss: 0.558172\n",
      "Train Epoch: 13 [79360/84843 (94%)]\tLoss: 0.211978\n",
      "Train Epoch: 13 [80000/84843 (94%)]\tLoss: 0.444214\n",
      "Train Epoch: 13 [80640/84843 (95%)]\tLoss: 0.379750\n",
      "Train Epoch: 13 [81280/84843 (96%)]\tLoss: 0.496365\n",
      "Train Epoch: 13 [81920/84843 (97%)]\tLoss: 0.221823\n",
      "Train Epoch: 13 [82560/84843 (97%)]\tLoss: 0.387593\n",
      "Train Epoch: 13 [83200/84843 (98%)]\tLoss: 0.339366\n",
      "Train Epoch: 13 [83840/84843 (99%)]\tLoss: 0.646777\n",
      "Train Epoch: 13 [84480/84843 (100%)]\tLoss: 0.281754\n",
      "Accuracy: 9481/11005 (86%)\n",
      "\n",
      "Train Epoch: 14 [0/84843 (0%)]\tLoss: 0.197079\n",
      "Train Epoch: 14 [640/84843 (1%)]\tLoss: 0.129960\n",
      "Train Epoch: 14 [1280/84843 (2%)]\tLoss: 0.544825\n",
      "Train Epoch: 14 [1920/84843 (2%)]\tLoss: 0.108681\n",
      "Train Epoch: 14 [2560/84843 (3%)]\tLoss: 0.500830\n",
      "Train Epoch: 14 [3200/84843 (4%)]\tLoss: 0.081403\n",
      "Train Epoch: 14 [3840/84843 (5%)]\tLoss: 0.731236\n",
      "Train Epoch: 14 [4480/84843 (5%)]\tLoss: 0.542567\n",
      "Train Epoch: 14 [5120/84843 (6%)]\tLoss: 0.071046\n",
      "Train Epoch: 14 [5760/84843 (7%)]\tLoss: 0.270210\n",
      "Train Epoch: 14 [6400/84843 (8%)]\tLoss: 0.246572\n",
      "Train Epoch: 14 [7040/84843 (8%)]\tLoss: 0.436001\n",
      "Train Epoch: 14 [7680/84843 (9%)]\tLoss: 0.485375\n",
      "Train Epoch: 14 [8320/84843 (10%)]\tLoss: 0.718408\n",
      "Train Epoch: 14 [8960/84843 (11%)]\tLoss: 0.352201\n",
      "Train Epoch: 14 [9600/84843 (11%)]\tLoss: 0.328162\n",
      "Train Epoch: 14 [10240/84843 (12%)]\tLoss: 0.316702\n",
      "Train Epoch: 14 [10880/84843 (13%)]\tLoss: 0.165066\n",
      "Train Epoch: 14 [11520/84843 (14%)]\tLoss: 0.325542\n",
      "Train Epoch: 14 [12160/84843 (14%)]\tLoss: 0.328816\n",
      "Train Epoch: 14 [12800/84843 (15%)]\tLoss: 0.130704\n",
      "Train Epoch: 14 [13440/84843 (16%)]\tLoss: 0.544798\n",
      "Train Epoch: 14 [14080/84843 (17%)]\tLoss: 0.187136\n",
      "Train Epoch: 14 [14720/84843 (17%)]\tLoss: 0.284686\n",
      "Train Epoch: 14 [15360/84843 (18%)]\tLoss: 0.266098\n",
      "Train Epoch: 14 [16000/84843 (19%)]\tLoss: 0.382619\n",
      "Train Epoch: 14 [16640/84843 (20%)]\tLoss: 0.506775\n",
      "Train Epoch: 14 [17280/84843 (20%)]\tLoss: 0.348688\n",
      "Train Epoch: 14 [17920/84843 (21%)]\tLoss: 0.186995\n",
      "Train Epoch: 14 [18560/84843 (22%)]\tLoss: 0.426516\n",
      "Train Epoch: 14 [19200/84843 (23%)]\tLoss: 0.307180\n",
      "Train Epoch: 14 [19840/84843 (23%)]\tLoss: 0.256538\n",
      "Train Epoch: 14 [20480/84843 (24%)]\tLoss: 0.404359\n",
      "Train Epoch: 14 [21120/84843 (25%)]\tLoss: 0.284371\n",
      "Train Epoch: 14 [21760/84843 (26%)]\tLoss: 0.398195\n",
      "Train Epoch: 14 [22400/84843 (26%)]\tLoss: 0.089578\n",
      "Train Epoch: 14 [23040/84843 (27%)]\tLoss: 0.065972\n",
      "Train Epoch: 14 [23680/84843 (28%)]\tLoss: 0.556853\n",
      "Train Epoch: 14 [24320/84843 (29%)]\tLoss: 0.278805\n",
      "Train Epoch: 14 [24960/84843 (29%)]\tLoss: 0.265996\n",
      "Train Epoch: 14 [25600/84843 (30%)]\tLoss: 0.412347\n",
      "Train Epoch: 14 [26240/84843 (31%)]\tLoss: 0.499780\n",
      "Train Epoch: 14 [26880/84843 (32%)]\tLoss: 0.420700\n",
      "Train Epoch: 14 [27520/84843 (32%)]\tLoss: 0.206215\n",
      "Train Epoch: 14 [28160/84843 (33%)]\tLoss: 0.479873\n",
      "Train Epoch: 14 [28800/84843 (34%)]\tLoss: 0.134237\n",
      "Train Epoch: 14 [29440/84843 (35%)]\tLoss: 0.160468\n",
      "Train Epoch: 14 [30080/84843 (35%)]\tLoss: 0.236653\n",
      "Train Epoch: 14 [30720/84843 (36%)]\tLoss: 0.385226\n",
      "Train Epoch: 14 [31360/84843 (37%)]\tLoss: 0.572080\n",
      "Train Epoch: 14 [32000/84843 (38%)]\tLoss: 0.313465\n",
      "Train Epoch: 14 [32640/84843 (38%)]\tLoss: 0.342963\n",
      "Train Epoch: 14 [33280/84843 (39%)]\tLoss: 0.330084\n",
      "Train Epoch: 14 [33920/84843 (40%)]\tLoss: 0.238745\n",
      "Train Epoch: 14 [34560/84843 (41%)]\tLoss: 0.753739\n",
      "Train Epoch: 14 [35200/84843 (41%)]\tLoss: 0.213209\n",
      "Train Epoch: 14 [35840/84843 (42%)]\tLoss: 0.670354\n",
      "Train Epoch: 14 [36480/84843 (43%)]\tLoss: 0.173706\n",
      "Train Epoch: 14 [37120/84843 (44%)]\tLoss: 0.481310\n",
      "Train Epoch: 14 [37760/84843 (44%)]\tLoss: 0.618555\n",
      "Train Epoch: 14 [38400/84843 (45%)]\tLoss: 0.248121\n",
      "Train Epoch: 14 [39040/84843 (46%)]\tLoss: 0.240201\n",
      "Train Epoch: 14 [39680/84843 (47%)]\tLoss: 0.540423\n",
      "Train Epoch: 14 [40320/84843 (48%)]\tLoss: 0.386628\n",
      "Train Epoch: 14 [40960/84843 (48%)]\tLoss: 0.324637\n",
      "Train Epoch: 14 [41600/84843 (49%)]\tLoss: 0.295853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [42240/84843 (50%)]\tLoss: 0.301463\n",
      "Train Epoch: 14 [42880/84843 (51%)]\tLoss: 0.038654\n",
      "Train Epoch: 14 [43520/84843 (51%)]\tLoss: 0.493505\n",
      "Train Epoch: 14 [44160/84843 (52%)]\tLoss: 0.377338\n",
      "Train Epoch: 14 [44800/84843 (53%)]\tLoss: 0.601811\n",
      "Train Epoch: 14 [45440/84843 (54%)]\tLoss: 0.300954\n",
      "Train Epoch: 14 [46080/84843 (54%)]\tLoss: 0.851339\n",
      "Train Epoch: 14 [46720/84843 (55%)]\tLoss: 0.252251\n",
      "Train Epoch: 14 [47360/84843 (56%)]\tLoss: 0.195852\n",
      "Train Epoch: 14 [48000/84843 (57%)]\tLoss: 0.238614\n",
      "Train Epoch: 14 [48640/84843 (57%)]\tLoss: 0.553025\n",
      "Train Epoch: 14 [49280/84843 (58%)]\tLoss: 0.472590\n",
      "Train Epoch: 14 [49920/84843 (59%)]\tLoss: 0.477978\n",
      "Train Epoch: 14 [50560/84843 (60%)]\tLoss: 0.362935\n",
      "Train Epoch: 14 [51200/84843 (60%)]\tLoss: 0.552330\n",
      "Train Epoch: 14 [51840/84843 (61%)]\tLoss: 0.357186\n",
      "Train Epoch: 14 [52480/84843 (62%)]\tLoss: 0.358855\n",
      "Train Epoch: 14 [53120/84843 (63%)]\tLoss: 0.077150\n",
      "Train Epoch: 14 [53760/84843 (63%)]\tLoss: 0.505391\n",
      "Train Epoch: 14 [54400/84843 (64%)]\tLoss: 0.384897\n",
      "Train Epoch: 14 [55040/84843 (65%)]\tLoss: 0.148711\n",
      "Train Epoch: 14 [55680/84843 (66%)]\tLoss: 0.369071\n",
      "Train Epoch: 14 [56320/84843 (66%)]\tLoss: 0.452979\n",
      "Train Epoch: 14 [56960/84843 (67%)]\tLoss: 0.489670\n",
      "Train Epoch: 14 [57600/84843 (68%)]\tLoss: 0.344568\n",
      "Train Epoch: 14 [58240/84843 (69%)]\tLoss: 0.764138\n",
      "Train Epoch: 14 [58880/84843 (69%)]\tLoss: 0.077571\n",
      "Train Epoch: 14 [59520/84843 (70%)]\tLoss: 0.517212\n",
      "Train Epoch: 14 [60160/84843 (71%)]\tLoss: 0.234614\n",
      "Train Epoch: 14 [60800/84843 (72%)]\tLoss: 0.490418\n",
      "Train Epoch: 14 [61440/84843 (72%)]\tLoss: 0.328147\n",
      "Train Epoch: 14 [62080/84843 (73%)]\tLoss: 0.204408\n",
      "Train Epoch: 14 [62720/84843 (74%)]\tLoss: 0.211292\n",
      "Train Epoch: 14 [63360/84843 (75%)]\tLoss: 0.558766\n",
      "Train Epoch: 14 [64000/84843 (75%)]\tLoss: 0.190555\n",
      "Train Epoch: 14 [64640/84843 (76%)]\tLoss: 0.446139\n",
      "Train Epoch: 14 [65280/84843 (77%)]\tLoss: 0.493707\n",
      "Train Epoch: 14 [65920/84843 (78%)]\tLoss: 0.389001\n",
      "Train Epoch: 14 [66560/84843 (78%)]\tLoss: 0.484850\n",
      "Train Epoch: 14 [67200/84843 (79%)]\tLoss: 0.507524\n",
      "Train Epoch: 14 [67840/84843 (80%)]\tLoss: 0.492306\n",
      "Train Epoch: 14 [68480/84843 (81%)]\tLoss: 0.399075\n",
      "Train Epoch: 14 [69120/84843 (81%)]\tLoss: 0.618531\n",
      "Train Epoch: 14 [69760/84843 (82%)]\tLoss: 0.289881\n",
      "Train Epoch: 14 [70400/84843 (83%)]\tLoss: 0.547628\n",
      "Train Epoch: 14 [71040/84843 (84%)]\tLoss: 0.243352\n",
      "Train Epoch: 14 [71680/84843 (84%)]\tLoss: 0.253857\n",
      "Train Epoch: 14 [72320/84843 (85%)]\tLoss: 1.249849\n",
      "Train Epoch: 14 [72960/84843 (86%)]\tLoss: 0.502749\n",
      "Train Epoch: 14 [73600/84843 (87%)]\tLoss: 0.735927\n",
      "Train Epoch: 14 [74240/84843 (87%)]\tLoss: 0.388398\n",
      "Train Epoch: 14 [74880/84843 (88%)]\tLoss: 0.091634\n",
      "Train Epoch: 14 [75520/84843 (89%)]\tLoss: 0.372297\n",
      "Train Epoch: 14 [76160/84843 (90%)]\tLoss: 0.296106\n",
      "Train Epoch: 14 [76800/84843 (90%)]\tLoss: 0.607762\n",
      "Train Epoch: 14 [77440/84843 (91%)]\tLoss: 0.404812\n",
      "Train Epoch: 14 [78080/84843 (92%)]\tLoss: 0.434867\n",
      "Train Epoch: 14 [78720/84843 (93%)]\tLoss: 0.411199\n",
      "Train Epoch: 14 [79360/84843 (94%)]\tLoss: 0.657431\n",
      "Train Epoch: 14 [80000/84843 (94%)]\tLoss: 0.722670\n",
      "Train Epoch: 14 [80640/84843 (95%)]\tLoss: 0.419634\n",
      "Train Epoch: 14 [81280/84843 (96%)]\tLoss: 0.644365\n",
      "Train Epoch: 14 [81920/84843 (97%)]\tLoss: 0.553958\n",
      "Train Epoch: 14 [82560/84843 (97%)]\tLoss: 0.319250\n",
      "Train Epoch: 14 [83200/84843 (98%)]\tLoss: 0.284489\n",
      "Train Epoch: 14 [83840/84843 (99%)]\tLoss: 0.459924\n",
      "Train Epoch: 14 [84480/84843 (100%)]\tLoss: 0.501966\n",
      "Accuracy: 9461/11005 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/84843 (0%)]\tLoss: 0.418166\n",
      "Train Epoch: 15 [640/84843 (1%)]\tLoss: 0.141418\n",
      "Train Epoch: 15 [1280/84843 (2%)]\tLoss: 0.186031\n",
      "Train Epoch: 15 [1920/84843 (2%)]\tLoss: 0.113229\n",
      "Train Epoch: 15 [2560/84843 (3%)]\tLoss: 0.179038\n",
      "Train Epoch: 15 [3200/84843 (4%)]\tLoss: 0.514486\n",
      "Train Epoch: 15 [3840/84843 (5%)]\tLoss: 0.241696\n",
      "Train Epoch: 15 [4480/84843 (5%)]\tLoss: 0.197808\n",
      "Train Epoch: 15 [5120/84843 (6%)]\tLoss: 0.141200\n",
      "Train Epoch: 15 [5760/84843 (7%)]\tLoss: 0.317010\n",
      "Train Epoch: 15 [6400/84843 (8%)]\tLoss: 0.661951\n",
      "Train Epoch: 15 [7040/84843 (8%)]\tLoss: 0.457052\n",
      "Train Epoch: 15 [7680/84843 (9%)]\tLoss: 0.131956\n",
      "Train Epoch: 15 [8320/84843 (10%)]\tLoss: 0.365784\n",
      "Train Epoch: 15 [8960/84843 (11%)]\tLoss: 0.155480\n",
      "Train Epoch: 15 [9600/84843 (11%)]\tLoss: 0.316754\n",
      "Train Epoch: 15 [10240/84843 (12%)]\tLoss: 0.381762\n",
      "Train Epoch: 15 [10880/84843 (13%)]\tLoss: 0.203281\n",
      "Train Epoch: 15 [11520/84843 (14%)]\tLoss: 0.614546\n",
      "Train Epoch: 15 [12160/84843 (14%)]\tLoss: 0.552844\n",
      "Train Epoch: 15 [12800/84843 (15%)]\tLoss: 0.464818\n",
      "Train Epoch: 15 [13440/84843 (16%)]\tLoss: 0.263561\n",
      "Train Epoch: 15 [14080/84843 (17%)]\tLoss: 0.319479\n",
      "Train Epoch: 15 [14720/84843 (17%)]\tLoss: 0.269734\n",
      "Train Epoch: 15 [15360/84843 (18%)]\tLoss: 0.202756\n",
      "Train Epoch: 15 [16000/84843 (19%)]\tLoss: 0.388843\n",
      "Train Epoch: 15 [16640/84843 (20%)]\tLoss: 0.205049\n",
      "Train Epoch: 15 [17280/84843 (20%)]\tLoss: 0.261044\n",
      "Train Epoch: 15 [17920/84843 (21%)]\tLoss: 0.416180\n",
      "Train Epoch: 15 [18560/84843 (22%)]\tLoss: 0.209011\n",
      "Train Epoch: 15 [19200/84843 (23%)]\tLoss: 0.346314\n",
      "Train Epoch: 15 [19840/84843 (23%)]\tLoss: 0.202987\n",
      "Train Epoch: 15 [20480/84843 (24%)]\tLoss: 0.563177\n",
      "Train Epoch: 15 [21120/84843 (25%)]\tLoss: 0.513719\n",
      "Train Epoch: 15 [21760/84843 (26%)]\tLoss: 0.664139\n",
      "Train Epoch: 15 [22400/84843 (26%)]\tLoss: 0.188774\n",
      "Train Epoch: 15 [23040/84843 (27%)]\tLoss: 0.352037\n",
      "Train Epoch: 15 [23680/84843 (28%)]\tLoss: 0.408870\n",
      "Train Epoch: 15 [24320/84843 (29%)]\tLoss: 0.495503\n",
      "Train Epoch: 15 [24960/84843 (29%)]\tLoss: 0.655993\n",
      "Train Epoch: 15 [25600/84843 (30%)]\tLoss: 0.250181\n",
      "Train Epoch: 15 [26240/84843 (31%)]\tLoss: 0.369842\n",
      "Train Epoch: 15 [26880/84843 (32%)]\tLoss: 0.734131\n",
      "Train Epoch: 15 [27520/84843 (32%)]\tLoss: 0.711534\n",
      "Train Epoch: 15 [28160/84843 (33%)]\tLoss: 0.524765\n",
      "Train Epoch: 15 [28800/84843 (34%)]\tLoss: 0.215839\n",
      "Train Epoch: 15 [29440/84843 (35%)]\tLoss: 0.397942\n",
      "Train Epoch: 15 [30080/84843 (35%)]\tLoss: 0.787414\n",
      "Train Epoch: 15 [30720/84843 (36%)]\tLoss: 0.289317\n",
      "Train Epoch: 15 [31360/84843 (37%)]\tLoss: 0.285067\n",
      "Train Epoch: 15 [32000/84843 (38%)]\tLoss: 0.381177\n",
      "Train Epoch: 15 [32640/84843 (38%)]\tLoss: 0.899791\n",
      "Train Epoch: 15 [33280/84843 (39%)]\tLoss: 0.205061\n",
      "Train Epoch: 15 [33920/84843 (40%)]\tLoss: 0.558412\n",
      "Train Epoch: 15 [34560/84843 (41%)]\tLoss: 0.120117\n",
      "Train Epoch: 15 [35200/84843 (41%)]\tLoss: 0.326764\n",
      "Train Epoch: 15 [35840/84843 (42%)]\tLoss: 0.287947\n",
      "Train Epoch: 15 [36480/84843 (43%)]\tLoss: 0.306806\n",
      "Train Epoch: 15 [37120/84843 (44%)]\tLoss: 0.451600\n",
      "Train Epoch: 15 [37760/84843 (44%)]\tLoss: 0.586115\n",
      "Train Epoch: 15 [38400/84843 (45%)]\tLoss: 0.721931\n",
      "Train Epoch: 15 [39040/84843 (46%)]\tLoss: 0.190858\n",
      "Train Epoch: 15 [39680/84843 (47%)]\tLoss: 0.123605\n",
      "Train Epoch: 15 [40320/84843 (48%)]\tLoss: 0.350227\n",
      "Train Epoch: 15 [40960/84843 (48%)]\tLoss: 0.271999\n",
      "Train Epoch: 15 [41600/84843 (49%)]\tLoss: 0.316875\n",
      "Train Epoch: 15 [42240/84843 (50%)]\tLoss: 0.414456\n",
      "Train Epoch: 15 [42880/84843 (51%)]\tLoss: 0.313649\n",
      "Train Epoch: 15 [43520/84843 (51%)]\tLoss: 0.176702\n",
      "Train Epoch: 15 [44160/84843 (52%)]\tLoss: 0.175262\n",
      "Train Epoch: 15 [44800/84843 (53%)]\tLoss: 0.605810\n",
      "Train Epoch: 15 [45440/84843 (54%)]\tLoss: 0.338686\n",
      "Train Epoch: 15 [46080/84843 (54%)]\tLoss: 0.412328\n",
      "Train Epoch: 15 [46720/84843 (55%)]\tLoss: 0.387205\n",
      "Train Epoch: 15 [47360/84843 (56%)]\tLoss: 0.320158\n",
      "Train Epoch: 15 [48000/84843 (57%)]\tLoss: 0.466627\n",
      "Train Epoch: 15 [48640/84843 (57%)]\tLoss: 0.184629\n",
      "Train Epoch: 15 [49280/84843 (58%)]\tLoss: 0.191295\n",
      "Train Epoch: 15 [49920/84843 (59%)]\tLoss: 0.198208\n",
      "Train Epoch: 15 [50560/84843 (60%)]\tLoss: 0.311944\n",
      "Train Epoch: 15 [51200/84843 (60%)]\tLoss: 0.461248\n",
      "Train Epoch: 15 [51840/84843 (61%)]\tLoss: 0.085431\n",
      "Train Epoch: 15 [52480/84843 (62%)]\tLoss: 0.721993\n",
      "Train Epoch: 15 [53120/84843 (63%)]\tLoss: 0.371658\n",
      "Train Epoch: 15 [53760/84843 (63%)]\tLoss: 0.414912\n",
      "Train Epoch: 15 [54400/84843 (64%)]\tLoss: 0.222875\n",
      "Train Epoch: 15 [55040/84843 (65%)]\tLoss: 0.518822\n",
      "Train Epoch: 15 [55680/84843 (66%)]\tLoss: 0.464706\n",
      "Train Epoch: 15 [56320/84843 (66%)]\tLoss: 0.758324\n",
      "Train Epoch: 15 [56960/84843 (67%)]\tLoss: 0.396410\n",
      "Train Epoch: 15 [57600/84843 (68%)]\tLoss: 0.614082\n",
      "Train Epoch: 15 [58240/84843 (69%)]\tLoss: 0.409510\n",
      "Train Epoch: 15 [58880/84843 (69%)]\tLoss: 0.476150\n",
      "Train Epoch: 15 [59520/84843 (70%)]\tLoss: 0.472962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [60160/84843 (71%)]\tLoss: 0.617751\n",
      "Train Epoch: 15 [60800/84843 (72%)]\tLoss: 0.341723\n",
      "Train Epoch: 15 [61440/84843 (72%)]\tLoss: 0.454355\n",
      "Train Epoch: 15 [62080/84843 (73%)]\tLoss: 0.786526\n",
      "Train Epoch: 15 [62720/84843 (74%)]\tLoss: 0.338125\n",
      "Train Epoch: 15 [63360/84843 (75%)]\tLoss: 0.466006\n",
      "Train Epoch: 15 [64000/84843 (75%)]\tLoss: 0.517246\n",
      "Train Epoch: 15 [64640/84843 (76%)]\tLoss: 0.462289\n",
      "Train Epoch: 15 [65280/84843 (77%)]\tLoss: 0.457802\n",
      "Train Epoch: 15 [65920/84843 (78%)]\tLoss: 0.278409\n",
      "Train Epoch: 15 [66560/84843 (78%)]\tLoss: 0.425982\n",
      "Train Epoch: 15 [67200/84843 (79%)]\tLoss: 0.289424\n",
      "Train Epoch: 15 [67840/84843 (80%)]\tLoss: 0.361098\n",
      "Train Epoch: 15 [68480/84843 (81%)]\tLoss: 0.392337\n",
      "Train Epoch: 15 [69120/84843 (81%)]\tLoss: 0.243713\n",
      "Train Epoch: 15 [69760/84843 (82%)]\tLoss: 0.406092\n",
      "Train Epoch: 15 [70400/84843 (83%)]\tLoss: 0.530720\n",
      "Train Epoch: 15 [71040/84843 (84%)]\tLoss: 0.453920\n",
      "Train Epoch: 15 [71680/84843 (84%)]\tLoss: 0.259531\n",
      "Train Epoch: 15 [72320/84843 (85%)]\tLoss: 0.327976\n",
      "Train Epoch: 15 [72960/84843 (86%)]\tLoss: 0.257322\n",
      "Train Epoch: 15 [73600/84843 (87%)]\tLoss: 0.268213\n",
      "Train Epoch: 15 [74240/84843 (87%)]\tLoss: 0.262978\n",
      "Train Epoch: 15 [74880/84843 (88%)]\tLoss: 0.398653\n",
      "Train Epoch: 15 [75520/84843 (89%)]\tLoss: 0.354476\n",
      "Train Epoch: 15 [76160/84843 (90%)]\tLoss: 0.954121\n",
      "Train Epoch: 15 [76800/84843 (90%)]\tLoss: 0.354109\n",
      "Train Epoch: 15 [77440/84843 (91%)]\tLoss: 0.388009\n",
      "Train Epoch: 15 [78080/84843 (92%)]\tLoss: 0.263730\n",
      "Train Epoch: 15 [78720/84843 (93%)]\tLoss: 0.125719\n",
      "Train Epoch: 15 [79360/84843 (94%)]\tLoss: 0.412130\n",
      "Train Epoch: 15 [80000/84843 (94%)]\tLoss: 0.259033\n",
      "Train Epoch: 15 [80640/84843 (95%)]\tLoss: 0.342847\n",
      "Train Epoch: 15 [81280/84843 (96%)]\tLoss: 0.393192\n",
      "Train Epoch: 15 [81920/84843 (97%)]\tLoss: 0.521728\n",
      "Train Epoch: 15 [82560/84843 (97%)]\tLoss: 0.538082\n",
      "Train Epoch: 15 [83200/84843 (98%)]\tLoss: 0.388760\n",
      "Train Epoch: 15 [83840/84843 (99%)]\tLoss: 0.335250\n",
      "Train Epoch: 15 [84480/84843 (100%)]\tLoss: 0.416309\n",
      "Accuracy: 9411/11005 (86%)\n",
      "\n",
      "Train Epoch: 16 [0/84843 (0%)]\tLoss: 0.173480\n",
      "Train Epoch: 16 [640/84843 (1%)]\tLoss: 0.287469\n",
      "Train Epoch: 16 [1280/84843 (2%)]\tLoss: 0.492012\n",
      "Train Epoch: 16 [1920/84843 (2%)]\tLoss: 0.499723\n",
      "Train Epoch: 16 [2560/84843 (3%)]\tLoss: 0.222762\n",
      "Train Epoch: 16 [3200/84843 (4%)]\tLoss: 0.426311\n",
      "Train Epoch: 16 [3840/84843 (5%)]\tLoss: 0.270618\n",
      "Train Epoch: 16 [4480/84843 (5%)]\tLoss: 0.156754\n",
      "Train Epoch: 16 [5120/84843 (6%)]\tLoss: 0.560842\n",
      "Train Epoch: 16 [5760/84843 (7%)]\tLoss: 0.301995\n",
      "Train Epoch: 16 [6400/84843 (8%)]\tLoss: 0.295529\n",
      "Train Epoch: 16 [7040/84843 (8%)]\tLoss: 0.563615\n",
      "Train Epoch: 16 [7680/84843 (9%)]\tLoss: 0.313972\n",
      "Train Epoch: 16 [8320/84843 (10%)]\tLoss: 0.395903\n",
      "Train Epoch: 16 [8960/84843 (11%)]\tLoss: 0.189388\n",
      "Train Epoch: 16 [9600/84843 (11%)]\tLoss: 0.262788\n",
      "Train Epoch: 16 [10240/84843 (12%)]\tLoss: 0.319782\n",
      "Train Epoch: 16 [10880/84843 (13%)]\tLoss: 0.449987\n",
      "Train Epoch: 16 [11520/84843 (14%)]\tLoss: 0.404631\n",
      "Train Epoch: 16 [12160/84843 (14%)]\tLoss: 0.319342\n",
      "Train Epoch: 16 [12800/84843 (15%)]\tLoss: 0.371560\n",
      "Train Epoch: 16 [13440/84843 (16%)]\tLoss: 0.836153\n",
      "Train Epoch: 16 [14080/84843 (17%)]\tLoss: 0.349336\n",
      "Train Epoch: 16 [14720/84843 (17%)]\tLoss: 0.330474\n",
      "Train Epoch: 16 [15360/84843 (18%)]\tLoss: 0.198399\n",
      "Train Epoch: 16 [16000/84843 (19%)]\tLoss: 0.179266\n",
      "Train Epoch: 16 [16640/84843 (20%)]\tLoss: 0.511607\n",
      "Train Epoch: 16 [17280/84843 (20%)]\tLoss: 0.149814\n",
      "Train Epoch: 16 [17920/84843 (21%)]\tLoss: 0.411927\n",
      "Train Epoch: 16 [18560/84843 (22%)]\tLoss: 0.455244\n",
      "Train Epoch: 16 [19200/84843 (23%)]\tLoss: 0.277233\n",
      "Train Epoch: 16 [19840/84843 (23%)]\tLoss: 0.281673\n",
      "Train Epoch: 16 [20480/84843 (24%)]\tLoss: 0.440512\n",
      "Train Epoch: 16 [21120/84843 (25%)]\tLoss: 0.160830\n",
      "Train Epoch: 16 [21760/84843 (26%)]\tLoss: 0.734286\n",
      "Train Epoch: 16 [22400/84843 (26%)]\tLoss: 0.441880\n",
      "Train Epoch: 16 [23040/84843 (27%)]\tLoss: 0.468478\n",
      "Train Epoch: 16 [23680/84843 (28%)]\tLoss: 0.333870\n",
      "Train Epoch: 16 [24320/84843 (29%)]\tLoss: 0.085740\n",
      "Train Epoch: 16 [24960/84843 (29%)]\tLoss: 0.203934\n",
      "Train Epoch: 16 [25600/84843 (30%)]\tLoss: 0.285921\n",
      "Train Epoch: 16 [26240/84843 (31%)]\tLoss: 0.608407\n",
      "Train Epoch: 16 [26880/84843 (32%)]\tLoss: 0.513849\n",
      "Train Epoch: 16 [27520/84843 (32%)]\tLoss: 0.112148\n",
      "Train Epoch: 16 [28160/84843 (33%)]\tLoss: 0.337819\n",
      "Train Epoch: 16 [28800/84843 (34%)]\tLoss: 0.483307\n",
      "Train Epoch: 16 [29440/84843 (35%)]\tLoss: 0.258146\n",
      "Train Epoch: 16 [30080/84843 (35%)]\tLoss: 0.302940\n",
      "Train Epoch: 16 [30720/84843 (36%)]\tLoss: 0.306835\n",
      "Train Epoch: 16 [31360/84843 (37%)]\tLoss: 0.364495\n",
      "Train Epoch: 16 [32000/84843 (38%)]\tLoss: 0.249546\n",
      "Train Epoch: 16 [32640/84843 (38%)]\tLoss: 0.547433\n",
      "Train Epoch: 16 [33280/84843 (39%)]\tLoss: 0.159883\n",
      "Train Epoch: 16 [33920/84843 (40%)]\tLoss: 0.478981\n",
      "Train Epoch: 16 [34560/84843 (41%)]\tLoss: 0.292191\n",
      "Train Epoch: 16 [35200/84843 (41%)]\tLoss: 0.555556\n",
      "Train Epoch: 16 [35840/84843 (42%)]\tLoss: 0.366100\n",
      "Train Epoch: 16 [36480/84843 (43%)]\tLoss: 0.149817\n",
      "Train Epoch: 16 [37120/84843 (44%)]\tLoss: 0.668316\n",
      "Train Epoch: 16 [37760/84843 (44%)]\tLoss: 0.305995\n",
      "Train Epoch: 16 [38400/84843 (45%)]\tLoss: 0.272510\n",
      "Train Epoch: 16 [39040/84843 (46%)]\tLoss: 0.298698\n",
      "Train Epoch: 16 [39680/84843 (47%)]\tLoss: 0.286839\n",
      "Train Epoch: 16 [40320/84843 (48%)]\tLoss: 0.346931\n",
      "Train Epoch: 16 [40960/84843 (48%)]\tLoss: 0.325270\n",
      "Train Epoch: 16 [41600/84843 (49%)]\tLoss: 0.226726\n",
      "Train Epoch: 16 [42240/84843 (50%)]\tLoss: 0.239016\n",
      "Train Epoch: 16 [42880/84843 (51%)]\tLoss: 0.381875\n",
      "Train Epoch: 16 [43520/84843 (51%)]\tLoss: 0.631465\n",
      "Train Epoch: 16 [44160/84843 (52%)]\tLoss: 0.332214\n",
      "Train Epoch: 16 [44800/84843 (53%)]\tLoss: 0.264705\n",
      "Train Epoch: 16 [45440/84843 (54%)]\tLoss: 0.420088\n",
      "Train Epoch: 16 [46080/84843 (54%)]\tLoss: 0.389553\n",
      "Train Epoch: 16 [46720/84843 (55%)]\tLoss: 0.059253\n",
      "Train Epoch: 16 [47360/84843 (56%)]\tLoss: 0.291455\n",
      "Train Epoch: 16 [48000/84843 (57%)]\tLoss: 0.252088\n",
      "Train Epoch: 16 [48640/84843 (57%)]\tLoss: 0.249421\n",
      "Train Epoch: 16 [49280/84843 (58%)]\tLoss: 0.330960\n",
      "Train Epoch: 16 [49920/84843 (59%)]\tLoss: 0.589984\n",
      "Train Epoch: 16 [50560/84843 (60%)]\tLoss: 0.450833\n",
      "Train Epoch: 16 [51200/84843 (60%)]\tLoss: 0.440605\n",
      "Train Epoch: 16 [51840/84843 (61%)]\tLoss: 0.303485\n",
      "Train Epoch: 16 [52480/84843 (62%)]\tLoss: 0.249682\n",
      "Train Epoch: 16 [53120/84843 (63%)]\tLoss: 0.415601\n",
      "Train Epoch: 16 [53760/84843 (63%)]\tLoss: 0.325627\n",
      "Train Epoch: 16 [54400/84843 (64%)]\tLoss: 0.713844\n",
      "Train Epoch: 16 [55040/84843 (65%)]\tLoss: 0.312138\n",
      "Train Epoch: 16 [55680/84843 (66%)]\tLoss: 0.491531\n",
      "Train Epoch: 16 [56320/84843 (66%)]\tLoss: 0.159275\n",
      "Train Epoch: 16 [56960/84843 (67%)]\tLoss: 0.588501\n",
      "Train Epoch: 16 [57600/84843 (68%)]\tLoss: 0.655752\n",
      "Train Epoch: 16 [58240/84843 (69%)]\tLoss: 0.674727\n",
      "Train Epoch: 16 [58880/84843 (69%)]\tLoss: 0.331411\n",
      "Train Epoch: 16 [59520/84843 (70%)]\tLoss: 0.106967\n",
      "Train Epoch: 16 [60160/84843 (71%)]\tLoss: 0.180310\n",
      "Train Epoch: 16 [60800/84843 (72%)]\tLoss: 0.426029\n",
      "Train Epoch: 16 [61440/84843 (72%)]\tLoss: 0.214130\n",
      "Train Epoch: 16 [62080/84843 (73%)]\tLoss: 0.436518\n",
      "Train Epoch: 16 [62720/84843 (74%)]\tLoss: 0.429928\n",
      "Train Epoch: 16 [63360/84843 (75%)]\tLoss: 0.142797\n",
      "Train Epoch: 16 [64000/84843 (75%)]\tLoss: 0.294980\n",
      "Train Epoch: 16 [64640/84843 (76%)]\tLoss: 0.573906\n",
      "Train Epoch: 16 [65280/84843 (77%)]\tLoss: 0.559197\n",
      "Train Epoch: 16 [65920/84843 (78%)]\tLoss: 0.291245\n",
      "Train Epoch: 16 [66560/84843 (78%)]\tLoss: 0.664920\n",
      "Train Epoch: 16 [67200/84843 (79%)]\tLoss: 0.526841\n",
      "Train Epoch: 16 [67840/84843 (80%)]\tLoss: 0.229603\n",
      "Train Epoch: 16 [68480/84843 (81%)]\tLoss: 0.085763\n",
      "Train Epoch: 16 [69120/84843 (81%)]\tLoss: 0.143419\n",
      "Train Epoch: 16 [69760/84843 (82%)]\tLoss: 0.554393\n",
      "Train Epoch: 16 [70400/84843 (83%)]\tLoss: 0.680224\n",
      "Train Epoch: 16 [71040/84843 (84%)]\tLoss: 0.209852\n",
      "Train Epoch: 16 [71680/84843 (84%)]\tLoss: 0.488097\n",
      "Train Epoch: 16 [72320/84843 (85%)]\tLoss: 0.339499\n",
      "Train Epoch: 16 [72960/84843 (86%)]\tLoss: 0.419687\n",
      "Train Epoch: 16 [73600/84843 (87%)]\tLoss: 0.477390\n",
      "Train Epoch: 16 [74240/84843 (87%)]\tLoss: 0.277248\n",
      "Train Epoch: 16 [74880/84843 (88%)]\tLoss: 0.157327\n",
      "Train Epoch: 16 [75520/84843 (89%)]\tLoss: 0.316427\n",
      "Train Epoch: 16 [76160/84843 (90%)]\tLoss: 0.418671\n",
      "Train Epoch: 16 [76800/84843 (90%)]\tLoss: 0.569516\n",
      "Train Epoch: 16 [77440/84843 (91%)]\tLoss: 0.248964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [78080/84843 (92%)]\tLoss: 0.477911\n",
      "Train Epoch: 16 [78720/84843 (93%)]\tLoss: 0.618130\n",
      "Train Epoch: 16 [79360/84843 (94%)]\tLoss: 0.423323\n",
      "Train Epoch: 16 [80000/84843 (94%)]\tLoss: 0.753285\n",
      "Train Epoch: 16 [80640/84843 (95%)]\tLoss: 0.222553\n",
      "Train Epoch: 16 [81280/84843 (96%)]\tLoss: 0.401161\n",
      "Train Epoch: 16 [81920/84843 (97%)]\tLoss: 0.159475\n",
      "Train Epoch: 16 [82560/84843 (97%)]\tLoss: 0.431981\n",
      "Train Epoch: 16 [83200/84843 (98%)]\tLoss: 0.320566\n",
      "Train Epoch: 16 [83840/84843 (99%)]\tLoss: 0.409659\n",
      "Train Epoch: 16 [84480/84843 (100%)]\tLoss: 0.332064\n",
      "Accuracy: 9413/11005 (86%)\n",
      "\n",
      "Train Epoch: 17 [0/84843 (0%)]\tLoss: 0.183403\n",
      "Train Epoch: 17 [640/84843 (1%)]\tLoss: 0.317997\n",
      "Train Epoch: 17 [1280/84843 (2%)]\tLoss: 0.529951\n",
      "Train Epoch: 17 [1920/84843 (2%)]\tLoss: 0.504628\n",
      "Train Epoch: 17 [2560/84843 (3%)]\tLoss: 0.221326\n",
      "Train Epoch: 17 [3200/84843 (4%)]\tLoss: 0.186031\n",
      "Train Epoch: 17 [3840/84843 (5%)]\tLoss: 0.283224\n",
      "Train Epoch: 17 [4480/84843 (5%)]\tLoss: 0.209057\n",
      "Train Epoch: 17 [5120/84843 (6%)]\tLoss: 0.190009\n",
      "Train Epoch: 17 [5760/84843 (7%)]\tLoss: 0.655044\n",
      "Train Epoch: 17 [6400/84843 (8%)]\tLoss: 0.345199\n",
      "Train Epoch: 17 [7040/84843 (8%)]\tLoss: 0.199753\n",
      "Train Epoch: 17 [7680/84843 (9%)]\tLoss: 0.430850\n",
      "Train Epoch: 17 [8320/84843 (10%)]\tLoss: 0.536455\n",
      "Train Epoch: 17 [8960/84843 (11%)]\tLoss: 0.288156\n",
      "Train Epoch: 17 [9600/84843 (11%)]\tLoss: 0.347910\n",
      "Train Epoch: 17 [10240/84843 (12%)]\tLoss: 0.382958\n",
      "Train Epoch: 17 [10880/84843 (13%)]\tLoss: 0.317891\n",
      "Train Epoch: 17 [11520/84843 (14%)]\tLoss: 0.652722\n",
      "Train Epoch: 17 [12160/84843 (14%)]\tLoss: 0.425547\n",
      "Train Epoch: 17 [12800/84843 (15%)]\tLoss: 0.155182\n",
      "Train Epoch: 17 [13440/84843 (16%)]\tLoss: 0.275108\n",
      "Train Epoch: 17 [14080/84843 (17%)]\tLoss: 0.222871\n",
      "Train Epoch: 17 [14720/84843 (17%)]\tLoss: 0.565491\n",
      "Train Epoch: 17 [15360/84843 (18%)]\tLoss: 0.429032\n",
      "Train Epoch: 17 [16000/84843 (19%)]\tLoss: 0.337202\n",
      "Train Epoch: 17 [16640/84843 (20%)]\tLoss: 0.420198\n",
      "Train Epoch: 17 [17280/84843 (20%)]\tLoss: 0.496724\n",
      "Train Epoch: 17 [17920/84843 (21%)]\tLoss: 0.302721\n",
      "Train Epoch: 17 [18560/84843 (22%)]\tLoss: 0.187190\n",
      "Train Epoch: 17 [19200/84843 (23%)]\tLoss: 0.144739\n",
      "Train Epoch: 17 [19840/84843 (23%)]\tLoss: 0.639609\n",
      "Train Epoch: 17 [20480/84843 (24%)]\tLoss: 0.245724\n",
      "Train Epoch: 17 [21120/84843 (25%)]\tLoss: 0.326202\n",
      "Train Epoch: 17 [21760/84843 (26%)]\tLoss: 0.333980\n",
      "Train Epoch: 17 [22400/84843 (26%)]\tLoss: 0.255324\n",
      "Train Epoch: 17 [23040/84843 (27%)]\tLoss: 0.355094\n",
      "Train Epoch: 17 [23680/84843 (28%)]\tLoss: 0.161335\n",
      "Train Epoch: 17 [24320/84843 (29%)]\tLoss: 0.205297\n",
      "Train Epoch: 17 [24960/84843 (29%)]\tLoss: 0.303791\n",
      "Train Epoch: 17 [25600/84843 (30%)]\tLoss: 0.228962\n",
      "Train Epoch: 17 [26240/84843 (31%)]\tLoss: 0.445378\n",
      "Train Epoch: 17 [26880/84843 (32%)]\tLoss: 0.844916\n",
      "Train Epoch: 17 [27520/84843 (32%)]\tLoss: 0.524048\n",
      "Train Epoch: 17 [28160/84843 (33%)]\tLoss: 0.330859\n",
      "Train Epoch: 17 [28800/84843 (34%)]\tLoss: 0.434782\n",
      "Train Epoch: 17 [29440/84843 (35%)]\tLoss: 0.292333\n",
      "Train Epoch: 17 [30080/84843 (35%)]\tLoss: 0.520826\n",
      "Train Epoch: 17 [30720/84843 (36%)]\tLoss: 0.310147\n",
      "Train Epoch: 17 [31360/84843 (37%)]\tLoss: 0.826101\n",
      "Train Epoch: 17 [32000/84843 (38%)]\tLoss: 0.757586\n",
      "Train Epoch: 17 [32640/84843 (38%)]\tLoss: 0.198372\n",
      "Train Epoch: 17 [33280/84843 (39%)]\tLoss: 0.312318\n",
      "Train Epoch: 17 [33920/84843 (40%)]\tLoss: 0.346086\n",
      "Train Epoch: 17 [34560/84843 (41%)]\tLoss: 0.283920\n",
      "Train Epoch: 17 [35200/84843 (41%)]\tLoss: 0.294626\n",
      "Train Epoch: 17 [35840/84843 (42%)]\tLoss: 0.512993\n",
      "Train Epoch: 17 [36480/84843 (43%)]\tLoss: 0.233483\n",
      "Train Epoch: 17 [37120/84843 (44%)]\tLoss: 0.481936\n",
      "Train Epoch: 17 [37760/84843 (44%)]\tLoss: 0.364200\n",
      "Train Epoch: 17 [38400/84843 (45%)]\tLoss: 0.545120\n",
      "Train Epoch: 17 [39040/84843 (46%)]\tLoss: 0.553040\n",
      "Train Epoch: 17 [39680/84843 (47%)]\tLoss: 0.377706\n",
      "Train Epoch: 17 [40320/84843 (48%)]\tLoss: 0.718331\n",
      "Train Epoch: 17 [40960/84843 (48%)]\tLoss: 0.429458\n",
      "Train Epoch: 17 [41600/84843 (49%)]\tLoss: 0.256683\n",
      "Train Epoch: 17 [42240/84843 (50%)]\tLoss: 0.151148\n",
      "Train Epoch: 17 [42880/84843 (51%)]\tLoss: 0.213983\n",
      "Train Epoch: 17 [43520/84843 (51%)]\tLoss: 0.118290\n",
      "Train Epoch: 17 [44160/84843 (52%)]\tLoss: 0.408448\n",
      "Train Epoch: 17 [44800/84843 (53%)]\tLoss: 0.210993\n",
      "Train Epoch: 17 [45440/84843 (54%)]\tLoss: 0.474988\n",
      "Train Epoch: 17 [46080/84843 (54%)]\tLoss: 0.462768\n",
      "Train Epoch: 17 [46720/84843 (55%)]\tLoss: 0.075791\n",
      "Train Epoch: 17 [47360/84843 (56%)]\tLoss: 0.357031\n",
      "Train Epoch: 17 [48000/84843 (57%)]\tLoss: 0.298621\n",
      "Train Epoch: 17 [48640/84843 (57%)]\tLoss: 0.171256\n",
      "Train Epoch: 17 [49280/84843 (58%)]\tLoss: 0.273309\n",
      "Train Epoch: 17 [49920/84843 (59%)]\tLoss: 0.570834\n",
      "Train Epoch: 17 [50560/84843 (60%)]\tLoss: 0.275873\n",
      "Train Epoch: 17 [51200/84843 (60%)]\tLoss: 0.462164\n",
      "Train Epoch: 17 [51840/84843 (61%)]\tLoss: 0.358932\n",
      "Train Epoch: 17 [52480/84843 (62%)]\tLoss: 0.480889\n",
      "Train Epoch: 17 [53120/84843 (63%)]\tLoss: 0.806217\n",
      "Train Epoch: 17 [53760/84843 (63%)]\tLoss: 0.464481\n",
      "Train Epoch: 17 [54400/84843 (64%)]\tLoss: 0.593369\n",
      "Train Epoch: 17 [55040/84843 (65%)]\tLoss: 0.357966\n",
      "Train Epoch: 17 [55680/84843 (66%)]\tLoss: 0.148229\n",
      "Train Epoch: 17 [56320/84843 (66%)]\tLoss: 0.203744\n",
      "Train Epoch: 17 [56960/84843 (67%)]\tLoss: 0.492276\n",
      "Train Epoch: 17 [57600/84843 (68%)]\tLoss: 0.287862\n",
      "Train Epoch: 17 [58240/84843 (69%)]\tLoss: 0.279492\n",
      "Train Epoch: 17 [58880/84843 (69%)]\tLoss: 0.522131\n",
      "Train Epoch: 17 [59520/84843 (70%)]\tLoss: 0.372107\n",
      "Train Epoch: 17 [60160/84843 (71%)]\tLoss: 0.329970\n",
      "Train Epoch: 17 [60800/84843 (72%)]\tLoss: 0.095265\n",
      "Train Epoch: 17 [61440/84843 (72%)]\tLoss: 0.203741\n",
      "Train Epoch: 17 [62080/84843 (73%)]\tLoss: 0.512701\n",
      "Train Epoch: 17 [62720/84843 (74%)]\tLoss: 0.182585\n",
      "Train Epoch: 17 [63360/84843 (75%)]\tLoss: 0.228265\n",
      "Train Epoch: 17 [64000/84843 (75%)]\tLoss: 0.508774\n",
      "Train Epoch: 17 [64640/84843 (76%)]\tLoss: 0.439190\n",
      "Train Epoch: 17 [65280/84843 (77%)]\tLoss: 0.495410\n",
      "Train Epoch: 17 [65920/84843 (78%)]\tLoss: 0.537258\n",
      "Train Epoch: 17 [66560/84843 (78%)]\tLoss: 0.294565\n",
      "Train Epoch: 17 [67200/84843 (79%)]\tLoss: 0.521403\n",
      "Train Epoch: 17 [67840/84843 (80%)]\tLoss: 0.222758\n",
      "Train Epoch: 17 [68480/84843 (81%)]\tLoss: 0.268526\n",
      "Train Epoch: 17 [69120/84843 (81%)]\tLoss: 0.176245\n",
      "Train Epoch: 17 [69760/84843 (82%)]\tLoss: 0.267987\n",
      "Train Epoch: 17 [70400/84843 (83%)]\tLoss: 0.475712\n",
      "Train Epoch: 17 [71040/84843 (84%)]\tLoss: 0.678557\n",
      "Train Epoch: 17 [71680/84843 (84%)]\tLoss: 0.095770\n",
      "Train Epoch: 17 [72320/84843 (85%)]\tLoss: 0.026971\n",
      "Train Epoch: 17 [72960/84843 (86%)]\tLoss: 0.389277\n",
      "Train Epoch: 17 [73600/84843 (87%)]\tLoss: 0.350037\n",
      "Train Epoch: 17 [74240/84843 (87%)]\tLoss: 0.189447\n",
      "Train Epoch: 17 [74880/84843 (88%)]\tLoss: 0.360347\n",
      "Train Epoch: 17 [75520/84843 (89%)]\tLoss: 0.340126\n",
      "Train Epoch: 17 [76160/84843 (90%)]\tLoss: 0.168477\n",
      "Train Epoch: 17 [76800/84843 (90%)]\tLoss: 0.622899\n",
      "Train Epoch: 17 [77440/84843 (91%)]\tLoss: 0.266404\n",
      "Train Epoch: 17 [78080/84843 (92%)]\tLoss: 0.295393\n",
      "Train Epoch: 17 [78720/84843 (93%)]\tLoss: 0.548656\n",
      "Train Epoch: 17 [79360/84843 (94%)]\tLoss: 0.322207\n",
      "Train Epoch: 17 [80000/84843 (94%)]\tLoss: 0.438960\n",
      "Train Epoch: 17 [80640/84843 (95%)]\tLoss: 0.590945\n",
      "Train Epoch: 17 [81280/84843 (96%)]\tLoss: 0.413572\n",
      "Train Epoch: 17 [81920/84843 (97%)]\tLoss: 0.263094\n",
      "Train Epoch: 17 [82560/84843 (97%)]\tLoss: 0.482920\n",
      "Train Epoch: 17 [83200/84843 (98%)]\tLoss: 0.466496\n",
      "Train Epoch: 17 [83840/84843 (99%)]\tLoss: 0.216818\n",
      "Train Epoch: 17 [84480/84843 (100%)]\tLoss: 0.281934\n",
      "Accuracy: 9514/11005 (86%)\n",
      "\n",
      "Train Epoch: 18 [0/84843 (0%)]\tLoss: 0.122740\n",
      "Train Epoch: 18 [640/84843 (1%)]\tLoss: 0.256166\n",
      "Train Epoch: 18 [1280/84843 (2%)]\tLoss: 0.296598\n",
      "Train Epoch: 18 [1920/84843 (2%)]\tLoss: 0.389953\n",
      "Train Epoch: 18 [2560/84843 (3%)]\tLoss: 0.122498\n",
      "Train Epoch: 18 [3200/84843 (4%)]\tLoss: 0.245773\n",
      "Train Epoch: 18 [3840/84843 (5%)]\tLoss: 0.556997\n",
      "Train Epoch: 18 [4480/84843 (5%)]\tLoss: 0.261489\n",
      "Train Epoch: 18 [5120/84843 (6%)]\tLoss: 0.272207\n",
      "Train Epoch: 18 [5760/84843 (7%)]\tLoss: 0.228955\n",
      "Train Epoch: 18 [6400/84843 (8%)]\tLoss: 0.809568\n",
      "Train Epoch: 18 [7040/84843 (8%)]\tLoss: 0.443334\n",
      "Train Epoch: 18 [7680/84843 (9%)]\tLoss: 0.614289\n",
      "Train Epoch: 18 [8320/84843 (10%)]\tLoss: 0.218025\n",
      "Train Epoch: 18 [8960/84843 (11%)]\tLoss: 0.445476\n",
      "Train Epoch: 18 [9600/84843 (11%)]\tLoss: 0.309972\n",
      "Train Epoch: 18 [10240/84843 (12%)]\tLoss: 0.435534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [10880/84843 (13%)]\tLoss: 0.567463\n",
      "Train Epoch: 18 [11520/84843 (14%)]\tLoss: 0.407993\n",
      "Train Epoch: 18 [12160/84843 (14%)]\tLoss: 0.279603\n",
      "Train Epoch: 18 [12800/84843 (15%)]\tLoss: 0.514688\n",
      "Train Epoch: 18 [13440/84843 (16%)]\tLoss: 0.226527\n",
      "Train Epoch: 18 [14080/84843 (17%)]\tLoss: 0.585587\n",
      "Train Epoch: 18 [14720/84843 (17%)]\tLoss: 0.253296\n",
      "Train Epoch: 18 [15360/84843 (18%)]\tLoss: 0.391144\n",
      "Train Epoch: 18 [16000/84843 (19%)]\tLoss: 0.128084\n",
      "Train Epoch: 18 [16640/84843 (20%)]\tLoss: 0.236773\n",
      "Train Epoch: 18 [17280/84843 (20%)]\tLoss: 0.391316\n",
      "Train Epoch: 18 [17920/84843 (21%)]\tLoss: 0.799641\n",
      "Train Epoch: 18 [18560/84843 (22%)]\tLoss: 0.115183\n",
      "Train Epoch: 18 [19200/84843 (23%)]\tLoss: 0.173912\n",
      "Train Epoch: 18 [19840/84843 (23%)]\tLoss: 0.564562\n",
      "Train Epoch: 18 [20480/84843 (24%)]\tLoss: 0.393002\n",
      "Train Epoch: 18 [21120/84843 (25%)]\tLoss: 0.278547\n",
      "Train Epoch: 18 [21760/84843 (26%)]\tLoss: 0.195222\n",
      "Train Epoch: 18 [22400/84843 (26%)]\tLoss: 0.347320\n",
      "Train Epoch: 18 [23040/84843 (27%)]\tLoss: 0.301819\n",
      "Train Epoch: 18 [23680/84843 (28%)]\tLoss: 0.248612\n",
      "Train Epoch: 18 [24320/84843 (29%)]\tLoss: 0.154986\n",
      "Train Epoch: 18 [24960/84843 (29%)]\tLoss: 0.246096\n",
      "Train Epoch: 18 [25600/84843 (30%)]\tLoss: 0.204258\n",
      "Train Epoch: 18 [26240/84843 (31%)]\tLoss: 0.270729\n",
      "Train Epoch: 18 [26880/84843 (32%)]\tLoss: 0.419439\n",
      "Train Epoch: 18 [27520/84843 (32%)]\tLoss: 0.387498\n",
      "Train Epoch: 18 [28160/84843 (33%)]\tLoss: 0.638960\n",
      "Train Epoch: 18 [28800/84843 (34%)]\tLoss: 0.237175\n",
      "Train Epoch: 18 [29440/84843 (35%)]\tLoss: 0.632787\n",
      "Train Epoch: 18 [30080/84843 (35%)]\tLoss: 0.287906\n",
      "Train Epoch: 18 [30720/84843 (36%)]\tLoss: 0.547169\n",
      "Train Epoch: 18 [31360/84843 (37%)]\tLoss: 0.210553\n",
      "Train Epoch: 18 [32000/84843 (38%)]\tLoss: 0.186314\n",
      "Train Epoch: 18 [32640/84843 (38%)]\tLoss: 0.709840\n",
      "Train Epoch: 18 [33280/84843 (39%)]\tLoss: 0.130066\n",
      "Train Epoch: 18 [33920/84843 (40%)]\tLoss: 0.746983\n",
      "Train Epoch: 18 [34560/84843 (41%)]\tLoss: 0.333459\n",
      "Train Epoch: 18 [35200/84843 (41%)]\tLoss: 0.492194\n",
      "Train Epoch: 18 [35840/84843 (42%)]\tLoss: 0.088471\n",
      "Train Epoch: 18 [36480/84843 (43%)]\tLoss: 0.558944\n",
      "Train Epoch: 18 [37120/84843 (44%)]\tLoss: 0.430730\n",
      "Train Epoch: 18 [37760/84843 (44%)]\tLoss: 0.560195\n",
      "Train Epoch: 18 [38400/84843 (45%)]\tLoss: 0.474982\n",
      "Train Epoch: 18 [39040/84843 (46%)]\tLoss: 0.500423\n",
      "Train Epoch: 18 [39680/84843 (47%)]\tLoss: 0.478038\n",
      "Train Epoch: 18 [40320/84843 (48%)]\tLoss: 0.605276\n",
      "Train Epoch: 18 [40960/84843 (48%)]\tLoss: 0.709456\n",
      "Train Epoch: 18 [41600/84843 (49%)]\tLoss: 0.379550\n",
      "Train Epoch: 18 [42240/84843 (50%)]\tLoss: 0.415642\n",
      "Train Epoch: 18 [42880/84843 (51%)]\tLoss: 0.404502\n",
      "Train Epoch: 18 [43520/84843 (51%)]\tLoss: 0.411681\n",
      "Train Epoch: 18 [44160/84843 (52%)]\tLoss: 0.360056\n",
      "Train Epoch: 18 [44800/84843 (53%)]\tLoss: 0.707871\n",
      "Train Epoch: 18 [45440/84843 (54%)]\tLoss: 0.425337\n",
      "Train Epoch: 18 [46080/84843 (54%)]\tLoss: 0.542789\n",
      "Train Epoch: 18 [46720/84843 (55%)]\tLoss: 0.212519\n",
      "Train Epoch: 18 [47360/84843 (56%)]\tLoss: 0.476787\n",
      "Train Epoch: 18 [48000/84843 (57%)]\tLoss: 0.166057\n",
      "Train Epoch: 18 [48640/84843 (57%)]\tLoss: 0.279460\n",
      "Train Epoch: 18 [49280/84843 (58%)]\tLoss: 0.125568\n",
      "Train Epoch: 18 [49920/84843 (59%)]\tLoss: 0.481813\n",
      "Train Epoch: 18 [50560/84843 (60%)]\tLoss: 0.412657\n",
      "Train Epoch: 18 [51200/84843 (60%)]\tLoss: 0.582075\n",
      "Train Epoch: 18 [51840/84843 (61%)]\tLoss: 0.371391\n",
      "Train Epoch: 18 [52480/84843 (62%)]\tLoss: 0.270883\n",
      "Train Epoch: 18 [53120/84843 (63%)]\tLoss: 0.434392\n",
      "Train Epoch: 18 [53760/84843 (63%)]\tLoss: 0.216498\n",
      "Train Epoch: 18 [54400/84843 (64%)]\tLoss: 0.793804\n",
      "Train Epoch: 18 [55040/84843 (65%)]\tLoss: 0.457924\n",
      "Train Epoch: 18 [55680/84843 (66%)]\tLoss: 0.304381\n",
      "Train Epoch: 18 [56320/84843 (66%)]\tLoss: 0.162742\n",
      "Train Epoch: 18 [56960/84843 (67%)]\tLoss: 1.010724\n",
      "Train Epoch: 18 [57600/84843 (68%)]\tLoss: 0.180028\n",
      "Train Epoch: 18 [58240/84843 (69%)]\tLoss: 0.312619\n",
      "Train Epoch: 18 [58880/84843 (69%)]\tLoss: 0.235012\n",
      "Train Epoch: 18 [59520/84843 (70%)]\tLoss: 0.140841\n",
      "Train Epoch: 18 [60160/84843 (71%)]\tLoss: 0.388260\n",
      "Train Epoch: 18 [60800/84843 (72%)]\tLoss: 0.251377\n",
      "Train Epoch: 18 [61440/84843 (72%)]\tLoss: 0.434596\n",
      "Train Epoch: 18 [62080/84843 (73%)]\tLoss: 0.502710\n",
      "Train Epoch: 18 [62720/84843 (74%)]\tLoss: 0.425661\n",
      "Train Epoch: 18 [63360/84843 (75%)]\tLoss: 0.625003\n",
      "Train Epoch: 18 [64000/84843 (75%)]\tLoss: 0.250968\n",
      "Train Epoch: 18 [64640/84843 (76%)]\tLoss: 0.345079\n",
      "Train Epoch: 18 [65280/84843 (77%)]\tLoss: 0.436758\n",
      "Train Epoch: 18 [65920/84843 (78%)]\tLoss: 0.376445\n",
      "Train Epoch: 18 [66560/84843 (78%)]\tLoss: 0.595054\n",
      "Train Epoch: 18 [67200/84843 (79%)]\tLoss: 0.198826\n",
      "Train Epoch: 18 [67840/84843 (80%)]\tLoss: 0.631551\n",
      "Train Epoch: 18 [68480/84843 (81%)]\tLoss: 0.166043\n",
      "Train Epoch: 18 [69120/84843 (81%)]\tLoss: 0.263840\n",
      "Train Epoch: 18 [69760/84843 (82%)]\tLoss: 0.349097\n",
      "Train Epoch: 18 [70400/84843 (83%)]\tLoss: 0.501022\n",
      "Train Epoch: 18 [71040/84843 (84%)]\tLoss: 0.607306\n",
      "Train Epoch: 18 [71680/84843 (84%)]\tLoss: 0.832661\n",
      "Train Epoch: 18 [72320/84843 (85%)]\tLoss: 0.454963\n",
      "Train Epoch: 18 [72960/84843 (86%)]\tLoss: 0.208539\n",
      "Train Epoch: 18 [73600/84843 (87%)]\tLoss: 0.381853\n",
      "Train Epoch: 18 [74240/84843 (87%)]\tLoss: 0.355938\n",
      "Train Epoch: 18 [74880/84843 (88%)]\tLoss: 0.333095\n",
      "Train Epoch: 18 [75520/84843 (89%)]\tLoss: 0.275335\n",
      "Train Epoch: 18 [76160/84843 (90%)]\tLoss: 0.278941\n",
      "Train Epoch: 18 [76800/84843 (90%)]\tLoss: 0.175876\n",
      "Train Epoch: 18 [77440/84843 (91%)]\tLoss: 0.699850\n",
      "Train Epoch: 18 [78080/84843 (92%)]\tLoss: 0.434739\n",
      "Train Epoch: 18 [78720/84843 (93%)]\tLoss: 0.416669\n",
      "Train Epoch: 18 [79360/84843 (94%)]\tLoss: 0.809215\n",
      "Train Epoch: 18 [80000/84843 (94%)]\tLoss: 0.555958\n",
      "Train Epoch: 18 [80640/84843 (95%)]\tLoss: 0.240847\n",
      "Train Epoch: 18 [81280/84843 (96%)]\tLoss: 0.668409\n",
      "Train Epoch: 18 [81920/84843 (97%)]\tLoss: 0.273630\n",
      "Train Epoch: 18 [82560/84843 (97%)]\tLoss: 0.099669\n",
      "Train Epoch: 18 [83200/84843 (98%)]\tLoss: 0.313753\n",
      "Train Epoch: 18 [83840/84843 (99%)]\tLoss: 0.564428\n",
      "Train Epoch: 18 [84480/84843 (100%)]\tLoss: 0.638617\n",
      "Accuracy: 9451/11005 (86%)\n",
      "\n",
      "Train Epoch: 19 [0/84843 (0%)]\tLoss: 0.250084\n",
      "Train Epoch: 19 [640/84843 (1%)]\tLoss: 0.131968\n",
      "Train Epoch: 19 [1280/84843 (2%)]\tLoss: 0.345225\n",
      "Train Epoch: 19 [1920/84843 (2%)]\tLoss: 0.392618\n",
      "Train Epoch: 19 [2560/84843 (3%)]\tLoss: 0.165544\n",
      "Train Epoch: 19 [3200/84843 (4%)]\tLoss: 0.381177\n",
      "Train Epoch: 19 [3840/84843 (5%)]\tLoss: 0.395457\n",
      "Train Epoch: 19 [4480/84843 (5%)]\tLoss: 0.277089\n",
      "Train Epoch: 19 [5120/84843 (6%)]\tLoss: 0.431597\n",
      "Train Epoch: 19 [5760/84843 (7%)]\tLoss: 0.160412\n",
      "Train Epoch: 19 [6400/84843 (8%)]\tLoss: 0.529635\n",
      "Train Epoch: 19 [7040/84843 (8%)]\tLoss: 0.161891\n",
      "Train Epoch: 19 [7680/84843 (9%)]\tLoss: 0.139640\n",
      "Train Epoch: 19 [8320/84843 (10%)]\tLoss: 0.324246\n",
      "Train Epoch: 19 [8960/84843 (11%)]\tLoss: 0.547650\n",
      "Train Epoch: 19 [9600/84843 (11%)]\tLoss: 0.187934\n",
      "Train Epoch: 19 [10240/84843 (12%)]\tLoss: 0.338278\n",
      "Train Epoch: 19 [10880/84843 (13%)]\tLoss: 0.247639\n",
      "Train Epoch: 19 [11520/84843 (14%)]\tLoss: 0.362011\n",
      "Train Epoch: 19 [12160/84843 (14%)]\tLoss: 0.485147\n",
      "Train Epoch: 19 [12800/84843 (15%)]\tLoss: 0.105194\n",
      "Train Epoch: 19 [13440/84843 (16%)]\tLoss: 0.176260\n",
      "Train Epoch: 19 [14080/84843 (17%)]\tLoss: 0.468605\n",
      "Train Epoch: 19 [14720/84843 (17%)]\tLoss: 0.441556\n",
      "Train Epoch: 19 [15360/84843 (18%)]\tLoss: 0.167329\n",
      "Train Epoch: 19 [16000/84843 (19%)]\tLoss: 0.198473\n",
      "Train Epoch: 19 [16640/84843 (20%)]\tLoss: 0.358261\n",
      "Train Epoch: 19 [17280/84843 (20%)]\tLoss: 0.250763\n",
      "Train Epoch: 19 [17920/84843 (21%)]\tLoss: 0.249974\n",
      "Train Epoch: 19 [18560/84843 (22%)]\tLoss: 0.371987\n",
      "Train Epoch: 19 [19200/84843 (23%)]\tLoss: 0.495777\n",
      "Train Epoch: 19 [19840/84843 (23%)]\tLoss: 0.207733\n",
      "Train Epoch: 19 [20480/84843 (24%)]\tLoss: 0.429985\n",
      "Train Epoch: 19 [21120/84843 (25%)]\tLoss: 0.447517\n",
      "Train Epoch: 19 [21760/84843 (26%)]\tLoss: 0.228724\n",
      "Train Epoch: 19 [22400/84843 (26%)]\tLoss: 0.474915\n",
      "Train Epoch: 19 [23040/84843 (27%)]\tLoss: 0.434936\n",
      "Train Epoch: 19 [23680/84843 (28%)]\tLoss: 0.423941\n",
      "Train Epoch: 19 [24320/84843 (29%)]\tLoss: 0.339337\n",
      "Train Epoch: 19 [24960/84843 (29%)]\tLoss: 0.472012\n",
      "Train Epoch: 19 [25600/84843 (30%)]\tLoss: 0.287959\n",
      "Train Epoch: 19 [26240/84843 (31%)]\tLoss: 0.330687\n",
      "Train Epoch: 19 [26880/84843 (32%)]\tLoss: 0.223549\n",
      "Train Epoch: 19 [27520/84843 (32%)]\tLoss: 0.090345\n",
      "Train Epoch: 19 [28160/84843 (33%)]\tLoss: 0.044289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [28800/84843 (34%)]\tLoss: 0.230917\n",
      "Train Epoch: 19 [29440/84843 (35%)]\tLoss: 0.570217\n",
      "Train Epoch: 19 [30080/84843 (35%)]\tLoss: 0.161679\n",
      "Train Epoch: 19 [30720/84843 (36%)]\tLoss: 0.416764\n",
      "Train Epoch: 19 [31360/84843 (37%)]\tLoss: 0.466276\n",
      "Train Epoch: 19 [32000/84843 (38%)]\tLoss: 0.225475\n",
      "Train Epoch: 19 [32640/84843 (38%)]\tLoss: 0.219609\n",
      "Train Epoch: 19 [33280/84843 (39%)]\tLoss: 0.315111\n",
      "Train Epoch: 19 [33920/84843 (40%)]\tLoss: 0.660868\n",
      "Train Epoch: 19 [34560/84843 (41%)]\tLoss: 0.190762\n",
      "Train Epoch: 19 [35200/84843 (41%)]\tLoss: 0.244937\n",
      "Train Epoch: 19 [35840/84843 (42%)]\tLoss: 0.518983\n",
      "Train Epoch: 19 [36480/84843 (43%)]\tLoss: 0.774919\n",
      "Train Epoch: 19 [37120/84843 (44%)]\tLoss: 0.283380\n",
      "Train Epoch: 19 [37760/84843 (44%)]\tLoss: 0.402310\n",
      "Train Epoch: 19 [38400/84843 (45%)]\tLoss: 0.186124\n",
      "Train Epoch: 19 [39040/84843 (46%)]\tLoss: 0.444957\n",
      "Train Epoch: 19 [39680/84843 (47%)]\tLoss: 0.537916\n",
      "Train Epoch: 19 [40320/84843 (48%)]\tLoss: 0.376470\n",
      "Train Epoch: 19 [40960/84843 (48%)]\tLoss: 0.405260\n",
      "Train Epoch: 19 [41600/84843 (49%)]\tLoss: 0.334648\n",
      "Train Epoch: 19 [42240/84843 (50%)]\tLoss: 0.414670\n",
      "Train Epoch: 19 [42880/84843 (51%)]\tLoss: 0.063401\n",
      "Train Epoch: 19 [43520/84843 (51%)]\tLoss: 0.257267\n",
      "Train Epoch: 19 [44160/84843 (52%)]\tLoss: 0.458178\n",
      "Train Epoch: 19 [44800/84843 (53%)]\tLoss: 0.368110\n",
      "Train Epoch: 19 [45440/84843 (54%)]\tLoss: 0.129630\n",
      "Train Epoch: 19 [46080/84843 (54%)]\tLoss: 0.142011\n",
      "Train Epoch: 19 [46720/84843 (55%)]\tLoss: 0.292363\n",
      "Train Epoch: 19 [47360/84843 (56%)]\tLoss: 0.737645\n",
      "Train Epoch: 19 [48000/84843 (57%)]\tLoss: 0.418864\n",
      "Train Epoch: 19 [48640/84843 (57%)]\tLoss: 0.148981\n",
      "Train Epoch: 19 [49280/84843 (58%)]\tLoss: 0.735639\n",
      "Train Epoch: 19 [49920/84843 (59%)]\tLoss: 0.226850\n",
      "Train Epoch: 19 [50560/84843 (60%)]\tLoss: 0.314890\n",
      "Train Epoch: 19 [51200/84843 (60%)]\tLoss: 0.362792\n",
      "Train Epoch: 19 [51840/84843 (61%)]\tLoss: 0.295867\n",
      "Train Epoch: 19 [52480/84843 (62%)]\tLoss: 0.642377\n",
      "Train Epoch: 19 [53120/84843 (63%)]\tLoss: 0.220372\n",
      "Train Epoch: 19 [53760/84843 (63%)]\tLoss: 0.437860\n",
      "Train Epoch: 19 [54400/84843 (64%)]\tLoss: 0.520058\n",
      "Train Epoch: 19 [55040/84843 (65%)]\tLoss: 0.216365\n",
      "Train Epoch: 19 [55680/84843 (66%)]\tLoss: 0.380990\n",
      "Train Epoch: 19 [56320/84843 (66%)]\tLoss: 0.487330\n",
      "Train Epoch: 19 [56960/84843 (67%)]\tLoss: 0.266937\n",
      "Train Epoch: 19 [57600/84843 (68%)]\tLoss: 0.382886\n",
      "Train Epoch: 19 [58240/84843 (69%)]\tLoss: 0.394225\n",
      "Train Epoch: 19 [58880/84843 (69%)]\tLoss: 0.295754\n",
      "Train Epoch: 19 [59520/84843 (70%)]\tLoss: 0.389184\n",
      "Train Epoch: 19 [60160/84843 (71%)]\tLoss: 0.338799\n",
      "Train Epoch: 19 [60800/84843 (72%)]\tLoss: 0.264414\n",
      "Train Epoch: 19 [61440/84843 (72%)]\tLoss: 0.255864\n",
      "Train Epoch: 19 [62080/84843 (73%)]\tLoss: 0.332471\n",
      "Train Epoch: 19 [62720/84843 (74%)]\tLoss: 0.397958\n",
      "Train Epoch: 19 [63360/84843 (75%)]\tLoss: 0.246533\n",
      "Train Epoch: 19 [64000/84843 (75%)]\tLoss: 0.126597\n",
      "Train Epoch: 19 [64640/84843 (76%)]\tLoss: 0.213981\n",
      "Train Epoch: 19 [65280/84843 (77%)]\tLoss: 0.327176\n",
      "Train Epoch: 19 [65920/84843 (78%)]\tLoss: 0.171569\n",
      "Train Epoch: 19 [66560/84843 (78%)]\tLoss: 0.184039\n",
      "Train Epoch: 19 [67200/84843 (79%)]\tLoss: 0.194242\n",
      "Train Epoch: 19 [67840/84843 (80%)]\tLoss: 0.288842\n",
      "Train Epoch: 19 [68480/84843 (81%)]\tLoss: 0.310668\n",
      "Train Epoch: 19 [69120/84843 (81%)]\tLoss: 0.167054\n",
      "Train Epoch: 19 [69760/84843 (82%)]\tLoss: 0.312150\n",
      "Train Epoch: 19 [70400/84843 (83%)]\tLoss: 0.274027\n",
      "Train Epoch: 19 [71040/84843 (84%)]\tLoss: 0.652817\n",
      "Train Epoch: 19 [71680/84843 (84%)]\tLoss: 0.229894\n",
      "Train Epoch: 19 [72320/84843 (85%)]\tLoss: 0.290590\n",
      "Train Epoch: 19 [72960/84843 (86%)]\tLoss: 0.400951\n",
      "Train Epoch: 19 [73600/84843 (87%)]\tLoss: 0.199749\n",
      "Train Epoch: 19 [74240/84843 (87%)]\tLoss: 0.469142\n",
      "Train Epoch: 19 [74880/84843 (88%)]\tLoss: 0.428917\n",
      "Train Epoch: 19 [75520/84843 (89%)]\tLoss: 0.469238\n",
      "Train Epoch: 19 [76160/84843 (90%)]\tLoss: 0.376414\n",
      "Train Epoch: 19 [76800/84843 (90%)]\tLoss: 0.199573\n",
      "Train Epoch: 19 [77440/84843 (91%)]\tLoss: 0.532584\n",
      "Train Epoch: 19 [78080/84843 (92%)]\tLoss: 0.347858\n",
      "Train Epoch: 19 [78720/84843 (93%)]\tLoss: 0.225262\n",
      "Train Epoch: 19 [79360/84843 (94%)]\tLoss: 0.511340\n",
      "Train Epoch: 19 [80000/84843 (94%)]\tLoss: 0.216290\n",
      "Train Epoch: 19 [80640/84843 (95%)]\tLoss: 0.739163\n",
      "Train Epoch: 19 [81280/84843 (96%)]\tLoss: 0.400600\n",
      "Train Epoch: 19 [81920/84843 (97%)]\tLoss: 0.427202\n",
      "Train Epoch: 19 [82560/84843 (97%)]\tLoss: 0.170613\n",
      "Train Epoch: 19 [83200/84843 (98%)]\tLoss: 0.766412\n",
      "Train Epoch: 19 [83840/84843 (99%)]\tLoss: 0.353300\n",
      "Train Epoch: 19 [84480/84843 (100%)]\tLoss: 0.661304\n",
      "Accuracy: 9417/11005 (86%)\n",
      "\n",
      "Train Epoch: 20 [0/84843 (0%)]\tLoss: 0.192027\n",
      "Train Epoch: 20 [640/84843 (1%)]\tLoss: 0.417463\n",
      "Train Epoch: 20 [1280/84843 (2%)]\tLoss: 0.389809\n",
      "Train Epoch: 20 [1920/84843 (2%)]\tLoss: 0.339030\n",
      "Train Epoch: 20 [2560/84843 (3%)]\tLoss: 0.196972\n",
      "Train Epoch: 20 [3200/84843 (4%)]\tLoss: 0.497511\n",
      "Train Epoch: 20 [3840/84843 (5%)]\tLoss: 0.346277\n",
      "Train Epoch: 20 [4480/84843 (5%)]\tLoss: 0.214113\n",
      "Train Epoch: 20 [5120/84843 (6%)]\tLoss: 0.433021\n",
      "Train Epoch: 20 [5760/84843 (7%)]\tLoss: 0.338819\n",
      "Train Epoch: 20 [6400/84843 (8%)]\tLoss: 0.098725\n",
      "Train Epoch: 20 [7040/84843 (8%)]\tLoss: 0.242712\n",
      "Train Epoch: 20 [7680/84843 (9%)]\tLoss: 0.249488\n",
      "Train Epoch: 20 [8320/84843 (10%)]\tLoss: 0.354118\n",
      "Train Epoch: 20 [8960/84843 (11%)]\tLoss: 0.558724\n",
      "Train Epoch: 20 [9600/84843 (11%)]\tLoss: 0.147716\n",
      "Train Epoch: 20 [10240/84843 (12%)]\tLoss: 0.385054\n",
      "Train Epoch: 20 [10880/84843 (13%)]\tLoss: 0.092780\n",
      "Train Epoch: 20 [11520/84843 (14%)]\tLoss: 0.309151\n",
      "Train Epoch: 20 [12160/84843 (14%)]\tLoss: 0.116425\n",
      "Train Epoch: 20 [12800/84843 (15%)]\tLoss: 0.283024\n",
      "Train Epoch: 20 [13440/84843 (16%)]\tLoss: 0.327668\n",
      "Train Epoch: 20 [14080/84843 (17%)]\tLoss: 0.452624\n",
      "Train Epoch: 20 [14720/84843 (17%)]\tLoss: 0.178706\n",
      "Train Epoch: 20 [15360/84843 (18%)]\tLoss: 0.290483\n",
      "Train Epoch: 20 [16000/84843 (19%)]\tLoss: 0.387447\n",
      "Train Epoch: 20 [16640/84843 (20%)]\tLoss: 0.325563\n",
      "Train Epoch: 20 [17280/84843 (20%)]\tLoss: 0.200769\n",
      "Train Epoch: 20 [17920/84843 (21%)]\tLoss: 0.509689\n",
      "Train Epoch: 20 [18560/84843 (22%)]\tLoss: 0.472407\n",
      "Train Epoch: 20 [19200/84843 (23%)]\tLoss: 0.501578\n",
      "Train Epoch: 20 [19840/84843 (23%)]\tLoss: 0.729377\n",
      "Train Epoch: 20 [20480/84843 (24%)]\tLoss: 0.218480\n",
      "Train Epoch: 20 [21120/84843 (25%)]\tLoss: 0.255486\n",
      "Train Epoch: 20 [21760/84843 (26%)]\tLoss: 0.176917\n",
      "Train Epoch: 20 [22400/84843 (26%)]\tLoss: 0.216734\n",
      "Train Epoch: 20 [23040/84843 (27%)]\tLoss: 0.437340\n",
      "Train Epoch: 20 [23680/84843 (28%)]\tLoss: 0.211603\n",
      "Train Epoch: 20 [24320/84843 (29%)]\tLoss: 0.149665\n",
      "Train Epoch: 20 [24960/84843 (29%)]\tLoss: 0.807816\n",
      "Train Epoch: 20 [25600/84843 (30%)]\tLoss: 0.156882\n",
      "Train Epoch: 20 [26240/84843 (31%)]\tLoss: 0.534207\n",
      "Train Epoch: 20 [26880/84843 (32%)]\tLoss: 0.899497\n",
      "Train Epoch: 20 [27520/84843 (32%)]\tLoss: 0.394673\n",
      "Train Epoch: 20 [28160/84843 (33%)]\tLoss: 0.139126\n",
      "Train Epoch: 20 [28800/84843 (34%)]\tLoss: 0.199618\n",
      "Train Epoch: 20 [29440/84843 (35%)]\tLoss: 0.124364\n",
      "Train Epoch: 20 [30080/84843 (35%)]\tLoss: 0.231470\n",
      "Train Epoch: 20 [30720/84843 (36%)]\tLoss: 0.391265\n",
      "Train Epoch: 20 [31360/84843 (37%)]\tLoss: 0.521643\n",
      "Train Epoch: 20 [32000/84843 (38%)]\tLoss: 0.307719\n",
      "Train Epoch: 20 [32640/84843 (38%)]\tLoss: 0.258070\n",
      "Train Epoch: 20 [33280/84843 (39%)]\tLoss: 0.218623\n",
      "Train Epoch: 20 [33920/84843 (40%)]\tLoss: 0.304234\n",
      "Train Epoch: 20 [34560/84843 (41%)]\tLoss: 0.326351\n",
      "Train Epoch: 20 [35200/84843 (41%)]\tLoss: 0.171632\n",
      "Train Epoch: 20 [35840/84843 (42%)]\tLoss: 0.277878\n",
      "Train Epoch: 20 [36480/84843 (43%)]\tLoss: 0.170360\n",
      "Train Epoch: 20 [37120/84843 (44%)]\tLoss: 0.350457\n",
      "Train Epoch: 20 [37760/84843 (44%)]\tLoss: 0.324453\n",
      "Train Epoch: 20 [38400/84843 (45%)]\tLoss: 0.231054\n",
      "Train Epoch: 20 [39040/84843 (46%)]\tLoss: 0.446101\n",
      "Train Epoch: 20 [39680/84843 (47%)]\tLoss: 0.172221\n",
      "Train Epoch: 20 [40320/84843 (48%)]\tLoss: 0.260894\n",
      "Train Epoch: 20 [40960/84843 (48%)]\tLoss: 0.245582\n",
      "Train Epoch: 20 [41600/84843 (49%)]\tLoss: 0.521884\n",
      "Train Epoch: 20 [42240/84843 (50%)]\tLoss: 0.218848\n",
      "Train Epoch: 20 [42880/84843 (51%)]\tLoss: 0.246361\n",
      "Train Epoch: 20 [43520/84843 (51%)]\tLoss: 0.519179\n",
      "Train Epoch: 20 [44160/84843 (52%)]\tLoss: 0.722572\n",
      "Train Epoch: 20 [44800/84843 (53%)]\tLoss: 0.290432\n",
      "Train Epoch: 20 [45440/84843 (54%)]\tLoss: 0.358767\n",
      "Train Epoch: 20 [46080/84843 (54%)]\tLoss: 0.349921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [46720/84843 (55%)]\tLoss: 0.522850\n",
      "Train Epoch: 20 [47360/84843 (56%)]\tLoss: 0.317932\n",
      "Train Epoch: 20 [48000/84843 (57%)]\tLoss: 0.714553\n",
      "Train Epoch: 20 [48640/84843 (57%)]\tLoss: 0.331549\n",
      "Train Epoch: 20 [49280/84843 (58%)]\tLoss: 0.338114\n",
      "Train Epoch: 20 [49920/84843 (59%)]\tLoss: 0.450678\n",
      "Train Epoch: 20 [50560/84843 (60%)]\tLoss: 0.327990\n",
      "Train Epoch: 20 [51200/84843 (60%)]\tLoss: 0.252806\n",
      "Train Epoch: 20 [51840/84843 (61%)]\tLoss: 0.303290\n",
      "Train Epoch: 20 [52480/84843 (62%)]\tLoss: 0.922283\n",
      "Train Epoch: 20 [53120/84843 (63%)]\tLoss: 0.398921\n",
      "Train Epoch: 20 [53760/84843 (63%)]\tLoss: 0.341955\n",
      "Train Epoch: 20 [54400/84843 (64%)]\tLoss: 0.525481\n",
      "Train Epoch: 20 [55040/84843 (65%)]\tLoss: 0.431597\n",
      "Train Epoch: 20 [55680/84843 (66%)]\tLoss: 0.780367\n",
      "Train Epoch: 20 [56320/84843 (66%)]\tLoss: 0.378198\n",
      "Train Epoch: 20 [56960/84843 (67%)]\tLoss: 0.292054\n",
      "Train Epoch: 20 [57600/84843 (68%)]\tLoss: 0.219422\n",
      "Train Epoch: 20 [58240/84843 (69%)]\tLoss: 0.466148\n",
      "Train Epoch: 20 [58880/84843 (69%)]\tLoss: 0.255114\n",
      "Train Epoch: 20 [59520/84843 (70%)]\tLoss: 0.538214\n",
      "Train Epoch: 20 [60160/84843 (71%)]\tLoss: 0.053422\n",
      "Train Epoch: 20 [60800/84843 (72%)]\tLoss: 0.172231\n",
      "Train Epoch: 20 [61440/84843 (72%)]\tLoss: 0.489238\n",
      "Train Epoch: 20 [62080/84843 (73%)]\tLoss: 0.468396\n",
      "Train Epoch: 20 [62720/84843 (74%)]\tLoss: 0.253564\n",
      "Train Epoch: 20 [63360/84843 (75%)]\tLoss: 0.651642\n",
      "Train Epoch: 20 [64000/84843 (75%)]\tLoss: 0.489504\n",
      "Train Epoch: 20 [64640/84843 (76%)]\tLoss: 0.582061\n",
      "Train Epoch: 20 [65280/84843 (77%)]\tLoss: 0.284230\n",
      "Train Epoch: 20 [65920/84843 (78%)]\tLoss: 0.509627\n",
      "Train Epoch: 20 [66560/84843 (78%)]\tLoss: 0.243718\n",
      "Train Epoch: 20 [67200/84843 (79%)]\tLoss: 0.336202\n",
      "Train Epoch: 20 [67840/84843 (80%)]\tLoss: 0.702901\n",
      "Train Epoch: 20 [68480/84843 (81%)]\tLoss: 0.359957\n",
      "Train Epoch: 20 [69120/84843 (81%)]\tLoss: 0.141589\n",
      "Train Epoch: 20 [69760/84843 (82%)]\tLoss: 0.181984\n",
      "Train Epoch: 20 [70400/84843 (83%)]\tLoss: 0.229628\n",
      "Train Epoch: 20 [71040/84843 (84%)]\tLoss: 0.570280\n",
      "Train Epoch: 20 [71680/84843 (84%)]\tLoss: 0.440835\n",
      "Train Epoch: 20 [72320/84843 (85%)]\tLoss: 0.603675\n",
      "Train Epoch: 20 [72960/84843 (86%)]\tLoss: 0.331546\n",
      "Train Epoch: 20 [73600/84843 (87%)]\tLoss: 0.208505\n",
      "Train Epoch: 20 [74240/84843 (87%)]\tLoss: 0.392655\n",
      "Train Epoch: 20 [74880/84843 (88%)]\tLoss: 0.357599\n",
      "Train Epoch: 20 [75520/84843 (89%)]\tLoss: 0.055957\n",
      "Train Epoch: 20 [76160/84843 (90%)]\tLoss: 0.550438\n",
      "Train Epoch: 20 [76800/84843 (90%)]\tLoss: 0.482063\n",
      "Train Epoch: 20 [77440/84843 (91%)]\tLoss: 0.295447\n",
      "Train Epoch: 20 [78080/84843 (92%)]\tLoss: 0.670051\n",
      "Train Epoch: 20 [78720/84843 (93%)]\tLoss: 0.180150\n",
      "Train Epoch: 20 [79360/84843 (94%)]\tLoss: 0.351679\n",
      "Train Epoch: 20 [80000/84843 (94%)]\tLoss: 0.399308\n",
      "Train Epoch: 20 [80640/84843 (95%)]\tLoss: 0.187548\n",
      "Train Epoch: 20 [81280/84843 (96%)]\tLoss: 0.393810\n",
      "Train Epoch: 20 [81920/84843 (97%)]\tLoss: 0.560734\n",
      "Train Epoch: 20 [82560/84843 (97%)]\tLoss: 0.253128\n",
      "Train Epoch: 20 [83200/84843 (98%)]\tLoss: 0.251013\n",
      "Train Epoch: 20 [83840/84843 (99%)]\tLoss: 0.053953\n",
      "Train Epoch: 20 [84480/84843 (100%)]\tLoss: 0.264147\n",
      "Accuracy: 9516/11005 (86%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# longer retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 20\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(long_retrained_converted_model, epoch, log_interval)\n",
    "        test(long_retrained_converted_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e726316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77708/84843 (92%)\n",
      "\n",
      "Accuracy: 8725/9981 (87%)\n",
      "\n",
      "Accuracy: 9516/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(long_retrained_converted_model, train_loader)\n",
    "test(long_retrained_converted_model, val_loader)\n",
    "test(long_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdfcbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### save models\n",
    "\n",
    "# model_name = 'sample_FGN_converted_model_SPEECHCOMMANDS'\n",
    "# save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0ef9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'sample_FGN_converted_fast_retrained_model_SPEECHCOMMANDS'\n",
    "\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(fast_retrained_converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(fast_retrained_converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eace12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'sample_FGN_converted_long_retrained_model_SPEECHCOMMANDS'\n",
    "\n",
    "# print('Saving trained model {} in {}'.format(model_name, save_path))\n",
    "\n",
    "# # save model converted_model\n",
    "# torch.save(long_retrained_converted_model, save_path+model_name+'_full.pth')\n",
    "\n",
    "# # save model weights\n",
    "# torch.save(long_retrained_converted_model.state_dict(), save_path+model_name+'_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54fa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
