{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce12f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of various conv1d models on the SPEECHCOMMANDS dataset\n",
    "# classic / fgn trained from scratch / converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f16bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c81a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb27928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad07c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110be973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b60f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_loader, val_loader, test_loader) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "                                                                          batch_size = 32,\n",
    "                                                                          batchsize_for_val =32,\n",
    "                                                                          num_workers=5, \n",
    "                                                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4570dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to test models\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "    print(f\"Accuracy: {correct}/{len(loader.dataset)} ({100. * correct / len(loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b27576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model classes\n",
    "\n",
    "## classic model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "    \n",
    "# FGN model    \n",
    "class FGN_M5(nn.Module):\n",
    "    \n",
    "    # changes:\n",
    "    # nn.Conv1d -> fgnl.FGN_Conv1d\n",
    "    # added g to conv inputs and outputs\n",
    "    # make sure you pass g through the same pooling steps as x\n",
    "    \n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.fgn_conv1 = fgnl.FGN_Conv1d(in_channels=n_input, out_channels=n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv2 = fgnl.FGN_Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv3 = fgnl.FGN_Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv4 = fgnl.FGN_Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        \n",
    "        #TODO change to self.pool1d_fgn() for each pooling of Gs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, g = self.fgn_conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        g = self.pool1(g)\n",
    "        x, g = self.fgn_conv2(x, g)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        g = self.pool2(g)\n",
    "        x, g = self.fgn_conv3(x ,g)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        g = self.pool3(g)\n",
    "        x, _ = self.fgn_conv4(x, g)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570df71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "\n",
    "classic_model_name= 'sample_classic_model_SPEECHCOMMANDS'\n",
    "fgn_model_name = 'sample_FGN_model_SPEECHCOMMANDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b733ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M5(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_model = M5()\n",
    "classic_model.load_state_dict(torch.load(save_path+classic_model_name+'_state_dict.pth'))\n",
    "classic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d421b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgn_model = FGN_M5()\n",
    "fgn_model.load_state_dict(torch.load(save_path+fgn_model_name+'_state_dict.pth'))\n",
    "fgn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d6c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test models\n",
    "test(classic_model, train_loader)\n",
    "test(classic_model, val_loader)\n",
    "test(classic_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26887222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(fgn_model, train_loader)\n",
    "test(fgn_model, val_loader)\n",
    "test(fgn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579deba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb16bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_model = copy.deepcopy(fgn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b624a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73489/84843 (87%)\n",
      "\n",
      "Accuracy: 8572/9981 (86%)\n",
      "\n",
      "Accuracy: 9244/11005 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e12d9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "converting conv layer\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n",
      "transfering state_dicts\n"
     ]
    }
   ],
   "source": [
    "for classic_model_layer,fgn_model_layer in zip(classic_model.children(), converted_model.children()):\n",
    "\n",
    "    if type(fgn_model_layer)==fgnl.FGN_Conv1d:\n",
    "        print('converting conv layer')\n",
    "        fgnl.convert_layer_conv1D_to_fgn(classic_model_layer,fgn_model_layer)\n",
    "    else:\n",
    "        print('transfering state_dicts')\n",
    "        fgn_model_layer.load_state_dict(classic_model_layer.state_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30d5ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the converted model matches classic behavior\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5be4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76655/84843 (90%)\n",
      "\n",
      "Accuracy: 8755/9981 (88%)\n",
      "\n",
      "Accuracy: 9468/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the original model hasn't changed\n",
    "test(converted_model, train_loader)\n",
    "test(converted_model, val_loader)\n",
    "test(converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74b9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a803b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f450fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189c9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target) + lmbda_sigma*fgnl.sigmas_loss(model, covar_type='sphere')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd3d63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_retrained_converted_model = copy.deepcopy(converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "044ff4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda_sigma = 1e-5\n",
    "optimizer = optim.Adam(fast_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# note LR is 10x smaller because the models have already beenm trained for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dfe4969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668b76a67cda4e42aeb0ea5fbf3f9f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 569473.375000\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.607516\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.570802\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.648478\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.708704\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.730980\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.626619\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.695850\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.983909\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.553858\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.457170\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 1.158071\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.466663\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.771917\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.537751\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.492841\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 0.779520\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.670316\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.635499\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.592665\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.750289\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.644955\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 1.070051\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 1.041631\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.741574\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.956067\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.693849\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 0.722164\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.481698\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 0.426834\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 1.126073\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.948112\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.757819\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.561019\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.938233\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 0.829423\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.657344\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 0.764391\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.872260\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.715708\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 1.020259\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.848597\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.696127\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 1.046784\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.820373\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 1.036655\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.883641\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.689304\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.804595\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.829452\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.623385\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.725424\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.572220\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 1.021865\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.662050\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.857585\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.558829\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.601104\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.732862\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.479769\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.629599\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.752116\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.612089\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 1.086114\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 0.426215\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.694166\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.728338\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.604710\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.951862\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.741631\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.680084\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.807896\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.525820\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.824837\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.475101\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.680812\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.645855\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.491031\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.619066\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.369544\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.542176\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 1.211060\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.556517\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.864958\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.776596\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.863776\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.929258\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.604522\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.883176\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.557961\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.386290\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.724915\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.437231\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.939741\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.539730\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.581794\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.506001\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 1.164087\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.525264\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.971455\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.407963\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.803307\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.535547\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.797529\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.636595\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.835892\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.842108\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.652542\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.848379\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 0.721519\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.381687\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.802017\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.581285\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.739791\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.755316\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.872746\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.682968\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.664005\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 0.429282\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.743546\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.791254\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 1.000588\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 0.580485\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.750069\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 0.501429\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 0.523842\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.667943\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.854810\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 1.125525\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 0.806259\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.474848\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.786612\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.507478\n",
      "Accuracy: 9418/11005 (86%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 1\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(fast_retrained_converted_model, epoch, log_interval)\n",
    "        test(fast_retrained_converted_model, test_loader)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce186fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76173/84843 (90%)\n",
      "\n",
      "Accuracy: 8702/9981 (87%)\n",
      "\n",
      "Accuracy: 9418/11005 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(fast_retrained_converted_model, train_loader)\n",
    "test(fast_retrained_converted_model, val_loader)\n",
    "test(fast_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee645ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bbc4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_retrained_converted_model = copy.deepcopy(fast_retrained_converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dced8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(long_retrained_converted_model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1932f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcca9b1afb14c7d88928037174cef65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: 0.593730\n",
      "Train Epoch: 1 [640/84843 (1%)]\tLoss: 0.647424\n",
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: 0.452424\n",
      "Train Epoch: 1 [1920/84843 (2%)]\tLoss: 0.463932\n",
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: 0.413830\n",
      "Train Epoch: 1 [3200/84843 (4%)]\tLoss: 0.455938\n",
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: 0.344253\n",
      "Train Epoch: 1 [4480/84843 (5%)]\tLoss: 0.723838\n",
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: 0.579033\n",
      "Train Epoch: 1 [5760/84843 (7%)]\tLoss: 0.629117\n",
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: 0.553000\n",
      "Train Epoch: 1 [7040/84843 (8%)]\tLoss: 0.416191\n",
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: 0.406114\n",
      "Train Epoch: 1 [8320/84843 (10%)]\tLoss: 0.372227\n",
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: 0.187963\n",
      "Train Epoch: 1 [9600/84843 (11%)]\tLoss: 0.497532\n",
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: 0.212778\n",
      "Train Epoch: 1 [10880/84843 (13%)]\tLoss: 0.368652\n",
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: 0.151380\n",
      "Train Epoch: 1 [12160/84843 (14%)]\tLoss: 0.392837\n",
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: 0.533434\n",
      "Train Epoch: 1 [13440/84843 (16%)]\tLoss: 0.295123\n",
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: 0.119574\n",
      "Train Epoch: 1 [14720/84843 (17%)]\tLoss: 0.449613\n",
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: 0.442154\n",
      "Train Epoch: 1 [16000/84843 (19%)]\tLoss: 0.646109\n",
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: 0.305885\n",
      "Train Epoch: 1 [17280/84843 (20%)]\tLoss: 0.425533\n",
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: 0.364707\n",
      "Train Epoch: 1 [18560/84843 (22%)]\tLoss: 0.182509\n",
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: 0.205809\n",
      "Train Epoch: 1 [19840/84843 (23%)]\tLoss: 0.311001\n",
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: 0.403750\n",
      "Train Epoch: 1 [21120/84843 (25%)]\tLoss: 0.968769\n",
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: 0.713004\n",
      "Train Epoch: 1 [22400/84843 (26%)]\tLoss: 0.529964\n",
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: 0.450986\n",
      "Train Epoch: 1 [23680/84843 (28%)]\tLoss: 0.454164\n",
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: 0.371408\n",
      "Train Epoch: 1 [24960/84843 (29%)]\tLoss: 0.457664\n",
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: 0.525151\n",
      "Train Epoch: 1 [26240/84843 (31%)]\tLoss: 0.405297\n",
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: 0.383052\n",
      "Train Epoch: 1 [27520/84843 (32%)]\tLoss: 0.509004\n",
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: 0.237589\n",
      "Train Epoch: 1 [28800/84843 (34%)]\tLoss: 0.212193\n",
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: 0.147084\n",
      "Train Epoch: 1 [30080/84843 (35%)]\tLoss: 0.482445\n",
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: 0.262520\n",
      "Train Epoch: 1 [31360/84843 (37%)]\tLoss: 0.721980\n",
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: 0.412559\n",
      "Train Epoch: 1 [32640/84843 (38%)]\tLoss: 0.661598\n",
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: 0.406099\n",
      "Train Epoch: 1 [33920/84843 (40%)]\tLoss: 0.418816\n",
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: 0.302553\n",
      "Train Epoch: 1 [35200/84843 (41%)]\tLoss: 0.757042\n",
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: 0.501495\n",
      "Train Epoch: 1 [36480/84843 (43%)]\tLoss: 0.702141\n",
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: 0.381341\n",
      "Train Epoch: 1 [37760/84843 (44%)]\tLoss: 0.626239\n",
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: 0.750144\n",
      "Train Epoch: 1 [39040/84843 (46%)]\tLoss: 0.429249\n",
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: 0.275986\n",
      "Train Epoch: 1 [40320/84843 (48%)]\tLoss: 0.284547\n",
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: 0.034870\n",
      "Train Epoch: 1 [41600/84843 (49%)]\tLoss: 0.357141\n",
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: 0.311904\n",
      "Train Epoch: 1 [42880/84843 (51%)]\tLoss: 0.432991\n",
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: 0.715727\n",
      "Train Epoch: 1 [44160/84843 (52%)]\tLoss: 0.244217\n",
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: 0.274671\n",
      "Train Epoch: 1 [45440/84843 (54%)]\tLoss: 0.538065\n",
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: 0.636607\n",
      "Train Epoch: 1 [46720/84843 (55%)]\tLoss: 0.525555\n",
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: 0.294727\n",
      "Train Epoch: 1 [48000/84843 (57%)]\tLoss: 0.507053\n",
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: 0.506168\n",
      "Train Epoch: 1 [49280/84843 (58%)]\tLoss: 0.628511\n",
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: 0.540777\n",
      "Train Epoch: 1 [50560/84843 (60%)]\tLoss: 0.394093\n",
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: 0.379220\n",
      "Train Epoch: 1 [51840/84843 (61%)]\tLoss: 0.273637\n",
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: 0.449506\n",
      "Train Epoch: 1 [53120/84843 (63%)]\tLoss: 0.564719\n",
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: 0.914168\n",
      "Train Epoch: 1 [54400/84843 (64%)]\tLoss: 0.082771\n",
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: 0.717121\n",
      "Train Epoch: 1 [55680/84843 (66%)]\tLoss: 0.343166\n",
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: 0.896077\n",
      "Train Epoch: 1 [56960/84843 (67%)]\tLoss: 0.707477\n",
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: 0.194777\n",
      "Train Epoch: 1 [58240/84843 (69%)]\tLoss: 0.344089\n",
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: 0.528898\n",
      "Train Epoch: 1 [59520/84843 (70%)]\tLoss: 0.257986\n",
      "Train Epoch: 1 [60160/84843 (71%)]\tLoss: 0.147304\n",
      "Train Epoch: 1 [60800/84843 (72%)]\tLoss: 0.293512\n",
      "Train Epoch: 1 [61440/84843 (72%)]\tLoss: 0.192341\n",
      "Train Epoch: 1 [62080/84843 (73%)]\tLoss: 0.530994\n",
      "Train Epoch: 1 [62720/84843 (74%)]\tLoss: 0.409622\n",
      "Train Epoch: 1 [63360/84843 (75%)]\tLoss: 0.305310\n",
      "Train Epoch: 1 [64000/84843 (75%)]\tLoss: 0.395467\n",
      "Train Epoch: 1 [64640/84843 (76%)]\tLoss: 0.593066\n",
      "Train Epoch: 1 [65280/84843 (77%)]\tLoss: 0.434320\n",
      "Train Epoch: 1 [65920/84843 (78%)]\tLoss: 0.488263\n",
      "Train Epoch: 1 [66560/84843 (78%)]\tLoss: 0.292460\n",
      "Train Epoch: 1 [67200/84843 (79%)]\tLoss: 0.541316\n",
      "Train Epoch: 1 [67840/84843 (80%)]\tLoss: 0.774606\n",
      "Train Epoch: 1 [68480/84843 (81%)]\tLoss: 0.281458\n",
      "Train Epoch: 1 [69120/84843 (81%)]\tLoss: 0.471679\n",
      "Train Epoch: 1 [69760/84843 (82%)]\tLoss: 0.342216\n",
      "Train Epoch: 1 [70400/84843 (83%)]\tLoss: 0.656991\n",
      "Train Epoch: 1 [71040/84843 (84%)]\tLoss: 0.545899\n",
      "Train Epoch: 1 [71680/84843 (84%)]\tLoss: 0.339824\n",
      "Train Epoch: 1 [72320/84843 (85%)]\tLoss: 0.493910\n",
      "Train Epoch: 1 [72960/84843 (86%)]\tLoss: 0.599113\n",
      "Train Epoch: 1 [73600/84843 (87%)]\tLoss: 0.244047\n",
      "Train Epoch: 1 [74240/84843 (87%)]\tLoss: 0.365949\n",
      "Train Epoch: 1 [74880/84843 (88%)]\tLoss: 0.044281\n",
      "Train Epoch: 1 [75520/84843 (89%)]\tLoss: 0.265694\n",
      "Train Epoch: 1 [76160/84843 (90%)]\tLoss: 0.663065\n",
      "Train Epoch: 1 [76800/84843 (90%)]\tLoss: 0.243388\n",
      "Train Epoch: 1 [77440/84843 (91%)]\tLoss: 0.380807\n",
      "Train Epoch: 1 [78080/84843 (92%)]\tLoss: 0.609194\n",
      "Train Epoch: 1 [78720/84843 (93%)]\tLoss: 0.761603\n",
      "Train Epoch: 1 [79360/84843 (94%)]\tLoss: 0.237605\n",
      "Train Epoch: 1 [80000/84843 (94%)]\tLoss: 0.749160\n",
      "Train Epoch: 1 [80640/84843 (95%)]\tLoss: 0.331223\n",
      "Train Epoch: 1 [81280/84843 (96%)]\tLoss: 0.366105\n",
      "Train Epoch: 1 [81920/84843 (97%)]\tLoss: 0.370927\n",
      "Train Epoch: 1 [82560/84843 (97%)]\tLoss: 0.363394\n",
      "Train Epoch: 1 [83200/84843 (98%)]\tLoss: 0.537978\n",
      "Train Epoch: 1 [83840/84843 (99%)]\tLoss: 0.350001\n",
      "Train Epoch: 1 [84480/84843 (100%)]\tLoss: 0.171284\n",
      "Accuracy: 9401/11005 (85%)\n",
      "\n",
      "Train Epoch: 2 [0/84843 (0%)]\tLoss: 0.383731\n",
      "Train Epoch: 2 [640/84843 (1%)]\tLoss: 0.180015\n",
      "Train Epoch: 2 [1280/84843 (2%)]\tLoss: 0.406815\n",
      "Train Epoch: 2 [1920/84843 (2%)]\tLoss: 0.202378\n",
      "Train Epoch: 2 [2560/84843 (3%)]\tLoss: 0.565841\n",
      "Train Epoch: 2 [3200/84843 (4%)]\tLoss: 0.201788\n",
      "Train Epoch: 2 [3840/84843 (5%)]\tLoss: 0.595776\n",
      "Train Epoch: 2 [4480/84843 (5%)]\tLoss: 0.265694\n",
      "Train Epoch: 2 [5120/84843 (6%)]\tLoss: 0.611477\n",
      "Train Epoch: 2 [5760/84843 (7%)]\tLoss: 0.178710\n",
      "Train Epoch: 2 [6400/84843 (8%)]\tLoss: 0.855583\n",
      "Train Epoch: 2 [7040/84843 (8%)]\tLoss: 0.369303\n",
      "Train Epoch: 2 [7680/84843 (9%)]\tLoss: 0.680764\n",
      "Train Epoch: 2 [8320/84843 (10%)]\tLoss: 0.386390\n",
      "Train Epoch: 2 [8960/84843 (11%)]\tLoss: 0.706068\n",
      "Train Epoch: 2 [9600/84843 (11%)]\tLoss: 0.559858\n",
      "Train Epoch: 2 [10240/84843 (12%)]\tLoss: 0.290691\n",
      "Train Epoch: 2 [10880/84843 (13%)]\tLoss: 0.284982\n",
      "Train Epoch: 2 [11520/84843 (14%)]\tLoss: 0.667770\n",
      "Train Epoch: 2 [12160/84843 (14%)]\tLoss: 0.443157\n",
      "Train Epoch: 2 [12800/84843 (15%)]\tLoss: 0.153864\n",
      "Train Epoch: 2 [13440/84843 (16%)]\tLoss: 0.294084\n",
      "Train Epoch: 2 [14080/84843 (17%)]\tLoss: 0.253142\n",
      "Train Epoch: 2 [14720/84843 (17%)]\tLoss: 0.601184\n",
      "Train Epoch: 2 [15360/84843 (18%)]\tLoss: 0.609192\n",
      "Train Epoch: 2 [16000/84843 (19%)]\tLoss: 0.392524\n",
      "Train Epoch: 2 [16640/84843 (20%)]\tLoss: 0.445074\n",
      "Train Epoch: 2 [17280/84843 (20%)]\tLoss: 0.423031\n",
      "Train Epoch: 2 [17920/84843 (21%)]\tLoss: 0.346625\n",
      "Train Epoch: 2 [18560/84843 (22%)]\tLoss: 0.543523\n",
      "Train Epoch: 2 [19200/84843 (23%)]\tLoss: 0.419970\n",
      "Train Epoch: 2 [19840/84843 (23%)]\tLoss: 0.241238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [20480/84843 (24%)]\tLoss: 0.424053\n",
      "Train Epoch: 2 [21120/84843 (25%)]\tLoss: 0.564802\n",
      "Train Epoch: 2 [21760/84843 (26%)]\tLoss: 0.434176\n",
      "Train Epoch: 2 [22400/84843 (26%)]\tLoss: 0.344183\n",
      "Train Epoch: 2 [23040/84843 (27%)]\tLoss: 0.395888\n",
      "Train Epoch: 2 [23680/84843 (28%)]\tLoss: 0.544507\n",
      "Train Epoch: 2 [24320/84843 (29%)]\tLoss: 0.233617\n",
      "Train Epoch: 2 [24960/84843 (29%)]\tLoss: 0.539178\n",
      "Train Epoch: 2 [25600/84843 (30%)]\tLoss: 0.465553\n",
      "Train Epoch: 2 [26240/84843 (31%)]\tLoss: 0.552109\n",
      "Train Epoch: 2 [26880/84843 (32%)]\tLoss: 0.367343\n",
      "Train Epoch: 2 [27520/84843 (32%)]\tLoss: 0.426576\n",
      "Train Epoch: 2 [28160/84843 (33%)]\tLoss: 0.205420\n",
      "Train Epoch: 2 [28800/84843 (34%)]\tLoss: 0.229924\n",
      "Train Epoch: 2 [29440/84843 (35%)]\tLoss: 0.339696\n",
      "Train Epoch: 2 [30080/84843 (35%)]\tLoss: 0.322260\n",
      "Train Epoch: 2 [30720/84843 (36%)]\tLoss: 0.509919\n",
      "Train Epoch: 2 [31360/84843 (37%)]\tLoss: 0.667047\n",
      "Train Epoch: 2 [32000/84843 (38%)]\tLoss: 0.939134\n",
      "Train Epoch: 2 [32640/84843 (38%)]\tLoss: 0.360841\n",
      "Train Epoch: 2 [33280/84843 (39%)]\tLoss: 0.347728\n",
      "Train Epoch: 2 [33920/84843 (40%)]\tLoss: 0.347946\n",
      "Train Epoch: 2 [34560/84843 (41%)]\tLoss: 0.292387\n",
      "Train Epoch: 2 [35200/84843 (41%)]\tLoss: 0.811113\n",
      "Train Epoch: 2 [35840/84843 (42%)]\tLoss: 0.742133\n",
      "Train Epoch: 2 [36480/84843 (43%)]\tLoss: 0.505946\n",
      "Train Epoch: 2 [37120/84843 (44%)]\tLoss: 0.210698\n",
      "Train Epoch: 2 [37760/84843 (44%)]\tLoss: 0.385580\n",
      "Train Epoch: 2 [38400/84843 (45%)]\tLoss: 0.331216\n",
      "Train Epoch: 2 [39040/84843 (46%)]\tLoss: 0.122923\n",
      "Train Epoch: 2 [39680/84843 (47%)]\tLoss: 0.574689\n",
      "Train Epoch: 2 [40320/84843 (48%)]\tLoss: 0.452454\n",
      "Train Epoch: 2 [40960/84843 (48%)]\tLoss: 0.420156\n",
      "Train Epoch: 2 [41600/84843 (49%)]\tLoss: 0.256369\n",
      "Train Epoch: 2 [42240/84843 (50%)]\tLoss: 0.169686\n",
      "Train Epoch: 2 [42880/84843 (51%)]\tLoss: 0.586538\n",
      "Train Epoch: 2 [43520/84843 (51%)]\tLoss: 0.411350\n",
      "Train Epoch: 2 [44160/84843 (52%)]\tLoss: 0.332357\n",
      "Train Epoch: 2 [44800/84843 (53%)]\tLoss: 0.340158\n",
      "Train Epoch: 2 [45440/84843 (54%)]\tLoss: 0.433127\n",
      "Train Epoch: 2 [46080/84843 (54%)]\tLoss: 0.397375\n",
      "Train Epoch: 2 [46720/84843 (55%)]\tLoss: 0.405609\n",
      "Train Epoch: 2 [47360/84843 (56%)]\tLoss: 0.551355\n",
      "Train Epoch: 2 [48000/84843 (57%)]\tLoss: 0.537862\n",
      "Train Epoch: 2 [48640/84843 (57%)]\tLoss: 0.339483\n",
      "Train Epoch: 2 [49280/84843 (58%)]\tLoss: 0.389591\n",
      "Train Epoch: 2 [49920/84843 (59%)]\tLoss: 0.317845\n",
      "Train Epoch: 2 [50560/84843 (60%)]\tLoss: 0.495422\n",
      "Train Epoch: 2 [51200/84843 (60%)]\tLoss: 0.182857\n",
      "Train Epoch: 2 [51840/84843 (61%)]\tLoss: 0.366805\n",
      "Train Epoch: 2 [52480/84843 (62%)]\tLoss: 0.268810\n",
      "Train Epoch: 2 [53120/84843 (63%)]\tLoss: 0.159683\n",
      "Train Epoch: 2 [53760/84843 (63%)]\tLoss: 0.338139\n",
      "Train Epoch: 2 [54400/84843 (64%)]\tLoss: 0.344748\n",
      "Train Epoch: 2 [55040/84843 (65%)]\tLoss: 0.186918\n",
      "Train Epoch: 2 [55680/84843 (66%)]\tLoss: 0.582105\n",
      "Train Epoch: 2 [56320/84843 (66%)]\tLoss: 0.352378\n",
      "Train Epoch: 2 [56960/84843 (67%)]\tLoss: 0.379865\n",
      "Train Epoch: 2 [57600/84843 (68%)]\tLoss: 0.409790\n",
      "Train Epoch: 2 [58240/84843 (69%)]\tLoss: 0.591334\n",
      "Train Epoch: 2 [58880/84843 (69%)]\tLoss: 0.173160\n",
      "Train Epoch: 2 [59520/84843 (70%)]\tLoss: 0.183853\n",
      "Train Epoch: 2 [60160/84843 (71%)]\tLoss: 0.093018\n",
      "Train Epoch: 2 [60800/84843 (72%)]\tLoss: 0.283018\n",
      "Train Epoch: 2 [61440/84843 (72%)]\tLoss: 0.211586\n",
      "Train Epoch: 2 [62080/84843 (73%)]\tLoss: 0.384760\n",
      "Train Epoch: 2 [62720/84843 (74%)]\tLoss: 0.503792\n",
      "Train Epoch: 2 [63360/84843 (75%)]\tLoss: 0.615404\n",
      "Train Epoch: 2 [64000/84843 (75%)]\tLoss: 0.764252\n",
      "Train Epoch: 2 [64640/84843 (76%)]\tLoss: 0.460904\n",
      "Train Epoch: 2 [65280/84843 (77%)]\tLoss: 0.455485\n",
      "Train Epoch: 2 [65920/84843 (78%)]\tLoss: 0.428681\n",
      "Train Epoch: 2 [66560/84843 (78%)]\tLoss: 0.521850\n",
      "Train Epoch: 2 [67200/84843 (79%)]\tLoss: 0.326708\n",
      "Train Epoch: 2 [67840/84843 (80%)]\tLoss: 0.214404\n",
      "Train Epoch: 2 [68480/84843 (81%)]\tLoss: 0.464283\n",
      "Train Epoch: 2 [69120/84843 (81%)]\tLoss: 0.421558\n",
      "Train Epoch: 2 [69760/84843 (82%)]\tLoss: 0.596741\n",
      "Train Epoch: 2 [70400/84843 (83%)]\tLoss: 0.454312\n",
      "Train Epoch: 2 [71040/84843 (84%)]\tLoss: 0.415886\n",
      "Train Epoch: 2 [71680/84843 (84%)]\tLoss: 0.295561\n",
      "Train Epoch: 2 [72320/84843 (85%)]\tLoss: 0.299004\n",
      "Train Epoch: 2 [72960/84843 (86%)]\tLoss: 0.359579\n",
      "Train Epoch: 2 [73600/84843 (87%)]\tLoss: 0.317805\n",
      "Train Epoch: 2 [74240/84843 (87%)]\tLoss: 0.291858\n",
      "Train Epoch: 2 [74880/84843 (88%)]\tLoss: 0.469747\n",
      "Train Epoch: 2 [75520/84843 (89%)]\tLoss: 0.580380\n",
      "Train Epoch: 2 [76160/84843 (90%)]\tLoss: 0.462916\n",
      "Train Epoch: 2 [76800/84843 (90%)]\tLoss: 0.274245\n",
      "Train Epoch: 2 [77440/84843 (91%)]\tLoss: 0.446322\n",
      "Train Epoch: 2 [78080/84843 (92%)]\tLoss: 0.644435\n",
      "Train Epoch: 2 [78720/84843 (93%)]\tLoss: 0.168252\n",
      "Train Epoch: 2 [79360/84843 (94%)]\tLoss: 0.249546\n",
      "Train Epoch: 2 [80000/84843 (94%)]\tLoss: 0.609381\n",
      "Train Epoch: 2 [80640/84843 (95%)]\tLoss: 0.766756\n",
      "Train Epoch: 2 [81280/84843 (96%)]\tLoss: 0.308160\n",
      "Train Epoch: 2 [81920/84843 (97%)]\tLoss: 0.360059\n",
      "Train Epoch: 2 [82560/84843 (97%)]\tLoss: 0.173226\n",
      "Train Epoch: 2 [83200/84843 (98%)]\tLoss: 0.567244\n",
      "Train Epoch: 2 [83840/84843 (99%)]\tLoss: 0.386737\n",
      "Train Epoch: 2 [84480/84843 (100%)]\tLoss: 0.363014\n",
      "Accuracy: 9383/11005 (85%)\n",
      "\n",
      "Train Epoch: 3 [0/84843 (0%)]\tLoss: 0.214249\n",
      "Train Epoch: 3 [640/84843 (1%)]\tLoss: 0.569193\n",
      "Train Epoch: 3 [1280/84843 (2%)]\tLoss: 0.379346\n",
      "Train Epoch: 3 [1920/84843 (2%)]\tLoss: 0.231242\n",
      "Train Epoch: 3 [2560/84843 (3%)]\tLoss: 0.393451\n",
      "Train Epoch: 3 [3200/84843 (4%)]\tLoss: 0.214450\n",
      "Train Epoch: 3 [3840/84843 (5%)]\tLoss: 0.239388\n",
      "Train Epoch: 3 [4480/84843 (5%)]\tLoss: 0.612699\n",
      "Train Epoch: 3 [5120/84843 (6%)]\tLoss: 0.717439\n",
      "Train Epoch: 3 [5760/84843 (7%)]\tLoss: 0.248327\n",
      "Train Epoch: 3 [6400/84843 (8%)]\tLoss: 0.274941\n",
      "Train Epoch: 3 [7040/84843 (8%)]\tLoss: 0.650388\n",
      "Train Epoch: 3 [7680/84843 (9%)]\tLoss: 0.335817\n",
      "Train Epoch: 3 [8320/84843 (10%)]\tLoss: 0.260505\n",
      "Train Epoch: 3 [8960/84843 (11%)]\tLoss: 0.289496\n",
      "Train Epoch: 3 [9600/84843 (11%)]\tLoss: 0.291473\n",
      "Train Epoch: 3 [10240/84843 (12%)]\tLoss: 0.358497\n",
      "Train Epoch: 3 [10880/84843 (13%)]\tLoss: 0.434721\n",
      "Train Epoch: 3 [11520/84843 (14%)]\tLoss: 0.146908\n",
      "Train Epoch: 3 [12160/84843 (14%)]\tLoss: 0.493405\n",
      "Train Epoch: 3 [12800/84843 (15%)]\tLoss: 0.129467\n",
      "Train Epoch: 3 [13440/84843 (16%)]\tLoss: 0.388016\n",
      "Train Epoch: 3 [14080/84843 (17%)]\tLoss: 0.449060\n",
      "Train Epoch: 3 [14720/84843 (17%)]\tLoss: 0.612129\n",
      "Train Epoch: 3 [15360/84843 (18%)]\tLoss: 0.226562\n",
      "Train Epoch: 3 [16000/84843 (19%)]\tLoss: 0.309473\n",
      "Train Epoch: 3 [16640/84843 (20%)]\tLoss: 0.378132\n",
      "Train Epoch: 3 [17280/84843 (20%)]\tLoss: 0.290316\n",
      "Train Epoch: 3 [17920/84843 (21%)]\tLoss: 0.319022\n",
      "Train Epoch: 3 [18560/84843 (22%)]\tLoss: 0.196517\n",
      "Train Epoch: 3 [19200/84843 (23%)]\tLoss: 0.400714\n",
      "Train Epoch: 3 [19840/84843 (23%)]\tLoss: 0.269021\n",
      "Train Epoch: 3 [20480/84843 (24%)]\tLoss: 0.270188\n",
      "Train Epoch: 3 [21120/84843 (25%)]\tLoss: 0.249834\n",
      "Train Epoch: 3 [21760/84843 (26%)]\tLoss: 0.518430\n",
      "Train Epoch: 3 [22400/84843 (26%)]\tLoss: 0.363301\n",
      "Train Epoch: 3 [23040/84843 (27%)]\tLoss: 0.064060\n",
      "Train Epoch: 3 [23680/84843 (28%)]\tLoss: 0.274231\n",
      "Train Epoch: 3 [24320/84843 (29%)]\tLoss: 0.663078\n",
      "Train Epoch: 3 [24960/84843 (29%)]\tLoss: 0.684542\n",
      "Train Epoch: 3 [25600/84843 (30%)]\tLoss: 0.301832\n",
      "Train Epoch: 3 [26240/84843 (31%)]\tLoss: 0.327159\n",
      "Train Epoch: 3 [26880/84843 (32%)]\tLoss: 0.282166\n",
      "Train Epoch: 3 [27520/84843 (32%)]\tLoss: 0.569809\n",
      "Train Epoch: 3 [28160/84843 (33%)]\tLoss: 0.272591\n",
      "Train Epoch: 3 [28800/84843 (34%)]\tLoss: 0.364660\n",
      "Train Epoch: 3 [29440/84843 (35%)]\tLoss: 0.379533\n",
      "Train Epoch: 3 [30080/84843 (35%)]\tLoss: 0.213173\n",
      "Train Epoch: 3 [30720/84843 (36%)]\tLoss: 0.500157\n",
      "Train Epoch: 3 [31360/84843 (37%)]\tLoss: 0.523965\n",
      "Train Epoch: 3 [32000/84843 (38%)]\tLoss: 0.349665\n",
      "Train Epoch: 3 [32640/84843 (38%)]\tLoss: 0.412255\n",
      "Train Epoch: 3 [33280/84843 (39%)]\tLoss: 0.551958\n",
      "Train Epoch: 3 [33920/84843 (40%)]\tLoss: 0.250578\n",
      "Train Epoch: 3 [34560/84843 (41%)]\tLoss: 0.397440\n",
      "Train Epoch: 3 [35200/84843 (41%)]\tLoss: 0.860182\n",
      "Train Epoch: 3 [35840/84843 (42%)]\tLoss: 0.306196\n",
      "Train Epoch: 3 [36480/84843 (43%)]\tLoss: 0.442060\n",
      "Train Epoch: 3 [37120/84843 (44%)]\tLoss: 0.070356\n",
      "Train Epoch: 3 [37760/84843 (44%)]\tLoss: 0.471766\n",
      "Train Epoch: 3 [38400/84843 (45%)]\tLoss: 0.288106\n",
      "Train Epoch: 3 [39040/84843 (46%)]\tLoss: 0.337607\n",
      "Train Epoch: 3 [39680/84843 (47%)]\tLoss: 0.221523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [40320/84843 (48%)]\tLoss: 0.254444\n",
      "Train Epoch: 3 [40960/84843 (48%)]\tLoss: 0.636647\n",
      "Train Epoch: 3 [41600/84843 (49%)]\tLoss: 0.451768\n",
      "Train Epoch: 3 [42240/84843 (50%)]\tLoss: 0.417810\n",
      "Train Epoch: 3 [42880/84843 (51%)]\tLoss: 0.241567\n",
      "Train Epoch: 3 [43520/84843 (51%)]\tLoss: 0.483856\n",
      "Train Epoch: 3 [44160/84843 (52%)]\tLoss: 0.646982\n",
      "Train Epoch: 3 [44800/84843 (53%)]\tLoss: 0.770773\n",
      "Train Epoch: 3 [45440/84843 (54%)]\tLoss: 0.274732\n",
      "Train Epoch: 3 [46080/84843 (54%)]\tLoss: 0.186158\n",
      "Train Epoch: 3 [46720/84843 (55%)]\tLoss: 0.307415\n",
      "Train Epoch: 3 [47360/84843 (56%)]\tLoss: 0.372190\n",
      "Train Epoch: 3 [48000/84843 (57%)]\tLoss: 0.168942\n",
      "Train Epoch: 3 [48640/84843 (57%)]\tLoss: 0.301063\n",
      "Train Epoch: 3 [49280/84843 (58%)]\tLoss: 0.263631\n",
      "Train Epoch: 3 [49920/84843 (59%)]\tLoss: 0.515767\n",
      "Train Epoch: 3 [50560/84843 (60%)]\tLoss: 0.468115\n",
      "Train Epoch: 3 [51200/84843 (60%)]\tLoss: 0.102583\n",
      "Train Epoch: 3 [51840/84843 (61%)]\tLoss: 0.621563\n",
      "Train Epoch: 3 [52480/84843 (62%)]\tLoss: 0.493441\n",
      "Train Epoch: 3 [53120/84843 (63%)]\tLoss: 0.581129\n",
      "Train Epoch: 3 [53760/84843 (63%)]\tLoss: 0.544046\n",
      "Train Epoch: 3 [54400/84843 (64%)]\tLoss: 0.323879\n",
      "Train Epoch: 3 [55040/84843 (65%)]\tLoss: 0.075736\n",
      "Train Epoch: 3 [55680/84843 (66%)]\tLoss: 0.241771\n",
      "Train Epoch: 3 [56320/84843 (66%)]\tLoss: 0.191225\n",
      "Train Epoch: 3 [56960/84843 (67%)]\tLoss: 0.626936\n",
      "Train Epoch: 3 [57600/84843 (68%)]\tLoss: 0.623681\n",
      "Train Epoch: 3 [58240/84843 (69%)]\tLoss: 0.221359\n",
      "Train Epoch: 3 [58880/84843 (69%)]\tLoss: 0.305674\n",
      "Train Epoch: 3 [59520/84843 (70%)]\tLoss: 0.491038\n",
      "Train Epoch: 3 [60160/84843 (71%)]\tLoss: 0.545022\n",
      "Train Epoch: 3 [60800/84843 (72%)]\tLoss: 0.493055\n",
      "Train Epoch: 3 [61440/84843 (72%)]\tLoss: 0.503870\n",
      "Train Epoch: 3 [62080/84843 (73%)]\tLoss: 0.616019\n",
      "Train Epoch: 3 [62720/84843 (74%)]\tLoss: 0.298725\n",
      "Train Epoch: 3 [63360/84843 (75%)]\tLoss: 0.429678\n",
      "Train Epoch: 3 [64000/84843 (75%)]\tLoss: 0.244269\n",
      "Train Epoch: 3 [64640/84843 (76%)]\tLoss: 0.428437\n",
      "Train Epoch: 3 [65280/84843 (77%)]\tLoss: 0.568229\n",
      "Train Epoch: 3 [65920/84843 (78%)]\tLoss: 0.228949\n",
      "Train Epoch: 3 [66560/84843 (78%)]\tLoss: 0.698866\n",
      "Train Epoch: 3 [67200/84843 (79%)]\tLoss: 0.399538\n",
      "Train Epoch: 3 [67840/84843 (80%)]\tLoss: 0.469309\n",
      "Train Epoch: 3 [68480/84843 (81%)]\tLoss: 0.176650\n",
      "Train Epoch: 3 [69120/84843 (81%)]\tLoss: 0.285785\n",
      "Train Epoch: 3 [69760/84843 (82%)]\tLoss: 0.797559\n",
      "Train Epoch: 3 [70400/84843 (83%)]\tLoss: 0.707022\n",
      "Train Epoch: 3 [71040/84843 (84%)]\tLoss: 0.638989\n",
      "Train Epoch: 3 [71680/84843 (84%)]\tLoss: 0.636998\n",
      "Train Epoch: 3 [72320/84843 (85%)]\tLoss: 0.534123\n",
      "Train Epoch: 3 [72960/84843 (86%)]\tLoss: 0.283237\n",
      "Train Epoch: 3 [73600/84843 (87%)]\tLoss: 0.131348\n",
      "Train Epoch: 3 [74240/84843 (87%)]\tLoss: 0.327074\n",
      "Train Epoch: 3 [74880/84843 (88%)]\tLoss: 0.165921\n",
      "Train Epoch: 3 [75520/84843 (89%)]\tLoss: 0.244148\n",
      "Train Epoch: 3 [76160/84843 (90%)]\tLoss: 0.486694\n",
      "Train Epoch: 3 [76800/84843 (90%)]\tLoss: 0.457823\n",
      "Train Epoch: 3 [77440/84843 (91%)]\tLoss: 0.267406\n",
      "Train Epoch: 3 [78080/84843 (92%)]\tLoss: 0.484803\n",
      "Train Epoch: 3 [78720/84843 (93%)]\tLoss: 0.354995\n",
      "Train Epoch: 3 [79360/84843 (94%)]\tLoss: 0.252446\n",
      "Train Epoch: 3 [80000/84843 (94%)]\tLoss: 0.222226\n",
      "Train Epoch: 3 [80640/84843 (95%)]\tLoss: 0.424553\n",
      "Train Epoch: 3 [81280/84843 (96%)]\tLoss: 0.289204\n",
      "Train Epoch: 3 [81920/84843 (97%)]\tLoss: 0.380414\n",
      "Train Epoch: 3 [82560/84843 (97%)]\tLoss: 0.359814\n",
      "Train Epoch: 3 [83200/84843 (98%)]\tLoss: 0.395444\n",
      "Train Epoch: 3 [83840/84843 (99%)]\tLoss: 0.285195\n",
      "Train Epoch: 3 [84480/84843 (100%)]\tLoss: 0.244550\n",
      "Accuracy: 9354/11005 (85%)\n",
      "\n",
      "Train Epoch: 4 [0/84843 (0%)]\tLoss: 0.291167\n",
      "Train Epoch: 4 [640/84843 (1%)]\tLoss: 0.301562\n",
      "Train Epoch: 4 [1280/84843 (2%)]\tLoss: 0.599895\n",
      "Train Epoch: 4 [1920/84843 (2%)]\tLoss: 0.536345\n",
      "Train Epoch: 4 [2560/84843 (3%)]\tLoss: 0.686304\n",
      "Train Epoch: 4 [3200/84843 (4%)]\tLoss: 0.469563\n",
      "Train Epoch: 4 [3840/84843 (5%)]\tLoss: 0.759682\n",
      "Train Epoch: 4 [4480/84843 (5%)]\tLoss: 0.276328\n",
      "Train Epoch: 4 [5120/84843 (6%)]\tLoss: 0.568244\n",
      "Train Epoch: 4 [5760/84843 (7%)]\tLoss: 0.315075\n",
      "Train Epoch: 4 [6400/84843 (8%)]\tLoss: 0.395382\n",
      "Train Epoch: 4 [7040/84843 (8%)]\tLoss: 0.240546\n",
      "Train Epoch: 4 [7680/84843 (9%)]\tLoss: 0.468802\n",
      "Train Epoch: 4 [8320/84843 (10%)]\tLoss: 0.286679\n",
      "Train Epoch: 4 [8960/84843 (11%)]\tLoss: 0.540994\n",
      "Train Epoch: 4 [9600/84843 (11%)]\tLoss: 0.442919\n",
      "Train Epoch: 4 [10240/84843 (12%)]\tLoss: 0.478639\n",
      "Train Epoch: 4 [10880/84843 (13%)]\tLoss: 0.275137\n",
      "Train Epoch: 4 [11520/84843 (14%)]\tLoss: 0.441111\n",
      "Train Epoch: 4 [12160/84843 (14%)]\tLoss: 0.429095\n",
      "Train Epoch: 4 [12800/84843 (15%)]\tLoss: 0.366904\n",
      "Train Epoch: 4 [13440/84843 (16%)]\tLoss: 0.267835\n",
      "Train Epoch: 4 [14080/84843 (17%)]\tLoss: 0.183580\n",
      "Train Epoch: 4 [14720/84843 (17%)]\tLoss: 0.314550\n",
      "Train Epoch: 4 [15360/84843 (18%)]\tLoss: 0.241296\n",
      "Train Epoch: 4 [16000/84843 (19%)]\tLoss: 0.493303\n",
      "Train Epoch: 4 [16640/84843 (20%)]\tLoss: 0.350266\n",
      "Train Epoch: 4 [17280/84843 (20%)]\tLoss: 0.479193\n",
      "Train Epoch: 4 [17920/84843 (21%)]\tLoss: 0.391960\n",
      "Train Epoch: 4 [18560/84843 (22%)]\tLoss: 0.322994\n",
      "Train Epoch: 4 [19200/84843 (23%)]\tLoss: 0.321152\n",
      "Train Epoch: 4 [19840/84843 (23%)]\tLoss: 0.467395\n",
      "Train Epoch: 4 [20480/84843 (24%)]\tLoss: 0.391814\n",
      "Train Epoch: 4 [21120/84843 (25%)]\tLoss: 0.152175\n",
      "Train Epoch: 4 [21760/84843 (26%)]\tLoss: 0.253011\n",
      "Train Epoch: 4 [22400/84843 (26%)]\tLoss: 0.590926\n",
      "Train Epoch: 4 [23040/84843 (27%)]\tLoss: 0.156035\n",
      "Train Epoch: 4 [23680/84843 (28%)]\tLoss: 0.226545\n",
      "Train Epoch: 4 [24320/84843 (29%)]\tLoss: 0.162416\n",
      "Train Epoch: 4 [24960/84843 (29%)]\tLoss: 0.449379\n",
      "Train Epoch: 4 [25600/84843 (30%)]\tLoss: 0.316518\n",
      "Train Epoch: 4 [26240/84843 (31%)]\tLoss: 0.585687\n",
      "Train Epoch: 4 [26880/84843 (32%)]\tLoss: 0.567091\n",
      "Train Epoch: 4 [27520/84843 (32%)]\tLoss: 0.586586\n",
      "Train Epoch: 4 [28160/84843 (33%)]\tLoss: 0.847914\n",
      "Train Epoch: 4 [28800/84843 (34%)]\tLoss: 0.263063\n",
      "Train Epoch: 4 [29440/84843 (35%)]\tLoss: 0.293802\n",
      "Train Epoch: 4 [30080/84843 (35%)]\tLoss: 0.080076\n",
      "Train Epoch: 4 [30720/84843 (36%)]\tLoss: 0.533322\n",
      "Train Epoch: 4 [31360/84843 (37%)]\tLoss: 0.447271\n",
      "Train Epoch: 4 [32000/84843 (38%)]\tLoss: 0.321821\n",
      "Train Epoch: 4 [32640/84843 (38%)]\tLoss: 0.213379\n",
      "Train Epoch: 4 [33280/84843 (39%)]\tLoss: 0.306527\n",
      "Train Epoch: 4 [33920/84843 (40%)]\tLoss: 0.504307\n",
      "Train Epoch: 4 [34560/84843 (41%)]\tLoss: 0.363038\n",
      "Train Epoch: 4 [35200/84843 (41%)]\tLoss: 0.484029\n",
      "Train Epoch: 4 [35840/84843 (42%)]\tLoss: 0.373660\n",
      "Train Epoch: 4 [36480/84843 (43%)]\tLoss: 0.456969\n",
      "Train Epoch: 4 [37120/84843 (44%)]\tLoss: 0.361224\n",
      "Train Epoch: 4 [37760/84843 (44%)]\tLoss: 0.554409\n",
      "Train Epoch: 4 [38400/84843 (45%)]\tLoss: 0.500851\n",
      "Train Epoch: 4 [39040/84843 (46%)]\tLoss: 0.491352\n",
      "Train Epoch: 4 [39680/84843 (47%)]\tLoss: 0.148149\n",
      "Train Epoch: 4 [40320/84843 (48%)]\tLoss: 0.443678\n",
      "Train Epoch: 4 [40960/84843 (48%)]\tLoss: 0.222815\n",
      "Train Epoch: 4 [41600/84843 (49%)]\tLoss: 0.214321\n",
      "Train Epoch: 4 [42240/84843 (50%)]\tLoss: 0.740498\n",
      "Train Epoch: 4 [42880/84843 (51%)]\tLoss: 0.396462\n",
      "Train Epoch: 4 [43520/84843 (51%)]\tLoss: 0.372429\n",
      "Train Epoch: 4 [44160/84843 (52%)]\tLoss: 0.460236\n",
      "Train Epoch: 4 [44800/84843 (53%)]\tLoss: 0.491025\n",
      "Train Epoch: 4 [45440/84843 (54%)]\tLoss: 0.417205\n",
      "Train Epoch: 4 [46080/84843 (54%)]\tLoss: 0.308885\n",
      "Train Epoch: 4 [46720/84843 (55%)]\tLoss: 0.640949\n",
      "Train Epoch: 4 [47360/84843 (56%)]\tLoss: 0.271375\n",
      "Train Epoch: 4 [48000/84843 (57%)]\tLoss: 0.317453\n",
      "Train Epoch: 4 [48640/84843 (57%)]\tLoss: 0.300436\n",
      "Train Epoch: 4 [49280/84843 (58%)]\tLoss: 0.156012\n",
      "Train Epoch: 4 [49920/84843 (59%)]\tLoss: 0.440127\n",
      "Train Epoch: 4 [50560/84843 (60%)]\tLoss: 0.407307\n",
      "Train Epoch: 4 [51200/84843 (60%)]\tLoss: 0.463897\n",
      "Train Epoch: 4 [51840/84843 (61%)]\tLoss: 0.644983\n",
      "Train Epoch: 4 [52480/84843 (62%)]\tLoss: 0.397355\n",
      "Train Epoch: 4 [53120/84843 (63%)]\tLoss: 0.362813\n",
      "Train Epoch: 4 [53760/84843 (63%)]\tLoss: 0.386110\n",
      "Train Epoch: 4 [54400/84843 (64%)]\tLoss: 0.663486\n",
      "Train Epoch: 4 [55040/84843 (65%)]\tLoss: 0.298288\n",
      "Train Epoch: 4 [55680/84843 (66%)]\tLoss: 0.206245\n",
      "Train Epoch: 4 [56320/84843 (66%)]\tLoss: 0.178834\n",
      "Train Epoch: 4 [56960/84843 (67%)]\tLoss: 0.376159\n",
      "Train Epoch: 4 [57600/84843 (68%)]\tLoss: 0.400560\n",
      "Train Epoch: 4 [58240/84843 (69%)]\tLoss: 0.467775\n",
      "Train Epoch: 4 [58880/84843 (69%)]\tLoss: 0.362625\n",
      "Train Epoch: 4 [59520/84843 (70%)]\tLoss: 0.100696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [60160/84843 (71%)]\tLoss: 0.501250\n",
      "Train Epoch: 4 [60800/84843 (72%)]\tLoss: 0.224827\n",
      "Train Epoch: 4 [61440/84843 (72%)]\tLoss: 0.527216\n",
      "Train Epoch: 4 [62080/84843 (73%)]\tLoss: 0.428892\n",
      "Train Epoch: 4 [62720/84843 (74%)]\tLoss: 0.673670\n",
      "Train Epoch: 4 [63360/84843 (75%)]\tLoss: 0.287131\n",
      "Train Epoch: 4 [64000/84843 (75%)]\tLoss: 0.332425\n",
      "Train Epoch: 4 [64640/84843 (76%)]\tLoss: 0.450771\n",
      "Train Epoch: 4 [65280/84843 (77%)]\tLoss: 0.245984\n",
      "Train Epoch: 4 [65920/84843 (78%)]\tLoss: 0.567181\n",
      "Train Epoch: 4 [66560/84843 (78%)]\tLoss: 0.130967\n",
      "Train Epoch: 4 [67200/84843 (79%)]\tLoss: 0.375433\n",
      "Train Epoch: 4 [67840/84843 (80%)]\tLoss: 0.581069\n",
      "Train Epoch: 4 [68480/84843 (81%)]\tLoss: 0.439048\n",
      "Train Epoch: 4 [69120/84843 (81%)]\tLoss: 0.463379\n",
      "Train Epoch: 4 [69760/84843 (82%)]\tLoss: 0.358943\n",
      "Train Epoch: 4 [70400/84843 (83%)]\tLoss: 0.399621\n",
      "Train Epoch: 4 [71040/84843 (84%)]\tLoss: 0.341854\n",
      "Train Epoch: 4 [71680/84843 (84%)]\tLoss: 0.204438\n",
      "Train Epoch: 4 [72320/84843 (85%)]\tLoss: 0.295025\n",
      "Train Epoch: 4 [72960/84843 (86%)]\tLoss: 0.457823\n",
      "Train Epoch: 4 [73600/84843 (87%)]\tLoss: 0.345820\n",
      "Train Epoch: 4 [74240/84843 (87%)]\tLoss: 0.528356\n",
      "Train Epoch: 4 [74880/84843 (88%)]\tLoss: 0.093522\n",
      "Train Epoch: 4 [75520/84843 (89%)]\tLoss: 0.356946\n",
      "Train Epoch: 4 [76160/84843 (90%)]\tLoss: 0.699942\n",
      "Train Epoch: 4 [76800/84843 (90%)]\tLoss: 0.236953\n",
      "Train Epoch: 4 [77440/84843 (91%)]\tLoss: 0.263224\n",
      "Train Epoch: 4 [78080/84843 (92%)]\tLoss: 0.465169\n",
      "Train Epoch: 4 [78720/84843 (93%)]\tLoss: 0.310811\n",
      "Train Epoch: 4 [79360/84843 (94%)]\tLoss: 0.561986\n",
      "Train Epoch: 4 [80000/84843 (94%)]\tLoss: 0.286762\n",
      "Train Epoch: 4 [80640/84843 (95%)]\tLoss: 0.423658\n",
      "Train Epoch: 4 [81280/84843 (96%)]\tLoss: 0.776887\n",
      "Train Epoch: 4 [81920/84843 (97%)]\tLoss: 0.303696\n",
      "Train Epoch: 4 [82560/84843 (97%)]\tLoss: 0.511324\n",
      "Train Epoch: 4 [83200/84843 (98%)]\tLoss: 0.466838\n",
      "Train Epoch: 4 [83840/84843 (99%)]\tLoss: 0.520212\n",
      "Train Epoch: 4 [84480/84843 (100%)]\tLoss: 0.420668\n",
      "Accuracy: 9463/11005 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/84843 (0%)]\tLoss: 0.395650\n",
      "Train Epoch: 5 [640/84843 (1%)]\tLoss: 0.371168\n",
      "Train Epoch: 5 [1280/84843 (2%)]\tLoss: 0.518420\n",
      "Train Epoch: 5 [1920/84843 (2%)]\tLoss: 0.210365\n",
      "Train Epoch: 5 [2560/84843 (3%)]\tLoss: 0.273768\n",
      "Train Epoch: 5 [3200/84843 (4%)]\tLoss: 0.276869\n",
      "Train Epoch: 5 [3840/84843 (5%)]\tLoss: 0.203228\n",
      "Train Epoch: 5 [4480/84843 (5%)]\tLoss: 0.423038\n",
      "Train Epoch: 5 [5120/84843 (6%)]\tLoss: 0.400811\n",
      "Train Epoch: 5 [5760/84843 (7%)]\tLoss: 0.626935\n",
      "Train Epoch: 5 [6400/84843 (8%)]\tLoss: 0.275094\n",
      "Train Epoch: 5 [7040/84843 (8%)]\tLoss: 0.373649\n",
      "Train Epoch: 5 [7680/84843 (9%)]\tLoss: 0.357596\n",
      "Train Epoch: 5 [8320/84843 (10%)]\tLoss: 0.252261\n",
      "Train Epoch: 5 [8960/84843 (11%)]\tLoss: 0.358071\n",
      "Train Epoch: 5 [9600/84843 (11%)]\tLoss: 0.155190\n",
      "Train Epoch: 5 [10240/84843 (12%)]\tLoss: 0.416526\n",
      "Train Epoch: 5 [10880/84843 (13%)]\tLoss: 0.572209\n",
      "Train Epoch: 5 [11520/84843 (14%)]\tLoss: 0.248309\n",
      "Train Epoch: 5 [12160/84843 (14%)]\tLoss: 0.560986\n",
      "Train Epoch: 5 [12800/84843 (15%)]\tLoss: 0.382950\n",
      "Train Epoch: 5 [13440/84843 (16%)]\tLoss: 0.308147\n",
      "Train Epoch: 5 [14080/84843 (17%)]\tLoss: 0.326780\n",
      "Train Epoch: 5 [14720/84843 (17%)]\tLoss: 0.336796\n",
      "Train Epoch: 5 [15360/84843 (18%)]\tLoss: 0.444315\n",
      "Train Epoch: 5 [16000/84843 (19%)]\tLoss: 0.347851\n",
      "Train Epoch: 5 [16640/84843 (20%)]\tLoss: 0.444575\n",
      "Train Epoch: 5 [17280/84843 (20%)]\tLoss: 0.323543\n",
      "Train Epoch: 5 [17920/84843 (21%)]\tLoss: 0.363512\n",
      "Train Epoch: 5 [18560/84843 (22%)]\tLoss: 0.442949\n",
      "Train Epoch: 5 [19200/84843 (23%)]\tLoss: 0.219311\n",
      "Train Epoch: 5 [19840/84843 (23%)]\tLoss: 0.238494\n",
      "Train Epoch: 5 [20480/84843 (24%)]\tLoss: 0.116149\n",
      "Train Epoch: 5 [21120/84843 (25%)]\tLoss: 0.259065\n",
      "Train Epoch: 5 [21760/84843 (26%)]\tLoss: 0.390618\n",
      "Train Epoch: 5 [22400/84843 (26%)]\tLoss: 0.741784\n",
      "Train Epoch: 5 [23040/84843 (27%)]\tLoss: 0.233862\n",
      "Train Epoch: 5 [23680/84843 (28%)]\tLoss: 0.422325\n",
      "Train Epoch: 5 [24320/84843 (29%)]\tLoss: 0.358727\n",
      "Train Epoch: 5 [24960/84843 (29%)]\tLoss: 0.335370\n",
      "Train Epoch: 5 [25600/84843 (30%)]\tLoss: 0.438113\n",
      "Train Epoch: 5 [26240/84843 (31%)]\tLoss: 0.515801\n",
      "Train Epoch: 5 [26880/84843 (32%)]\tLoss: 0.366720\n",
      "Train Epoch: 5 [27520/84843 (32%)]\tLoss: 0.306794\n",
      "Train Epoch: 5 [28160/84843 (33%)]\tLoss: 0.369058\n",
      "Train Epoch: 5 [28800/84843 (34%)]\tLoss: 0.310113\n",
      "Train Epoch: 5 [29440/84843 (35%)]\tLoss: 0.417838\n",
      "Train Epoch: 5 [30080/84843 (35%)]\tLoss: 0.589821\n",
      "Train Epoch: 5 [30720/84843 (36%)]\tLoss: 0.593387\n",
      "Train Epoch: 5 [31360/84843 (37%)]\tLoss: 0.231290\n",
      "Train Epoch: 5 [32000/84843 (38%)]\tLoss: 0.825374\n",
      "Train Epoch: 5 [32640/84843 (38%)]\tLoss: 0.181625\n",
      "Train Epoch: 5 [33280/84843 (39%)]\tLoss: 0.281079\n",
      "Train Epoch: 5 [33920/84843 (40%)]\tLoss: 0.294319\n",
      "Train Epoch: 5 [34560/84843 (41%)]\tLoss: 0.438273\n",
      "Train Epoch: 5 [35200/84843 (41%)]\tLoss: 0.279498\n",
      "Train Epoch: 5 [35840/84843 (42%)]\tLoss: 0.679353\n",
      "Train Epoch: 5 [36480/84843 (43%)]\tLoss: 0.489498\n",
      "Train Epoch: 5 [37120/84843 (44%)]\tLoss: 0.468254\n",
      "Train Epoch: 5 [37760/84843 (44%)]\tLoss: 0.438308\n",
      "Train Epoch: 5 [38400/84843 (45%)]\tLoss: 0.455726\n",
      "Train Epoch: 5 [39040/84843 (46%)]\tLoss: 0.307560\n",
      "Train Epoch: 5 [39680/84843 (47%)]\tLoss: 0.499232\n",
      "Train Epoch: 5 [40320/84843 (48%)]\tLoss: 0.257709\n",
      "Train Epoch: 5 [40960/84843 (48%)]\tLoss: 0.340703\n",
      "Train Epoch: 5 [41600/84843 (49%)]\tLoss: 0.446223\n",
      "Train Epoch: 5 [42240/84843 (50%)]\tLoss: 0.397314\n",
      "Train Epoch: 5 [42880/84843 (51%)]\tLoss: 0.292590\n",
      "Train Epoch: 5 [43520/84843 (51%)]\tLoss: 0.796110\n",
      "Train Epoch: 5 [44160/84843 (52%)]\tLoss: 0.939510\n",
      "Train Epoch: 5 [44800/84843 (53%)]\tLoss: 0.447760\n",
      "Train Epoch: 5 [45440/84843 (54%)]\tLoss: 0.959660\n",
      "Train Epoch: 5 [46080/84843 (54%)]\tLoss: 0.389304\n",
      "Train Epoch: 5 [46720/84843 (55%)]\tLoss: 0.481806\n",
      "Train Epoch: 5 [47360/84843 (56%)]\tLoss: 0.524508\n",
      "Train Epoch: 5 [48000/84843 (57%)]\tLoss: 0.570296\n",
      "Train Epoch: 5 [48640/84843 (57%)]\tLoss: 0.132072\n",
      "Train Epoch: 5 [49280/84843 (58%)]\tLoss: 0.158438\n",
      "Train Epoch: 5 [49920/84843 (59%)]\tLoss: 0.574537\n",
      "Train Epoch: 5 [50560/84843 (60%)]\tLoss: 0.495775\n",
      "Train Epoch: 5 [51200/84843 (60%)]\tLoss: 0.821891\n",
      "Train Epoch: 5 [51840/84843 (61%)]\tLoss: 0.525861\n",
      "Train Epoch: 5 [52480/84843 (62%)]\tLoss: 0.430286\n",
      "Train Epoch: 5 [53120/84843 (63%)]\tLoss: 0.450257\n",
      "Train Epoch: 5 [53760/84843 (63%)]\tLoss: 0.451407\n",
      "Train Epoch: 5 [54400/84843 (64%)]\tLoss: 0.239512\n",
      "Train Epoch: 5 [55040/84843 (65%)]\tLoss: 0.351737\n",
      "Train Epoch: 5 [55680/84843 (66%)]\tLoss: 0.271583\n",
      "Train Epoch: 5 [56320/84843 (66%)]\tLoss: 0.334505\n",
      "Train Epoch: 5 [56960/84843 (67%)]\tLoss: 0.739575\n",
      "Train Epoch: 5 [57600/84843 (68%)]\tLoss: 0.381515\n",
      "Train Epoch: 5 [58240/84843 (69%)]\tLoss: 0.414889\n",
      "Train Epoch: 5 [58880/84843 (69%)]\tLoss: 0.611847\n",
      "Train Epoch: 5 [59520/84843 (70%)]\tLoss: 0.228068\n",
      "Train Epoch: 5 [60160/84843 (71%)]\tLoss: 0.391253\n",
      "Train Epoch: 5 [60800/84843 (72%)]\tLoss: 0.504471\n",
      "Train Epoch: 5 [61440/84843 (72%)]\tLoss: 0.345040\n",
      "Train Epoch: 5 [62080/84843 (73%)]\tLoss: 0.499758\n",
      "Train Epoch: 5 [62720/84843 (74%)]\tLoss: 0.282692\n",
      "Train Epoch: 5 [63360/84843 (75%)]\tLoss: 0.254852\n",
      "Train Epoch: 5 [64000/84843 (75%)]\tLoss: 0.472646\n",
      "Train Epoch: 5 [64640/84843 (76%)]\tLoss: 0.218720\n",
      "Train Epoch: 5 [65280/84843 (77%)]\tLoss: 0.430522\n",
      "Train Epoch: 5 [65920/84843 (78%)]\tLoss: 0.192417\n",
      "Train Epoch: 5 [66560/84843 (78%)]\tLoss: 0.490068\n",
      "Train Epoch: 5 [67200/84843 (79%)]\tLoss: 0.412191\n",
      "Train Epoch: 5 [67840/84843 (80%)]\tLoss: 0.457308\n",
      "Train Epoch: 5 [68480/84843 (81%)]\tLoss: 0.627375\n",
      "Train Epoch: 5 [69120/84843 (81%)]\tLoss: 0.096175\n",
      "Train Epoch: 5 [69760/84843 (82%)]\tLoss: 0.410807\n",
      "Train Epoch: 5 [70400/84843 (83%)]\tLoss: 0.704714\n",
      "Train Epoch: 5 [71040/84843 (84%)]\tLoss: 0.497227\n",
      "Train Epoch: 5 [71680/84843 (84%)]\tLoss: 0.824873\n",
      "Train Epoch: 5 [72320/84843 (85%)]\tLoss: 0.436650\n",
      "Train Epoch: 5 [72960/84843 (86%)]\tLoss: 0.203143\n",
      "Train Epoch: 5 [73600/84843 (87%)]\tLoss: 0.390242\n",
      "Train Epoch: 5 [74240/84843 (87%)]\tLoss: 0.643427\n",
      "Train Epoch: 5 [74880/84843 (88%)]\tLoss: 0.342906\n",
      "Train Epoch: 5 [75520/84843 (89%)]\tLoss: 0.323043\n",
      "Train Epoch: 5 [76160/84843 (90%)]\tLoss: 0.266404\n",
      "Train Epoch: 5 [76800/84843 (90%)]\tLoss: 0.495330\n",
      "Train Epoch: 5 [77440/84843 (91%)]\tLoss: 0.488295\n",
      "Train Epoch: 5 [78080/84843 (92%)]\tLoss: 0.269082\n",
      "Train Epoch: 5 [78720/84843 (93%)]\tLoss: 0.168301\n",
      "Train Epoch: 5 [79360/84843 (94%)]\tLoss: 0.196060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [80000/84843 (94%)]\tLoss: 0.164629\n",
      "Train Epoch: 5 [80640/84843 (95%)]\tLoss: 0.201807\n",
      "Train Epoch: 5 [81280/84843 (96%)]\tLoss: 0.414738\n",
      "Train Epoch: 5 [81920/84843 (97%)]\tLoss: 0.244289\n",
      "Train Epoch: 5 [82560/84843 (97%)]\tLoss: 0.274602\n",
      "Train Epoch: 5 [83200/84843 (98%)]\tLoss: 0.374336\n",
      "Train Epoch: 5 [83840/84843 (99%)]\tLoss: 0.479721\n",
      "Train Epoch: 5 [84480/84843 (100%)]\tLoss: 0.251939\n",
      "Accuracy: 9436/11005 (86%)\n",
      "\n",
      "Train Epoch: 6 [0/84843 (0%)]\tLoss: 0.251898\n",
      "Train Epoch: 6 [640/84843 (1%)]\tLoss: 0.213981\n",
      "Train Epoch: 6 [1280/84843 (2%)]\tLoss: 0.325060\n",
      "Train Epoch: 6 [1920/84843 (2%)]\tLoss: 0.219026\n",
      "Train Epoch: 6 [2560/84843 (3%)]\tLoss: 0.613633\n",
      "Train Epoch: 6 [3200/84843 (4%)]\tLoss: 0.296381\n",
      "Train Epoch: 6 [3840/84843 (5%)]\tLoss: 0.239596\n",
      "Train Epoch: 6 [4480/84843 (5%)]\tLoss: 0.459909\n",
      "Train Epoch: 6 [5120/84843 (6%)]\tLoss: 0.517578\n",
      "Train Epoch: 6 [5760/84843 (7%)]\tLoss: 0.256359\n",
      "Train Epoch: 6 [6400/84843 (8%)]\tLoss: 0.504849\n",
      "Train Epoch: 6 [7040/84843 (8%)]\tLoss: 0.327583\n",
      "Train Epoch: 6 [7680/84843 (9%)]\tLoss: 0.354545\n",
      "Train Epoch: 6 [8320/84843 (10%)]\tLoss: 0.390224\n",
      "Train Epoch: 6 [8960/84843 (11%)]\tLoss: 0.345366\n",
      "Train Epoch: 6 [9600/84843 (11%)]\tLoss: 0.420827\n",
      "Train Epoch: 6 [10240/84843 (12%)]\tLoss: 0.344591\n",
      "Train Epoch: 6 [10880/84843 (13%)]\tLoss: 0.100280\n",
      "Train Epoch: 6 [11520/84843 (14%)]\tLoss: 0.564660\n",
      "Train Epoch: 6 [12160/84843 (14%)]\tLoss: 0.400183\n",
      "Train Epoch: 6 [12800/84843 (15%)]\tLoss: 0.453095\n",
      "Train Epoch: 6 [13440/84843 (16%)]\tLoss: 0.469816\n",
      "Train Epoch: 6 [14080/84843 (17%)]\tLoss: 0.463274\n",
      "Train Epoch: 6 [14720/84843 (17%)]\tLoss: 0.432909\n",
      "Train Epoch: 6 [15360/84843 (18%)]\tLoss: 0.354703\n",
      "Train Epoch: 6 [16000/84843 (19%)]\tLoss: 0.296362\n",
      "Train Epoch: 6 [16640/84843 (20%)]\tLoss: 0.230746\n",
      "Train Epoch: 6 [17280/84843 (20%)]\tLoss: 0.134911\n",
      "Train Epoch: 6 [17920/84843 (21%)]\tLoss: 0.396568\n",
      "Train Epoch: 6 [18560/84843 (22%)]\tLoss: 0.607814\n",
      "Train Epoch: 6 [19200/84843 (23%)]\tLoss: 0.176390\n",
      "Train Epoch: 6 [19840/84843 (23%)]\tLoss: 0.623493\n",
      "Train Epoch: 6 [20480/84843 (24%)]\tLoss: 0.576669\n",
      "Train Epoch: 6 [21120/84843 (25%)]\tLoss: 0.239161\n",
      "Train Epoch: 6 [21760/84843 (26%)]\tLoss: 0.398607\n",
      "Train Epoch: 6 [22400/84843 (26%)]\tLoss: 0.187322\n",
      "Train Epoch: 6 [23040/84843 (27%)]\tLoss: 0.516774\n",
      "Train Epoch: 6 [23680/84843 (28%)]\tLoss: 0.517924\n",
      "Train Epoch: 6 [24320/84843 (29%)]\tLoss: 0.694294\n",
      "Train Epoch: 6 [24960/84843 (29%)]\tLoss: 0.397923\n",
      "Train Epoch: 6 [25600/84843 (30%)]\tLoss: 0.184269\n",
      "Train Epoch: 6 [26240/84843 (31%)]\tLoss: 0.491062\n",
      "Train Epoch: 6 [26880/84843 (32%)]\tLoss: 0.535751\n",
      "Train Epoch: 6 [27520/84843 (32%)]\tLoss: 0.521385\n",
      "Train Epoch: 6 [28160/84843 (33%)]\tLoss: 0.158094\n",
      "Train Epoch: 6 [28800/84843 (34%)]\tLoss: 0.375831\n",
      "Train Epoch: 6 [29440/84843 (35%)]\tLoss: 0.636495\n",
      "Train Epoch: 6 [30080/84843 (35%)]\tLoss: 0.488901\n",
      "Train Epoch: 6 [30720/84843 (36%)]\tLoss: 0.211249\n",
      "Train Epoch: 6 [31360/84843 (37%)]\tLoss: 0.374686\n",
      "Train Epoch: 6 [32000/84843 (38%)]\tLoss: 0.090153\n",
      "Train Epoch: 6 [32640/84843 (38%)]\tLoss: 0.468134\n",
      "Train Epoch: 6 [33280/84843 (39%)]\tLoss: 0.404808\n",
      "Train Epoch: 6 [33920/84843 (40%)]\tLoss: 0.476916\n",
      "Train Epoch: 6 [34560/84843 (41%)]\tLoss: 0.571448\n",
      "Train Epoch: 6 [35200/84843 (41%)]\tLoss: 0.418453\n",
      "Train Epoch: 6 [35840/84843 (42%)]\tLoss: 0.193511\n",
      "Train Epoch: 6 [36480/84843 (43%)]\tLoss: 0.164174\n",
      "Train Epoch: 6 [37120/84843 (44%)]\tLoss: 0.506930\n",
      "Train Epoch: 6 [37760/84843 (44%)]\tLoss: 0.533400\n",
      "Train Epoch: 6 [38400/84843 (45%)]\tLoss: 0.321514\n",
      "Train Epoch: 6 [39040/84843 (46%)]\tLoss: 0.523639\n",
      "Train Epoch: 6 [39680/84843 (47%)]\tLoss: 0.150389\n",
      "Train Epoch: 6 [40320/84843 (48%)]\tLoss: 0.333538\n",
      "Train Epoch: 6 [40960/84843 (48%)]\tLoss: 0.250746\n",
      "Train Epoch: 6 [41600/84843 (49%)]\tLoss: 0.083770\n",
      "Train Epoch: 6 [42240/84843 (50%)]\tLoss: 0.214776\n",
      "Train Epoch: 6 [42880/84843 (51%)]\tLoss: 0.481107\n",
      "Train Epoch: 6 [43520/84843 (51%)]\tLoss: 0.243240\n",
      "Train Epoch: 6 [44160/84843 (52%)]\tLoss: 0.133083\n",
      "Train Epoch: 6 [44800/84843 (53%)]\tLoss: 0.178495\n",
      "Train Epoch: 6 [45440/84843 (54%)]\tLoss: 0.168210\n",
      "Train Epoch: 6 [46080/84843 (54%)]\tLoss: 0.265344\n",
      "Train Epoch: 6 [46720/84843 (55%)]\tLoss: 0.661878\n",
      "Train Epoch: 6 [47360/84843 (56%)]\tLoss: 0.329818\n",
      "Train Epoch: 6 [48000/84843 (57%)]\tLoss: 0.149091\n",
      "Train Epoch: 6 [48640/84843 (57%)]\tLoss: 0.757349\n",
      "Train Epoch: 6 [49280/84843 (58%)]\tLoss: 0.356834\n",
      "Train Epoch: 6 [49920/84843 (59%)]\tLoss: 0.119922\n",
      "Train Epoch: 6 [50560/84843 (60%)]\tLoss: 0.199490\n",
      "Train Epoch: 6 [51200/84843 (60%)]\tLoss: 0.118579\n",
      "Train Epoch: 6 [51840/84843 (61%)]\tLoss: 0.248051\n",
      "Train Epoch: 6 [52480/84843 (62%)]\tLoss: 0.438004\n",
      "Train Epoch: 6 [53120/84843 (63%)]\tLoss: 0.299716\n",
      "Train Epoch: 6 [53760/84843 (63%)]\tLoss: 0.448578\n",
      "Train Epoch: 6 [54400/84843 (64%)]\tLoss: 0.290131\n",
      "Train Epoch: 6 [55040/84843 (65%)]\tLoss: 0.168584\n",
      "Train Epoch: 6 [55680/84843 (66%)]\tLoss: 0.521557\n",
      "Train Epoch: 6 [56320/84843 (66%)]\tLoss: 0.401657\n",
      "Train Epoch: 6 [56960/84843 (67%)]\tLoss: 0.296848\n",
      "Train Epoch: 6 [57600/84843 (68%)]\tLoss: 0.362675\n",
      "Train Epoch: 6 [58240/84843 (69%)]\tLoss: 0.394686\n",
      "Train Epoch: 6 [58880/84843 (69%)]\tLoss: 0.359628\n",
      "Train Epoch: 6 [59520/84843 (70%)]\tLoss: 0.598120\n",
      "Train Epoch: 6 [60160/84843 (71%)]\tLoss: 0.736316\n",
      "Train Epoch: 6 [60800/84843 (72%)]\tLoss: 0.564056\n",
      "Train Epoch: 6 [61440/84843 (72%)]\tLoss: 0.482840\n",
      "Train Epoch: 6 [62080/84843 (73%)]\tLoss: 0.443441\n",
      "Train Epoch: 6 [62720/84843 (74%)]\tLoss: 0.199995\n",
      "Train Epoch: 6 [63360/84843 (75%)]\tLoss: 0.430450\n",
      "Train Epoch: 6 [64000/84843 (75%)]\tLoss: 0.310181\n",
      "Train Epoch: 6 [64640/84843 (76%)]\tLoss: 0.110340\n",
      "Train Epoch: 6 [65280/84843 (77%)]\tLoss: 0.509711\n",
      "Train Epoch: 6 [65920/84843 (78%)]\tLoss: 0.337018\n",
      "Train Epoch: 6 [66560/84843 (78%)]\tLoss: 0.118051\n",
      "Train Epoch: 6 [67200/84843 (79%)]\tLoss: 0.391200\n",
      "Train Epoch: 6 [67840/84843 (80%)]\tLoss: 0.326178\n",
      "Train Epoch: 6 [68480/84843 (81%)]\tLoss: 0.680409\n",
      "Train Epoch: 6 [69120/84843 (81%)]\tLoss: 0.742241\n",
      "Train Epoch: 6 [69760/84843 (82%)]\tLoss: 0.166138\n",
      "Train Epoch: 6 [70400/84843 (83%)]\tLoss: 0.284839\n",
      "Train Epoch: 6 [71040/84843 (84%)]\tLoss: 0.358061\n",
      "Train Epoch: 6 [71680/84843 (84%)]\tLoss: 0.203138\n",
      "Train Epoch: 6 [72320/84843 (85%)]\tLoss: 0.249272\n",
      "Train Epoch: 6 [72960/84843 (86%)]\tLoss: 0.464682\n",
      "Train Epoch: 6 [73600/84843 (87%)]\tLoss: 0.366048\n",
      "Train Epoch: 6 [74240/84843 (87%)]\tLoss: 0.518809\n",
      "Train Epoch: 6 [74880/84843 (88%)]\tLoss: 0.537433\n",
      "Train Epoch: 6 [75520/84843 (89%)]\tLoss: 0.336379\n",
      "Train Epoch: 6 [76160/84843 (90%)]\tLoss: 0.560868\n",
      "Train Epoch: 6 [76800/84843 (90%)]\tLoss: 0.492561\n",
      "Train Epoch: 6 [77440/84843 (91%)]\tLoss: 0.533017\n",
      "Train Epoch: 6 [78080/84843 (92%)]\tLoss: 0.337399\n",
      "Train Epoch: 6 [78720/84843 (93%)]\tLoss: 0.364046\n",
      "Train Epoch: 6 [79360/84843 (94%)]\tLoss: 0.439468\n",
      "Train Epoch: 6 [80000/84843 (94%)]\tLoss: 0.222043\n",
      "Train Epoch: 6 [80640/84843 (95%)]\tLoss: 0.393386\n",
      "Train Epoch: 6 [81280/84843 (96%)]\tLoss: 0.270118\n",
      "Train Epoch: 6 [81920/84843 (97%)]\tLoss: 0.477983\n",
      "Train Epoch: 6 [82560/84843 (97%)]\tLoss: 0.364465\n",
      "Train Epoch: 6 [83200/84843 (98%)]\tLoss: 0.466733\n",
      "Train Epoch: 6 [83840/84843 (99%)]\tLoss: 0.604912\n",
      "Train Epoch: 6 [84480/84843 (100%)]\tLoss: 0.496018\n",
      "Accuracy: 9438/11005 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/84843 (0%)]\tLoss: 0.589495\n",
      "Train Epoch: 7 [640/84843 (1%)]\tLoss: 0.538857\n",
      "Train Epoch: 7 [1280/84843 (2%)]\tLoss: 0.291301\n",
      "Train Epoch: 7 [1920/84843 (2%)]\tLoss: 0.390877\n",
      "Train Epoch: 7 [2560/84843 (3%)]\tLoss: 0.269686\n",
      "Train Epoch: 7 [3200/84843 (4%)]\tLoss: 0.506922\n",
      "Train Epoch: 7 [3840/84843 (5%)]\tLoss: 0.447310\n",
      "Train Epoch: 7 [4480/84843 (5%)]\tLoss: 0.335163\n",
      "Train Epoch: 7 [5120/84843 (6%)]\tLoss: 0.121404\n",
      "Train Epoch: 7 [5760/84843 (7%)]\tLoss: 0.766728\n",
      "Train Epoch: 7 [6400/84843 (8%)]\tLoss: 0.267120\n",
      "Train Epoch: 7 [7040/84843 (8%)]\tLoss: 0.294766\n",
      "Train Epoch: 7 [7680/84843 (9%)]\tLoss: 0.582344\n",
      "Train Epoch: 7 [8320/84843 (10%)]\tLoss: 0.360339\n",
      "Train Epoch: 7 [8960/84843 (11%)]\tLoss: 0.143978\n",
      "Train Epoch: 7 [9600/84843 (11%)]\tLoss: 0.470916\n",
      "Train Epoch: 7 [10240/84843 (12%)]\tLoss: 0.474892\n",
      "Train Epoch: 7 [10880/84843 (13%)]\tLoss: 0.187026\n",
      "Train Epoch: 7 [11520/84843 (14%)]\tLoss: 0.113980\n",
      "Train Epoch: 7 [12160/84843 (14%)]\tLoss: 0.420170\n",
      "Train Epoch: 7 [12800/84843 (15%)]\tLoss: 0.779113\n",
      "Train Epoch: 7 [13440/84843 (16%)]\tLoss: 0.359919\n",
      "Train Epoch: 7 [14080/84843 (17%)]\tLoss: 0.589402\n",
      "Train Epoch: 7 [14720/84843 (17%)]\tLoss: 0.385422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [15360/84843 (18%)]\tLoss: 0.198369\n",
      "Train Epoch: 7 [16000/84843 (19%)]\tLoss: 0.342084\n",
      "Train Epoch: 7 [16640/84843 (20%)]\tLoss: 0.363473\n",
      "Train Epoch: 7 [17280/84843 (20%)]\tLoss: 0.119368\n",
      "Train Epoch: 7 [17920/84843 (21%)]\tLoss: 0.168545\n",
      "Train Epoch: 7 [18560/84843 (22%)]\tLoss: 0.472648\n",
      "Train Epoch: 7 [19200/84843 (23%)]\tLoss: 0.489822\n",
      "Train Epoch: 7 [19840/84843 (23%)]\tLoss: 0.113341\n",
      "Train Epoch: 7 [20480/84843 (24%)]\tLoss: 0.363324\n",
      "Train Epoch: 7 [21120/84843 (25%)]\tLoss: 0.573969\n",
      "Train Epoch: 7 [21760/84843 (26%)]\tLoss: 0.456604\n",
      "Train Epoch: 7 [22400/84843 (26%)]\tLoss: 0.537859\n",
      "Train Epoch: 7 [23040/84843 (27%)]\tLoss: 0.439044\n",
      "Train Epoch: 7 [23680/84843 (28%)]\tLoss: 0.355658\n",
      "Train Epoch: 7 [24320/84843 (29%)]\tLoss: 0.458340\n",
      "Train Epoch: 7 [24960/84843 (29%)]\tLoss: 0.103405\n",
      "Train Epoch: 7 [25600/84843 (30%)]\tLoss: 0.485997\n",
      "Train Epoch: 7 [26240/84843 (31%)]\tLoss: 0.256063\n",
      "Train Epoch: 7 [26880/84843 (32%)]\tLoss: 0.354402\n",
      "Train Epoch: 7 [27520/84843 (32%)]\tLoss: 0.235696\n",
      "Train Epoch: 7 [28160/84843 (33%)]\tLoss: 0.322764\n",
      "Train Epoch: 7 [28800/84843 (34%)]\tLoss: 0.705002\n",
      "Train Epoch: 7 [29440/84843 (35%)]\tLoss: 0.328201\n",
      "Train Epoch: 7 [30080/84843 (35%)]\tLoss: 0.379419\n",
      "Train Epoch: 7 [30720/84843 (36%)]\tLoss: 0.557647\n",
      "Train Epoch: 7 [31360/84843 (37%)]\tLoss: 0.626726\n",
      "Train Epoch: 7 [32000/84843 (38%)]\tLoss: 0.502776\n",
      "Train Epoch: 7 [32640/84843 (38%)]\tLoss: 0.221856\n",
      "Train Epoch: 7 [33280/84843 (39%)]\tLoss: 0.365811\n",
      "Train Epoch: 7 [33920/84843 (40%)]\tLoss: 0.367584\n",
      "Train Epoch: 7 [34560/84843 (41%)]\tLoss: 0.596224\n",
      "Train Epoch: 7 [35200/84843 (41%)]\tLoss: 0.452810\n",
      "Train Epoch: 7 [35840/84843 (42%)]\tLoss: 0.528032\n",
      "Train Epoch: 7 [36480/84843 (43%)]\tLoss: 0.207988\n",
      "Train Epoch: 7 [37120/84843 (44%)]\tLoss: 0.332066\n",
      "Train Epoch: 7 [37760/84843 (44%)]\tLoss: 0.343718\n",
      "Train Epoch: 7 [38400/84843 (45%)]\tLoss: 0.238279\n",
      "Train Epoch: 7 [39040/84843 (46%)]\tLoss: 0.229410\n",
      "Train Epoch: 7 [39680/84843 (47%)]\tLoss: 0.503816\n",
      "Train Epoch: 7 [40320/84843 (48%)]\tLoss: 0.354874\n",
      "Train Epoch: 7 [40960/84843 (48%)]\tLoss: 0.321498\n",
      "Train Epoch: 7 [41600/84843 (49%)]\tLoss: 0.253298\n",
      "Train Epoch: 7 [42240/84843 (50%)]\tLoss: 0.480831\n",
      "Train Epoch: 7 [42880/84843 (51%)]\tLoss: 0.623895\n",
      "Train Epoch: 7 [43520/84843 (51%)]\tLoss: 0.210154\n",
      "Train Epoch: 7 [44160/84843 (52%)]\tLoss: 0.694422\n",
      "Train Epoch: 7 [44800/84843 (53%)]\tLoss: 0.210287\n",
      "Train Epoch: 7 [45440/84843 (54%)]\tLoss: 0.233615\n",
      "Train Epoch: 7 [46080/84843 (54%)]\tLoss: 0.476111\n",
      "Train Epoch: 7 [46720/84843 (55%)]\tLoss: 0.230644\n",
      "Train Epoch: 7 [47360/84843 (56%)]\tLoss: 0.568444\n",
      "Train Epoch: 7 [48000/84843 (57%)]\tLoss: 0.246411\n",
      "Train Epoch: 7 [48640/84843 (57%)]\tLoss: 0.950972\n",
      "Train Epoch: 7 [49280/84843 (58%)]\tLoss: 0.460906\n",
      "Train Epoch: 7 [49920/84843 (59%)]\tLoss: 0.271213\n",
      "Train Epoch: 7 [50560/84843 (60%)]\tLoss: 0.303702\n",
      "Train Epoch: 7 [51200/84843 (60%)]\tLoss: 0.224466\n",
      "Train Epoch: 7 [51840/84843 (61%)]\tLoss: 0.362161\n",
      "Train Epoch: 7 [52480/84843 (62%)]\tLoss: 0.473708\n",
      "Train Epoch: 7 [53120/84843 (63%)]\tLoss: 0.255347\n",
      "Train Epoch: 7 [53760/84843 (63%)]\tLoss: 0.605635\n",
      "Train Epoch: 7 [54400/84843 (64%)]\tLoss: 0.405007\n",
      "Train Epoch: 7 [55040/84843 (65%)]\tLoss: 0.353957\n",
      "Train Epoch: 7 [55680/84843 (66%)]\tLoss: 0.589542\n",
      "Train Epoch: 7 [56320/84843 (66%)]\tLoss: 0.402914\n",
      "Train Epoch: 7 [56960/84843 (67%)]\tLoss: 0.536949\n",
      "Train Epoch: 7 [57600/84843 (68%)]\tLoss: 0.611676\n",
      "Train Epoch: 7 [58240/84843 (69%)]\tLoss: 0.386514\n",
      "Train Epoch: 7 [58880/84843 (69%)]\tLoss: 0.557194\n",
      "Train Epoch: 7 [59520/84843 (70%)]\tLoss: 0.431656\n",
      "Train Epoch: 7 [60160/84843 (71%)]\tLoss: 0.265537\n",
      "Train Epoch: 7 [60800/84843 (72%)]\tLoss: 0.560653\n",
      "Train Epoch: 7 [61440/84843 (72%)]\tLoss: 0.506688\n",
      "Train Epoch: 7 [62080/84843 (73%)]\tLoss: 0.189839\n",
      "Train Epoch: 7 [62720/84843 (74%)]\tLoss: 0.169922\n",
      "Train Epoch: 7 [63360/84843 (75%)]\tLoss: 0.189519\n",
      "Train Epoch: 7 [64000/84843 (75%)]\tLoss: 0.137474\n",
      "Train Epoch: 7 [64640/84843 (76%)]\tLoss: 0.121007\n",
      "Train Epoch: 7 [65280/84843 (77%)]\tLoss: 0.455993\n",
      "Train Epoch: 7 [65920/84843 (78%)]\tLoss: 0.378577\n",
      "Train Epoch: 7 [66560/84843 (78%)]\tLoss: 0.396633\n",
      "Train Epoch: 7 [67200/84843 (79%)]\tLoss: 0.140109\n",
      "Train Epoch: 7 [67840/84843 (80%)]\tLoss: 0.604581\n",
      "Train Epoch: 7 [68480/84843 (81%)]\tLoss: 0.209405\n",
      "Train Epoch: 7 [69120/84843 (81%)]\tLoss: 0.311223\n",
      "Train Epoch: 7 [69760/84843 (82%)]\tLoss: 0.306929\n",
      "Train Epoch: 7 [70400/84843 (83%)]\tLoss: 0.354357\n",
      "Train Epoch: 7 [71040/84843 (84%)]\tLoss: 0.526665\n",
      "Train Epoch: 7 [71680/84843 (84%)]\tLoss: 0.249559\n",
      "Train Epoch: 7 [72320/84843 (85%)]\tLoss: 0.517039\n",
      "Train Epoch: 7 [72960/84843 (86%)]\tLoss: 0.580175\n",
      "Train Epoch: 7 [73600/84843 (87%)]\tLoss: 0.144915\n",
      "Train Epoch: 7 [74240/84843 (87%)]\tLoss: 0.433821\n",
      "Train Epoch: 7 [74880/84843 (88%)]\tLoss: 0.295757\n",
      "Train Epoch: 7 [75520/84843 (89%)]\tLoss: 0.661869\n",
      "Train Epoch: 7 [76160/84843 (90%)]\tLoss: 0.184184\n",
      "Train Epoch: 7 [76800/84843 (90%)]\tLoss: 0.534296\n",
      "Train Epoch: 7 [77440/84843 (91%)]\tLoss: 0.344967\n",
      "Train Epoch: 7 [78080/84843 (92%)]\tLoss: 0.339585\n",
      "Train Epoch: 7 [78720/84843 (93%)]\tLoss: 0.348468\n",
      "Train Epoch: 7 [79360/84843 (94%)]\tLoss: 0.291464\n",
      "Train Epoch: 7 [80000/84843 (94%)]\tLoss: 0.123240\n",
      "Train Epoch: 7 [80640/84843 (95%)]\tLoss: 0.214855\n",
      "Train Epoch: 7 [81280/84843 (96%)]\tLoss: 0.385142\n",
      "Train Epoch: 7 [81920/84843 (97%)]\tLoss: 0.262417\n",
      "Train Epoch: 7 [82560/84843 (97%)]\tLoss: 0.437361\n",
      "Train Epoch: 7 [83200/84843 (98%)]\tLoss: 0.753226\n",
      "Train Epoch: 7 [83840/84843 (99%)]\tLoss: 0.205344\n",
      "Train Epoch: 7 [84480/84843 (100%)]\tLoss: 0.386222\n",
      "Accuracy: 9472/11005 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/84843 (0%)]\tLoss: 0.328414\n",
      "Train Epoch: 8 [640/84843 (1%)]\tLoss: 0.791281\n",
      "Train Epoch: 8 [1280/84843 (2%)]\tLoss: 0.202029\n",
      "Train Epoch: 8 [1920/84843 (2%)]\tLoss: 0.315407\n",
      "Train Epoch: 8 [2560/84843 (3%)]\tLoss: 0.196905\n",
      "Train Epoch: 8 [3200/84843 (4%)]\tLoss: 0.541372\n",
      "Train Epoch: 8 [3840/84843 (5%)]\tLoss: 0.295213\n",
      "Train Epoch: 8 [4480/84843 (5%)]\tLoss: 0.311539\n",
      "Train Epoch: 8 [5120/84843 (6%)]\tLoss: 0.181229\n",
      "Train Epoch: 8 [5760/84843 (7%)]\tLoss: 0.269249\n",
      "Train Epoch: 8 [6400/84843 (8%)]\tLoss: 0.223148\n",
      "Train Epoch: 8 [7040/84843 (8%)]\tLoss: 0.283199\n",
      "Train Epoch: 8 [7680/84843 (9%)]\tLoss: 0.581525\n",
      "Train Epoch: 8 [8320/84843 (10%)]\tLoss: 0.364095\n",
      "Train Epoch: 8 [8960/84843 (11%)]\tLoss: 0.245953\n",
      "Train Epoch: 8 [9600/84843 (11%)]\tLoss: 0.579057\n",
      "Train Epoch: 8 [10240/84843 (12%)]\tLoss: 0.616900\n",
      "Train Epoch: 8 [10880/84843 (13%)]\tLoss: 0.444207\n",
      "Train Epoch: 8 [11520/84843 (14%)]\tLoss: 0.484512\n",
      "Train Epoch: 8 [12160/84843 (14%)]\tLoss: 0.236599\n",
      "Train Epoch: 8 [12800/84843 (15%)]\tLoss: 0.374146\n",
      "Train Epoch: 8 [13440/84843 (16%)]\tLoss: 0.502581\n",
      "Train Epoch: 8 [14080/84843 (17%)]\tLoss: 0.501508\n",
      "Train Epoch: 8 [14720/84843 (17%)]\tLoss: 0.449600\n",
      "Train Epoch: 8 [15360/84843 (18%)]\tLoss: 0.349154\n",
      "Train Epoch: 8 [16000/84843 (19%)]\tLoss: 0.263412\n",
      "Train Epoch: 8 [16640/84843 (20%)]\tLoss: 0.068895\n",
      "Train Epoch: 8 [17280/84843 (20%)]\tLoss: 0.687787\n",
      "Train Epoch: 8 [17920/84843 (21%)]\tLoss: 0.308179\n",
      "Train Epoch: 8 [18560/84843 (22%)]\tLoss: 0.289084\n",
      "Train Epoch: 8 [19200/84843 (23%)]\tLoss: 0.292794\n",
      "Train Epoch: 8 [19840/84843 (23%)]\tLoss: 0.629713\n",
      "Train Epoch: 8 [20480/84843 (24%)]\tLoss: 0.352184\n",
      "Train Epoch: 8 [21120/84843 (25%)]\tLoss: 0.275049\n",
      "Train Epoch: 8 [21760/84843 (26%)]\tLoss: 0.337011\n",
      "Train Epoch: 8 [22400/84843 (26%)]\tLoss: 0.174141\n",
      "Train Epoch: 8 [23040/84843 (27%)]\tLoss: 0.507523\n",
      "Train Epoch: 8 [23680/84843 (28%)]\tLoss: 0.352720\n",
      "Train Epoch: 8 [24320/84843 (29%)]\tLoss: 0.441761\n",
      "Train Epoch: 8 [24960/84843 (29%)]\tLoss: 0.493476\n",
      "Train Epoch: 8 [25600/84843 (30%)]\tLoss: 0.618037\n",
      "Train Epoch: 8 [26240/84843 (31%)]\tLoss: 0.025754\n",
      "Train Epoch: 8 [26880/84843 (32%)]\tLoss: 0.707718\n",
      "Train Epoch: 8 [27520/84843 (32%)]\tLoss: 0.477963\n",
      "Train Epoch: 8 [28160/84843 (33%)]\tLoss: 0.239512\n",
      "Train Epoch: 8 [28800/84843 (34%)]\tLoss: 0.502573\n",
      "Train Epoch: 8 [29440/84843 (35%)]\tLoss: 0.360245\n",
      "Train Epoch: 8 [30080/84843 (35%)]\tLoss: 0.724332\n",
      "Train Epoch: 8 [30720/84843 (36%)]\tLoss: 0.594154\n",
      "Train Epoch: 8 [31360/84843 (37%)]\tLoss: 0.490571\n",
      "Train Epoch: 8 [32000/84843 (38%)]\tLoss: 0.519237\n",
      "Train Epoch: 8 [32640/84843 (38%)]\tLoss: 0.359746\n",
      "Train Epoch: 8 [33280/84843 (39%)]\tLoss: 0.509680\n",
      "Train Epoch: 8 [33920/84843 (40%)]\tLoss: 0.422931\n",
      "Train Epoch: 8 [34560/84843 (41%)]\tLoss: 0.428461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [35200/84843 (41%)]\tLoss: 0.524001\n",
      "Train Epoch: 8 [35840/84843 (42%)]\tLoss: 0.232844\n",
      "Train Epoch: 8 [36480/84843 (43%)]\tLoss: 0.317180\n",
      "Train Epoch: 8 [37120/84843 (44%)]\tLoss: 0.773124\n",
      "Train Epoch: 8 [37760/84843 (44%)]\tLoss: 0.236675\n",
      "Train Epoch: 8 [38400/84843 (45%)]\tLoss: 0.515612\n",
      "Train Epoch: 8 [39040/84843 (46%)]\tLoss: 0.368092\n",
      "Train Epoch: 8 [39680/84843 (47%)]\tLoss: 0.224621\n",
      "Train Epoch: 8 [40320/84843 (48%)]\tLoss: 0.063501\n",
      "Train Epoch: 8 [40960/84843 (48%)]\tLoss: 0.338740\n",
      "Train Epoch: 8 [41600/84843 (49%)]\tLoss: 0.343596\n",
      "Train Epoch: 8 [42240/84843 (50%)]\tLoss: 0.436595\n",
      "Train Epoch: 8 [42880/84843 (51%)]\tLoss: 0.286970\n",
      "Train Epoch: 8 [43520/84843 (51%)]\tLoss: 0.339002\n",
      "Train Epoch: 8 [44160/84843 (52%)]\tLoss: 0.128705\n",
      "Train Epoch: 8 [44800/84843 (53%)]\tLoss: 0.672965\n",
      "Train Epoch: 8 [45440/84843 (54%)]\tLoss: 0.680940\n",
      "Train Epoch: 8 [46080/84843 (54%)]\tLoss: 0.386288\n",
      "Train Epoch: 8 [46720/84843 (55%)]\tLoss: 0.450744\n",
      "Train Epoch: 8 [47360/84843 (56%)]\tLoss: 0.332997\n",
      "Train Epoch: 8 [48000/84843 (57%)]\tLoss: 0.357480\n",
      "Train Epoch: 8 [48640/84843 (57%)]\tLoss: 0.468815\n",
      "Train Epoch: 8 [49280/84843 (58%)]\tLoss: 0.200884\n",
      "Train Epoch: 8 [49920/84843 (59%)]\tLoss: 0.195797\n",
      "Train Epoch: 8 [50560/84843 (60%)]\tLoss: 0.713042\n",
      "Train Epoch: 8 [51200/84843 (60%)]\tLoss: 0.503467\n",
      "Train Epoch: 8 [51840/84843 (61%)]\tLoss: 0.514323\n",
      "Train Epoch: 8 [52480/84843 (62%)]\tLoss: 0.305175\n",
      "Train Epoch: 8 [53120/84843 (63%)]\tLoss: 0.506084\n",
      "Train Epoch: 8 [53760/84843 (63%)]\tLoss: 0.225168\n",
      "Train Epoch: 8 [54400/84843 (64%)]\tLoss: 0.417136\n",
      "Train Epoch: 8 [55040/84843 (65%)]\tLoss: 0.828700\n",
      "Train Epoch: 8 [55680/84843 (66%)]\tLoss: 0.098873\n",
      "Train Epoch: 8 [56320/84843 (66%)]\tLoss: 0.232183\n",
      "Train Epoch: 8 [56960/84843 (67%)]\tLoss: 0.280964\n",
      "Train Epoch: 8 [57600/84843 (68%)]\tLoss: 0.350201\n",
      "Train Epoch: 8 [58240/84843 (69%)]\tLoss: 0.895404\n",
      "Train Epoch: 8 [58880/84843 (69%)]\tLoss: 0.337922\n",
      "Train Epoch: 8 [59520/84843 (70%)]\tLoss: 0.267273\n",
      "Train Epoch: 8 [60160/84843 (71%)]\tLoss: 0.448670\n",
      "Train Epoch: 8 [60800/84843 (72%)]\tLoss: 0.415016\n",
      "Train Epoch: 8 [61440/84843 (72%)]\tLoss: 0.600651\n",
      "Train Epoch: 8 [62080/84843 (73%)]\tLoss: 0.389059\n",
      "Train Epoch: 8 [62720/84843 (74%)]\tLoss: 0.451522\n",
      "Train Epoch: 8 [63360/84843 (75%)]\tLoss: 0.198218\n",
      "Train Epoch: 8 [64000/84843 (75%)]\tLoss: 0.524837\n",
      "Train Epoch: 8 [64640/84843 (76%)]\tLoss: 0.344629\n",
      "Train Epoch: 8 [65280/84843 (77%)]\tLoss: 0.317708\n",
      "Train Epoch: 8 [65920/84843 (78%)]\tLoss: 0.438162\n",
      "Train Epoch: 8 [66560/84843 (78%)]\tLoss: 0.590226\n",
      "Train Epoch: 8 [67200/84843 (79%)]\tLoss: 0.257671\n",
      "Train Epoch: 8 [67840/84843 (80%)]\tLoss: 0.368580\n",
      "Train Epoch: 8 [68480/84843 (81%)]\tLoss: 0.739171\n",
      "Train Epoch: 8 [69120/84843 (81%)]\tLoss: 0.535983\n",
      "Train Epoch: 8 [69760/84843 (82%)]\tLoss: 0.305049\n",
      "Train Epoch: 8 [70400/84843 (83%)]\tLoss: 0.379778\n",
      "Train Epoch: 8 [71040/84843 (84%)]\tLoss: 0.249616\n",
      "Train Epoch: 8 [71680/84843 (84%)]\tLoss: 0.147647\n",
      "Train Epoch: 8 [72320/84843 (85%)]\tLoss: 0.362060\n",
      "Train Epoch: 8 [72960/84843 (86%)]\tLoss: 0.306551\n",
      "Train Epoch: 8 [73600/84843 (87%)]\tLoss: 0.187637\n",
      "Train Epoch: 8 [74240/84843 (87%)]\tLoss: 0.370261\n",
      "Train Epoch: 8 [74880/84843 (88%)]\tLoss: 0.220278\n",
      "Train Epoch: 8 [75520/84843 (89%)]\tLoss: 0.172028\n",
      "Train Epoch: 8 [76160/84843 (90%)]\tLoss: 0.513749\n",
      "Train Epoch: 8 [76800/84843 (90%)]\tLoss: 0.491574\n",
      "Train Epoch: 8 [77440/84843 (91%)]\tLoss: 0.431506\n",
      "Train Epoch: 8 [78080/84843 (92%)]\tLoss: 0.442932\n",
      "Train Epoch: 8 [78720/84843 (93%)]\tLoss: 0.406409\n",
      "Train Epoch: 8 [79360/84843 (94%)]\tLoss: 0.290552\n",
      "Train Epoch: 8 [80000/84843 (94%)]\tLoss: 0.286929\n",
      "Train Epoch: 8 [80640/84843 (95%)]\tLoss: 0.063536\n",
      "Train Epoch: 8 [81280/84843 (96%)]\tLoss: 0.245834\n",
      "Train Epoch: 8 [81920/84843 (97%)]\tLoss: 0.359337\n",
      "Train Epoch: 8 [82560/84843 (97%)]\tLoss: 0.544327\n",
      "Train Epoch: 8 [83200/84843 (98%)]\tLoss: 0.418670\n",
      "Train Epoch: 8 [83840/84843 (99%)]\tLoss: 0.431773\n",
      "Train Epoch: 8 [84480/84843 (100%)]\tLoss: 0.574288\n",
      "Accuracy: 9431/11005 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/84843 (0%)]\tLoss: 0.182988\n",
      "Train Epoch: 9 [640/84843 (1%)]\tLoss: 0.129581\n",
      "Train Epoch: 9 [1280/84843 (2%)]\tLoss: 0.122450\n",
      "Train Epoch: 9 [1920/84843 (2%)]\tLoss: 0.186032\n",
      "Train Epoch: 9 [2560/84843 (3%)]\tLoss: 0.395188\n",
      "Train Epoch: 9 [3200/84843 (4%)]\tLoss: 0.326234\n",
      "Train Epoch: 9 [3840/84843 (5%)]\tLoss: 0.158470\n",
      "Train Epoch: 9 [4480/84843 (5%)]\tLoss: 0.341538\n",
      "Train Epoch: 9 [5120/84843 (6%)]\tLoss: 0.245308\n",
      "Train Epoch: 9 [5760/84843 (7%)]\tLoss: 0.382808\n",
      "Train Epoch: 9 [6400/84843 (8%)]\tLoss: 0.306027\n",
      "Train Epoch: 9 [7040/84843 (8%)]\tLoss: 0.372344\n",
      "Train Epoch: 9 [7680/84843 (9%)]\tLoss: 0.616096\n",
      "Train Epoch: 9 [8320/84843 (10%)]\tLoss: 0.426387\n",
      "Train Epoch: 9 [8960/84843 (11%)]\tLoss: 0.455300\n",
      "Train Epoch: 9 [9600/84843 (11%)]\tLoss: 0.244771\n",
      "Train Epoch: 9 [10240/84843 (12%)]\tLoss: 0.395618\n",
      "Train Epoch: 9 [10880/84843 (13%)]\tLoss: 0.190092\n",
      "Train Epoch: 9 [11520/84843 (14%)]\tLoss: 0.203184\n",
      "Train Epoch: 9 [12160/84843 (14%)]\tLoss: 0.482754\n",
      "Train Epoch: 9 [12800/84843 (15%)]\tLoss: 0.344130\n",
      "Train Epoch: 9 [13440/84843 (16%)]\tLoss: 0.256264\n",
      "Train Epoch: 9 [14080/84843 (17%)]\tLoss: 0.512699\n",
      "Train Epoch: 9 [14720/84843 (17%)]\tLoss: 0.296986\n",
      "Train Epoch: 9 [15360/84843 (18%)]\tLoss: 0.516854\n",
      "Train Epoch: 9 [16000/84843 (19%)]\tLoss: 0.147842\n",
      "Train Epoch: 9 [16640/84843 (20%)]\tLoss: 0.220278\n",
      "Train Epoch: 9 [17280/84843 (20%)]\tLoss: 0.656012\n",
      "Train Epoch: 9 [17920/84843 (21%)]\tLoss: 0.303038\n",
      "Train Epoch: 9 [18560/84843 (22%)]\tLoss: 0.956901\n",
      "Train Epoch: 9 [19200/84843 (23%)]\tLoss: 0.175964\n",
      "Train Epoch: 9 [19840/84843 (23%)]\tLoss: 0.229809\n",
      "Train Epoch: 9 [20480/84843 (24%)]\tLoss: 0.379230\n",
      "Train Epoch: 9 [21120/84843 (25%)]\tLoss: 0.413577\n",
      "Train Epoch: 9 [21760/84843 (26%)]\tLoss: 0.232456\n",
      "Train Epoch: 9 [22400/84843 (26%)]\tLoss: 0.505273\n",
      "Train Epoch: 9 [23040/84843 (27%)]\tLoss: 0.273695\n",
      "Train Epoch: 9 [23680/84843 (28%)]\tLoss: 0.441432\n",
      "Train Epoch: 9 [24320/84843 (29%)]\tLoss: 0.374723\n",
      "Train Epoch: 9 [24960/84843 (29%)]\tLoss: 0.366408\n",
      "Train Epoch: 9 [25600/84843 (30%)]\tLoss: 0.320637\n",
      "Train Epoch: 9 [26240/84843 (31%)]\tLoss: 0.093834\n",
      "Train Epoch: 9 [26880/84843 (32%)]\tLoss: 0.427962\n",
      "Train Epoch: 9 [27520/84843 (32%)]\tLoss: 0.354593\n",
      "Train Epoch: 9 [28160/84843 (33%)]\tLoss: 0.460023\n",
      "Train Epoch: 9 [28800/84843 (34%)]\tLoss: 0.447120\n",
      "Train Epoch: 9 [29440/84843 (35%)]\tLoss: 0.650219\n",
      "Train Epoch: 9 [30080/84843 (35%)]\tLoss: 0.642255\n",
      "Train Epoch: 9 [30720/84843 (36%)]\tLoss: 0.276291\n",
      "Train Epoch: 9 [31360/84843 (37%)]\tLoss: 0.557030\n",
      "Train Epoch: 9 [32000/84843 (38%)]\tLoss: 0.826082\n",
      "Train Epoch: 9 [32640/84843 (38%)]\tLoss: 0.269474\n",
      "Train Epoch: 9 [33280/84843 (39%)]\tLoss: 0.302859\n",
      "Train Epoch: 9 [33920/84843 (40%)]\tLoss: 0.623221\n",
      "Train Epoch: 9 [34560/84843 (41%)]\tLoss: 0.328444\n",
      "Train Epoch: 9 [35200/84843 (41%)]\tLoss: 0.287283\n",
      "Train Epoch: 9 [35840/84843 (42%)]\tLoss: 0.412607\n",
      "Train Epoch: 9 [36480/84843 (43%)]\tLoss: 0.588518\n",
      "Train Epoch: 9 [37120/84843 (44%)]\tLoss: 0.216619\n",
      "Train Epoch: 9 [37760/84843 (44%)]\tLoss: 0.380904\n",
      "Train Epoch: 9 [38400/84843 (45%)]\tLoss: 0.428538\n",
      "Train Epoch: 9 [39040/84843 (46%)]\tLoss: 0.477090\n",
      "Train Epoch: 9 [39680/84843 (47%)]\tLoss: 0.627305\n",
      "Train Epoch: 9 [40320/84843 (48%)]\tLoss: 0.473458\n",
      "Train Epoch: 9 [40960/84843 (48%)]\tLoss: 0.053281\n",
      "Train Epoch: 9 [41600/84843 (49%)]\tLoss: 0.345083\n",
      "Train Epoch: 9 [42240/84843 (50%)]\tLoss: 0.483224\n",
      "Train Epoch: 9 [42880/84843 (51%)]\tLoss: 0.542962\n",
      "Train Epoch: 9 [43520/84843 (51%)]\tLoss: 0.299670\n",
      "Train Epoch: 9 [44160/84843 (52%)]\tLoss: 0.294147\n",
      "Train Epoch: 9 [44800/84843 (53%)]\tLoss: 0.241371\n",
      "Train Epoch: 9 [45440/84843 (54%)]\tLoss: 0.420642\n",
      "Train Epoch: 9 [46080/84843 (54%)]\tLoss: 0.413057\n",
      "Train Epoch: 9 [46720/84843 (55%)]\tLoss: 0.508864\n",
      "Train Epoch: 9 [47360/84843 (56%)]\tLoss: 0.283732\n",
      "Train Epoch: 9 [48000/84843 (57%)]\tLoss: 0.137770\n",
      "Train Epoch: 9 [48640/84843 (57%)]\tLoss: 0.114623\n",
      "Train Epoch: 9 [49280/84843 (58%)]\tLoss: 0.127718\n",
      "Train Epoch: 9 [49920/84843 (59%)]\tLoss: 0.253286\n",
      "Train Epoch: 9 [50560/84843 (60%)]\tLoss: 0.436874\n",
      "Train Epoch: 9 [51200/84843 (60%)]\tLoss: 0.683324\n",
      "Train Epoch: 9 [51840/84843 (61%)]\tLoss: 0.481420\n",
      "Train Epoch: 9 [52480/84843 (62%)]\tLoss: 0.129718\n",
      "Train Epoch: 9 [53120/84843 (63%)]\tLoss: 0.130732\n",
      "Train Epoch: 9 [53760/84843 (63%)]\tLoss: 0.210926\n",
      "Train Epoch: 9 [54400/84843 (64%)]\tLoss: 0.498266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [55040/84843 (65%)]\tLoss: 0.242604\n",
      "Train Epoch: 9 [55680/84843 (66%)]\tLoss: 0.247191\n",
      "Train Epoch: 9 [56320/84843 (66%)]\tLoss: 0.297560\n",
      "Train Epoch: 9 [56960/84843 (67%)]\tLoss: 0.431917\n",
      "Train Epoch: 9 [57600/84843 (68%)]\tLoss: 0.161780\n",
      "Train Epoch: 9 [58240/84843 (69%)]\tLoss: 0.385029\n",
      "Train Epoch: 9 [58880/84843 (69%)]\tLoss: 0.081591\n",
      "Train Epoch: 9 [59520/84843 (70%)]\tLoss: 0.339154\n",
      "Train Epoch: 9 [60160/84843 (71%)]\tLoss: 0.431709\n",
      "Train Epoch: 9 [60800/84843 (72%)]\tLoss: 0.643423\n",
      "Train Epoch: 9 [61440/84843 (72%)]\tLoss: 0.380961\n",
      "Train Epoch: 9 [62080/84843 (73%)]\tLoss: 0.362633\n",
      "Train Epoch: 9 [62720/84843 (74%)]\tLoss: 0.204411\n",
      "Train Epoch: 9 [63360/84843 (75%)]\tLoss: 0.262995\n",
      "Train Epoch: 9 [64000/84843 (75%)]\tLoss: 0.437309\n",
      "Train Epoch: 9 [64640/84843 (76%)]\tLoss: 0.420181\n",
      "Train Epoch: 9 [65280/84843 (77%)]\tLoss: 0.402398\n",
      "Train Epoch: 9 [65920/84843 (78%)]\tLoss: 0.369846\n",
      "Train Epoch: 9 [66560/84843 (78%)]\tLoss: 0.410082\n",
      "Train Epoch: 9 [67200/84843 (79%)]\tLoss: 0.268341\n",
      "Train Epoch: 9 [67840/84843 (80%)]\tLoss: 0.169618\n",
      "Train Epoch: 9 [68480/84843 (81%)]\tLoss: 0.295719\n",
      "Train Epoch: 9 [69120/84843 (81%)]\tLoss: 0.477111\n",
      "Train Epoch: 9 [69760/84843 (82%)]\tLoss: 0.538543\n",
      "Train Epoch: 9 [70400/84843 (83%)]\tLoss: 0.871155\n",
      "Train Epoch: 9 [71040/84843 (84%)]\tLoss: 0.374698\n",
      "Train Epoch: 9 [71680/84843 (84%)]\tLoss: 0.226286\n",
      "Train Epoch: 9 [72320/84843 (85%)]\tLoss: 0.430999\n",
      "Train Epoch: 9 [72960/84843 (86%)]\tLoss: 0.436639\n",
      "Train Epoch: 9 [73600/84843 (87%)]\tLoss: 0.415635\n",
      "Train Epoch: 9 [74240/84843 (87%)]\tLoss: 0.317008\n",
      "Train Epoch: 9 [74880/84843 (88%)]\tLoss: 0.394367\n",
      "Train Epoch: 9 [75520/84843 (89%)]\tLoss: 0.446470\n",
      "Train Epoch: 9 [76160/84843 (90%)]\tLoss: 0.358989\n",
      "Train Epoch: 9 [76800/84843 (90%)]\tLoss: 0.338243\n",
      "Train Epoch: 9 [77440/84843 (91%)]\tLoss: 0.262167\n",
      "Train Epoch: 9 [78080/84843 (92%)]\tLoss: 1.109366\n",
      "Train Epoch: 9 [78720/84843 (93%)]\tLoss: 0.229735\n",
      "Train Epoch: 9 [79360/84843 (94%)]\tLoss: 0.444270\n",
      "Train Epoch: 9 [80000/84843 (94%)]\tLoss: 0.297271\n",
      "Train Epoch: 9 [80640/84843 (95%)]\tLoss: 0.280362\n",
      "Train Epoch: 9 [81280/84843 (96%)]\tLoss: 0.288309\n",
      "Train Epoch: 9 [81920/84843 (97%)]\tLoss: 0.509286\n",
      "Train Epoch: 9 [82560/84843 (97%)]\tLoss: 0.428093\n",
      "Train Epoch: 9 [83200/84843 (98%)]\tLoss: 0.680419\n",
      "Train Epoch: 9 [83840/84843 (99%)]\tLoss: 0.295399\n",
      "Train Epoch: 9 [84480/84843 (100%)]\tLoss: 0.453782\n",
      "Accuracy: 9431/11005 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/84843 (0%)]\tLoss: 0.260047\n",
      "Train Epoch: 10 [640/84843 (1%)]\tLoss: 0.424083\n",
      "Train Epoch: 10 [1280/84843 (2%)]\tLoss: 0.457345\n",
      "Train Epoch: 10 [1920/84843 (2%)]\tLoss: 0.440599\n",
      "Train Epoch: 10 [2560/84843 (3%)]\tLoss: 0.468933\n",
      "Train Epoch: 10 [3200/84843 (4%)]\tLoss: 0.244916\n",
      "Train Epoch: 10 [3840/84843 (5%)]\tLoss: 0.449411\n",
      "Train Epoch: 10 [4480/84843 (5%)]\tLoss: 0.117643\n",
      "Train Epoch: 10 [5120/84843 (6%)]\tLoss: 0.525942\n",
      "Train Epoch: 10 [5760/84843 (7%)]\tLoss: 0.472172\n",
      "Train Epoch: 10 [6400/84843 (8%)]\tLoss: 0.325089\n",
      "Train Epoch: 10 [7040/84843 (8%)]\tLoss: 0.388212\n",
      "Train Epoch: 10 [7680/84843 (9%)]\tLoss: 0.272615\n",
      "Train Epoch: 10 [8320/84843 (10%)]\tLoss: 0.375045\n",
      "Train Epoch: 10 [8960/84843 (11%)]\tLoss: 0.543795\n",
      "Train Epoch: 10 [9600/84843 (11%)]\tLoss: 0.406462\n",
      "Train Epoch: 10 [10240/84843 (12%)]\tLoss: 0.251170\n",
      "Train Epoch: 10 [10880/84843 (13%)]\tLoss: 0.655699\n",
      "Train Epoch: 10 [11520/84843 (14%)]\tLoss: 0.395533\n",
      "Train Epoch: 10 [12160/84843 (14%)]\tLoss: 0.290714\n",
      "Train Epoch: 10 [12800/84843 (15%)]\tLoss: 0.611825\n",
      "Train Epoch: 10 [13440/84843 (16%)]\tLoss: 0.620340\n",
      "Train Epoch: 10 [14080/84843 (17%)]\tLoss: 0.207754\n",
      "Train Epoch: 10 [14720/84843 (17%)]\tLoss: 0.292725\n",
      "Train Epoch: 10 [15360/84843 (18%)]\tLoss: 0.412016\n",
      "Train Epoch: 10 [16000/84843 (19%)]\tLoss: 0.326531\n",
      "Train Epoch: 10 [16640/84843 (20%)]\tLoss: 0.423315\n",
      "Train Epoch: 10 [17280/84843 (20%)]\tLoss: 0.233676\n",
      "Train Epoch: 10 [17920/84843 (21%)]\tLoss: 0.672326\n",
      "Train Epoch: 10 [18560/84843 (22%)]\tLoss: 0.720071\n",
      "Train Epoch: 10 [19200/84843 (23%)]\tLoss: 0.190350\n",
      "Train Epoch: 10 [19840/84843 (23%)]\tLoss: 0.191480\n",
      "Train Epoch: 10 [20480/84843 (24%)]\tLoss: 0.412978\n",
      "Train Epoch: 10 [21120/84843 (25%)]\tLoss: 0.192912\n",
      "Train Epoch: 10 [21760/84843 (26%)]\tLoss: 0.467449\n",
      "Train Epoch: 10 [22400/84843 (26%)]\tLoss: 0.309483\n",
      "Train Epoch: 10 [23040/84843 (27%)]\tLoss: 0.229793\n",
      "Train Epoch: 10 [23680/84843 (28%)]\tLoss: 0.215780\n",
      "Train Epoch: 10 [24320/84843 (29%)]\tLoss: 0.336596\n",
      "Train Epoch: 10 [24960/84843 (29%)]\tLoss: 0.257757\n",
      "Train Epoch: 10 [25600/84843 (30%)]\tLoss: 0.240228\n",
      "Train Epoch: 10 [26240/84843 (31%)]\tLoss: 0.345862\n",
      "Train Epoch: 10 [26880/84843 (32%)]\tLoss: 0.320889\n",
      "Train Epoch: 10 [27520/84843 (32%)]\tLoss: 0.619857\n",
      "Train Epoch: 10 [28160/84843 (33%)]\tLoss: 0.495738\n",
      "Train Epoch: 10 [28800/84843 (34%)]\tLoss: 0.741845\n",
      "Train Epoch: 10 [29440/84843 (35%)]\tLoss: 0.556479\n",
      "Train Epoch: 10 [30080/84843 (35%)]\tLoss: 0.687266\n",
      "Train Epoch: 10 [30720/84843 (36%)]\tLoss: 0.383337\n",
      "Train Epoch: 10 [31360/84843 (37%)]\tLoss: 0.423817\n",
      "Train Epoch: 10 [32000/84843 (38%)]\tLoss: 0.359919\n",
      "Train Epoch: 10 [32640/84843 (38%)]\tLoss: 0.255762\n",
      "Train Epoch: 10 [33280/84843 (39%)]\tLoss: 0.343587\n",
      "Train Epoch: 10 [33920/84843 (40%)]\tLoss: 0.213126\n",
      "Train Epoch: 10 [34560/84843 (41%)]\tLoss: 0.400346\n",
      "Train Epoch: 10 [35200/84843 (41%)]\tLoss: 0.742134\n",
      "Train Epoch: 10 [35840/84843 (42%)]\tLoss: 0.322929\n",
      "Train Epoch: 10 [36480/84843 (43%)]\tLoss: 0.451790\n",
      "Train Epoch: 10 [37120/84843 (44%)]\tLoss: 0.436106\n",
      "Train Epoch: 10 [37760/84843 (44%)]\tLoss: 0.394089\n",
      "Train Epoch: 10 [38400/84843 (45%)]\tLoss: 0.541098\n",
      "Train Epoch: 10 [39040/84843 (46%)]\tLoss: 0.689344\n",
      "Train Epoch: 10 [39680/84843 (47%)]\tLoss: 0.726275\n",
      "Train Epoch: 10 [40320/84843 (48%)]\tLoss: 0.588931\n",
      "Train Epoch: 10 [40960/84843 (48%)]\tLoss: 0.502966\n",
      "Train Epoch: 10 [41600/84843 (49%)]\tLoss: 0.431359\n",
      "Train Epoch: 10 [42240/84843 (50%)]\tLoss: 0.322560\n",
      "Train Epoch: 10 [42880/84843 (51%)]\tLoss: 0.408585\n",
      "Train Epoch: 10 [43520/84843 (51%)]\tLoss: 0.075585\n",
      "Train Epoch: 10 [44160/84843 (52%)]\tLoss: 0.322471\n",
      "Train Epoch: 10 [44800/84843 (53%)]\tLoss: 0.446793\n",
      "Train Epoch: 10 [45440/84843 (54%)]\tLoss: 0.148465\n",
      "Train Epoch: 10 [46080/84843 (54%)]\tLoss: 0.547842\n",
      "Train Epoch: 10 [46720/84843 (55%)]\tLoss: 0.422913\n",
      "Train Epoch: 10 [47360/84843 (56%)]\tLoss: 0.359158\n",
      "Train Epoch: 10 [48000/84843 (57%)]\tLoss: 0.185364\n",
      "Train Epoch: 10 [48640/84843 (57%)]\tLoss: 0.160581\n",
      "Train Epoch: 10 [49280/84843 (58%)]\tLoss: 0.392376\n",
      "Train Epoch: 10 [49920/84843 (59%)]\tLoss: 0.557334\n",
      "Train Epoch: 10 [50560/84843 (60%)]\tLoss: 0.407435\n",
      "Train Epoch: 10 [51200/84843 (60%)]\tLoss: 0.156398\n",
      "Train Epoch: 10 [51840/84843 (61%)]\tLoss: 0.281371\n",
      "Train Epoch: 10 [52480/84843 (62%)]\tLoss: 0.219269\n",
      "Train Epoch: 10 [53120/84843 (63%)]\tLoss: 0.614445\n",
      "Train Epoch: 10 [53760/84843 (63%)]\tLoss: 0.346042\n",
      "Train Epoch: 10 [54400/84843 (64%)]\tLoss: 0.392563\n",
      "Train Epoch: 10 [55040/84843 (65%)]\tLoss: 0.416242\n",
      "Train Epoch: 10 [55680/84843 (66%)]\tLoss: 0.167133\n",
      "Train Epoch: 10 [56320/84843 (66%)]\tLoss: 0.499868\n",
      "Train Epoch: 10 [56960/84843 (67%)]\tLoss: 0.250777\n",
      "Train Epoch: 10 [57600/84843 (68%)]\tLoss: 0.460875\n",
      "Train Epoch: 10 [58240/84843 (69%)]\tLoss: 0.183025\n",
      "Train Epoch: 10 [58880/84843 (69%)]\tLoss: 1.080722\n",
      "Train Epoch: 10 [59520/84843 (70%)]\tLoss: 0.432773\n",
      "Train Epoch: 10 [60160/84843 (71%)]\tLoss: 0.577353\n",
      "Train Epoch: 10 [60800/84843 (72%)]\tLoss: 0.359813\n",
      "Train Epoch: 10 [61440/84843 (72%)]\tLoss: 0.336355\n",
      "Train Epoch: 10 [62080/84843 (73%)]\tLoss: 0.272495\n",
      "Train Epoch: 10 [62720/84843 (74%)]\tLoss: 0.162758\n",
      "Train Epoch: 10 [63360/84843 (75%)]\tLoss: 0.352554\n",
      "Train Epoch: 10 [64000/84843 (75%)]\tLoss: 0.219846\n",
      "Train Epoch: 10 [64640/84843 (76%)]\tLoss: 0.334441\n",
      "Train Epoch: 10 [65280/84843 (77%)]\tLoss: 0.235892\n",
      "Train Epoch: 10 [65920/84843 (78%)]\tLoss: 0.564455\n",
      "Train Epoch: 10 [66560/84843 (78%)]\tLoss: 0.272800\n",
      "Train Epoch: 10 [67200/84843 (79%)]\tLoss: 0.192871\n",
      "Train Epoch: 10 [67840/84843 (80%)]\tLoss: 0.296185\n",
      "Train Epoch: 10 [68480/84843 (81%)]\tLoss: 0.604532\n",
      "Train Epoch: 10 [69120/84843 (81%)]\tLoss: 0.310546\n",
      "Train Epoch: 10 [69760/84843 (82%)]\tLoss: 0.371380\n",
      "Train Epoch: 10 [70400/84843 (83%)]\tLoss: 0.307597\n",
      "Train Epoch: 10 [71040/84843 (84%)]\tLoss: 0.450035\n",
      "Train Epoch: 10 [71680/84843 (84%)]\tLoss: 0.384515\n",
      "Train Epoch: 10 [72320/84843 (85%)]\tLoss: 0.280622\n",
      "Train Epoch: 10 [72960/84843 (86%)]\tLoss: 0.561782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [73600/84843 (87%)]\tLoss: 0.885403\n",
      "Train Epoch: 10 [74240/84843 (87%)]\tLoss: 0.210718\n",
      "Train Epoch: 10 [74880/84843 (88%)]\tLoss: 0.261975\n",
      "Train Epoch: 10 [75520/84843 (89%)]\tLoss: 0.381532\n",
      "Train Epoch: 10 [76160/84843 (90%)]\tLoss: 0.215224\n",
      "Train Epoch: 10 [76800/84843 (90%)]\tLoss: 0.092760\n",
      "Train Epoch: 10 [77440/84843 (91%)]\tLoss: 0.508985\n",
      "Train Epoch: 10 [78080/84843 (92%)]\tLoss: 0.349670\n",
      "Train Epoch: 10 [78720/84843 (93%)]\tLoss: 0.332398\n",
      "Train Epoch: 10 [79360/84843 (94%)]\tLoss: 0.470098\n",
      "Train Epoch: 10 [80000/84843 (94%)]\tLoss: 0.226882\n",
      "Train Epoch: 10 [80640/84843 (95%)]\tLoss: 0.446288\n",
      "Train Epoch: 10 [81280/84843 (96%)]\tLoss: 0.518469\n",
      "Train Epoch: 10 [81920/84843 (97%)]\tLoss: 0.613580\n",
      "Train Epoch: 10 [82560/84843 (97%)]\tLoss: 0.182081\n",
      "Train Epoch: 10 [83200/84843 (98%)]\tLoss: 0.223096\n",
      "Train Epoch: 10 [83840/84843 (99%)]\tLoss: 0.366736\n",
      "Train Epoch: 10 [84480/84843 (100%)]\tLoss: 0.350648\n",
      "Accuracy: 9444/11005 (86%)\n",
      "\n",
      "Train Epoch: 11 [0/84843 (0%)]\tLoss: 0.336942\n",
      "Train Epoch: 11 [640/84843 (1%)]\tLoss: 0.373590\n",
      "Train Epoch: 11 [1280/84843 (2%)]\tLoss: 0.383083\n",
      "Train Epoch: 11 [1920/84843 (2%)]\tLoss: 0.085475\n",
      "Train Epoch: 11 [2560/84843 (3%)]\tLoss: 0.360927\n",
      "Train Epoch: 11 [3200/84843 (4%)]\tLoss: 0.088844\n",
      "Train Epoch: 11 [3840/84843 (5%)]\tLoss: 0.355186\n",
      "Train Epoch: 11 [4480/84843 (5%)]\tLoss: 0.544496\n",
      "Train Epoch: 11 [5120/84843 (6%)]\tLoss: 0.585897\n",
      "Train Epoch: 11 [5760/84843 (7%)]\tLoss: 0.061763\n",
      "Train Epoch: 11 [6400/84843 (8%)]\tLoss: 0.202923\n",
      "Train Epoch: 11 [7040/84843 (8%)]\tLoss: 0.450040\n",
      "Train Epoch: 11 [7680/84843 (9%)]\tLoss: 0.261051\n",
      "Train Epoch: 11 [8320/84843 (10%)]\tLoss: 0.125417\n",
      "Train Epoch: 11 [8960/84843 (11%)]\tLoss: 0.285820\n",
      "Train Epoch: 11 [9600/84843 (11%)]\tLoss: 0.192533\n",
      "Train Epoch: 11 [10240/84843 (12%)]\tLoss: 0.334306\n",
      "Train Epoch: 11 [10880/84843 (13%)]\tLoss: 0.452302\n",
      "Train Epoch: 11 [11520/84843 (14%)]\tLoss: 0.332267\n",
      "Train Epoch: 11 [12160/84843 (14%)]\tLoss: 0.400980\n",
      "Train Epoch: 11 [12800/84843 (15%)]\tLoss: 0.274767\n",
      "Train Epoch: 11 [13440/84843 (16%)]\tLoss: 0.477756\n",
      "Train Epoch: 11 [14080/84843 (17%)]\tLoss: 0.251678\n",
      "Train Epoch: 11 [14720/84843 (17%)]\tLoss: 0.216573\n",
      "Train Epoch: 11 [15360/84843 (18%)]\tLoss: 0.335708\n",
      "Train Epoch: 11 [16000/84843 (19%)]\tLoss: 0.587867\n",
      "Train Epoch: 11 [16640/84843 (20%)]\tLoss: 0.325754\n",
      "Train Epoch: 11 [17280/84843 (20%)]\tLoss: 0.625248\n",
      "Train Epoch: 11 [17920/84843 (21%)]\tLoss: 0.232139\n",
      "Train Epoch: 11 [18560/84843 (22%)]\tLoss: 0.428359\n",
      "Train Epoch: 11 [19200/84843 (23%)]\tLoss: 0.139150\n",
      "Train Epoch: 11 [19840/84843 (23%)]\tLoss: 0.218247\n",
      "Train Epoch: 11 [20480/84843 (24%)]\tLoss: 0.260900\n",
      "Train Epoch: 11 [21120/84843 (25%)]\tLoss: 0.538279\n",
      "Train Epoch: 11 [21760/84843 (26%)]\tLoss: 0.323892\n",
      "Train Epoch: 11 [22400/84843 (26%)]\tLoss: 0.181784\n",
      "Train Epoch: 11 [23040/84843 (27%)]\tLoss: 0.368854\n",
      "Train Epoch: 11 [23680/84843 (28%)]\tLoss: 0.336923\n",
      "Train Epoch: 11 [24320/84843 (29%)]\tLoss: 0.563064\n",
      "Train Epoch: 11 [24960/84843 (29%)]\tLoss: 0.184156\n",
      "Train Epoch: 11 [25600/84843 (30%)]\tLoss: 0.134132\n",
      "Train Epoch: 11 [26240/84843 (31%)]\tLoss: 0.239642\n",
      "Train Epoch: 11 [26880/84843 (32%)]\tLoss: 0.357111\n",
      "Train Epoch: 11 [27520/84843 (32%)]\tLoss: 0.428603\n",
      "Train Epoch: 11 [28160/84843 (33%)]\tLoss: 0.274412\n",
      "Train Epoch: 11 [28800/84843 (34%)]\tLoss: 0.414339\n",
      "Train Epoch: 11 [29440/84843 (35%)]\tLoss: 0.387786\n",
      "Train Epoch: 11 [30080/84843 (35%)]\tLoss: 0.279669\n",
      "Train Epoch: 11 [30720/84843 (36%)]\tLoss: 0.365393\n",
      "Train Epoch: 11 [31360/84843 (37%)]\tLoss: 0.244063\n",
      "Train Epoch: 11 [32000/84843 (38%)]\tLoss: 0.279639\n",
      "Train Epoch: 11 [32640/84843 (38%)]\tLoss: 0.426685\n",
      "Train Epoch: 11 [33280/84843 (39%)]\tLoss: 0.473913\n",
      "Train Epoch: 11 [33920/84843 (40%)]\tLoss: 0.609122\n",
      "Train Epoch: 11 [34560/84843 (41%)]\tLoss: 0.509376\n",
      "Train Epoch: 11 [35200/84843 (41%)]\tLoss: 0.171516\n",
      "Train Epoch: 11 [35840/84843 (42%)]\tLoss: 0.425531\n",
      "Train Epoch: 11 [36480/84843 (43%)]\tLoss: 0.100799\n",
      "Train Epoch: 11 [37120/84843 (44%)]\tLoss: 0.285805\n",
      "Train Epoch: 11 [37760/84843 (44%)]\tLoss: 0.237106\n",
      "Train Epoch: 11 [38400/84843 (45%)]\tLoss: 0.283279\n",
      "Train Epoch: 11 [39040/84843 (46%)]\tLoss: 0.098035\n",
      "Train Epoch: 11 [39680/84843 (47%)]\tLoss: 0.397559\n",
      "Train Epoch: 11 [40320/84843 (48%)]\tLoss: 0.239511\n",
      "Train Epoch: 11 [40960/84843 (48%)]\tLoss: 0.248640\n",
      "Train Epoch: 11 [41600/84843 (49%)]\tLoss: 0.368756\n",
      "Train Epoch: 11 [42240/84843 (50%)]\tLoss: 0.242592\n",
      "Train Epoch: 11 [42880/84843 (51%)]\tLoss: 0.504860\n",
      "Train Epoch: 11 [43520/84843 (51%)]\tLoss: 0.202354\n",
      "Train Epoch: 11 [44160/84843 (52%)]\tLoss: 0.874354\n",
      "Train Epoch: 11 [44800/84843 (53%)]\tLoss: 0.140222\n",
      "Train Epoch: 11 [45440/84843 (54%)]\tLoss: 0.347178\n",
      "Train Epoch: 11 [46080/84843 (54%)]\tLoss: 0.338993\n",
      "Train Epoch: 11 [46720/84843 (55%)]\tLoss: 0.367083\n",
      "Train Epoch: 11 [47360/84843 (56%)]\tLoss: 0.274320\n",
      "Train Epoch: 11 [48000/84843 (57%)]\tLoss: 0.331945\n",
      "Train Epoch: 11 [48640/84843 (57%)]\tLoss: 0.066262\n",
      "Train Epoch: 11 [49280/84843 (58%)]\tLoss: 0.388215\n",
      "Train Epoch: 11 [49920/84843 (59%)]\tLoss: 0.187351\n",
      "Train Epoch: 11 [50560/84843 (60%)]\tLoss: 0.152701\n",
      "Train Epoch: 11 [51200/84843 (60%)]\tLoss: 0.336546\n",
      "Train Epoch: 11 [51840/84843 (61%)]\tLoss: 0.393506\n",
      "Train Epoch: 11 [52480/84843 (62%)]\tLoss: 0.180642\n",
      "Train Epoch: 11 [53120/84843 (63%)]\tLoss: 0.164923\n",
      "Train Epoch: 11 [53760/84843 (63%)]\tLoss: 0.441443\n",
      "Train Epoch: 11 [54400/84843 (64%)]\tLoss: 0.237776\n",
      "Train Epoch: 11 [55040/84843 (65%)]\tLoss: 0.422340\n",
      "Train Epoch: 11 [55680/84843 (66%)]\tLoss: 0.402173\n",
      "Train Epoch: 11 [56320/84843 (66%)]\tLoss: 0.127947\n",
      "Train Epoch: 11 [56960/84843 (67%)]\tLoss: 0.561141\n",
      "Train Epoch: 11 [57600/84843 (68%)]\tLoss: 0.273500\n",
      "Train Epoch: 11 [58240/84843 (69%)]\tLoss: 0.194899\n",
      "Train Epoch: 11 [58880/84843 (69%)]\tLoss: 0.809857\n",
      "Train Epoch: 11 [59520/84843 (70%)]\tLoss: 0.668401\n",
      "Train Epoch: 11 [60160/84843 (71%)]\tLoss: 0.273992\n",
      "Train Epoch: 11 [60800/84843 (72%)]\tLoss: 0.383176\n",
      "Train Epoch: 11 [61440/84843 (72%)]\tLoss: 0.391227\n",
      "Train Epoch: 11 [62080/84843 (73%)]\tLoss: 0.121319\n",
      "Train Epoch: 11 [62720/84843 (74%)]\tLoss: 0.497784\n",
      "Train Epoch: 11 [63360/84843 (75%)]\tLoss: 0.379251\n",
      "Train Epoch: 11 [64000/84843 (75%)]\tLoss: 0.591764\n",
      "Train Epoch: 11 [64640/84843 (76%)]\tLoss: 0.527303\n",
      "Train Epoch: 11 [65280/84843 (77%)]\tLoss: 0.324653\n",
      "Train Epoch: 11 [65920/84843 (78%)]\tLoss: 0.630524\n",
      "Train Epoch: 11 [66560/84843 (78%)]\tLoss: 0.181343\n",
      "Train Epoch: 11 [67200/84843 (79%)]\tLoss: 0.432396\n",
      "Train Epoch: 11 [67840/84843 (80%)]\tLoss: 0.320981\n",
      "Train Epoch: 11 [68480/84843 (81%)]\tLoss: 0.487297\n",
      "Train Epoch: 11 [69120/84843 (81%)]\tLoss: 0.352784\n",
      "Train Epoch: 11 [69760/84843 (82%)]\tLoss: 0.580099\n",
      "Train Epoch: 11 [70400/84843 (83%)]\tLoss: 0.648987\n",
      "Train Epoch: 11 [71040/84843 (84%)]\tLoss: 0.614545\n",
      "Train Epoch: 11 [71680/84843 (84%)]\tLoss: 0.902416\n",
      "Train Epoch: 11 [72320/84843 (85%)]\tLoss: 0.434694\n",
      "Train Epoch: 11 [72960/84843 (86%)]\tLoss: 0.423607\n",
      "Train Epoch: 11 [73600/84843 (87%)]\tLoss: 0.347357\n",
      "Train Epoch: 11 [74240/84843 (87%)]\tLoss: 0.320191\n",
      "Train Epoch: 11 [74880/84843 (88%)]\tLoss: 0.478336\n",
      "Train Epoch: 11 [75520/84843 (89%)]\tLoss: 0.220519\n",
      "Train Epoch: 11 [76160/84843 (90%)]\tLoss: 0.277355\n",
      "Train Epoch: 11 [76800/84843 (90%)]\tLoss: 0.421061\n",
      "Train Epoch: 11 [77440/84843 (91%)]\tLoss: 0.423726\n",
      "Train Epoch: 11 [78080/84843 (92%)]\tLoss: 0.421127\n",
      "Train Epoch: 11 [78720/84843 (93%)]\tLoss: 0.570978\n",
      "Train Epoch: 11 [79360/84843 (94%)]\tLoss: 0.230584\n",
      "Train Epoch: 11 [80000/84843 (94%)]\tLoss: 0.321865\n",
      "Train Epoch: 11 [80640/84843 (95%)]\tLoss: 0.217990\n",
      "Train Epoch: 11 [81280/84843 (96%)]\tLoss: 0.330408\n",
      "Train Epoch: 11 [81920/84843 (97%)]\tLoss: 0.552710\n",
      "Train Epoch: 11 [82560/84843 (97%)]\tLoss: 0.346990\n",
      "Train Epoch: 11 [83200/84843 (98%)]\tLoss: 0.351145\n",
      "Train Epoch: 11 [83840/84843 (99%)]\tLoss: 0.142589\n",
      "Train Epoch: 11 [84480/84843 (100%)]\tLoss: 0.294802\n",
      "Accuracy: 9446/11005 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/84843 (0%)]\tLoss: 0.662412\n",
      "Train Epoch: 12 [640/84843 (1%)]\tLoss: 0.447918\n",
      "Train Epoch: 12 [1280/84843 (2%)]\tLoss: 0.259910\n",
      "Train Epoch: 12 [1920/84843 (2%)]\tLoss: 0.298105\n",
      "Train Epoch: 12 [2560/84843 (3%)]\tLoss: 0.351916\n",
      "Train Epoch: 12 [3200/84843 (4%)]\tLoss: 0.790405\n",
      "Train Epoch: 12 [3840/84843 (5%)]\tLoss: 0.327640\n",
      "Train Epoch: 12 [4480/84843 (5%)]\tLoss: 0.151528\n",
      "Train Epoch: 12 [5120/84843 (6%)]\tLoss: 0.317070\n",
      "Train Epoch: 12 [5760/84843 (7%)]\tLoss: 0.391164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [6400/84843 (8%)]\tLoss: 0.381570\n",
      "Train Epoch: 12 [7040/84843 (8%)]\tLoss: 0.697736\n",
      "Train Epoch: 12 [7680/84843 (9%)]\tLoss: 0.196910\n",
      "Train Epoch: 12 [8320/84843 (10%)]\tLoss: 0.262203\n",
      "Train Epoch: 12 [8960/84843 (11%)]\tLoss: 0.513870\n",
      "Train Epoch: 12 [9600/84843 (11%)]\tLoss: 0.264032\n"
     ]
    }
   ],
   "source": [
    "# longer retrain the converted model\n",
    "log_interval = 20\n",
    "n_epoch = 20\n",
    "\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "losses = []\n",
    "\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "# transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(long_retrained_converted_model, epoch, log_interval)\n",
    "        test(long_retrained_converted_model, test_loader)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the fast retrained converted model improved and is good.\n",
    "test(long_retrained_converted_model, train_loader)\n",
    "test(long_retrained_converted_model, val_loader)\n",
    "test(long_retrained_converted_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0429d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
