{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b807a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack the SPEECHCOMMAND models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca533fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41323d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eb8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cdfd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcrescent              \u001b[m  Thu Oct  7 17:29:08 2021  \u001b[1m\u001b[30m418.152.00\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[1m\u001b[31m 54'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2244\u001b[m / \u001b[33m10989\u001b[m MB | \u001b[1m\u001b[30msalami\u001b[m(\u001b[33m2233M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "# check gpus\n",
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db34771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# manually set cuda device\n",
    "torch.cuda.set_device(1)\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be55675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddf7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "batch_size = 32\n",
    "batchsize_for_val = 32\n",
    "(train_loader, val_loader, test_loader) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "                                                                          batch_size = batch_size,\n",
    "                                                                          batchsize_for_val = batchsize_for_val,\n",
    "                                                                          num_workers=5, \n",
    "                                                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631ac6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model classes\n",
    "\n",
    "## classic model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2).squeeze()\n",
    "    \n",
    "# FGN model    \n",
    "class FGN_M5(nn.Module):\n",
    "    \n",
    "    # changes:\n",
    "    # nn.Conv1d -> fgnl.FGN_Conv1d\n",
    "    # added g to conv inputs and outputs\n",
    "    # make sure you pass g through the same pooling steps as x\n",
    "    \n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.fgn_conv1 = fgnl.FGN_Conv1d(in_channels=n_input, out_channels=n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv2 = fgnl.FGN_Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv3 = fgnl.FGN_Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv4 = fgnl.FGN_Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, g = self.fgn_conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        g = self.pool1(g)\n",
    "        x, g = self.fgn_conv2(x, g)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        g = self.pool2(g)\n",
    "        x, g = self.fgn_conv3(x ,g)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        g = self.pool3(g)\n",
    "        x, _ = self.fgn_conv4(x, g)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eed4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained models paths\n",
    "save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "\n",
    "classic_model_name= 'sample_classic_model_SPEECHCOMMANDS'\n",
    "fgn_model_name = 'sample_FGN_model_SPEECHCOMMANDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4d8da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and load the models\n",
    "# classic model\n",
    "classic_model = M5()\n",
    "classic_model.load_state_dict(torch.load(save_path+classic_model_name+'_state_dict.pth'))\n",
    "classic_model.to(device)\n",
    "\n",
    "# fgn model trained from scratch\n",
    "fgn_model_from_scratch = FGN_M5()\n",
    "fgn_model_from_scratch.load_state_dict(torch.load(save_path+fgn_model_name+'_state_dict.pth'))\n",
    "fgn_model_from_scratch.to(device)\n",
    "\n",
    "# converted fgn model (no retraining)\n",
    "fgn_model_converted_no_retraining = FGN_M5()\n",
    "fgn_model_converted_no_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_no_retraining.to(device)\n",
    "\n",
    "# converted and retrained 1 epoch fgn model\n",
    "fgn_model_converted_fast_retraining = FGN_M5()\n",
    "fgn_model_converted_fast_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_fast_retrained_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_fast_retraining.to(device)\n",
    "\n",
    "# converted and retrained 21 epoch fgn model\n",
    "fgn_model_converted_long_retraining = FGN_M5()\n",
    "fgn_model_converted_long_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_long_retrained_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_long_retraining.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b89c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set all models to eval mode\n",
    "classic_model.eval()\n",
    "fgn_model_from_scratch.eval()\n",
    "fgn_model_converted_no_retraining.eval()\n",
    "fgn_model_converted_fast_retraining.eval()\n",
    "fgn_model_converted_long_retraining.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c9f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to test models\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "    print(f'Accuracy: {correct}/{len(loader.dataset)} ({100. * correct / len(loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43d3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for Classic Model\n",
      "Accuracy: 76655/84843 (90%)\n",
      "Accuracy: 8755/9981 (88%)\n",
      "Accuracy: 9468/11005 (86%)\n",
      "Train/Test/Val accuracy for FGN model trained from scratch\n",
      "Accuracy: 73489/84843 (87%)\n",
      "Accuracy: 8572/9981 (86%)\n",
      "Accuracy: 9244/11005 (84%)\n",
      "Train/Test/Val accuracy for FGN model converted from classic (no retraining)\n",
      "Accuracy: 76655/84843 (90%)\n",
      "Accuracy: 8755/9981 (88%)\n",
      "Accuracy: 9468/11005 (86%)\n",
      "Train/Test/Val accuracy for FGN model converted from classic (fast retraining)\n",
      "Accuracy: 76264/84843 (90%)\n",
      "Accuracy: 8654/9981 (87%)\n",
      "Accuracy: 9394/11005 (85%)\n",
      "Train/Test/Val accuracy for FGN model converted from classic (long retraining)\n",
      "Accuracy: 77561/84843 (91%)\n",
      "Accuracy: 8726/9981 (87%)\n",
      "Accuracy: 9411/11005 (86%)\n"
     ]
    }
   ],
   "source": [
    "# # verify accuracies\n",
    "print('Train/Test/Val accuracy for Classic Model')\n",
    "test(classic_model, train_loader)\n",
    "test(classic_model, val_loader)\n",
    "test(classic_model, test_loader)\n",
    "\n",
    "print('Train/Test/Val accuracy for FGN model trained from scratch')\n",
    "test(fgn_model_from_scratch, train_loader)\n",
    "test(fgn_model_from_scratch, val_loader)\n",
    "test(fgn_model_from_scratch, test_loader)\n",
    "\n",
    "print('Train/Test/Val accuracy for FGN model converted from classic (no retraining)')\n",
    "test(fgn_model_converted_no_retraining, train_loader)\n",
    "test(fgn_model_converted_no_retraining, val_loader)\n",
    "test(fgn_model_converted_no_retraining, test_loader)\n",
    "\n",
    "print('Train/Test/Val accuracy for FGN model converted from classic (fast retraining)')\n",
    "test(fgn_model_converted_fast_retraining, train_loader)\n",
    "test(fgn_model_converted_fast_retraining, val_loader)\n",
    "test(fgn_model_converted_fast_retraining, test_loader)\n",
    "\n",
    "print('Train/Test/Val accuracy for FGN model converted from classic (long retraining)')\n",
    "test(fgn_model_converted_long_retraining, train_loader)\n",
    "test(fgn_model_converted_long_retraining, val_loader)\n",
    "test(fgn_model_converted_long_retraining, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28d3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Attacking the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74c76526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a078c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d9d85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model bounds and preprocessing\n",
    "\n",
    "# precomputed bounds min and max input values\n",
    "min_bound = -1.3844940662384033\n",
    "max_bound = 1.3773366212844849\n",
    "\n",
    "bounds = (min_bound, max_bound)\n",
    "# preprocessing - I think these would be used in similar way to pytorch preprocessing\n",
    "# but possible passed to whatever architecture is used (torch, tensorflow, other) \n",
    "# in my case the dataloaders already normalizes the data\n",
    "preprocessing = dict(mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b17d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready the models for foolbox\n",
    "classic_f_model = foolbox.PyTorchModel(classic_model, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_from_scratch = foolbox.PyTorchModel(fgn_model_from_scratch, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_no_retraining = foolbox.PyTorchModel(fgn_model_converted_no_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_fast_retraining = foolbox.PyTorchModel(fgn_model_converted_fast_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_long_retraining = foolbox.PyTorchModel(fgn_model_converted_long_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09fdc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont need the old models, free memory (help GC do so)\n",
    "del(classic_model)\n",
    "del(fgn_model_from_scratch)\n",
    "del(fgn_model_converted_no_retraining)\n",
    "del(fgn_model_converted_fast_retraining)\n",
    "del(fgn_model_converted_long_retraining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd86c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21d6ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foolbox.accuracy doesn't work with dataloaders, so building a custom func to do so\n",
    "def f_accuracy(model, dataloader, proc_func=None):\n",
    "    # given a model and a dataloader, computes accuracy\n",
    "    # proc_func is a processing function to apply to the values of the dataloader\n",
    "    # that returns (inputs, targets)\n",
    "    \n",
    "    # get model device\n",
    "    device = model.device\n",
    "    \n",
    "    running_count = 0\n",
    "    running_average = 0\n",
    "    # go through the dataset (assumes inputs and target are what is returned )\n",
    "    for batch in tqdm(dataloader):\n",
    "        # apply proc_func \n",
    "        if proc_func != None:\n",
    "            inputs, targets = proc_func(*batch)\n",
    "        else:\n",
    "            inputs, targets = batch\n",
    "        \n",
    "        # send data to proper device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # update running average accuracy and count\n",
    "        running_average = (len(inputs)*foolbox.utils.accuracy(model, inputs, targets) + running_count*running_average)/(len(inputs)+running_count)\n",
    "        running_count += len(inputs)\n",
    "    \n",
    "    return(running_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "942ddfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for Classic Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac66e855d2442db84c5a0c6c71f06b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9034923328972337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b498af3f1fc44c1abc05928d4928b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8771666166371758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd68304c94524770ae81ba5a6e9ac3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.860336210726608\n"
     ]
    }
   ],
   "source": [
    "# check model accuracies\n",
    "print('Train/Test/Val accuracy for Classic Model')\n",
    "print(f_accuracy(classic_f_model, train_loader))\n",
    "print(f_accuracy(classic_f_model, val_loader))\n",
    "print(f_accuracy(classic_f_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75db9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for FGN model trained from scratch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bc64f551244073995b68eac7cb29bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8661763492638878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5438718900414cb5131a6b9cba541e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8588317804484171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387233c3b9064e0093949fda053a6682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8399818263558677\n"
     ]
    }
   ],
   "source": [
    "print('Train/Test/Val accuracy for FGN model trained from scratch')\n",
    "print(f_accuracy(fgn_f_model_from_scratch, train_loader))\n",
    "print(f_accuracy(fgn_f_model_from_scratch, val_loader))\n",
    "print(f_accuracy(fgn_f_model_from_scratch, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ec85e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for FGN model converted from classic (no retraining)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53f8b71189c4783a22d041dcbb608b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.903492332900746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5409a317cafb4aef8651e89b8507c0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8771666166371758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac904ec9f2413da917690e81d93d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.860336210726608\n"
     ]
    }
   ],
   "source": [
    "print('Train/Test/Val accuracy for FGN model converted from classic (no retraining)')\n",
    "print(f_accuracy(fgn_f_model_converted_no_retraining, train_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_no_retraining, val_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_no_retraining, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db3d8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for FGN model converted from classic (fast retraining)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac796f3521345f9a41992acd3126d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8988838207076371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a0b3f9cb9549bda7826bf4e95fbd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.867047390106768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea5628d4691438e91fbbd5d01438e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8536119945100198\n"
     ]
    }
   ],
   "source": [
    "print('Train/Test/Val accuracy for FGN model converted from classic (fast retraining)')\n",
    "print(f_accuracy(fgn_f_model_converted_fast_retraining, train_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_fast_retraining, val_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_fast_retraining, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06793402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test/Val accuracy for FGN model converted from classic (long retraining)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ae3962ba4c47068fad94644c4e95f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2652.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9141708803354195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11e173bd1b426f9c142293203a26ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8742610961482465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1081a0b30bd74253bf7beb1a553d6f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=344.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8551567468465542\n"
     ]
    }
   ],
   "source": [
    "print('Train/Test/Val accuracy for FGN model converted from classic (long retraining)')\n",
    "print(f_accuracy(fgn_f_model_converted_long_retraining, train_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_long_retraining, val_loader))\n",
    "print(f_accuracy(fgn_f_model_converted_long_retraining, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d1ef7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### looks like they are the same, continue with attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec5ed013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilons: tensor([0.0000, 0.0108, 0.0162, 0.0216, 0.0324, 0.0432, 0.0647, 0.0863, 0.1295,\n",
      "        0.1726, 0.2589, 0.3452, 0.5178, 0.6905, 1.0357, 1.3809, 2.0714, 2.7618],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# attack params to explore\n",
    "epsilons = torch.tensor([(max_bound-min_bound)*x \n",
    "            for x in \n",
    "            [0.0,\n",
    "             1/256,\n",
    "             3/512,\n",
    "             1/128,\n",
    "             3/256,\n",
    "             1/64,\n",
    "             3/128,\n",
    "             1/32,\n",
    "             3/64,\n",
    "             1/16,\n",
    "             3/32,\n",
    "             1/8,\n",
    "             3/16,\n",
    "             1/4,\n",
    "             3/8,\n",
    "             1/2,\n",
    "             3/4,\n",
    "             1.0,] ], device=device)\n",
    "\n",
    "print('epsilons: {}'.format(epsilons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "deaeeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that attacks a model using a dataloader\n",
    "\n",
    "def perform_attack(attack_func, f_model, dataloader):\n",
    "    # iterates over dataloader \n",
    "    # attack is the attack function AFTER being defined: ex LinfPGD_attack=foolbox.attacks.LinfPGD()\n",
    "    # (so it's the output foolbox.attacks.LinfPGD(), not foolbox.attacks.LinfPGD itself)\n",
    "    # ensure the dataloader iterator returns (inputs, labels) \n",
    "    \n",
    "    # defines results to return, shape is (epsilons, sample, (sample shape))=(18,32xbatches,1,8000)\n",
    "    num_epsilons = 18 # hardcoded for now\n",
    "    data_shape = (1,8000) # next(iter(dataloader))[0].shape[1:] # this could be expensive, hardcoded for now\n",
    "    # create empty lists of the right shape\n",
    "    results = {'adv_raw':np.array([]).reshape((num_epsilons, 0, *(data_shape))),\n",
    "               'adv_clipped':np.array([]).reshape((num_epsilons, 0, *(data_shape))),\n",
    "               'adv_success':np.array([]).reshape((num_epsilons, 0))}\n",
    "    \n",
    "    # iterate over loader\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        \n",
    "        # attack\n",
    "        adv_raw, adv_clipped, adv_success = attack_func(f_model = f_model, \n",
    "                                                        inputs = inputs, \n",
    "                                                        labels =labels\n",
    "                                                       )\n",
    "        # compile with results\n",
    "        results['adv_raw'] = np.concatenate([results['adv_raw'],\n",
    "                                             np.array([x.cpu().numpy() for x in adv_raw])],\n",
    "                                            axis=1)\n",
    "        results['adv_clipped'] = np.concatenate([results['adv_clipped'],\n",
    "                                                 np.array([x.cpu().numpy() for x in adv_clipped])],\n",
    "                                                axis=1)\n",
    "        results['adv_success'] = np.concatenate([results['adv_success'],\n",
    "                                                 np.array([x.cpu().numpy() for x in adv_success])],\n",
    "                                                axis=1)\n",
    "\n",
    "    # return results dictionary\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5baf2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, perform the attacks on the models, saving the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96af4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### attack parameters\n",
    "L2CarliniWagner_attack=foolbox.attacks.L2CarliniWagnerAttack()\n",
    "LinfPGD_attack=foolbox.attacks.LinfPGD()\n",
    "\n",
    "\n",
    "# targetted vs untargetted\n",
    "from foolbox.criteria import Misclassification\n",
    "\n",
    "# define the entire attack function using epsilons, criterion,\n",
    "def L2CarliniWagner_attack_func(f_model, inputs, labels):\n",
    "    device = f_model.device\n",
    "    inputs = inputs.to(device)\n",
    "    criterions = Misclassification(labels.to(device))\n",
    "    return L2CarliniWagner_attack(model=f_model, inputs=inputs, criterion=criterions, epsilons=epsilons)\n",
    "\n",
    "def LinfPGD_attack_func(f_model, inputs, labels):\n",
    "    device = f_model.device\n",
    "    inputs = inputs.to(device)\n",
    "    criterions = Misclassification(labels.to(device))\n",
    "    return LinfPGD_attack(model=f_model, inputs=inputs, criterion=criterions, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d013e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Experiments/adversarial_attacks_results/1633724235.7860053\n"
     ]
    }
   ],
   "source": [
    "# name for the models we are attacking\n",
    "models_to_attack = {'classic_f_model':classic_f_model, \n",
    "                    'fgn_f_model_from_scratch':fgn_f_model_from_scratch, \n",
    "                    'fgn_model_converted_no_retraining':fgn_f_model_converted_no_retraining,\n",
    "                    'fgn_model_converted_fast_retraining':fgn_f_model_converted_fast_retraining,\n",
    "                    'fgn_model_converted_long_retraining':fgn_f_model_converted_long_retraining\n",
    "                   }\n",
    "\n",
    "# names of funcs for attacks\n",
    "attacks_to_perform = {'L2CarliniWagner':L2CarliniWagner_attack_func,\n",
    "                     'LinfPGD':LinfPGD_attack_func}\n",
    "\n",
    "import time\n",
    "save_folder = '../Experiments/adversarial_attacks_results/{}'.format(time.time())\n",
    "print(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f33c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87edb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current attack: L2CarliniWagner\n",
      "Current f_model: classic_f_model\n",
      "skipping\n",
      "Current f_model: fgn_f_model_from_scratch\n",
      "Attacking fgn_f_model_from_scratch with L2CarliniWagner\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e0f9625fb64f61945d0d4e9ec6a1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=312.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.mkdir(save_folder)\n",
    "for attack_name, attack in attacks_to_perform.items():\n",
    "    print('Current attack:', attack_name)\n",
    "    for model_name, f_model in models_to_attack.items():\n",
    "        print('Current f_model:', model_name)\n",
    "        \n",
    "        # skip classic+L2CarliniWagner\n",
    "        if (attack_name=='L2CarliniWagner') and (model_name=='classic_f_model'):\n",
    "            print('skipping')\n",
    "        else:\n",
    "            \n",
    "            # do attack\n",
    "            print('Attacking {} with {}'.format(model_name, attack_name))\n",
    "            results = perform_attack(attack, f_model, val_loader)\n",
    "            \n",
    "            # save results\n",
    "            # results dict is too large to save on its own apparently (about 22GB total), so split it up\n",
    "            with open(save_folder+'/{}_{}.adv_raw.pickle'.format(attack_name,model_name), 'wb') as handle:\n",
    "                pickle.dump(results['adv_raw'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            with open(save_folder+'/{}_{}.adv_clipped.pickle'.format(attack_name,model_name), 'wb') as handle:\n",
    "                pickle.dump(results['adv_clipped'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            with open(save_folder+'/{}_{}.adv_raw.pickle'.format(attack_name,model_name), 'wb') as handle:\n",
    "                pickle.dump(results['adv_success'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            # delete object to ensure it gets garbage collected\n",
    "            del(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06cec88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../Experiments/adversarial_attacks_results/1633715707.3646119/L2CarliniWagner_fgn_f_model_from_scratch.adv_clipped.pickle', 'rb') as f:\n",
    "#     res = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d44a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
