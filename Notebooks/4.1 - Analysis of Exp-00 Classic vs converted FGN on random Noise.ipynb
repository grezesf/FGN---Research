{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook analysising the results of Exp-00\n",
    "# classic models vs fully trained FGNs from scratch\n",
    "# how do they compare over random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import GPUtil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcrescent\u001b[0m  Thu Mar 19 15:19:02 2020\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 47'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 1857\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mfelix\u001b[0m(\u001b[0;33m717M\u001b[0m) \u001b[1;30mnear\u001b[0m(\u001b[0;33m487M\u001b[0m) \u001b[1;30mfelix\u001b[0m(\u001b[0;33m643M\u001b[0m)\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 37'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 4353\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mnear\u001b[0m(\u001b[0;33m4343M\u001b[0m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# manualy set cuda device\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory Exp-00\n",
    "exp_dir = '/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00/2020_01_07_at_23:28:46/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 0 - stats\n",
    "# checking all kinds of FGN have been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats\n",
    "classic_model_list = []\n",
    "fgn_model_list = []\n",
    "for path, dir,files in os.walk(exp_dir):\n",
    "    for file in files:\n",
    "        if 'trained_classic_model_full.pth' in file:\n",
    "            classic_model_list.append((path,file))\n",
    "        if 'trained_converted_fgn_model_full.pth' in file:\n",
    "            fgn_model_list.append((path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trained classic models: 185\n",
      "number of trained FGN models: 10360\n"
     ]
    }
   ],
   "source": [
    "print('number of trained classic models:', len(classic_model_list))\n",
    "print('number of trained FGN models:', len(fgn_model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [0, 16, 64, 256, 1024]\n",
    "hidden_layer_numbers  = [0, 1, 2, 3]\n",
    "dropout_probs = [0.0, 0.1, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic network counts\n",
    "# count all params\n",
    "layer_number_counts = {key:0 for key in hidden_layer_numbers}\n",
    "layer_sizes_counts = {key:0 for key in hidden_layer_sizes}\n",
    "dp_counts = {key:0  for key in dropout_probs}\n",
    "\n",
    "# for each path\n",
    "for path,_ in classic_model_list:\n",
    "    # get params\n",
    "    s1 = re.split('/', path)[-1]\n",
    "    s2 = re.split('_|\\[|\\]', s1)\n",
    "    s3 = re.split(',', s2[2])\n",
    "    if s3==['']:\n",
    "        number = 0 \n",
    "        size = 0\n",
    "    else:\n",
    "        number = len(re.split(',', s2[2]))\n",
    "        size = int(re.split(',', s2[2])[0])\n",
    "    drop_prob = float(s2[4][2:])\n",
    "    \n",
    "    \n",
    "    # add to dicts\n",
    "    layer_number_counts[number]+=1\n",
    "    layer_sizes_counts[size]+=1\n",
    "    dp_counts[drop_prob]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 classic networks with 0 hidden layers\n",
      "60 classic networks with 1 hidden layers\n",
      "60 classic networks with 2 hidden layers\n",
      "60 classic networks with 3 hidden layers\n",
      "5 classic networks with size 0 hidden layers\n",
      "45 classic networks with size 16 hidden layers\n",
      "45 classic networks with size 1024 hidden layers\n",
      "45 classic networks with size 64 hidden layers\n",
      "45 classic networks with size 256 hidden layers\n",
      "65 classic networks with drop prob 0.0\n",
      "60 classic networks with drop prob 0.4\n",
      "60 classic networks with drop prob 0.1\n"
     ]
    }
   ],
   "source": [
    "for number in layer_number_counts.keys():\n",
    "    print('{} classic networks with {} hidden layers'.format(layer_number_counts[number],number))\n",
    "    \n",
    "for size in layer_sizes_counts.keys():\n",
    "    print('{} classic networks with size {} hidden layers'.format(layer_sizes_counts[size],size))\n",
    "\n",
    "for dp in dp_counts.keys():\n",
    "    print('{} classic networks with drop prob {}'.format(dp_counts[dp],dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGN specific params\n",
    "covar_types = ['sphere', 'diag']\n",
    "ordinals = [0.5, 1.0, 2.0, 5.0]\n",
    "lmbda_sigmas = [8e-08, 8e-07, 4e-06, 8e-06, 1.6e-05, 8e-05, 0.0008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_params_from_path(path):\n",
    "    # extracts classic and fgn params from a path, to rebuild from state dict\n",
    "    # 3 cases: classic model, from scratch model, converted model\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    # get params\n",
    "    # s1 = last directory\n",
    "    s1 = re.split('/', path)[-1]\n",
    "    \n",
    "    s2 = re.split('_|\\[|\\]', s1)\n",
    "    s3 = re.split(',', s2[2])\n",
    "    if s3==['']:\n",
    "        number = 0 \n",
    "        size = 0\n",
    "    else:\n",
    "        number = len(re.split(',', s2[2]))\n",
    "        size = int(re.split(',', s2[2])[0])\n",
    "    \n",
    "    results_dict['hidden_layers_sizes'] = [size for _ in range(number)]\n",
    "    \n",
    "    drop_prob = float(s2[4][2:])\n",
    "    results_dict['drop_p'] = drop_prob\n",
    "    \n",
    "    # fgn specific\n",
    "    try:\n",
    "        covar_type = s2[5]\n",
    "        if covar_type in ['sphere', 'diag']:\n",
    "            results_dict['covar_type'] = covar_type\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ordinal = float(s2[6][3:])\n",
    "        if ordinal in [0.5, 1.0, 2.0, 5.0]:\n",
    "            results_dict['ordinal'] = ordinal\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ls = float(s2[7][2:])\n",
    "        if ls in [8e-08, 8e-07, 4e-06, 8e-06, 1.6e-05, 8e-05, 0.0008]:\n",
    "            results_dict['lmbda_sigma'] = ls\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00/2020_01_07_at_23:28:46/classic_hl[1024]_dp0.4_ite4/converted FGNs/converted_fgn_hl[1024]_dp0.4_sphere_ord1.0_ls8e-06',\n",
       " 'trained_converted_fgn_model_full.pth')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgn_model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = fgn_model_list[0][0]\n",
    "print(path)\n",
    "s1 = re.split('/', path)[-1]\n",
    "print(s1)\n",
    "s2 = re.split('_|\\[|\\]', s1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00/2020_01_07_at_23:28:46/classic_hl[1024]_dp0.4_ite4/converted FGNs/converted_fgn_hl[1024]_dp0.4_sphere_ord1.0_ls8e-06\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'hl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e6e5a5d9186a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'hl'"
     ]
    }
   ],
   "source": [
    "# fgn network counts\n",
    "# count all params\n",
    "layer_number_counts = {key:0 for key in hidden_layer_numbers}\n",
    "layer_sizes_counts = {key:0 for key in hidden_layer_sizes}\n",
    "dp_counts = {key:0  for key in dropout_probs}\n",
    "covar_types_count = {key:0  for key in covar_types}\n",
    "ordinals_counts = {key:0  for key in ordinals}\n",
    "lmbda_sigmas_count = {key:0  for key in lmbda_sigmas}\n",
    "\n",
    "# for each path\n",
    "for path,_ in fgn_model_list:\n",
    "    \n",
    "    print(path)\n",
    "    \n",
    "    # get params\n",
    "    s1 = re.split('/', path)[-1]\n",
    "    s2 = re.split('_|\\[|\\]', s1)\n",
    "    s3 = re.split(',', s2[2])\n",
    "    if s3==['']:\n",
    "        number = 0 \n",
    "        size = 0\n",
    "    else:\n",
    "        number = len(re.split(',', s2[2]))\n",
    "        size = int(re.split(',', s2[2])[0])\n",
    "        \n",
    "        \n",
    "    drop_prob = float(s2[4][2:])\n",
    "    covar_type = s2[5]\n",
    "    ordinal = float(s2[6][3:])\n",
    "    ls = float(s2[7][2:])\n",
    "    \n",
    "    # add to dicts\n",
    "    layer_number_counts[number]+=1\n",
    "    layer_sizes_counts[size]+=1\n",
    "    dp_counts[drop_prob]+=1\n",
    "    covar_types_count[covar_type]+=1\n",
    "    ordinals_counts[ordinal]+=1\n",
    "    lmbda_sigmas_count[ls]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in layer_number_counts.keys():\n",
    "    print('{} fgn networks with {} hidden layers'.format(layer_number_counts[number],number))\n",
    "    \n",
    "for size in layer_sizes_counts.keys():\n",
    "    print('{} fgn networks with size {} hidden layers'.format(layer_sizes_counts[size],size))\n",
    "\n",
    "for dp in dp_counts.keys():\n",
    "    print('{} fgn networks with drop prob {}'.format(dp_counts[dp],dp))\n",
    "    \n",
    "for covar in covar_types_count.keys():\n",
    "    print('{} fgn networks with {} covariance matrix'.format(covar_types_count[covar],covar))\n",
    "    \n",
    "for ordinal in ordinals_counts.keys():\n",
    "    print('{} fgn networks with {} ordinal '.format(ordinals_counts[ordinal],ordinal))\n",
    "\n",
    "for ls in lmbda_sigmas_count.keys():\n",
    "    print('{} fgn networks with lmbda_sigma of {}'.format(lmbda_sigmas_count[ls],ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 0 - comparison of performance\n",
    "# how do FGNs trained from scratch perform in accuracy over MNIST compared to classic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "batch_sizefor_train = 10000\n",
    "batch_size_for_val = 10000\n",
    "(mnist_train_loader, mnist_val_loader, mnist_test_loader) = fgnh.mnist_dataloaders(batch_size=batch_sizefor_train,\n",
    "                                                                                   batch_size_for_val=batch_size_for_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_models_test_acc = []\n",
    "classic_models_train_acc = []\n",
    "\n",
    "for classic_model_path, filename  in classic_model_list:\n",
    "    print('Working on {}'.format(classic_model_path))\n",
    "    \n",
    "    # load train history\n",
    "    train_history = pickle.load(open(classic_model_path + '/train_histories.pckl', 'rb')) \n",
    "    # add to list for histogram\n",
    "    classic_models_test_acc.append(train_history['test_acc_hist'])\n",
    "    classic_models_train_acc.append(train_history['train_acc_hist'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(classic_models_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgn_models_test_acc = []\n",
    "fgn_models_train_acc = []\n",
    "\n",
    "for fgn_model_path, filename  in fgn_model_list:\n",
    "    print('Working on {}'.format(fgn_model_path))\n",
    "    \n",
    "    # load train history\n",
    "    train_history = pickle.load(open(fgn_model_path + '/train_histories.pckl', 'rb')) \n",
    "    # add to list for histogram\n",
    "    fgn_models_test_acc.append(train_history['test_acc_hist'])\n",
    "    fgn_models_train_acc.append(train_history['train_acc_hist'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(fgn_models_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_models_test_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot means with error bars\n",
    "x = [0,1,2,3,4]\n",
    "y = stats.describe(classic_models_test_acc)[2]\n",
    "plt.plot(x,y, label='classic test mean', c='C0')\n",
    "y = stats.describe(classic_models_test_acc)[1][0]\n",
    "plt.plot(x,y, label='classic test min', linestyle='--', c='C0')\n",
    "# for y in classic_models_test_acc:\n",
    "#     plt.plot(x,y, linestyle='', marker='.', alpha=0.1, c='C0')\n",
    "\n",
    "\n",
    "y = stats.describe(fgn_models_test_acc)[2]\n",
    "plt.plot(x,y, label='fgn test mean', c='C1')\n",
    "y = stats.describe(fgn_models_test_acc)[1][0]\n",
    "plt.plot(x,y, label='fgn test min', linestyle='--', c='C1')\n",
    "# for y in fgn_models_test_acc:\n",
    "#     plt.plot(x,y, linestyle='', marker='.', alpha=0.01, c='C1')\n",
    "    \n",
    "plt.title('MNIST accuracy over training epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random noise\n",
    "num_samples = 5000\n",
    "# (actually done later)\n",
    "# white_noise_dataloader = fgnh.mnist_random_dataloader(num_samples=5000, batch_size=10000)\n",
    "# shuffled_noise_dataloader = fgnh.mnist_random_shuffled_dataloader(num_samples=5000, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show examples\n",
    "x = white_noise_dataloader.dataset.tensors[0][0]\n",
    "plt.imshow(x, cmap=plt.cm.get_cmap('Greys'))\n",
    "plt.title('Fully Random Image')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "x = shuffled_noise_dataloader.dataset.tensors[0][0]\n",
    "plt.imshow(x, cmap=plt.cm.get_cmap('Greys'))\n",
    "plt.title('Random from Real Image Shuffled Pixels')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_params_from_path(path):\n",
    "    # extracts classic and fgn params from a path, to rebuild from state dict\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    # get params\n",
    "    s1 = re.split('/', path)[-1]\n",
    "    s2 = re.split('_|\\[|\\]', s1)\n",
    "    s3 = re.split(',', s2[2])\n",
    "    if s3==['']:\n",
    "        number = 0 \n",
    "        size = 0\n",
    "    else:\n",
    "        number = len(re.split(',', s2[2]))\n",
    "        size = int(re.split(',', s2[2])[0])\n",
    "    \n",
    "    results_dict['hidden_layers_sizes'] = [size for _ in range(number)]\n",
    "    \n",
    "    drop_prob = float(s2[4][2:])\n",
    "    results_dict['drop_p'] = drop_prob\n",
    "    \n",
    "    # fgn specific\n",
    "    try:\n",
    "        covar_type = s2[5]\n",
    "        if covar_type in ['sphere', 'diag']:\n",
    "            results_dict['covar_type'] = covar_type\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ordinal = float(s2[6][3:])\n",
    "        if ordinal in [0.5, 1.0, 2.0, 5.0]:\n",
    "            results_dict['ordinal'] = ordinal\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ls = float(s2[7][2:])\n",
    "        if ls in [8e-08, 8e-07, 4e-06, 8e-06, 1.6e-05, 8e-05, 0.0008]:\n",
    "            results_dict['lmbda_sigma'] = ls\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test\n",
    "extract_params_from_path(classic_model_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram_of_preds(model, dataloader, device, verbose=False):\n",
    "    # given model\n",
    "    # and a dataloader\n",
    "    # returns a plt.hist of the predictions\n",
    "    \n",
    "    # send model to device and eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    preds_maxes = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for x_data in dataloader:\n",
    "            # in case the dataloader returns a x,y pair\n",
    "#             print(len(x_data))\n",
    "#             if len(x_data)==2:\n",
    "            x_data = x_data[0]\n",
    "            preds = model(x_data.to(device))\n",
    "            # apply softmax for probs\n",
    "            preds_softmax = np.array([np.exp(x)/sum(np.exp(x)) for x in preds.cpu().detach().numpy()])\n",
    "            # only save max\n",
    "            preds_maxes = np.concatenate((preds_maxes, np.max(preds_softmax, axis=1)))\n",
    "\n",
    "\n",
    "    # quick description of the maxes\n",
    "    stat = stats.describe(preds_maxes)\n",
    "    if verbose: print(stat)\n",
    "    # % of maxes above 0.5\n",
    "    if verbose: print(\"percentage of confident (>0.5) predictions:\",float(len([x for x in preds_maxes if x>=0.5])/float(len(preds_maxes))))\n",
    "\n",
    "    # histogram\n",
    "    hist = np.histogram(preds_maxes, bins=(np.arange(100)+1)/100.0)\n",
    "    # to replot the original: plt.hist(hist[1][:-1], weights=hist[0], bins=hist[1])\n",
    "    \n",
    "    return(stat, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first the classic nets\n",
    "classic_hist_list_white_noise = []\n",
    "classic_hist_list_shuffled_noise = []\n",
    "\n",
    "for classic_model_path, filename  in classic_model_list:\n",
    "    print('Working on {}'.format(classic_model_path))\n",
    "    \n",
    "    # load model\n",
    "    #try loading directly (will send to GPU it was trained on?)\n",
    "    try:\n",
    "        classic_model = torch.load(classic_model_path+'/'+filename)\n",
    "        print('Loaded model directly')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('loading model directly failed, rebuilding from state dict')\n",
    "        params = extract_params_from_path(classic_model_path)\n",
    "        print(params)\n",
    "        # build model\n",
    "        classic_model = fgnl.Feedforward_Classic_net(in_feats=28*28, \n",
    "                                                     out_feats = 10,\n",
    "                                                     hidden_layer_sizes=params['hidden_layers_sizes'],\n",
    "                                                     drop_p = params['drop_p']\n",
    "                                                     )\n",
    "        # load state_dict on CPU\n",
    "        classic_model.load_state_dict(torch.load(classic_model_path+'/trained_classic_model_state_dict.pth'))\n",
    "        \n",
    "    # send to most free device\n",
    "    # attempt to sent to GPU, else train over CPU\n",
    "    model_sent_to_device = False\n",
    "    sleep_time = 30\n",
    "    while not model_sent_to_device and sleep_time<4800:\n",
    "        # get free device\n",
    "        device = torch.device('cuda')\n",
    "        try:\n",
    "            device_id = GPUtil.getFirstAvailable(order='memory', maxLoad=1.0, maxMemory=0.8, verbose=False)[0]\n",
    "            # send to least used GPU\n",
    "            print('Using GPU:', device_id)\n",
    "            with torch.cuda.device(device_id):\n",
    "                classic_model.to(device)\n",
    "                model_sent_to_device=True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            sleep_time = 1.66*sleep_time\n",
    "            print('GPU error. Wait {}s and continue'.format(sleep_time))\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    if not model_sent_to_device:\n",
    "        print('Failed to send to GPU, using CPU')\n",
    "        classic_model = torch.device('cpu')\n",
    "        model.to(device)    \n",
    "        \n",
    "    # get new noise\n",
    "    white_noise_dataloader = fgnh.mnist_random_dataloader(num_samples=num_samples, batch_size=10000)\n",
    "    shuffled_noise_dataloader = fgnh.mnist_random_shuffled_dataloader(num_samples=num_samples, batch_size=10000)\n",
    "    \n",
    "    # get preds over white noise\n",
    "    # ~4kb per \n",
    "    stat, hist = get_histogram_of_preds(classic_model, white_noise_dataloader, device)\n",
    "    classic_hist_list_white_noise.append((classic_model_path, hist, stat))\n",
    "    \n",
    "    # get preds over shuffled noise\n",
    "    stat, hist = get_histogram_of_preds(classic_model, shuffled_noise_dataloader, device)\n",
    "    classic_hist_list_shuffled_noise.append((classic_model_path, hist, stat))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_getsizeof(x, seen=set(), verbose=False):\n",
    "    if id(x) in seen:\n",
    "        return 0\n",
    "    else:\n",
    "        s = sys.getsizeof(x)\n",
    "        if verbose: print(x,s)\n",
    "        seen.add(id(x))\n",
    "        # rec call\n",
    "        try:\n",
    "            for y in x:\n",
    "                s += recursive_getsizeof(y, seen, verbose=verbose)\n",
    "        except Exception as e:\n",
    "            if verbose: print(e)\n",
    "                \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_getsizeof(classic_hist_list_white_noise[0], seen=set(), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_getsizeof(classic_hist_list_white_noise, seen=set(), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# overall histogram - white noise\n",
    "bins = classic_hist_list_white_noise[0][1][1] #will be the same for all\n",
    "weights=[]\n",
    "for path, hist, stat in classic_hist_list_white_noise:\n",
    "    #weights\n",
    "    w = hist[0]\n",
    "    if len(weights) == 0:\n",
    "        weights=w\n",
    "    else:\n",
    "        weights+=w\n",
    "    \n",
    "s = float(np.sum(weights))\n",
    "weights = [w/s for w in weights]\n",
    "\n",
    "plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "plt.xticks((np.arange(10)+1)/10.0)\n",
    "plt.grid(True)\n",
    "plt.title(\"Classic-Net: Predictions over White Noise\")\n",
    "plt.show()\n",
    "# % above 0.5\n",
    "print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall histogram - shuffled noise\n",
    "bins = classic_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "weights=[]\n",
    "for path, hist, stat in classic_hist_list_shuffled_noise:\n",
    "    #weights\n",
    "    w = hist[0]\n",
    "    if len(weights) == 0:\n",
    "        weights=w\n",
    "    else:\n",
    "        weights+=w\n",
    "    \n",
    "s = float(np.sum(weights))\n",
    "weights = [w/s for w in weights]\n",
    "\n",
    "plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "plt.xticks((np.arange(10)+1)/10.0)\n",
    "plt.grid(True)\n",
    "plt.title(\"Classic-Net: Predictions over Shuffled Noise\")\n",
    "plt.show()\n",
    "# % above 0.5\n",
    "print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histogram per param\n",
    "# overall histogram - white noise\n",
    "bins = classic_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "\n",
    "for hl_size in hidden_layer_sizes:\n",
    "    weights=[]\n",
    "    for path, hist, stat in classic_hist_list_white_noise:\n",
    "        if str(hl_size) in path:\n",
    "            #weights\n",
    "            w = hist[0]\n",
    "            if len(weights) == 0:\n",
    "                weights=w\n",
    "            else:\n",
    "                weights+=w\n",
    "\n",
    "    s = float(np.sum(weights))\n",
    "    weights = [w/s for w in weights]\n",
    "\n",
    "\n",
    "\n",
    "    plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "    plt.xticks((np.arange(10)+1)/10.0)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Classic-Net {} layer size: Predictions over White Noise\".format(hl_size))\n",
    "    plt.show()\n",
    "    # % above 0.5\n",
    "    print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random noise num samples smaller because so many more FGNs\n",
    "num_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next the FGN\n",
    "fgn_hist_list_white_noise = []\n",
    "fgn_hist_list_shuffled_noise = []\n",
    "\n",
    "for fgn_model_path, filename  in fgn_model_list:\n",
    "    print('Working on {}'.format(fgn_model_path))\n",
    "    \n",
    "    # load model\n",
    "    #try loading directly (will send to GPU it was trained on?)\n",
    "    try:\n",
    "        fgn_model = torch.load(fgn_model_path+'/'+filename)\n",
    "        print('Loaded model directly')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('loading model directly failed, rebuilding from state dict')\n",
    "        params = extract_params_from_path(fgn_model_path)\n",
    "        # build model\n",
    "        fgn_model = fgnl.Feedforward_FGN_net(in_feats=28*28, \n",
    "                                             out_feats = 10,\n",
    "                                             hidden_layer_sizes=params['hidden_layers_sizes'],\n",
    "                                             drop_p = params['drop_p'],\n",
    "                                             covar_type=params['covar_type'],\n",
    "                                             non_lin=True)\n",
    "        # load state_dict on CPU\n",
    "        fgn_model.load_state_dict(torch.load(fgn_model_path+'/trained_fgn_model_state_dict.pth'))\n",
    "        \n",
    "    # send to most free device\n",
    "    # attempt to sent to GPU, else train over CPU\n",
    "    model_sent_to_device = False\n",
    "    sleep_time = 30\n",
    "    while not model_sent_to_device and sleep_time<4800:\n",
    "        # get free device\n",
    "        device = torch.device('cuda')\n",
    "        try:\n",
    "            device_id = GPUtil.getFirstAvailable(order='memory', maxLoad=1.0, maxMemory=0.8, verbose=False)[0]\n",
    "            # send to least used GPU\n",
    "            print('Using GPU:', device_id)\n",
    "            with torch.cuda.device(device_id):\n",
    "                fgn_model.to(device)\n",
    "                model_sent_to_device=True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            sleep_time = 1.66*sleep_time\n",
    "            print('GPU error. Wait {}s and continue'.format(sleep_time))\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    if not model_sent_to_device:\n",
    "        print('Failed to send to GPU, using CPU')\n",
    "        fgn_model = torch.device('cpu')\n",
    "        model.to(device)    \n",
    "        \n",
    "    # get new noise\n",
    "    white_noise_dataloader = fgnh.mnist_random_dataloader(num_samples=num_samples, batch_size=10000)\n",
    "    shuffled_noise_dataloader = fgnh.mnist_random_shuffled_dataloader(num_samples=num_samples, batch_size=10000)\n",
    "    \n",
    "    # get preds over white noise\n",
    "    # ~4kb per \n",
    "    stat, hist = get_histogram_of_preds(fgn_model, white_noise_dataloader, device)\n",
    "    fgn_hist_list_white_noise.append((fgn_model_path, hist, stat))\n",
    "    \n",
    "    # get preds over shuffled noise\n",
    "    stat, hist = get_histogram_of_preds(fgn_model, shuffled_noise_dataloader, device)\n",
    "    fgn_hist_list_shuffled_noise.append((fgn_model_path, hist, stat))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall histogram - white noise\n",
    "bins = fgn_hist_list_white_noise[0][1][1] #will be the same for all\n",
    "weights=[]\n",
    "for path, hist, stat in fgn_hist_list_white_noise:\n",
    "    #weights\n",
    "    w = hist[0]\n",
    "    if len(weights) == 0:\n",
    "        weights=w\n",
    "    else:\n",
    "        weights+=w\n",
    "    \n",
    "s = float(np.sum(weights))\n",
    "weights = [w/s for w in weights]\n",
    "\n",
    "plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "plt.xticks((np.arange(10)+1)/10.0)\n",
    "plt.grid(True)\n",
    "plt.title(\"FGNs: Predictions over White Noise\")\n",
    "plt.show()\n",
    "# % above 0.5\n",
    "print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall histogram - shuffled noise\n",
    "bins = fgn_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "weights=[]\n",
    "for path, hist, stat in fgn_hist_list_shuffled_noise:\n",
    "    #weights\n",
    "    w = hist[0]\n",
    "    if len(weights) == 0:\n",
    "        weights=w\n",
    "    else:\n",
    "        weights+=w\n",
    "    \n",
    "s = float(np.sum(weights))\n",
    "weights = [w/s for w in weights]\n",
    "\n",
    "plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "plt.xticks((np.arange(10)+1)/10.0)\n",
    "plt.grid(True)\n",
    "plt.title(\"FGNs: Predictions over Shuffled Noise\")\n",
    "plt.show()\n",
    "# % above 0.5\n",
    "print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histogram per param\n",
    "# overall histogram - white noise\n",
    "bins = classic_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "\n",
    "for ordinal in ordinals:\n",
    "    weights=[]\n",
    "    for path, hist, stat in fgn_hist_list_shuffled_noise:\n",
    "        if str(ordinal) in path:\n",
    "            #weights\n",
    "            w = hist[0]\n",
    "            if len(weights) == 0:\n",
    "                weights=w\n",
    "            else:\n",
    "                weights+=w\n",
    "\n",
    "    s = float(np.sum(weights))\n",
    "    weights = [w/s for w in weights]\n",
    "\n",
    "\n",
    "\n",
    "    plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "    plt.xticks((np.arange(10)+1)/10.0)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"FGN with ordinal {}: Predictions over Shuffled Noise\".format(ordinal))\n",
    "    plt.show()\n",
    "    # % above 0.5\n",
    "    print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histogram per param\n",
    "# overall histogram - shuffled noise\n",
    "bins = classic_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "\n",
    "for ls in lmbda_sigmas:\n",
    "    weights=[]\n",
    "    for path, hist, stat in fgn_hist_list_shuffled_noise:\n",
    "        if str(ls) in path:\n",
    "            #weights\n",
    "            w = hist[0]\n",
    "            if len(weights) == 0:\n",
    "                weights=w\n",
    "            else:\n",
    "                weights+=w\n",
    "\n",
    "    s = float(np.sum(weights))\n",
    "    weights = [w/s for w in weights]\n",
    "\n",
    "\n",
    "\n",
    "    plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "    plt.xticks((np.arange(10)+1)/10.0)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"FGN with lmbda_sigma {}: Predictions over Shuffled Noise\".format(ls))\n",
    "    plt.show()\n",
    "    # % above 0.5\n",
    "    print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram per param\n",
    "# overall histogram - shuffled noise\n",
    "bins = classic_hist_list_shuffled_noise[0][1][1] #will be the same for all\n",
    "\n",
    "for covar_type in covar_types:\n",
    "    weights=[]\n",
    "    for path, hist, stat in fgn_hist_list_shuffled_noise:\n",
    "        if str(covar_type) in path:\n",
    "            #weights\n",
    "            w = hist[0]\n",
    "            if len(weights) == 0:\n",
    "                weights=w\n",
    "            else:\n",
    "                weights+=w\n",
    "\n",
    "    s = float(np.sum(weights))\n",
    "    weights = [w/s for w in weights]\n",
    "\n",
    "\n",
    "\n",
    "    plt.hist(bins[:-1], weights=weights, bins=bins)\n",
    "    plt.xticks((np.arange(10)+1)/10.0)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"FGN with covar_type {}: Predictions over White Noise\".format(covar_type))\n",
    "    plt.show()\n",
    "    # % above 0.5\n",
    "    print(\"percentage of confident (>0.5) predictions:\", np.sum(weights[49:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
