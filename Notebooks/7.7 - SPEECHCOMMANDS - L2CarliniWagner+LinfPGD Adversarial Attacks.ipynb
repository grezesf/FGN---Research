{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b807a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack the SPEECHCOMMAND models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca533fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41323d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eb8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cdfd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcrescent              \u001b[m  Wed Nov 17 18:26:40 2021  \u001b[1m\u001b[30m418.152.00\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  940\u001b[m / \u001b[33m10989\u001b[m MB | \u001b[1m\u001b[30mvietanh\u001b[m(\u001b[33m929M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m10989\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "# check gpus\n",
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db34771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# manually set cuda device\n",
    "# torch.cuda.set_device(1)\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be55675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893e4511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version_info  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddf7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "batch_size = 32\n",
    "batchsize_for_val = 128\n",
    "(train_loader, val_loader, test_loader) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "                                                                          batch_size = batch_size,\n",
    "                                                                          batchsize_for_val = batchsize_for_val,\n",
    "                                                                          num_workers=5, \n",
    "                                                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631ac6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model classes\n",
    "\n",
    "## classic model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2).squeeze()\n",
    "    \n",
    "# FGN model    \n",
    "class FGN_M5(nn.Module):\n",
    "    \n",
    "    # changes:\n",
    "    # nn.Conv1d -> fgnl.FGN_Conv1d\n",
    "    # added g to conv inputs and outputs\n",
    "    # make sure you pass g through the same pooling steps as x\n",
    "    \n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.fgn_conv1 = fgnl.FGN_Conv1d(in_channels=n_input, out_channels=n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv2 = fgnl.FGN_Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv3 = fgnl.FGN_Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.fgn_conv4 = fgnl.FGN_Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, g = self.fgn_conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        g = self.pool1(g)\n",
    "        x, g = self.fgn_conv2(x, g)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        g = self.pool2(g)\n",
    "        x, g = self.fgn_conv3(x ,g)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        g = self.pool3(g)\n",
    "        x, _ = self.fgn_conv4(x, g)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eed4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained models paths\n",
    "save_path = '../Experiments/sample_SPEECHCOMMANDS_models/'\n",
    "\n",
    "classic_model_name= 'sample_classic_model_SPEECHCOMMANDS'\n",
    "fgn_model_name = 'sample_FGN_model_SPEECHCOMMANDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4d8da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "GeForce RTX 2080 Ti with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 2080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and load the models\n",
    "# classic model\n",
    "classic_model = M5()\n",
    "classic_model.load_state_dict(torch.load(save_path+classic_model_name+'_state_dict.pth'))\n",
    "classic_model.to(device)\n",
    "\n",
    "# fgn model trained from scratch\n",
    "fgn_model_from_scratch = FGN_M5()\n",
    "fgn_model_from_scratch.load_state_dict(torch.load(save_path+fgn_model_name+'_state_dict.pth'))\n",
    "fgn_model_from_scratch.to(device)\n",
    "\n",
    "# converted fgn model (no retraining)\n",
    "fgn_model_converted_no_retraining = FGN_M5()\n",
    "fgn_model_converted_no_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_no_retraining.to(device)\n",
    "\n",
    "# converted and retrained 1 epoch fgn model\n",
    "fgn_model_converted_fast_retraining = FGN_M5()\n",
    "fgn_model_converted_fast_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_fast_retrained_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_fast_retraining.to(device)\n",
    "\n",
    "# converted and retrained 21 epoch fgn model\n",
    "fgn_model_converted_long_retraining = FGN_M5()\n",
    "fgn_model_converted_long_retraining.load_state_dict(torch.load(save_path+'sample_FGN_converted_long_retrained_model_SPEECHCOMMANDS'+'_state_dict.pth'))\n",
    "fgn_model_converted_long_retraining.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b89c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FGN_M5(\n",
       "  (fgn_conv1): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
       "  )\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv2): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv3): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fgn_conv4): FGN_Conv1d(\n",
       "    (Conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  )\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=64, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set all models to eval mode\n",
    "classic_model.eval()\n",
    "fgn_model_from_scratch.eval()\n",
    "fgn_model_converted_no_retraining.eval()\n",
    "fgn_model_converted_fast_retraining.eval()\n",
    "fgn_model_converted_long_retraining.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c9f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to test models\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "    print(f'Accuracy: {correct}/{len(loader.dataset)} ({100. * correct / len(loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f43d3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # verify accuracies\n",
    "# print('Train/Test/Val accuracy for Classic Model')\n",
    "# test(classic_model, train_loader)\n",
    "# test(classic_model, val_loader)\n",
    "# test(classic_model, test_loader)\n",
    "\n",
    "# print('Train/Test/Val accuracy for FGN model trained from scratch')\n",
    "# test(fgn_model_from_scratch, train_loader)\n",
    "# test(fgn_model_from_scratch, val_loader)\n",
    "# test(fgn_model_from_scratch, test_loader)\n",
    "\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (no retraining)')\n",
    "# test(fgn_model_converted_no_retraining, train_loader)\n",
    "# test(fgn_model_converted_no_retraining, val_loader)\n",
    "# test(fgn_model_converted_no_retraining, test_loader)\n",
    "\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (fast retraining)')\n",
    "# test(fgn_model_converted_fast_retraining, train_loader)\n",
    "# test(fgn_model_converted_fast_retraining, val_loader)\n",
    "# test(fgn_model_converted_fast_retraining, test_loader)\n",
    "\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (long retraining)')\n",
    "# test(fgn_model_converted_long_retraining, train_loader)\n",
    "# test(fgn_model_converted_long_retraining, val_loader)\n",
    "# test(fgn_model_converted_long_retraining, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6011b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Results (no need to rerun):\n",
    "# Train/Test/Val accuracy for Classic Model\n",
    "# Accuracy: 76655/84843 (90%)\n",
    "# Accuracy: 8755/9981 (88%)\n",
    "# Accuracy: 9468/11005 (86%)\n",
    "# Train/Test/Val accuracy for FGN model trained from scratch\n",
    "# Accuracy: 73489/84843 (87%)\n",
    "# Accuracy: 8572/9981 (86%)\n",
    "# Accuracy: 9244/11005 (84%)\n",
    "# Train/Test/Val accuracy for FGN model converted from classic (no retraining)\n",
    "# Accuracy: 76655/84843 (90%)\n",
    "# Accuracy: 8755/9981 (88%)\n",
    "# Accuracy: 9468/11005 (86%)\n",
    "# Train/Test/Val accuracy for FGN model converted from classic (fast retraining)\n",
    "# Accuracy: 76264/84843 (90%)\n",
    "# Accuracy: 8654/9981 (87%)\n",
    "# Accuracy: 9394/11005 (85%)\n",
    "# Train/Test/Val accuracy for FGN model converted from classic (long retraining)\n",
    "# Accuracy: 77561/84843 (91%)\n",
    "# Accuracy: 8726/9981 (87%)\n",
    "# Accuracy: 9411/11005 (86%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d28d3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Attacking the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c76526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a078c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9d85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model bounds and preprocessing\n",
    "\n",
    "# precomputed bounds min and max input values\n",
    "min_bound = -1.3844940662384033\n",
    "max_bound = 1.3773366212844849\n",
    "\n",
    "bounds = (min_bound, max_bound)\n",
    "# preprocessing - I think these would be used in similar way to pytorch preprocessing\n",
    "# but possible passed to whatever architecture is used (torch, tensorflow, other) \n",
    "# in my case the dataloaders already normalizes the data\n",
    "preprocessing = dict(mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b17d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready the models for foolbox\n",
    "classic_f_model = foolbox.PyTorchModel(classic_model, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_from_scratch = foolbox.PyTorchModel(fgn_model_from_scratch, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_no_retraining = foolbox.PyTorchModel(fgn_model_converted_no_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_fast_retraining = foolbox.PyTorchModel(fgn_model_converted_fast_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n",
    "\n",
    "fgn_f_model_converted_long_retraining = foolbox.PyTorchModel(fgn_model_converted_long_retraining, bounds=bounds,\n",
    "                                       preprocessing=preprocessing, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd86c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f31be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug tool\n",
    "import itertools\n",
    "# \n",
    "start = 0\n",
    "stop = 36 # can be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d6ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foolbox.accuracy doesn't work with dataloaders, so building a custom func to do so\n",
    "def f_accuracy(model, dataloader, proc_func=None):\n",
    "    # given a model and a dataloader, computes accuracy\n",
    "    # proc_func is a processing function to apply to the values of the dataloader\n",
    "    # that returns (inputs, targets)\n",
    "    \n",
    "    # get model device\n",
    "    device = model.device\n",
    "    \n",
    "    running_count = 0\n",
    "    running_average = 0\n",
    "    # go through the dataset (assumes inputs and target are what is returned )\n",
    "    for batch in tqdm(itertools.islice(dataloader, start=start, end=end)):\n",
    "        # apply proc_func \n",
    "        if proc_func != None:\n",
    "            inputs, targets = proc_func(*batch)\n",
    "        else:\n",
    "            inputs, targets = batch\n",
    "        \n",
    "        # send data to proper device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # update running average accuracy and count\n",
    "        running_average = (len(inputs)*foolbox.utils.accuracy(model, inputs, targets) + running_count*running_average)/(len(inputs)+running_count)\n",
    "        running_count += len(inputs)\n",
    "    \n",
    "    return(running_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942ddfb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # check model accuracies\n",
    "# print('Train/Test/Val accuracy for Classic Model')\n",
    "# print(f_accuracy(classic_f_model, train_loader))\n",
    "# print(f_accuracy(classic_f_model, val_loader))\n",
    "# print(f_accuracy(classic_f_model, test_loader))\n",
    "# print('Train/Test/Val accuracy for FGN model trained from scratch')\n",
    "# print(f_accuracy(fgn_f_model_from_scratch, train_loader))\n",
    "# print(f_accuracy(fgn_f_model_from_scratch, val_loader))\n",
    "# print(f_accuracy(fgn_f_model_from_scratch, test_loader))\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (no retraining)')\n",
    "# print(f_accuracy(fgn_f_model_converted_no_retraining, train_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_no_retraining, val_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_no_retraining, test_loader))\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (fast retraining)')\n",
    "# print(f_accuracy(fgn_f_model_converted_fast_retraining, train_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_fast_retraining, val_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_fast_retraining, test_loader))\n",
    "# print('Train/Test/Val accuracy for FGN model converted from classic (long retraining)')\n",
    "# print(f_accuracy(fgn_f_model_converted_long_retraining, train_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_long_retraining, val_loader))\n",
    "# print(f_accuracy(fgn_f_model_converted_long_retraining, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f256cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results (should be close to identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d1ef7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### looks like they are the same, continue with attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec5ed013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilons: tensor([0.0000, 0.0108, 0.0162, 0.0216, 0.0324, 0.0432, 0.0647, 0.0863, 0.1295,\n",
      "        0.1726, 0.2589, 0.3452, 0.5178, 0.6905, 1.0357, 1.3809, 2.0714, 2.7618],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# attack params to explore\n",
    "epsilons = torch.tensor([(max_bound-min_bound)*x \n",
    "            for x in \n",
    "            [0.0,\n",
    "             1/256,\n",
    "             3/512,\n",
    "             1/128,\n",
    "             3/256,\n",
    "             1/64,\n",
    "             3/128,\n",
    "             1/32,\n",
    "             3/64,\n",
    "             1/16,\n",
    "             3/32,\n",
    "             1/8,\n",
    "             3/16,\n",
    "             1/4,\n",
    "             3/8,\n",
    "             1/2,\n",
    "             3/4,\n",
    "             1.0,] ], device=device)\n",
    "\n",
    "print('epsilons: {}'.format(epsilons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deaeeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that attacks a model using a dataloader\n",
    "\n",
    "def perform_attack(attack_func, f_model, dataloader):\n",
    "    # iterates over dataloader \n",
    "    # attack is the attack function AFTER being defined: ex LinfPGD_attack=foolbox.attacks.LinfPGD()\n",
    "    # (so it's the output foolbox.attacks.LinfPGD(), not foolbox.attacks.LinfPGD itself)\n",
    "    # ensure the dataloader iterator returns (inputs, labels) \n",
    "    \n",
    "    # defines results to return, shape is (epsilons, sample, (sample shape))=(18,32xbatches,1,8000)\n",
    "    num_epsilons = 18 # hardcoded for now\n",
    "    data_shape = (1,8000) # next(iter(dataloader))[0].shape[1:] # this could be expensive, hardcoded for now\n",
    "    # create empty lists of the right shape\n",
    "    results = {'adv_raw':np.array([]).reshape((num_epsilons, 0, *(data_shape))),\n",
    "               'adv_clipped':np.array([]).reshape((num_epsilons, 0, *(data_shape))),\n",
    "               'adv_success':np.array([]).reshape((num_epsilons, 0))}\n",
    "    \n",
    "    # iterate over loader\n",
    "    for inputs, labels in tqdm(itertools.islice(dataloader, start, stop)):\n",
    "        \n",
    "        # attack\n",
    "        adv_raw, adv_clipped, adv_success = attack_func(f_model = f_model, \n",
    "                                                        inputs = inputs, \n",
    "                                                        labels =labels\n",
    "                                                       )\n",
    "        # compile with results\n",
    "        results['adv_raw'] = np.concatenate([results['adv_raw'],\n",
    "                                             np.array([x.cpu().numpy() for x in adv_raw])],\n",
    "                                            axis=1)\n",
    "        results['adv_clipped'] = np.concatenate([results['adv_clipped'],\n",
    "                                                 np.array([x.cpu().numpy() for x in adv_clipped])],\n",
    "                                                axis=1)\n",
    "        results['adv_success'] = np.concatenate([results['adv_success'],\n",
    "                                                 np.array([x.cpu().numpy() for x in adv_success])],\n",
    "                                                axis=1)\n",
    "    \n",
    "    # return results dictionary\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f35cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now, perform the attacks on the models, saving the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5f50b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### attack parameters\n",
    "L2CarliniWagner_attack=foolbox.attacks.L2CarliniWagnerAttack()\n",
    "LinfPGD_attack=foolbox.attacks.LinfPGD()\n",
    "\n",
    "\n",
    "# targetted vs untargetted\n",
    "from foolbox.criteria import Misclassification\n",
    "\n",
    "# define the entire attack function using epsilons, criterion,\n",
    "def L2CarliniWagner_attack_func(f_model, inputs, labels):\n",
    "    device = f_model.device\n",
    "    inputs = inputs.to(device)\n",
    "    criterions = Misclassification(labels.to(device))\n",
    "    return L2CarliniWagner_attack(model=f_model, inputs=inputs, criterion=criterions, epsilons=epsilons)\n",
    "\n",
    "def LinfPGD_attack_func(f_model, inputs, labels):\n",
    "    device = f_model.device\n",
    "    inputs = inputs.to(device)\n",
    "    criterions = Misclassification(labels.to(device))\n",
    "    return LinfPGD_attack(model=f_model, inputs=inputs, criterion=criterions, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1efe5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for the models we are attacking\n",
    "models_to_attack = {'classic_f_model':classic_f_model, \n",
    "                    'fgn_f_model_from_scratch':fgn_f_model_from_scratch, \n",
    "                    'fgn_f_model_converted_no_retraining':fgn_f_model_converted_no_retraining,\n",
    "                    'fgn_f_model_converted_fast_retraining':fgn_f_model_converted_fast_retraining,\n",
    "                    'fgn_f_model_converted_long_retraining':fgn_f_model_converted_long_retraining\n",
    "                   }\n",
    "# names of funcs for attacks\n",
    "attacks_to_perform = {'L2CarliniWagner':L2CarliniWagner_attack_func,\n",
    "                     'LinfPGD':LinfPGD_attack_func}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "869c785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b8d692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp\n",
    "timestamp = time()\n",
    "save_folder = '../Experiments/adversarial_attacks_results/{}/'.format(timestamp)\n",
    "os.makedirs(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7568665",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing attack: L2CarliniWagner\n",
      "Attacking classic_f_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6dd94ad99a47a0868cd08ec2ecdc3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for attack_name, attack in attacks_to_perform.items():\n",
    "#     print('Performing attack:', attack_name)\n",
    "#     for model_name, f_model in models_to_attack.items():\n",
    "#         if not os.path.exists(save_folder+'{}_{}_{}.pickle'.format(attack_name, model_name, 'adv_raw')):\n",
    "#             print('Attacking', model_name)\n",
    "\n",
    "#             # do attack\n",
    "#             results = perform_attack(attack, f_model, val_loader)\n",
    "\n",
    "#             # save results\n",
    "#             # save files separately (can be as big as 11GB)\n",
    "#             for adv_name in ['adv_raw', 'adv_clipped', 'adv_success']:\n",
    "#                 with open(save_folder+'{}_{}_{}.pickle'.format(attack_name, model_name, adv_name), 'wb') as f:\n",
    "#                     pickle.dump(results[adv_name], f, protocol=4)\n",
    "\n",
    "#             # delete objects (might help the Garbage Collector free up space)\n",
    "# # #             del(results)\n",
    "# # #             del(f_model)\n",
    "# # #             torch.cuda.empty_cache()\n",
    "# # #             del(val_loader)\n",
    "# # #             gc.collect()\n",
    "# # #             (_, val_loader, _) = fgnh.SpeechCommands_Dataloaders(resample_rate = 8000,\n",
    "# #                                                                           batch_size = batch_size,\n",
    "# #                                                                           batchsize_for_val = batchsize_for_val,\n",
    "# #                                                                           num_workers=5, \n",
    "# #                                                                           pin_memory=True)\n",
    "            \n",
    "#         else:\n",
    "#             print('skipping')\n",
    "#             print(save_folder+'{}_{}_{}.pickle'.format(attack_name, model_name, 'adv_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46d87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mcrescent              \u001b[m  Mon Feb 21 15:58:41 2022  \u001b[1m\u001b[30m418.152.00\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ac73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 21 15:58:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.152.00   Driver Version: 418.152.00   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "|  0%   31C    P8    21W / 260W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:83:00.0 Off |                  N/A |\n",
      "|  0%   29C    P8     1W / 260W |      0MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02aeb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
