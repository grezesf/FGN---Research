{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev of full attack of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcountdown\u001b[0m  Sat Aug 17 01:04:58 2019\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 39'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m   12\u001b[0m / \u001b[0;33m 8119\u001b[0m MB |\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 38'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m  836\u001b[0m / \u001b[0;33m 8118\u001b[0m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# manualy set cuda device\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random seeds\n",
    "# torch.manual_seed(999)\n",
    "# np.random.seed(999)\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.cuda.manual_seed_all(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 192\n",
    "(mnist_train_loader, mnist_val_loader, mnist_test_loader) = fgnh.mnist_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedforward_Classic_net(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Dropout(p=0.03125)\n",
       "    (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.03125)\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.03125)\n",
       "  )\n",
       "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fl): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load new model\n",
    "# model_path = \"../Experiments/sample_models/sample_fgn_model_noisy_eval_p0.27_full.pth\"\n",
    "model_path = \"../Experiments/sample_models/sample_classic_model_noisy_eval_p0.65_full.pth\"\n",
    "model = torch.load(model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 0.2577, Accuracy: 46105/50000 (92%)\n",
      "Test set - Average loss: 0.2488, Accuracy: 9228/10000 (92%)\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "# switch to random eval\n",
    "try:\n",
    "    model.set_random_eval(True)\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# loss func\n",
    "cross_ent_loss = fgnh.def_classical_cross_ent_loss()\n",
    "\n",
    "test_res = fgnh.test(model, mnist_train_loader,\n",
    "                        cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)\n",
    "\n",
    "test_res = fgnh.test(model, mnist_val_loader,\n",
    "                        cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.RandomSampler at 0x7f85986bf650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_val_loader.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### start of dev work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_bounds(dataloader):\n",
    "    \n",
    "    # given a data loader, finds the absolute min and max of the data\n",
    "    # (future: get bounds per dimension? - optimize so only uses first batch, and doesn't go through batch twice?)\n",
    "    \n",
    "    mini = None\n",
    "    maxi = None\n",
    "    \n",
    "    # go through the data\n",
    "    for data, _ in dataloader:\n",
    "        \n",
    "        # find batch bounds\n",
    "        batch_min = float(data.min().detach().cpu().numpy())\n",
    "        batch_max = float(data.max().detach().cpu().numpy())\n",
    "        \n",
    "        # compare \n",
    "        if mini==None:\n",
    "            mini = batch_min\n",
    "        else:\n",
    "            mini = min(mini,batch_min)\n",
    "            \n",
    "        if maxi==None:\n",
    "            maxi = batch_max\n",
    "        else:\n",
    "            maxi = max(maxi,batch_max)\n",
    "\n",
    "    # return tuple\n",
    "    return (mini, maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_classes(dataloader):\n",
    "    \n",
    "    # returns an array with all the classes found in data loader:\n",
    "    # future: optimize so doesnt go through whole dataset?\n",
    "    \n",
    "    classes = set()\n",
    "    \n",
    "    for _, batch_classes in dataloader:\n",
    "        \n",
    "        classes = classes.union(batch_classes.detach().cpu().numpy())\n",
    "        \n",
    "    return list(classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataloader_classes(mnist_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_FGSM_attack(model, dataloader,\n",
    "                     num_attacks=None, targeted=False, attack_params=None, **kwargs):\n",
    "    # for a given model and dataset, runs #num_attacks untargeted attacks.\n",
    "    \n",
    "   # model: a pytorch model that outputs a raw vector for a N-class prediction\n",
    "    if not isinstance(model, torch.nn.Module):\n",
    "        raise TypeError(\"model is not a pytorch module\")\n",
    "    \n",
    "    # dataloader: a pytorch dataloader\n",
    "    if not isinstance(dataloader, torch.utils.data.dataloader.DataLoader):\n",
    "        raise TypeError(\"dataloader is not a pytorch dataloader\")\n",
    "    # force dataloader sampler to be random\n",
    "    if not isinstance(dataloader.sampler, torch.utils.data.sampler.RandomSampler):\n",
    "        raise TypeError(\"dataloader sampler is not random\")\n",
    "\n",
    "    # num_attacks: if None, will attack every point in dataloader\n",
    "    # otherwise will attack the given number, chosen randomly (this is why RandomSampler is required)\n",
    "    if num_attacks==None:\n",
    "        num_attacks = len(dataloader.dataset)\n",
    "        \n",
    "    #targeted: boolean, wether to do a targeted or untargeted attack\n",
    "        \n",
    "    # attack_params: dictionary with the parameters for FGSM attack\n",
    "    if attack_params==None:\n",
    "        # make some relatively arbitrary choices \n",
    "        if targeted:\n",
    "            data_classes = get_dataloader_classes(dataloader)\n",
    "        data_bounds = get_dataloader_bounds(dataloader)\n",
    "        max_noise = (max(data_bounds)-min(data_bounds))/10.0\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        step_size = max_noise/5.0\n",
    "        steps = 5\n",
    "        confidence_req = 0.5\n",
    "    else:\n",
    "        if targeted:\n",
    "            try:\n",
    "                data_classes = attack_params['target_class']\n",
    "            except:\n",
    "                data_classes = get_dataloader_classes(dataloader)\n",
    "        max_noise = attack_params['max_noise']\n",
    "        loss_func = attack_params['loss_func']\n",
    "        step_size = attack_params['step_size']\n",
    "        data_bounds = attack_params['data_bounds']\n",
    "        steps = attack_params['steps']\n",
    "        confidence_req = attack_params['confidence_req']\n",
    "    \n",
    "    \n",
    "    ### kwargs    \n",
    "    # verbose: boolean, used to print training stats\n",
    "    verbose = kwargs['verbose'] if 'verbose' in kwargs else False\n",
    "\n",
    "    # attack model\n",
    "    attack_count = 0\n",
    "    \n",
    "    # values to return\n",
    "    successful_attack_count = 0\n",
    "    confidence_dist = []\n",
    "    steps_dist = []\n",
    "    \n",
    "    # load a batch\n",
    "    for batch, classes in dataloader:\n",
    "        # check if enough attacks\n",
    "        if attack_count>=num_attacks:\n",
    "            # exit  for batch, classes in dataloader loop\n",
    "            break\n",
    "        \n",
    "        # traverse the batch \n",
    "        for data_point, point_class in zip(batch, classes):\n",
    "            \n",
    "            # check if enough attacks\n",
    "            if attack_count>=num_attacks:\n",
    "                # exit for data_point, point_class in zip(batch, classes):\n",
    "                break\n",
    "                           \n",
    "            # perform attack\n",
    "            if targeted:\n",
    "                # pick random class to attack\n",
    "                target_class=np.random.choice(data_classes)\n",
    "                if verbose: print(\"Attack model with target\", target_class)\n",
    "                adv_data, adv_noise, attack_results = fgnl.FGSM_attack_targeted(model, data_point, target_class, \n",
    "                                                                    max_noise, loss_func, step_size,\n",
    "                                                                    data_bounds, steps, confidence_req,\n",
    "                                                                    **kwargs)\n",
    "            else: # untargeted\n",
    "                if verbose: print(\"Untargeted attack of model\")\n",
    "                adv_data, adv_noise, attack_results = fgnl.FGSM_attack_untargeted(model, data_point, \n",
    "                                                                    max_noise, loss_func, step_size,\n",
    "                                                                    data_bounds, steps, confidence_req,\n",
    "                                                                   **kwargs)\n",
    "            \n",
    "            \n",
    "            # saved desired results\n",
    "            # attack successful?\n",
    "            if (attack_results['confidence']>=confidence_req):\n",
    "                successful_attack_count+=1\n",
    "            # final_confidence distribution\n",
    "            confidence_dist.append(attack_results['confidence'])\n",
    "            # number of steps\n",
    "            steps_dist.append(attack_results['steps'])\n",
    "            \n",
    "            # confidence\n",
    "            print(attack_results)\n",
    "            \n",
    "            # increment attack count\n",
    "            attack_count+=1\n",
    "            if verbose: print(\"Attack count:\", attack_count)\n",
    "        \n",
    "            # go to next in batch\n",
    "        # go to next batch\n",
    "        \n",
    "    # return results\n",
    "    return (successful_attack_count, confidence_dist, steps_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.874156177044:\n",
      "{'confidence': 0.8741562, 'steps': 2}\n",
      "Attack count: 1\n",
      "Untargeted attack of model\n",
      "{'confidence': -1.0, 'steps': 5}\n",
      "Attack count: 2\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.707192540169:\n",
      "{'confidence': 0.70719254, 'steps': 2}\n",
      "Attack count: 3\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.681775271893:\n",
      "{'confidence': 0.6817753, 'steps': 2}\n",
      "Attack count: 4\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.563039898872:\n",
      "{'confidence': 0.5630399, 'steps': 2}\n",
      "Attack count: 5\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.707117676735:\n",
      "{'confidence': 0.7071177, 'steps': 2}\n",
      "Attack count: 6\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.734332680702:\n",
      "{'confidence': 0.7343327, 'steps': 2}\n",
      "Attack count: 7\n",
      "Untargeted attack of model\n",
      "Early stopping at step 3 with confidence 0.501730442047:\n",
      "{'confidence': 0.50173044, 'steps': 3}\n",
      "Attack count: 8\n",
      "Untargeted attack of model\n",
      "Early stopping at step 3 with confidence 0.693682491779:\n",
      "{'confidence': 0.6936825, 'steps': 3}\n",
      "Attack count: 9\n",
      "Untargeted attack of model\n",
      "Early stopping at step 2 with confidence 0.722875356674:\n",
      "{'confidence': 0.72287536, 'steps': 2}\n",
      "Attack count: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " [0.8741562,\n",
       "  -1.0,\n",
       "  0.70719254,\n",
       "  0.6817753,\n",
       "  0.5630399,\n",
       "  0.7071177,\n",
       "  0.7343327,\n",
       "  0.50173044,\n",
       "  0.6936825,\n",
       "  0.72287536],\n",
       " [2, 5, 2, 2, 2, 2, 2, 3, 3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_FGSM_attack(model, mnist_val_loader, num_attacks=10, targeted=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
