{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev of cleverhans attack based on :\n",
    "# https://github.com/tensorflow/cleverhans/blob/master/cleverhans_tutorials/mnist_tutorial_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# set this 'backend' when using jupyter; do this before importing pyplot\n",
    "mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcountdown\u001b[0m  Mon Aug 12 13:58:23 2019\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 39'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m  613\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mfelix\u001b[0m(\u001b[0;33m601M\u001b[0m)\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 40'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m  836\u001b[0m / \u001b[0;33m 8118\u001b[0m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# manualy set cuda device\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset and dataloader declaration\n",
    "# transforms does both the conversion from 0-255 to 0-1\n",
    "# and normalizes by the precomputed mean and std\n",
    "\n",
    "batch_size = 192\n",
    "\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=True, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=False)\n",
    "\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=False, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Experiments/sample_models/sample_fgn_model_noisy_eval_p0.27_full.pth\n",
      "hidden_l_nums [32, 32]\n",
      "drop_p 0.03125\n",
      "ordinal 3.0\n",
      "lambda for l2 loss 6.66666666667e-06\n",
      "lambda for sigma loss 0.00666666666667\n",
      "noisy_centers False\n",
      "batch_size 192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model to test\n",
    "model_path = \"../Experiments/sample_models/sample_fgn_model_noisy_eval_p0.27_full.pth\"\n",
    "dict_path =  \"../Experiments/sample_models/sample_fgn_model_noisy_eval_p0.27_state_dict.pth\"\n",
    "params_paths = \"../Experiments/sample_models/sample_fgn_model_noisy_eval_p0.27_parameters.txt\"\n",
    "\n",
    "print(model_path)\n",
    "# exp params\n",
    "with open(params_paths) as f: \n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedforward_FGN_net(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Dropout(p=0.03125)\n",
       "    (1): FGN_layer()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.03125)\n",
       "    (4): FGN_layer()\n",
       "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.03125)\n",
       "  )\n",
       "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fl): FGN_layer()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # full load\n",
    "fgn_model = torch.load(model_path)\n",
    "fgn_model.to(device)\n",
    "\n",
    "# dict load\n",
    "# fgn_model = fgnl.Feedforward_FGN_net(in_feats=28*28, out_feats=10, hidden_l_nums=[64,64], \n",
    "#                                      drop_p=0, noisy_centers=False).to(device)\n",
    "# fgn_model.load_state_dict(state_dict=torch.load(dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "### Loss Functions for the FGN\n",
    "fgn_cross_ent_loss = (lambda model,output,target:  F.cross_entropy(output,target.long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 0.2918, Accuracy: 54331/60000 (91%)\n",
      "Test set - Average loss: 0.3059, Accuracy: 9040/10000 (90%)\n"
     ]
    }
   ],
   "source": [
    "# set random eval to false to check \n",
    "fgn_model.set_random_eval(False)\n",
    "fgn_test_res = fgnh.test(fgn_model, mnist_train_loader,\n",
    "                        fgn_cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)\n",
    "\n",
    "fgn_test_res = fgnh.test(fgn_model, mnist_test_loader,\n",
    "                        fgn_cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 0.2914, Accuracy: 54273/60000 (90%)\n",
      "Test set - Average loss: 0.3045, Accuracy: 9034/10000 (90%)\n"
     ]
    }
   ],
   "source": [
    "# change to random eval\n",
    "fgn_model.set_random_eval(True)\n",
    "fgn_test_res = fgnh.test(fgn_model, mnist_train_loader,\n",
    "                        fgn_cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)\n",
    "\n",
    "fgn_test_res = fgnh.test(fgn_model, mnist_test_loader,\n",
    "                        fgn_cross_ent_loss, pred_func=fgnh.cross_ent_pred_accuracy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### start of tutorial code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tutorial imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "# from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import warnings\n",
    "# import numpy as np\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch import optim\n",
    "from torch.autograd import Variable\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "# from cleverhans.compat import flags\n",
    "from cleverhans.model import CallableModelWrapper\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_pytorch import convert_pytorch_model_to_tf\n",
    "\n",
    "# FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs=NB_EPOCHS\n",
    "batch_size=BATCH_SIZE,\n",
    "train_end=-1\n",
    "test_end=-1\n",
    "learning_rate=LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use tf for evaluation on adversarial data\n",
    "sess = tf.Session()\n",
    "x_op = tf.placeholder(tf.float32, shape=(None, 1, 28, 28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pytorch model to a tf_model and wrap it in cleverhans\n",
    "torch_model = fgn_model\n",
    "tf_model_fn = convert_pytorch_model_to_tf(torch_model)\n",
    "cleverhans_model = CallableModelWrapper(tf_model_fn, output_layer='logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an FGSM attack\n",
    "fgsm_op = FastGradientMethod(cleverhans_model, sess=sess)\n",
    "fgsm_params = {'eps': 0.3,\n",
    "             'clip_min': 0.,\n",
    "             'clip_max': 1.}\n",
    "adv_x_op = fgsm_op.generate(x_op, **fgsm_params)\n",
    "adv_preds_op = tf_model_fn(adv_x_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192, 1, 28, 28]) torch.Size([192]) (?, 1, 28, 28)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [] [Condition x >= y did not hold element-wise:x (Placeholder:0) = ] [[[[-0.424212962 -0.424212962 -0.424212962...]]]...] [y (Cast/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert (defined at /home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py:624)  = Assert[T=[DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](assert_greater_equal/Assert/AssertGuard/Assert/Switch, assert_greater_equal/Assert/AssertGuard/Assert/data_0, assert_greater_equal/Assert/AssertGuard/Assert/data_1, assert_greater_equal/Assert/AssertGuard/Assert/Switch_1, assert_greater_equal/Assert/AssertGuard/Assert/data_3, assert_greater_equal/Assert/AssertGuard/Assert/Switch_2/_15)]]\n\t [[{{node PyFunc/_5}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_4_PyFunc\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'assert_greater_equal/Assert/AssertGuard/Assert', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-fce5812bc824>\", line 6, in <module>\n    adv_x_op = fgsm_op.generate(x_op, **fgsm_params)\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/attacks/__init__.py\", line 353, in generate\n    sanity_checks=self.sanity_checks)\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/attacks/__init__.py\", line 448, in fgm\n    x, tf.cast(clip_min, x.dtype)))\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py\", line 624, in assert_greater_equal\n    return tf.assert_greater_equal(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/check_ops.py\", line 717, in assert_greater_equal\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 167, in Assert\n    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2097, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1930, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 165, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 52, in _assert\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [] [Condition x >= y did not hold element-wise:x (Placeholder:0) = ] [[[[-0.424212962 -0.424212962 -0.424212962...]]]...] [y (Cast/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert (defined at /home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py:624)  = Assert[T=[DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](assert_greater_equal/Assert/AssertGuard/Assert/Switch, assert_greater_equal/Assert/AssertGuard/Assert/data_0, assert_greater_equal/Assert/AssertGuard/Assert/data_1, assert_greater_equal/Assert/AssertGuard/Assert/Switch_1, assert_greater_equal/Assert/AssertGuard/Assert/data_3, assert_greater_equal/Assert/AssertGuard/Assert/Switch_2/_15)]]\n\t [[{{node PyFunc/_5}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_4_PyFunc\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-28b9eeef6d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmnist_test_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0madv_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_preds_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_op\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [] [Condition x >= y did not hold element-wise:x (Placeholder:0) = ] [[[[-0.424212962 -0.424212962 -0.424212962...]]]...] [y (Cast/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert (defined at /home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py:624)  = Assert[T=[DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](assert_greater_equal/Assert/AssertGuard/Assert/Switch, assert_greater_equal/Assert/AssertGuard/Assert/data_0, assert_greater_equal/Assert/AssertGuard/Assert/data_1, assert_greater_equal/Assert/AssertGuard/Assert/Switch_1, assert_greater_equal/Assert/AssertGuard/Assert/data_3, assert_greater_equal/Assert/AssertGuard/Assert/Switch_2/_15)]]\n\t [[{{node PyFunc/_5}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_4_PyFunc\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'assert_greater_equal/Assert/AssertGuard/Assert', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-fce5812bc824>\", line 6, in <module>\n    adv_x_op = fgsm_op.generate(x_op, **fgsm_params)\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/attacks/__init__.py\", line 353, in generate\n    sanity_checks=self.sanity_checks)\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/attacks/__init__.py\", line 448, in fgm\n    x, tf.cast(clip_min, x.dtype)))\n  File \"/home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py\", line 624, in assert_greater_equal\n    return tf.assert_greater_equal(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/check_ops.py\", line 717, in assert_greater_equal\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 167, in Assert\n    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2097, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1930, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 165, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 52, in _assert\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): assertion failed: [] [Condition x >= y did not hold element-wise:x (Placeholder:0) = ] [[[[-0.424212962 -0.424212962 -0.424212962...]]]...] [y (Cast/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert (defined at /home/felix/.local/lib/python2.7/site-packages/cleverhans/utils_tf.py:624)  = Assert[T=[DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](assert_greater_equal/Assert/AssertGuard/Assert/Switch, assert_greater_equal/Assert/AssertGuard/Assert/data_0, assert_greater_equal/Assert/AssertGuard/Assert/data_1, assert_greater_equal/Assert/AssertGuard/Assert/Switch_1, assert_greater_equal/Assert/AssertGuard/Assert/data_3, assert_greater_equal/Assert/AssertGuard/Assert/Switch_2/_15)]]\n\t [[{{node PyFunc/_5}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_4_PyFunc\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Run an evaluation of our model against fgsm\n",
    "total = 0\n",
    "correct = 0\n",
    "for xs, ys in mnist_test_loader:\n",
    "    print(xs.shape, ys.shape, x_op.shape)\n",
    "    adv_preds = sess.run(adv_preds_op, feed_dict={x_op: xs})\n",
    "    correct += (np.argmax(adv_preds, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "    total += test_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
