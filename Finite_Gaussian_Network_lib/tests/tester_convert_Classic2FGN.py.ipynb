{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for convert_Classic2FGN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_Classic2FGN import convert_Classic2FGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from Classic_MNIST_Net import Classic_MNIST_Net\n",
    "from Feedforward_FGN_net import Feedforward_FGN_net\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "# MNIST dataset and dataloader declaration\n",
    "# transforms does both the conversion from 0-255 to 0-1\n",
    "# and normalizes by the precomputed mean and std\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=True, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=False, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedforward_FGN_net(\n",
       "  (id): Dropout(p=0.0)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): FGN_layer()\n",
       "    (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fl): FGN_layer()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create models to be converted\n",
    "classic_model = Classic_MNIST_Net(hidden_l_nums=[3])\n",
    "classic_model.to(device)\n",
    "fgn_model = Feedforward_FGN_net(28*28,10,[3])\n",
    "fgn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll loss function\n",
    "def classic_nll_loss_func(model, output, target):\n",
    "    return F.nll_loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll loss function\n",
    "def fgn_nll_loss_func(model, output, target):\n",
    "#     # split output into pred and likelihoods\n",
    "#     output, likelihood = output\n",
    "    return F.nll_loss(output, target)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct pred function for classic net\n",
    "def classic_pred_func(output, target):\n",
    "    output = output\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct pred function for fgnet\n",
    "def fgn_pred_func(output, target):\n",
    "#     # split output into pred and likelihoods\n",
    "#     output,_ = output\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 2.3767, Accuracy: 1178/10000 (12%)\n",
      "Test set - Average loss: 0.1097, Accuracy: 982/10000 (10%)\n"
     ]
    }
   ],
   "source": [
    "# before conversion\n",
    "classic_test_res = test(classic_model, device, mnist_test_loader, loss_func=classic_nll_loss_func, verbose=True, pred_func=classic_pred_func)\n",
    "fgn_test_res = test(fgn_model, device, mnist_test_loader, loss_func=fgn_nll_loss_func, verbose=True, pred_func=fgn_pred_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden_layers.0.weights', tensor([[ 22.5116, -12.7173,   3.1298,  ...,   9.2547,  17.2639,   8.1681],\n",
      "        [-13.0032,   9.9939,  -5.6512,  ...,  24.4244, -27.2463,   3.4933],\n",
      "        [-13.1889,  13.6434, -21.8499,  ...,  -1.0773,   1.7977, -18.1188]],\n",
      "       device='cuda:0')), ('hidden_layers.0.centers', tensor([[-0.5512,  0.1094, -0.5906,  ..., -0.2467, -1.6058,  1.1626],\n",
      "        [-2.5823, -0.7790, -0.6558,  ...,  0.6129,  0.6411, -0.8280],\n",
      "        [-0.4470,  0.4859, -0.5332,  ...,  0.9407, -3.4504,  0.9148]],\n",
      "       device='cuda:0')), ('hidden_layers.0.sigs', tensor([9.6147, 9.6147, 9.6147], device='cuda:0')), ('hidden_layers.1.weight', tensor([0.5414, 0.1278, 0.4758], device='cuda:0')), ('hidden_layers.1.bias', tensor([0., 0., 0.], device='cuda:0')), ('hidden_layers.1.running_mean', tensor([0., 0., 0.], device='cuda:0')), ('hidden_layers.1.running_var', tensor([1., 1., 1.], device='cuda:0')), ('hidden_layers.1.num_batches_tracked', tensor(0, device='cuda:0')), ('fl.weights', tensor([[-0.3482, -0.4630, -0.3370],\n",
      "        [ 1.2937, -1.4887, -0.0441],\n",
      "        [ 0.9363, -1.1036,  1.5180],\n",
      "        [-0.7773, -0.5894,  1.4641],\n",
      "        [-0.3897,  1.0790, -1.6365],\n",
      "        [ 0.5820, -0.2513,  0.5125],\n",
      "        [ 0.0579, -0.8973, -1.5764],\n",
      "        [-0.2356, -1.6768,  0.1456],\n",
      "        [-0.8118, -0.4692,  1.7300],\n",
      "        [-1.4278,  0.9059,  1.5449]], device='cuda:0')), ('fl.centers', tensor([[-0.5538, -0.2655,  0.1548],\n",
      "        [ 0.0757, -0.1177, -1.3301],\n",
      "        [-0.0857, -2.1393, -1.7832],\n",
      "        [-0.9588,  1.6646, -0.2477],\n",
      "        [ 1.1160, -1.9162,  1.1816],\n",
      "        [ 0.5876,  0.6302,  0.0532],\n",
      "        [-0.2913, -0.6582,  0.5189],\n",
      "        [-0.1609, -0.2803, -0.8565],\n",
      "        [-1.0143,  0.3366,  0.7710],\n",
      "        [ 2.3506, -2.5369,  0.9195]], device='cuda:0')), ('fl.sigs', tensor([1.5850, 1.5850, 1.5850, 1.5850, 1.5850, 1.5850, 1.5850, 1.5850, 1.5850,\n",
      "        1.5850], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# some fgnet dict values\n",
    "print(fgn_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Feedforward_FGN_net:\n\tMissing key(s) in state_dict: \"hidden_layers.1.running_var\", \"hidden_layers.1.bias\", \"hidden_layers.1.weight\", \"hidden_layers.1.running_mean\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2663e9f91ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CONVERT CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconvert_Classic2FGN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassic_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgn_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfgn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/felix/Research/Adversarial Research/FGN---Research/torch_helper_lib/convert_Classic2FGN.pyc\u001b[0m in \u001b[0;36mconvert_Classic2FGN\u001b[0;34m(classic_model, fgn_model)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mnew_state_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_state_dict_lin2FGN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mfgn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# return nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Feedforward_FGN_net:\n\tMissing key(s) in state_dict: \"hidden_layers.1.running_var\", \"hidden_layers.1.bias\", \"hidden_layers.1.weight\", \"hidden_layers.1.running_mean\". "
     ]
    }
   ],
   "source": [
    "# CONVERT CALL\n",
    "convert_Classic2FGN(classic_model=classic_model, fgn_model=fgn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after conversion\n",
    "classic_test_res = test(classic_model, device, mnist_test_loader, loss_func=classic_nll_loss_func, verbose=True, pred_func=classic_pred_func)\n",
    "fgn_test_res = test(fgn_model, device, mnist_test_loader, loss_func=fgn_nll_loss_func, verbose=True, pred_func=fgn_pred_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some fgnet dict values (should have changed)\n",
    "print(fgn_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: results to be close to identical\n",
    "# and without needing to reload the fgn_net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
