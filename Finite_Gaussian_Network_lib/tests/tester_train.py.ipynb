{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file for train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seeds\n",
    "torch.manual_seed(665)\n",
    "np.random.seed(326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model\n",
    "# classical feed forward model with variable number of hidden layers and units per layer\n",
    "class Classic_MNIST_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(Classic_MNIST_Net, self).__init__()\n",
    "        \n",
    "        # one layer\n",
    "        in_feats=28*28\n",
    "        self.fl = nn.Linear(in_feats, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # squash the image\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fl(x)\n",
    "        # softmax\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Classic_MNIST_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader declaration\n",
    "batch_size = 10000\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/home/felix/Research/Adversarial Research/MNIST-dataset', train=True, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/home/felix/Research/Adversarial Research/MNIST-dataset', train=False, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss_func(model, output, target):\n",
    "    return F.nll_loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch number\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct pred function\n",
    "def pred_func(output, target):\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train set - Average loss: 2.0711, Accuracy: 17386/60000 (29%)\n",
      "Test set - Average loss: 1.5468, Accuracy: 5902/10000 (59%)\n",
      "Epoch 1 Train set - Average loss: 1.3447, Accuracy: 39769/60000 (66%)\n",
      "Test set - Average loss: 1.0968, Accuracy: 7441/10000 (74%)\n",
      "Epoch 2 Train set - Average loss: 1.0226, Accuracy: 45794/60000 (76%)\n",
      "Test set - Average loss: 0.8932, Accuracy: 7981/10000 (80%)\n"
     ]
    }
   ],
   "source": [
    "### test 1: run on same device\n",
    "res = fgnh.train(model, train_loader, loss_func, optimizer, epochs, save_hist=2, verbose=True, pred_func=pred_func, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Expected\n",
    "\n",
    "# Epoch 0 Train set - Average loss: 2.0711, Accuracy: 17386/60000 (29%)\n",
    "# Test set - Average loss: 1.5468, Accuracy: 5902/10000 (59%)\n",
    "# Epoch 1 Train set - Average loss: 1.3447, Accuracy: 39769/60000 (66%)\n",
    "# Test set - Average loss: 1.0968, Accuracy: 7441/10000 (74%)\n",
    "# Epoch 2 Train set - Average loss: 1.0226, Accuracy: 45794/60000 (76%)\n",
    "# Test set - Average loss: 0.8932, Accuracy: 7981/10000 (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: device specified. This might change model and optimizer location (cuda<->cpu)\n",
      "Epoch 0 Train set - Average loss: 0.8631, Accuracy: 48105/60000 (80%)\n",
      "Warning: device specified. This might change model location (cuda<->cpu)\n",
      "Test set - Average loss: 0.7783, Accuracy: 8226/10000 (82%)\n",
      "Epoch 1 Train set - Average loss: 0.7674, Accuracy: 49345/60000 (82%)\n",
      "Warning: device specified. This might change model location (cuda<->cpu)\n",
      "Test set - Average loss: 0.7038, Accuracy: 8377/10000 (84%)\n",
      "Epoch 2 Train set - Average loss: 0.7030, Accuracy: 50126/60000 (84%)\n",
      "Warning: device specified. This might change model location (cuda<->cpu)\n",
      "Test set - Average loss: 0.6513, Accuracy: 8479/10000 (85%)\n"
     ]
    }
   ],
   "source": [
    "### test 2 :run on cpu instead of cuda\n",
    "res = fgnh.train(model, train_loader, loss_func, optimizer, epochs, save_hist=2, verbose=True, pred_func=pred_func, test_loader=test_loader, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Expected\n",
    "\n",
    "# Warning: device specified. This might change model location (cuda<->cpu)\n",
    "# Epoch 0 Train set - Average loss: 0.8631, Accuracy: 48105/60000 (80%)\n",
    "# Warning: device specified. This might change model location (cuda<->cpu)\n",
    "# Test set - Average loss: 0.7782, Accuracy: 8226/10000 (82%)\n",
    "# Epoch 1 Train set - Average loss: 0.7674, Accuracy: 49345/60000 (82%)\n",
    "# Warning: device specified. This might change model location (cuda<->cpu)\n",
    "# Test set - Average loss: 0.7038, Accuracy: 8377/10000 (84%)\n",
    "# Epoch 2 Train set - Average loss: 0.7030, Accuracy: 50126/60000 (84%)\n",
    "# Warning: device specified. This might change model location (cuda<->cpu)\n",
    "# Test set - Average loss: 0.6513, Accuracy: 8479/10000 (85%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['train_loss_hist', 'train_acc_hist', 'test_loss_hist', 'test_acc_hist', 'histories']\n"
     ]
    }
   ],
   "source": [
    "print(len(res))\n",
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist = res['train_loss_hist']\n",
    "print(len(train_loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "train_acc_hist = res['train_acc_hist']\n",
    "print(len(train_acc_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl.bias\n",
      "(19, 10)\n",
      "fl.weight\n",
      "(19, 10, 784)\n"
     ]
    }
   ],
   "source": [
    "histories = res['histories']\n",
    "for k in histories.keys():\n",
    "    print(k)\n",
    "    print(np.shape(histories[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fl.bias': array([[ 0.0317583 , -0.00306912,  0.00918836,  0.006821  ,  0.0169086 ,\n",
      "         0.00161701,  0.01314674,  0.00244241, -0.00876717, -0.02979792],\n",
      "       [ 0.03169271, -0.00306558,  0.00917751,  0.00681374,  0.01689558,\n",
      "         0.0017463 ,  0.01312565,  0.00254749, -0.00887485, -0.02981035],\n",
      "       [ 0.03164063, -0.00301919,  0.00917185,  0.00675552,  0.01692882,\n",
      "         0.00192847,  0.01309301,  0.00261771, -0.00901529, -0.02985333],\n",
      "       [ 0.03160081, -0.00297409,  0.00916784,  0.00670845,  0.01696748,\n",
      "         0.00212249,  0.01306231,  0.00269219, -0.0091623 , -0.02993697],\n",
      "       [ 0.03158792, -0.00299298,  0.00921473,  0.00666074,  0.01697877,\n",
      "         0.00227977,  0.01305747,  0.00274772, -0.00927933, -0.03000659],\n",
      "       [ 0.03155868, -0.00301797,  0.00926989,  0.00665513,  0.01696343,\n",
      "         0.00239735,  0.01303432,  0.00284923, -0.00940312, -0.03005874],\n",
      "       [ 0.03156726, -0.0030394 ,  0.00931849,  0.00665033,  0.01695803,\n",
      "         0.00251349,  0.01299941,  0.00291684, -0.00951009, -0.03012616],\n",
      "       [ 0.03156338, -0.00305229,  0.00935068,  0.00665324,  0.01694838,\n",
      "         0.00262779,  0.01296424,  0.00300088, -0.00962061, -0.03018747],\n",
      "       [ 0.03154842, -0.00304772,  0.00936692,  0.00661394,  0.01692975,\n",
      "         0.00274667,  0.01294731,  0.00307006, -0.00971752, -0.03020962],\n",
      "       [ 0.0315061 , -0.00303468,  0.00935065,  0.00659341,  0.01697835,\n",
      "         0.00287742,  0.01291875,  0.00312745, -0.00981106, -0.03025818],\n",
      "       [ 0.03148526, -0.00303961,  0.00934593,  0.00659364,  0.01695795,\n",
      "         0.00298199,  0.01290194,  0.00320101, -0.00988235, -0.03029756],\n",
      "       [ 0.03144568, -0.0030544 ,  0.00936549,  0.00657824,  0.01692879,\n",
      "         0.0031133 ,  0.01292681,  0.00326856, -0.00997129, -0.03035296],\n",
      "       [ 0.03141832, -0.00306858,  0.00940121,  0.00656269,  0.01690526,\n",
      "         0.00328245,  0.01290004,  0.00334009, -0.01006637, -0.03042688],\n",
      "       [ 0.03137737, -0.0030847 ,  0.00943903,  0.00650129,  0.01685603,\n",
      "         0.00345934,  0.0128796 ,  0.00342903, -0.0101368 , -0.03047198],\n",
      "       [ 0.03134366, -0.00308979,  0.0094732 ,  0.00645276,  0.01683635,\n",
      "         0.00359652,  0.01285537,  0.00350935, -0.01022709, -0.03050212],\n",
      "       [ 0.03132072, -0.00308222,  0.00950977,  0.00642632,  0.01685658,\n",
      "         0.00370408,  0.01284076,  0.00355569, -0.01032062, -0.03056287],\n",
      "       [ 0.0313307 , -0.00308388,  0.00954992,  0.00644277,  0.01688461,\n",
      "         0.00377405,  0.0128127 ,  0.00358326, -0.01041259, -0.03063334],\n",
      "       [ 0.03133314, -0.00310814,  0.00953834,  0.00648684,  0.01686492,\n",
      "         0.00387385,  0.01280858,  0.00363231, -0.01050922, -0.03067241],\n",
      "       [ 0.03132744, -0.00312061,  0.00951506,  0.00653627,  0.01685102,\n",
      "         0.0039609 ,  0.0128044 ,  0.00369232, -0.01059169, -0.03072691]],\n",
      "      dtype=float32), 'fl.weight': array([[[-0.0269651 ,  0.01795503, -0.01738468, ...,  0.00805861,\n",
      "         -0.0257817 , -0.03346497],\n",
      "        [ 0.00992633,  0.02499002,  0.00231849, ...,  0.02847031,\n",
      "         -0.01568423, -0.01541279],\n",
      "        [ 0.0047365 ,  0.02722993, -0.01725454, ..., -0.01441996,\n",
      "         -0.02886991,  0.02304127],\n",
      "        ...,\n",
      "        [-0.02272519, -0.02736211,  0.02638081, ..., -0.02318391,\n",
      "         -0.01140144,  0.03451377],\n",
      "        [ 0.02698973, -0.03022965, -0.00040812, ...,  0.02894087,\n",
      "         -0.00703943,  0.02676886],\n",
      "        [ 0.0140695 ,  0.00637808, -0.00210427, ..., -0.02248027,\n",
      "         -0.00335751,  0.02665576]],\n",
      "\n",
      "       [[-0.02693727,  0.01798285, -0.01735685, ...,  0.00808643,\n",
      "         -0.02575388, -0.03343715],\n",
      "        [ 0.00992483,  0.02498852,  0.00231699, ...,  0.02846881,\n",
      "         -0.01568573, -0.01541429],\n",
      "        [ 0.0047411 ,  0.02723453, -0.01724994, ..., -0.01441535,\n",
      "         -0.02886531,  0.02304587],\n",
      "        ...,\n",
      "        [-0.02276976, -0.02740668,  0.02633623, ..., -0.02322849,\n",
      "         -0.01144602,  0.03446919],\n",
      "        [ 0.02703541, -0.03018397, -0.00036244, ...,  0.02898655,\n",
      "         -0.00699375,  0.02681454],\n",
      "        [ 0.01407477,  0.00638335, -0.00209901, ..., -0.022475  ,\n",
      "         -0.00335225,  0.02666103]],\n",
      "\n",
      "       [[-0.02691518,  0.01800495, -0.01733476, ...,  0.00810852,\n",
      "         -0.02573179, -0.03341505],\n",
      "        [ 0.00990515,  0.02496884,  0.00229731, ...,  0.02844913,\n",
      "         -0.01570541, -0.01543397],\n",
      "        [ 0.0047435 ,  0.02723693, -0.01724754, ..., -0.01441295,\n",
      "         -0.02886291,  0.02304827],\n",
      "        ...,\n",
      "        [-0.02279955, -0.02743647,  0.02630644, ..., -0.02325827,\n",
      "         -0.01147581,  0.03443941],\n",
      "        [ 0.02709499, -0.03012439, -0.00030286, ...,  0.02904613,\n",
      "         -0.00693417,  0.02687412],\n",
      "        [ 0.014093  ,  0.00640159, -0.00208077, ..., -0.02245677,\n",
      "         -0.00333401,  0.02667927]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0267837 ,  0.01813642, -0.01720328, ...,  0.00824   ,\n",
      "         -0.02560031, -0.03328357],\n",
      "        [ 0.00993259,  0.02499628,  0.00232475, ...,  0.02847657,\n",
      "         -0.01567797, -0.01540652],\n",
      "        [ 0.00458312,  0.02707655, -0.01740792, ..., -0.01457334,\n",
      "         -0.02902329,  0.02288789],\n",
      "        ...,\n",
      "        [-0.02320915, -0.02784607,  0.02589684, ..., -0.02366787,\n",
      "         -0.01188541,  0.03402981],\n",
      "        [ 0.02768774, -0.02953164,  0.00028989, ...,  0.02963888,\n",
      "         -0.00634142,  0.02746687],\n",
      "        [ 0.01442389,  0.00673248, -0.00174988, ..., -0.02212588,\n",
      "         -0.00300312,  0.02701016]],\n",
      "\n",
      "       [[-0.02678474,  0.01813539, -0.01720432, ...,  0.00823896,\n",
      "         -0.02560134, -0.03328461],\n",
      "        [ 0.00994288,  0.02500657,  0.00233504, ...,  0.02848686,\n",
      "         -0.01566768, -0.01539623],\n",
      "        [ 0.00458803,  0.02708146, -0.01740301, ..., -0.01456842,\n",
      "         -0.02901838,  0.0228928 ],\n",
      "        ...,\n",
      "        [-0.02322996, -0.02786688,  0.02587604, ..., -0.02368868,\n",
      "         -0.01190621,  0.03400901],\n",
      "        [ 0.02772873, -0.02949065,  0.00033088, ...,  0.02967988,\n",
      "         -0.00630043,  0.02750786],\n",
      "        [ 0.01444047,  0.00674905, -0.00173331, ..., -0.02210931,\n",
      "         -0.00298655,  0.02702673]],\n",
      "\n",
      "       [[-0.02678232,  0.01813781, -0.0172019 , ...,  0.00824138,\n",
      "         -0.02559893, -0.03328219],\n",
      "        [ 0.00994817,  0.02501186,  0.00234034, ...,  0.02849215,\n",
      "         -0.01566239, -0.01539094],\n",
      "        [ 0.00459791,  0.02709134, -0.01739313, ..., -0.01455855,\n",
      "         -0.0290085 ,  0.02290268],\n",
      "        ...,\n",
      "        [-0.02325542, -0.02789233,  0.02585058, ..., -0.02371414,\n",
      "         -0.01193167,  0.03398355],\n",
      "        [ 0.02776372, -0.02945566,  0.00036586, ...,  0.02971486,\n",
      "         -0.00626545,  0.02754284],\n",
      "        [ 0.01446358,  0.00677217, -0.00171019, ..., -0.02208619,\n",
      "         -0.00296343,  0.02704985]]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Expected ? may be hard to get exact same numbers\n",
    "# {'fl.bias': array([[ 0.0317583 , -0.00306912,  0.00918836,  0.006821  ,  0.0169086 ,\n",
    "#          0.00161701,  0.01314674,  0.00244241, -0.00876717, -0.02979792],\n",
    "#        [ 0.03169271, -0.00306558,  0.00917751,  0.00681374,  0.01689558,\n",
    "#          0.0017463 ,  0.01312565,  0.00254749, -0.00887485, -0.02981035],\n",
    "#        [ 0.03164063, -0.00301919,  0.00917185,  0.00675552,  0.01692882,\n",
    "#          0.00192847,  0.01309301,  0.00261771, -0.00901529, -0.02985333],\n",
    "#        [ 0.03160081, -0.00297409,  0.00916784,  0.00670845,  0.01696748,\n",
    "#          0.00212249,  0.01306231,  0.00269219, -0.0091623 , -0.02993697],\n",
    "#        [ 0.03158792, -0.00299298,  0.00921473,  0.00666074,  0.01697877,\n",
    "#          0.00227977,  0.01305747,  0.00274772, -0.00927933, -0.03000659],\n",
    "#        [ 0.03155868, -0.00301797,  0.00926989,  0.00665513,  0.01696342,\n",
    "#          0.00239735,  0.01303432,  0.00284923, -0.00940312, -0.03005874],\n",
    "#        [ 0.03156726, -0.0030394 ,  0.00931849,  0.00665033,  0.01695803,\n",
    "#          0.00251349,  0.01299941,  0.00291684, -0.00951009, -0.03012616],\n",
    "#        [ 0.03156338, -0.00305229,  0.00935068,  0.00665324,  0.01694838,\n",
    "#          0.00262779,  0.01296424,  0.00300088, -0.00962061, -0.03018747],\n",
    "#        [ 0.03154842, -0.00304772,  0.00936692,  0.00661394,  0.01692975,\n",
    "#          0.00274667,  0.01294731,  0.00307006, -0.00971752, -0.03020962],\n",
    "#        [ 0.0315061 , -0.00303468,  0.00935065,  0.00659341,  0.01697835,\n",
    "#          0.00287742,  0.01291875,  0.00312745, -0.00981106, -0.03025818],\n",
    "#        [ 0.03148526, -0.00303961,  0.00934593,  0.00659364,  0.01695795,\n",
    "#          0.00298199,  0.01290194,  0.00320101, -0.00988235, -0.03029756],\n",
    "#        [ 0.03144568, -0.0030544 ,  0.00936549,  0.00657824,  0.01692879,\n",
    "#          0.0031133 ,  0.01292681,  0.00326856, -0.00997129, -0.03035296],\n",
    "#        [ 0.03141832, -0.00306858,  0.00940121,  0.00656269,  0.01690525,\n",
    "#          0.00328245,  0.01290004,  0.00334009, -0.01006637, -0.03042688],\n",
    "#        [ 0.03137737, -0.0030847 ,  0.00943903,  0.00650129,  0.01685603,\n",
    "#          0.00345934,  0.0128796 ,  0.00342903, -0.0101368 , -0.03047198],\n",
    "#        [ 0.03134366, -0.00308979,  0.0094732 ,  0.00645276,  0.01683635,\n",
    "#          0.00359652,  0.01285537,  0.00350935, -0.01022709, -0.03050212],\n",
    "#        [ 0.03132072, -0.00308222,  0.00950977,  0.00642632,  0.01685657,\n",
    "#          0.00370408,  0.01284076,  0.00355569, -0.01032062, -0.03056287],\n",
    "#        [ 0.0313307 , -0.00308388,  0.00954992,  0.00644277,  0.01688461,\n",
    "#          0.00377405,  0.0128127 ,  0.00358326, -0.01041259, -0.03063334],\n",
    "#        [ 0.03133314, -0.00310814,  0.00953834,  0.00648684,  0.01686492,\n",
    "#          0.00387385,  0.01280858,  0.00363231, -0.01050922, -0.03067241],\n",
    "#        [ 0.03132744, -0.00312061,  0.00951506,  0.00653627,  0.01685102,\n",
    "#          0.0039609 ,  0.0128044 ,  0.00369232, -0.01059169, -0.03072691]],\n",
    "#       dtype=float32), 'fl.weight': array([[[-0.0269651 ,  0.01795503, -0.01738468, ...,  0.00805861,\n",
    "#          -0.0257817 , -0.03346497],\n",
    "#         [ 0.00992633,  0.02499002,  0.00231849, ...,  0.02847031,\n",
    "#          -0.01568423, -0.01541279],\n",
    "#         [ 0.0047365 ,  0.02722993, -0.01725454, ..., -0.01441996,\n",
    "#          -0.02886991,  0.02304127],\n",
    "#         ...,\n",
    "#         [-0.02272519, -0.02736211,  0.02638081, ..., -0.02318391,\n",
    "#          -0.01140144,  0.03451377],\n",
    "#         [ 0.02698973, -0.03022965, -0.00040812, ...,  0.02894087,\n",
    "#          -0.00703943,  0.02676886],\n",
    "#         [ 0.0140695 ,  0.00637808, -0.00210427, ..., -0.02248027,\n",
    "#          -0.00335751,  0.02665576]],\n",
    "\n",
    "#        [[-0.02693727,  0.01798285, -0.01735685, ...,  0.00808643,\n",
    "#          -0.02575388, -0.03343715],\n",
    "#         [ 0.00992483,  0.02498852,  0.00231699, ...,  0.02846881,\n",
    "#          -0.01568573, -0.01541429],\n",
    "#         [ 0.0047411 ,  0.02723453, -0.01724994, ..., -0.01441535,\n",
    "#          -0.02886531,  0.02304587],\n",
    "#         ...,\n",
    "#         [-0.02276976, -0.02740668,  0.02633623, ..., -0.02322849,\n",
    "#          -0.01144602,  0.03446919],\n",
    "#         [ 0.02703541, -0.03018397, -0.00036244, ...,  0.02898655,\n",
    "#          -0.00699375,  0.02681454],\n",
    "#         [ 0.01407477,  0.00638335, -0.00209901, ..., -0.022475  ,\n",
    "#          -0.00335225,  0.02666103]],\n",
    "\n",
    "#        [[-0.02691518,  0.01800495, -0.01733476, ...,  0.00810852,\n",
    "#          -0.02573179, -0.03341505],\n",
    "#         [ 0.00990515,  0.02496884,  0.00229731, ...,  0.02844913,\n",
    "#          -0.01570541, -0.01543397],\n",
    "#         [ 0.0047435 ,  0.02723693, -0.01724754, ..., -0.01441295,\n",
    "#          -0.02886291,  0.02304827],\n",
    "#         ...,\n",
    "#         [-0.02279955, -0.02743647,  0.02630644, ..., -0.02325827,\n",
    "#          -0.01147581,  0.03443941],\n",
    "#         [ 0.02709499, -0.03012439, -0.00030286, ...,  0.02904613,\n",
    "#          -0.00693417,  0.02687412],\n",
    "#         [ 0.014093  ,  0.00640159, -0.00208077, ..., -0.02245677,\n",
    "#          -0.00333401,  0.02667927]],\n",
    "\n",
    "#        ...,\n",
    "\n",
    "#        [[-0.0267837 ,  0.01813642, -0.01720328, ...,  0.00824   ,\n",
    "#          -0.02560031, -0.03328357],\n",
    "#         [ 0.00993259,  0.02499628,  0.00232475, ...,  0.02847657,\n",
    "#          -0.01567797, -0.01540652],\n",
    "#         [ 0.00458312,  0.02707655, -0.01740792, ..., -0.01457334,\n",
    "#          -0.02902329,  0.02288789],\n",
    "#         ...,\n",
    "#         [-0.02320915, -0.02784607,  0.02589684, ..., -0.02366787,\n",
    "#          -0.01188541,  0.03402981],\n",
    "#         [ 0.02768774, -0.02953164,  0.00028989, ...,  0.02963888,\n",
    "#          -0.00634142,  0.02746687],\n",
    "#         [ 0.01442389,  0.00673248, -0.00174988, ..., -0.02212588,\n",
    "#          -0.00300312,  0.02701016]],\n",
    "\n",
    "#        [[-0.02678474,  0.01813539, -0.01720432, ...,  0.00823896,\n",
    "#          -0.02560134, -0.03328461],\n",
    "#         [ 0.00994288,  0.02500657,  0.00233504, ...,  0.02848686,\n",
    "#          -0.01566768, -0.01539623],\n",
    "#         [ 0.00458803,  0.02708146, -0.01740301, ..., -0.01456842,\n",
    "#          -0.02901838,  0.0228928 ],\n",
    "#         ...,\n",
    "#         [-0.02322996, -0.02786688,  0.02587604, ..., -0.02368868,\n",
    "#          -0.01190621,  0.03400901],\n",
    "#         [ 0.02772873, -0.02949065,  0.00033088, ...,  0.02967988,\n",
    "#          -0.00630043,  0.02750786],\n",
    "#         [ 0.01444047,  0.00674905, -0.00173331, ..., -0.02210931,\n",
    "#          -0.00298655,  0.02702673]],\n",
    "\n",
    "#        [[-0.02678232,  0.01813781, -0.0172019 , ...,  0.00824138,\n",
    "#          -0.02559893, -0.03328219],\n",
    "#         [ 0.00994817,  0.02501186,  0.00234034, ...,  0.02849215,\n",
    "#          -0.01566239, -0.01539094],\n",
    "#         [ 0.00459791,  0.02709134, -0.01739313, ..., -0.01455855,\n",
    "#          -0.0290085 ,  0.02290268],\n",
    "#         ...,\n",
    "#         [-0.02325542, -0.02789233,  0.02585058, ..., -0.02371414,\n",
    "#          -0.01193167,  0.03398355],\n",
    "#         [ 0.02776372, -0.02945566,  0.00036586, ...,  0.02971486,\n",
    "#          -0.00626545,  0.02754284],\n",
    "#         [ 0.01446358,  0.00677217, -0.00171019, ..., -0.02208619,\n",
    "#          -0.00296343,  0.02704985]]], dtype=float32)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
