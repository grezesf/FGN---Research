{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: Exp-00_description.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# the experiment description\n",
    "!cat Exp-00_description.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import GPUtil\n",
    "\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/felix/Research/Adversarial Research/FGN---Research/')\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4474ca80e67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdrop_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlmbda_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Adam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mopt_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist_train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# where to save results\n",
    "\n",
    "save_dir = \"/home/felix/Research/Adversarial Research/FGN---Research/Experiments/folder for dev/\"\n",
    "\n",
    "# fixed experiment parameters\n",
    "num_iter = 3\n",
    "batch_size = 32\n",
    "# (mnist_train_loader, mnist_val_loader, mnist_test_loader) = fgnh.mnist_dataloaders(batch_size=batch_size)\n",
    "in_feats = 28*28\n",
    "out_feats = 10\n",
    "num_epochs = 5\n",
    "drop_p = 0.0\n",
    "lmbda_l2 = (4.0*0.1/len(mnist_train_loader.dataset))\n",
    "optimizer = 'Adam'\n",
    "opt_lr = 0.001\n",
    "\n",
    "with open(save_dir+\"shared_parameters.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"Shared parameters between Classic and FGN feedforward networks training.\\n\")\n",
    "    text_file.write(\"batch_size {}\\n\".format(str(batch_size)))\n",
    "    text_file.write(\"num_epochs {}\\n\".format(str(num_epochs)))\n",
    "    text_file.write(\"drop_p {}\\n\".format(str(drop_p)))\n",
    "    text_file.write(\"lmbda_l2 {}\\n\".format(str(lmbda_l2)))\n",
    "    text_file.write(\"optimizer {}\\n\".format(optimizer))\n",
    "    text_file.write(\"opt_lr {}\\n\".format(opt_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to explore\n",
    "# width of the network\n",
    "hidden_layer_sizes_to_try = [64]\n",
    "# depth of the network\n",
    "number_of_hidden_layers_to_try = [2]\n",
    "# covariance type\n",
    "covar_types_to_try = ['sphere', 'diag']\n",
    "# various loss sigmas to try times lmbda_l2\n",
    "lmbda_sigma_to_try = [0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obviously try both classic and FGN\n",
    "network_types_to_try = ['classic', 'fgn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list with a bunch of dicts which represent the kwargs for an experiment\n",
    "exp_params_to_try = []\n",
    "\n",
    "\n",
    "# define the width and depth of network to try\n",
    "hidden_layer_params_to_try = []\n",
    "\n",
    "# # add the network with no hidden layers\n",
    "# hidden_layer_params_to_try.append([])\n",
    "\n",
    "for (num_layers, layer_sizes) in itertools.product(number_of_hidden_layers_to_try, hidden_layer_sizes_to_try):\n",
    "    hidden_layer_params_to_try.append([layer_sizes for _ in range(num_layers)])\n",
    "\n",
    "random.shuffle(hidden_layer_params_to_try)\n",
    "\n",
    "hidden_layer_params_to_try = list(itertools.product(hidden_layer_params_to_try, network_types_to_try))\n",
    "# print(\"hidden_layer_params_to_try\")\n",
    "# for x in hidden_layer_params_to_try:\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "\n",
    "fgn_params_to_try = list(itertools.product(lmbda_sigma_to_try, covar_types_to_try))\n",
    "# print(\"fgn_params_to_try\")\n",
    "# for x in fgn_params_to_try:\n",
    "#     print(x)          \n",
    "\n",
    "\n",
    "# hidden_layer_params_to_try.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define all the experiments to run\n",
    "for (ite, exp_p) in itertools.product(range(num_iter), hidden_layer_params_to_try):\n",
    "    hidden_layer_sizes, network_type = exp_p\n",
    "\n",
    "    if network_type == 'classic':\n",
    "            kwargs = {'hidden_layer_sizes':hidden_layer_sizes,\n",
    "                      'network_type':network_type,\n",
    "                      'ite':ite                \n",
    "            }\n",
    "            # add to exp to try\n",
    "            exp_params_to_try.append(kwargs)\n",
    "\n",
    "    elif network_type == 'fgn':\n",
    "        for (lmbda_sigs, covar_type) in fgn_params_to_try:\n",
    "            kwargs = {'hidden_layer_sizes':hidden_layer_sizes,\n",
    "                      'network_type':network_type,\n",
    "                      'ite':ite,\n",
    "                      'lmbda_sigs':lmbda_sigs,\n",
    "                      'covar_type':covar_type\n",
    "            }\n",
    "            # add to exp to try\n",
    "            exp_params_to_try.append(kwargs)\n",
    "\n",
    "    else:\n",
    "        # error\n",
    "        print(\"Error, wrong network type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'ite': 0, 'network_type': 'classic', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.01, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.01, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.1, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.1, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.5, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 0.5, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 1.0, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 1.0, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 2.0, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 2.0, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 10.0, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 10.0, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 100.0, 'covar_type': 'sphere', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "0 {'lmbda_sigs': 100.0, 'covar_type': 'diag', 'ite': 0, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'ite': 1, 'network_type': 'classic', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.01, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.01, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.1, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.1, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.5, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 0.5, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 1.0, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 1.0, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 2.0, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 2.0, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 10.0, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 10.0, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 100.0, 'covar_type': 'sphere', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "1 {'lmbda_sigs': 100.0, 'covar_type': 'diag', 'ite': 1, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'ite': 2, 'network_type': 'classic', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.01, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.01, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.1, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.1, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.5, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 0.5, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 1.0, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 1.0, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 2.0, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 2.0, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 10.0, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 10.0, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 100.0, 'covar_type': 'sphere', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n",
      "2 {'lmbda_sigs': 100.0, 'covar_type': 'diag', 'ite': 2, 'network_type': 'fgn', 'hidden_layer_sizes': [64, 64]}\n"
     ]
    }
   ],
   "source": [
    "for p in exp_params_to_try:\n",
    "    print(p['ite'], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_loss_name_from_kwargs(**kwargs):\n",
    "    \n",
    "    # given a bunch of kwargs that define an experiment to run, creates and returns the mode, loss and name\n",
    "    \n",
    "    # list of used kwargs \n",
    "    # for both network definitions\n",
    "    network_type = kwargs['network_type']\n",
    "    in_feats = kwargs['in_feats']\n",
    "    out_feats = kwargs['out_feats']\n",
    "    hidden_layer_sizes = kwargs['hidden_layer_sizes']\n",
    "    lmbda_l2 = kwargs['lmbda_l2']\n",
    "    \n",
    "    # for fgns\n",
    "    if network_type=='fgn':\n",
    "        lmbda_sigs = kwargs['lmbda_sigs']*lmbda_l2\n",
    "        covar_type = kwargs['covar_type']\n",
    "    \n",
    "    # used by both\n",
    "    timestamp = kwargs['timestamp']\n",
    "    ite = kwargs['ite']\n",
    "\n",
    "    if network_type=='classic':\n",
    "        model = fgnl.Feedforward_Classic_net(in_feats=in_feats, out_feats=out_feats, hidden_layer_sizes=hidden_layer_sizes)\n",
    "        loss  = fgnh.def_classical_cross_ent_loss(lmbda_l2=lmbda_l2)\n",
    "        name = \"_\".join((str(timestamp), str(hidden_layer_sizes), network_type, str(ite)))\n",
    "\n",
    "    elif network_type == 'fgn':\n",
    "        model = fgnl.Feedforward_FGN_net(in_feats=in_feats, out_feats=out_feats, hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                         covar_type=covar_type)\n",
    "        loss = fgnl.def_fgn_cross_ent_loss(lmbda_l2=lmbda_l2, lmbda_sigs=lmbda_sigs*lmbda_l2)\n",
    "        name = \"_\".join((str(timestamp), str(hidden_layer_sizes), network_type, covar_type, 'lsig{:.4E}'.format(lmbda_sigs), str(ite)))\n",
    "\n",
    "    \n",
    "    return model, loss, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ite': 0, 'network_type': 'classic', 'hidden_layer_sizes': [64, 64]}\n",
      "2019-09-18 22:25:20.684342\n",
      "Model name: 2019-09-18 22:25:20.684342_[64, 64]_classic_0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not find an available GPU after 1 attempts with 900 seconds interval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ca6774a355f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# get free device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFirstAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxLoad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxMemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# send to least used GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felix/.local/lib/python2.7/site-packages/GPUtil/GPUtil.pyc\u001b[0m in \u001b[0;36mgetFirstAvailable\u001b[0;34m(order, maxLoad, maxMemory, attempts, interval, verbose, includeNan, excludeID, excludeUUID)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Check if an GPU was found, or if the attempts simply ran out. Throw error, if no GPU was found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find an available GPU after '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' attempts with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' seconds interval.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# Return found GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not find an available GPU after 1 attempts with 900 seconds interval."
     ]
    }
   ],
   "source": [
    "for kwargs in exp_params_to_try:\n",
    "    print(kwargs)\n",
    "    timestamp = datetime.now()\n",
    "    print(str(timestamp))\n",
    "\n",
    "    # define model from kwargs\n",
    "    model, loss, model_name = define_model_loss_name_from_kwargs(in_feats=28*28, out_feats=10, timestamp=timestamp, \n",
    "                                                                 lmbda_l2=lmbda_l2, **kwargs)\n",
    "    print(\"Model name:\", model_name)\n",
    "    \n",
    "    # save parameters\n",
    "    with open(save_dir+model_name+\"_parameters.txt\", \"w\") as text_file:\n",
    "        for key in kwargs.keys():\n",
    "            if key != 'ite':\n",
    "                text_file.write(\"{} {}\\n\".format(key, kwargs[key]))\n",
    "\n",
    "    # attempt to sent to GPU\n",
    "    model_sent_to_device = False\n",
    "    while not model_sent_to_device:\n",
    "        # get free device\n",
    "        device = torch.device('cuda')\n",
    "        device_id = GPUtil.getFirstAvailable(order='memory', maxLoad=1.0, maxMemory=0.8, verbose=False)[0]\n",
    "\n",
    "        # send to least used GPU\n",
    "        print(\"Using GPU:\", device_id)\n",
    "        with torch.cuda.device(device_id):\n",
    "            # send to device\n",
    "            try:\n",
    "                model.to(device)\n",
    "                model_sent_to_device=True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Not enough ram. Wait 30s and continue\")\n",
    "                time.sleep(30)\n",
    "    \n",
    "    # optimize every params that require grad\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    \n",
    "    print(model)\n",
    "\n",
    "    # train model\n",
    "    try:\n",
    "        pass\n",
    "        # save results pre-training\n",
    "        print(\"Saving initial (before training) model {} in {}\".format(model_name, save_dir))\n",
    "\n",
    "        # save model entirely\n",
    "        torch.save(model, save_dir+model_name+\"_init_params_full.pth\")\n",
    "\n",
    "        # save model weights\n",
    "        torch.save(model.state_dict(), save_dir+model_name+\"_init_params_state_dict.pth\")\n",
    "        \n",
    "        print(\"Training\")\n",
    "        train_res = fgnh.train(model=model, train_loader=mnist_train_loader, loss_func=loss, \n",
    "                               optimizer=optimizer, epochs=num_epochs, save_hist=2, \n",
    "                               pred_func=fgnh.cross_ent_pred_accuracy, test_loader=mnist_val_loader, \n",
    "                               verbose=True) \n",
    "        \n",
    "        # save trained model\n",
    "        print(\"Saving trained model {} in {}\".format(model_name, save_dir))\n",
    "\n",
    "        # save model entirely\n",
    "        torch.save(model, save_dir+model_name+\"_trained_params_full.pth\")\n",
    "\n",
    "        # save model weights\n",
    "        torch.save(model.state_dict(), save_dir+model_name+\"_trained_params_state_dict.pth\")\n",
    "        \n",
    "        # save training histories as pickle\n",
    "        with open(run_dir+converted_model_path.replace(\"_full.pth\", \"_training_history.pckl\"),\"wb\") as pickle_file:\n",
    "            pickle.dump(converted_train_res,pickle_file)\n",
    "            \n",
    "        #  (old) save training histories as text\n",
    "        with open(save_dir+model_name+\"_training_history.txt\", \"w\") as text_file:\n",
    "            for key in train_res.keys():\n",
    "                text_file.write(\"{} {}\\n\".format(key, train_res[key]))\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Training failed. Moving on to next exp\" )\n",
    "        \n",
    "#     # clean up GPU space?\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to run \n",
    "stdbuf -o 0 python Exp-00-run.py 2>&1 | tee Exp-00-log-2019-09-13-00:56.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
