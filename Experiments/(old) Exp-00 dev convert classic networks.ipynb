{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev of code to convert classic networks and adjust sigmas for a run of exp 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/felix/Research/Adversarial Research/FGN---Research/\")\n",
    "import Finite_Gaussian_Network_lib as fgnl\n",
    "import Finite_Gaussian_Network_lib.fgn_helper_lib as fgnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcrescent\u001b[0m  Mon Sep 30 16:18:56 2019\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[1;31m 56'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 5906\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30mrichardso21\u001b[0m(\u001b[0;33m151M\u001b[0m) \u001b[1;30menis\u001b[0m(\u001b[0;33m5743M\u001b[0m)\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[1;31m 66'C\u001b[0m, \u001b[0;32m 23 %\u001b[0m | \u001b[0;36m\u001b[1;33m 6825\u001b[0m / \u001b[0;33m 8119\u001b[0m MB | \u001b[1;30msoumi\u001b[0m(\u001b[0;33m1343M\u001b[0m) \u001b[1;30mrichardso21\u001b[0m(\u001b[0;33m483M\u001b[0m) \u001b[1;30mvietanh\u001b[0m(\u001b[0;33m593M\u001b[0m) \u001b[1;30mnear\u001b[0m(\u001b[0;33m2269M\u001b[0m) \u001b[1;30menis\u001b[0m(\u001b[0;33m113M\u001b[0m) \u001b[1;30msoumi\u001b[0m(\u001b[0;33m1125M\u001b[0m) \u001b[1;30mfelix\u001b[0m(\u001b[0;33m887M\u001b[0m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# manualy set cuda device\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "batch_size = 1250\n",
    "(mnist_train_loader, mnist_val_loader, mnist_test_loader) = fgnh.mnist_dataloaders(batch_size)\n",
    "\n",
    "lmbda_l2 = (4.0*0.1/len(mnist_train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00_train_models-run2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of all the networks to convert\n",
    "classic_models_list = []\n",
    "\n",
    "for filename in os.listdir(run_dir):\n",
    "    if (\"classic\" in filename) and (\"_full.pth\" in filename) and (\"trained\" in filename):\n",
    "        classic_models_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-09-17 18:32:55.812514_[32, 32]_classic_1_trained_weights_full.pth', '2019-09-17 16:42:14.934314_[32, 32]_classic_0_trained_weights_full.pth', '2019-09-17 21:49:37.914325_[32, 32]_classic_2_trained_weights_full.pth']\n"
     ]
    }
   ],
   "source": [
    "print(classic_models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_p: 0.0\n"
     ]
    }
   ],
   "source": [
    "# get the shared run params\n",
    "\n",
    "with open(run_dir+\"shared_parameters.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        l = line.split(\" \")\n",
    "        if l[0] == \"drop_p\":\n",
    "            drop_p=float(l[1])\n",
    "        \n",
    "print(\"drop_p:\", drop_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get general fgn params\n",
    "covar_type = \"diag\"\n",
    "ordinal = float(2)\n",
    "non_lin = False\n",
    "noisy_centers = False\n",
    "random_eval = False\n",
    "\n",
    "# adjust sigmas params\n",
    "adjust_sigmas_loss = fgnl.def_fgn_cross_ent_loss(lmbda_l2=0.0, lmbda_sigs=1e1*lmbda_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward_Classic_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Converting model\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Adjusting sigmas\n",
      "Epoch 0 Train set - Average loss: 2.3392, Accuracy: 34743/50000 (69%)\n",
      "Test set - Average loss: 0.9036, Accuracy: 7469/10000 (75%)\n",
      "Saving results\n",
      "2019-09-17 18:32:55.812514_[32, 32]_classic_1_trained_weights_full.pth\n",
      "/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00_train_models-run2/2019-09-17 18:32:55.812514_[32, 32]_converted_adjusted_FGN_1_trained_weights_full.pth\n",
      "Feedforward_Classic_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Converting model\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Adjusting sigmas\n",
      "Epoch 0 Train set - Average loss: 2.2199, Accuracy: 36084/50000 (72%)\n",
      "Test set - Average loss: 0.8239, Accuracy: 7648/10000 (76%)\n",
      "Saving results\n",
      "2019-09-17 16:42:14.934314_[32, 32]_classic_0_trained_weights_full.pth\n",
      "/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00_train_models-run2/2019-09-17 16:42:14.934314_[32, 32]_converted_adjusted_FGN_0_trained_weights_full.pth\n",
      "Feedforward_Classic_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Converting model\n",
      "Feedforward_FGN_net(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): FGN_layer()\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): FGN_layer()\n",
      "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (ib): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fl): FGN_layer()\n",
      ")\n",
      "Adjusting sigmas\n",
      "Epoch 0 Train set - Average loss: 2.3083, Accuracy: 34880/50000 (70%)\n",
      "Test set - Average loss: 0.9162, Accuracy: 7544/10000 (75%)\n",
      "Saving results\n",
      "2019-09-17 21:49:37.914325_[32, 32]_classic_2_trained_weights_full.pth\n",
      "/home/felix/Research/Adversarial Research/FGN---Research/Experiments/Exp-00_train_models-run2/2019-09-17 21:49:37.914325_[32, 32]_converted_adjusted_FGN_2_trained_weights_full.pth\n"
     ]
    }
   ],
   "source": [
    "# for each model in the run\n",
    "for classic_model_path in classic_models_list:\n",
    "    # load the classic model\n",
    "    classic_model = torch.load(run_dir+classic_model_path, map_location=device)\n",
    "    print(classic_model)\n",
    "\n",
    "    # build the hidden layer that will be used to create the FGN\n",
    "    hidden_layer_sizes = []\n",
    "    for h in classic_model.hidden_layers.modules():\n",
    "        if type(h) == torch.nn.modules.Linear:\n",
    "            hidden_layer_sizes.append(h.out_features)\n",
    "            \n",
    "    fgn_model = fgnl.Feedforward_FGN_net(in_feats=28*28, out_feats=10, hidden_layer_sizes=hidden_layer_sizes, drop_p=drop_p,\n",
    "                                     covar_type=covar_type, ordinal=ordinal, non_lin=non_lin, \n",
    "                                     noisy_centers=noisy_centers)     \n",
    "    fgn_model.to(device)\n",
    "\n",
    "    print(fgn_model)\n",
    "    \n",
    "    print(\"Converting model\")\n",
    "    # convert\n",
    "    fgnl.convert_classic_to_fgn(classic_model=classic_model, fgn_model=fgn_model)\n",
    "    print(fgn_model)\n",
    "    \n",
    "    \n",
    "    print(\"Adjusting sigmas\")\n",
    "    # adjust sigmas\n",
    "    adjust_sigmas_optimizer = torch.optim.RMSprop(zip(*filter(lambda p: p[1].requires_grad and \"inv_covar\" in p[0], \n",
    "                                                 fgn_model.named_parameters()))[1])\n",
    "    \n",
    "    converted_train_res = fgnh.train(fgn_model, mnist_train_loader, \n",
    "                             adjust_sigmas_loss, adjust_sigmas_optimizer, epochs=1, save_hist=2, verbose=True, \n",
    "                             pred_func=fgnh.cross_ent_pred_accuracy, test_loader=mnist_test_loader)\n",
    "    \n",
    "    print(\"Saving results\")\n",
    "    # name to save as\n",
    "    converted_model_path = classic_model_path.replace(\"classic\", \"converted_adjusted_FGN\")\n",
    "    print(classic_model_path)\n",
    "    print(run_dir+converted_model_path)\n",
    "    \n",
    "    fgn_model.eval() \n",
    "    \n",
    "    # save model entirely (only if non_lin == False, otherwise pickle fails)\n",
    "    if non_lin==False:\n",
    "        torch.save(obj=fgn_model, f=run_dir+converted_model_path)\n",
    "\n",
    "    # save model weights\n",
    "    torch.save(fgn_model.state_dict(), run_dir+converted_model_path.replace(\"_full\", \"_state_dict\"))\n",
    "\n",
    "    # save training histories as pickle\n",
    "    with open(run_dir+converted_model_path.replace(\"_full.pth\", \"_training_history.pckl\"),\"wb\") as pickle_file:\n",
    "            pickle.dump(converted_train_res,pickle_file)\n",
    "    \n",
    "    \n",
    "    # (old) save as text file \n",
    "#     with open(run_dir+converted_model_path.replace(\"_full.pth\", \"_training_history.txt\"), \"w\") as text_file:\n",
    "#         for key in converted_train_res.keys():\n",
    "#             text_file.write(\"{} {}\\n\".format(key, converted_train_res[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
