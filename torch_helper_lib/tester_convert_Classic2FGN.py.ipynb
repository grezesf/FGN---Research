{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for convert_Classic2FGN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_Classic2FGN import convert_Classic2FGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from Classic_MNIST_Net import Classic_MNIST_Net\n",
    "from Feedforward_FGN_net import Feedforward_FGN_net\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "# MNIST dataset and dataloader declaration\n",
    "# transforms does both the conversion from 0-255 to 0-1\n",
    "# and normalizes by the precomputed mean and std\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=True, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../MNIST-dataset', train=False, download=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])), \n",
    "        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedforward_FGN_net(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): FGN_layer()\n",
       "  )\n",
       "  (fl): FGN_layer()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create models to be converted\n",
    "classic_model = Classic_MNIST_Net(hidden_l_nums=[3])\n",
    "classic_model.to(device)\n",
    "fgn_model = Feedforward_FGN_net(28*28,10,[3])\n",
    "fgn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll loss function\n",
    "def classic_nll_loss_func(model, output, target):\n",
    "    return F.nll_loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nll loss function\n",
    "def fgn_nll_loss_func(model, output, target):\n",
    "#     # split output into pred and likelihoods\n",
    "#     output, likelihood = output\n",
    "    return F.nll_loss(output, target)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct pred function for classic net\n",
    "def classic_pred_func(output, target):\n",
    "    output = output\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct pred function for fgnet\n",
    "def fgn_pred_func(output, target):\n",
    "#     # split output into pred and likelihoods\n",
    "#     output,_ = output\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct = pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 2.4534, Accuracy: 934/10000 (9%)\n",
      "Test set - Average loss: 2.8420, Accuracy: 1566/10000 (16%)\n"
     ]
    }
   ],
   "source": [
    "# before conversion\n",
    "classic_test_res = test(classic_model, device, mnist_test_loader, loss_func=classic_nll_loss_func, verbose=True, pred_func=classic_pred_func)\n",
    "fgn_test_res = test(fgn_model, device, mnist_test_loader, loss_func=fgn_nll_loss_func, verbose=True, pred_func=fgn_pred_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden_layers.0.weights', tensor([[ -1.5012,   8.2789, -12.7157,  ..., -21.5142,  25.9261,  14.6363],\n",
      "        [ 18.1362,   4.7484,   6.4255,  ...,   9.8120,  -9.6075, -20.5830],\n",
      "        [-10.6995,   6.7656,  23.1998,  ...,  16.8342,   3.2759, -27.5183]],\n",
      "       device='cuda:0')), ('hidden_layers.0.centers', tensor([[-0.0018,  0.0069, -0.0070,  ...,  0.0048, -0.0038, -0.0072],\n",
      "        [-0.0043, -0.0086, -0.0025,  ...,  0.0092,  0.0004, -0.0005],\n",
      "        [-0.0015, -0.0070, -0.0058,  ..., -0.0045,  0.0083, -0.0098]],\n",
      "       device='cuda:0')), ('hidden_layers.0.sigs', tensor([787.4385, 785.4504, 787.0408], device='cuda:0')), ('fl.weights', tensor([[-0.5860,  0.9203,  1.4646],\n",
      "        [ 1.2175,  0.4945, -1.7297],\n",
      "        [-0.2195, -1.5886,  1.4347],\n",
      "        [-0.5539, -1.7309,  0.6285],\n",
      "        [-1.7040, -0.7200, -0.8957],\n",
      "        [-1.4470,  0.8972, -0.5374],\n",
      "        [ 0.6258,  0.8309,  0.1203],\n",
      "        [-0.9475,  1.6287,  0.3470],\n",
      "        [ 1.4616,  0.1671, -0.3667],\n",
      "        [-1.0566, -0.3018, -1.5171]], device='cuda:0')), ('fl.centers', tensor([[-3.2195e-04, -4.6820e-03,  1.2590e-03],\n",
      "        [ 2.5868e-05, -9.4025e-04,  6.2408e-03],\n",
      "        [ 5.6584e-03, -7.3934e-03,  8.7551e-03],\n",
      "        [-4.4368e-03, -6.2525e-03,  4.0158e-03],\n",
      "        [ 9.1978e-03, -7.3786e-03, -7.3006e-03],\n",
      "        [-4.8340e-03, -9.4678e-03,  5.5054e-03],\n",
      "        [ 5.9960e-03,  8.2300e-03,  5.1956e-03],\n",
      "        [ 9.0871e-03,  3.4161e-03, -6.5686e-03],\n",
      "        [-4.7622e-03,  4.3419e-03, -9.5545e-03],\n",
      "        [ 2.3417e-03, -3.9009e-03,  1.0641e-03]], device='cuda:0')), ('fl.sigs', tensor([2.9809, 2.9890, 2.9974, 3.0027, 2.9826, 3.0101, 3.0157, 3.0030, 3.0124,\n",
      "        3.0241], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# some fgnet dict values\n",
    "print(fgn_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CONVERT CALL\n",
    "convert_Classic2FGN(classic_model=classic_model, fgn_model=fgn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set - Average loss: 2.4534, Accuracy: 934/10000 (9%)\n",
      "Test set - Average loss: 2.4037, Accuracy: 931/10000 (9%)\n"
     ]
    }
   ],
   "source": [
    "# after conversion\n",
    "classic_test_res = test(classic_model, device, mnist_test_loader, loss_func=classic_nll_loss_func, verbose=True, pred_func=classic_pred_func)\n",
    "fgn_test_res = test(fgn_model, device, mnist_test_loader, loss_func=fgn_nll_loss_func, verbose=True, pred_func=fgn_pred_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden_layers.0.weights', tensor([[ 0.0257, -0.0090,  0.0183,  ..., -0.0214, -0.0161,  0.0165],\n",
      "        [ 0.0206,  0.0172,  0.0077,  ...,  0.0005, -0.0324,  0.0327],\n",
      "        [ 0.0147,  0.0283,  0.0036,  ...,  0.0063, -0.0146,  0.0045]],\n",
      "       device='cuda:0')), ('hidden_layers.0.centers', tensor([[ 2.2244e-03, -7.8300e-04,  1.5831e-03,  ..., -1.8543e-03,\n",
      "         -1.3937e-03,  1.4337e-03],\n",
      "        [-1.4506e-03, -1.2149e-03, -5.4580e-04,  ..., -3.5653e-05,\n",
      "          2.2848e-03, -2.3083e-03],\n",
      "        [ 1.3063e-03,  2.5231e-03,  3.2489e-04,  ...,  5.6051e-04,\n",
      "         -1.2986e-03,  3.9727e-04]], device='cuda:0')), ('hidden_layers.0.sigs', tensor([787.4385, 785.4504, 787.0408], device='cuda:0')), ('fl.weights', tensor([[ 0.4657,  0.4746,  0.2616],\n",
      "        [-0.2940, -0.4533,  0.4877],\n",
      "        [-0.5544, -0.5662, -0.0455],\n",
      "        [-0.5734,  0.2629, -0.0180],\n",
      "        [-0.5472, -0.3655,  0.0111],\n",
      "        [-0.4185, -0.3685,  0.5030],\n",
      "        [ 0.4346,  0.1642,  0.4301],\n",
      "        [-0.4817, -0.4999, -0.0843],\n",
      "        [-0.0315,  0.2716,  0.1158],\n",
      "        [-0.1402,  0.3337, -0.5246]], device='cuda:0')), ('fl.centers', tensor([[-0.2546, -0.2595, -0.1430],\n",
      "        [-0.2186, -0.3369,  0.3625],\n",
      "        [-0.3215, -0.3283, -0.0264],\n",
      "        [-0.4695,  0.2152, -0.0148],\n",
      "        [-0.5376, -0.3591,  0.0109],\n",
      "        [ 0.4083,  0.3596, -0.4908],\n",
      "        [ 0.2200,  0.0831,  0.2177],\n",
      "        [ 0.2498,  0.2593,  0.0437],\n",
      "        [-0.0262,  0.2259,  0.0963],\n",
      "        [ 0.1549, -0.3687,  0.5797]], device='cuda:0')), ('fl.sigs', tensor([2.9809, 2.9890, 2.9974, 3.0027, 2.9826, 3.0101, 3.0157, 3.0030, 3.0124,\n",
      "        3.0241], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# somce fgnet dict values (should have changed)\n",
    "print(fgn_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: results to be close to identical\n",
    "# and without needing to reload the fgn_net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
